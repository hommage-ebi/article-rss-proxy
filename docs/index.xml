<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Thu, 22 May 2025 03:17:41 +0000</lastBuildDate><item><title>other arxiv papers 2025-05-22</title><link>https://arxiv.org/2025-05-22</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15170v1"&gt;Bridging Two Dimensions: Luminescent Sensors at the Intersection of Temperature and Pressure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15292v1"&gt;Stabilization of Martensite and Austenite Phases and Realization of Two-way Martensitic Transition in Co-Ni-Ga Ferromagnetic Shape Memory Alloy Nanoparticles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15397v1"&gt;Observation of Body-Centered Cubic Iron above 200 Gigapascals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15486v1"&gt;Eu-doped CsSrCl$_3$ Large Nanocrystal Clusters with Self-Reduction Effect and Near-Unity Quantum Yield&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15666v1"&gt;Shubnikov-de Haas Oscillations in 2D $\text{PtSe}_2$: A fermiological Charge Carrier Investigation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15238v1"&gt;Rare-Earth Nitrides: Fundamental Advances and Applications in Cryogenic Electronics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15719v1"&gt;Linear scaling relation between two-dimensional massless Dirac fermion Fermi velocity and Fe-As bond length in iron arsenide superconductor systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15193v1"&gt;Influences of Uncertainties in Thermodynamic Models on Pareto-optimized Dividing Wall Columns for Ideal Mixtures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15678v1"&gt;Optimization of fipronil removal via electro-Fenton using a carbon cloth air-diffusion electrode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15713v1"&gt;Electro-Fenton treatment of benzophenone-4 solutions: A sustainable approach for its removal using an air-diffusion cathode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15777v1"&gt;Projection-Based Correction for Enhancing Deep Inverse Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15106v1"&gt;A coupled HDG discretization for the interaction between acoustic and elastic waves&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15146v1"&gt;lmgame-Bench: How Good are LLMs at Playing Games?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15274v1"&gt;Identification of Probabilities of Causation: A Complete Characterization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15693v1"&gt;Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15023v1"&gt;Towards a Science of Causal Interpretability in Deep Learning for Software Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15038v1"&gt;Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15039v1"&gt;LogiCase: Effective Test Case Generation from Logical Description in Competitive Programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15046v1"&gt;ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15049v1"&gt;Towards a Working Definition of Designing Generative User Interfaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15062v1"&gt;Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15083v1"&gt;Robust Multi-Modal Forecasting: Integrating Static and Dynamic Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15088v1"&gt;Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15091v1"&gt;ThinkRec: Thinking-based recommendation via LLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15095v1"&gt;Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15098v1"&gt;Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15105v1"&gt;Mechanistic evaluation of Transformers and state space models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15111v1"&gt;iPad: Iterative Proposal-centric End-to-End Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15123v1"&gt;Seeing the Trees for the Forest: Rethinking Weakly-Supervised Medical Visual Grounding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15134v1"&gt;The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15138v1"&gt;Global Convergence for Average Reward Constrained MDPs with Primal-Dual Actor Critic Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15173v1"&gt;AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15206v1"&gt;EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15242v1"&gt;Adaptive Plan-Execute Framework for Smart Contract Security Auditing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15245v1"&gt;Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15250v1"&gt;Margin-aware Fuzzy Rough Feature Selection: Bridging Uncertainty Characterization and Pattern Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15256v1"&gt;Zero-Shot Gaze-based Volumetric Medical Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15276v1"&gt;When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15293v1"&gt;LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15306v1"&gt;Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15308v1"&gt;BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15337v1"&gt;Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15345v1"&gt;Hadamax Encoding: Elevating Performance in Model-Free Atari&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15358v1"&gt;Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15386v1"&gt;RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15400v1"&gt;When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15410v1"&gt;ClickSight: Interpreting Student Clickstreams to Reveal Insights on Learning Strategies via LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15420v1"&gt;Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15427v1"&gt;Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15444v1"&gt;Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15447v1"&gt;ViaRL: Adaptive Temporal Grounding via Visual Iterated Amplification Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15467v1"&gt;Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15469v1"&gt;A Qualitative Investigation into LLM-Generated Multilingual Code Comments and Automatic Evaluation Metrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15475v1"&gt;LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15501v1"&gt;Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15504v1"&gt;Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15524v1"&gt;Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15547v1"&gt;Oversmoothing, "Oversquashing", Heterophily, Long-Range, and more: Demystifying Common Beliefs in Graph Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15554v1"&gt;DayDreamer at CQs-Gen 2025: Generating Critical Questions through Argument Scheme Completion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15572v1"&gt;Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15581v1"&gt;UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15596v1"&gt;Exploring LLM-Generated Feedback for Economics Essays: How Teaching Assistants Evaluate and Envision Its Use&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15607v1"&gt;From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15647v1"&gt;Second-Order Convergence in Private Stochastic Non-Convex Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15657v1"&gt;LCDB 1.1: A Database Illustrating Learning Curves Are More Ill-Behaved Than Previously Thought&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15671v1"&gt;Enhancing Monte Carlo Dropout Performance for Uncertainty Quantification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15674v1"&gt;UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15687v1"&gt;Discovering Pathology Rationale and Token Allocation for Efficient Multimodal Pathology Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15694v1"&gt;A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15703v1"&gt;HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15722v1"&gt;Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15742v1"&gt;Neuro-Argumentative Learning with Case-Based Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15746v1"&gt;Higher-order Structure Boosts Link Prediction on Temporal Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15747v1"&gt;Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15765v1"&gt;Constructing a 3D Town from a Single Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15778v1"&gt;Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15779v1"&gt;IA-T2I: Internet-Augmented Text-to-Image Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15790v1"&gt;Exploring the Innovation Opportunities for Pre-trained Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15801v1"&gt;VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15031v1"&gt;Are the confidence scores of reviewers consistent with the review content? Evidence from top conference proceedings in AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15033v1"&gt;Toward Task Capable Active Matter: Learning to Avoid Clogging in Confined Collectives via Collisions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15034v1"&gt;RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15036v1"&gt;Fault-Tolerant Multi-Robot Coordination with Limited Sensing within Confined Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15044v1"&gt;Learning-based Airflow Inertial Odometry for MAVs using Thermal Anemometers in a GPS and vision denied environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15058v1"&gt;AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15065v1"&gt;The Pursuit of Empathy: Evaluating Small Language Models for PTSD Dialogue Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15068v1"&gt;ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15074v1"&gt;DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15075v1"&gt;Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15077v1"&gt;Data Augmentation and Resolution Enhancement using GANs and Diffusion Models for Tree Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15080v1"&gt;SUS backprop: linear backpropagation algorithm for long inputs in transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15090v1"&gt;DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15108v1"&gt;A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15116v1"&gt;Graph Foundation Models: A Comprehensive Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15133v1"&gt;DeepKD: A Deeply Decoupled and Denoised Knowledge Distillation Trainer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15141v1"&gt;BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15154v1"&gt;Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15197v1"&gt;Intentional Gesture: Deliver Your Intentions with Gestures for Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15201v1"&gt;Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15216v1"&gt;BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15234v1"&gt;SAMA-UNet: Enhancing Medical Image Segmentation with Self-Adaptive Mamba-Like Attention and Causal-Resonance Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15239v1"&gt;Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15240v1"&gt;Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15265v1"&gt;Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15270v1"&gt;Scaling Diffusion Transformers Efficiently via $μ$P&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15275v1"&gt;Learning-based Autonomous Oversteer Control and Collision Avoidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15285v1"&gt;Reconsider the Template Mesh in Deep Learning-based Mesh Reconstruction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15303v1"&gt;Laplace Sample Information: Data Informativeness Through a Bayesian Lens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15311v1"&gt;Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15333v1"&gt;Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15344v1"&gt;Alpay Algebra: A Universal Structural Foundation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15367v1"&gt;Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15380v1"&gt;Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15406v1"&gt;Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15418v1"&gt;Guided Policy Optimization under Partial Observability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15429v1"&gt;Uncertainty Quantification in SVM prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15433v1"&gt;Set-LLM: A Permutation-Invariant LLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15441v1"&gt;Stronger ViTs With Octic Equivariance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15507v1"&gt;Directional Non-Commutative Monoidal Structures for Compositional Embeddings in Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15514v1"&gt;AM-PPO: (Advantage) Alpha-Modulation with Proximal Policy Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15516v1"&gt;Explainable embeddings with Distance Explainer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15517v1"&gt;Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15553v1"&gt;Social Bias in Popular Question-Answering Benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15558v1"&gt;Robo-DM: Data Management For Large Robot Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15559v1"&gt;Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15594v1"&gt;Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15612v1"&gt;Learn to Reason Efficiently with Adaptive Length-based Reward Shaping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15633v1"&gt;Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15644v1"&gt;FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15683v1"&gt;A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15734v1"&gt;DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15738v1"&gt;Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15753v1"&gt;Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15754v1"&gt;Improving planning and MBRL with temporally-extended actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15784v1"&gt;Large Language Models as Computable Approximations to Solomonoff Induction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15792v1"&gt;Long-Form Information Alignment Evaluation Beyond Atomic Facts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15810v1"&gt;GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15589v1"&gt;World Models as Reference Trajectories for Rapid Motor Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15808v1"&gt;Neural Conditional Transport Maps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15030v1"&gt;Harnessing Large Language Models Locally: Empirical Results and Implications for AI PC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15040v1"&gt;RLBenchNet: The Right Network for the Right Reinforcement Learning Task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15076v1"&gt;Agentic Feature Augmentation: Unifying Selection and Generation with Teaming, Planning, and Memories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15103v1"&gt;Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15130v1"&gt;Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15140v1"&gt;EC-LDA : Label Distribution Inference Attack against Federated Graph Learning with Embedding Compression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15143v1"&gt;Filtering Learning Histories Enhances In-Context Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15151v1"&gt;Time Tracker: Mixture-of-Experts-Enhanced Foundation Time Series Forecasting Model with Decoupled Training Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15152v1"&gt;Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15174v1"&gt;Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15177v1"&gt;SpectralGap: Graph-Level Out-of-Distribution Detection via Laplacian Eigenvalue Gaps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15178v1"&gt;A Unified Gradient-based Framework for Task-agnostic Continual Learning-Unlearning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15180v1"&gt;NeuBM: Mitigating Model Bias in Graph Neural Networks through Neutral Input Calibration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15231v1"&gt;Finding separatrices of dynamical flows with Deep Koopman Eigenfunctions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15246v1"&gt;Mitigating Spurious Correlations with Causal Logit Perturbation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15251v1"&gt;Loss-Guided Auxiliary Agents for Overcoming Mode Collapse in GFlowNets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15312v1"&gt;Sonnet: Spectral Operator Neural Network for Multivariable Time Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15329v1"&gt;Fourier-Invertible Neural Encoder (FINE) for Homogeneous Flows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15340v1"&gt;SSR: Speculative Parallel Scaling Reasoning in Test-time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15371v1"&gt;Distributionally Robust Federated Learning with Client Drift Minimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15391v1"&gt;InTreeger: An End-to-End Framework for Integer-Only Decision Tree Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15405v1"&gt;HOPSE: Scalable Higher-Order Positional and Structural Encoder for Combinatorial Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15511v1"&gt;NOMAD Projection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15544v1"&gt;A Temporal Difference Method for Stochastic Continuous Dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15548v1"&gt;Short-Range Dependency Effects on Transformer Instability and a Decomposed Attention Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15570v1"&gt;Refining Neural Activation Patterns for Layer-Level Concept Discovery in Neural Network-Based Receivers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15622v1"&gt;Benchmarking Energy and Latency in TinyML: A Novel Method for Resource-Constrained AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15631v1"&gt;Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15668v1"&gt;Graph Conditional Flow Matching for Relational Data Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15782v1"&gt;Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15798v1"&gt;Model Merging is Secretly Certifiable: Non-Vacuous Generalisation Bounds for Low-Shot Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15803v1"&gt;Adaptive Estimation and Learning under Temporal Distribution Shift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15811v1"&gt;On the creation of narrow AI: hierarchy and nonlocality of neural network skills&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15022v1"&gt;Infinite hierarchical contrastive clustering for personal digital envirotyping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15157v1"&gt;Cascaded Diffusion Models for Neural Motion Planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15203v1"&gt;EEG-Based Inter-Patient Epileptic Seizure Detection Combining Domain Adversarial Training with CNN-BiLSTM Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15212v1"&gt;Group Distributionally Robust Optimization with Flexible Sample Queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15213v1"&gt;KernelOracle: Predicting the Linux Scheduler's Next Move with Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15218v1"&gt;Recognition of Unseen Combined Motions via Convex Combination-based EMG Pattern Synthesis for Myoelectric Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15219v1"&gt;Versatile Reservoir Computing for Heterogeneous Complex Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15248v1"&gt;VET-DINO: Learning Anatomical Understanding Through Multi-View Distillation in Veterinary Imaging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15252v1"&gt;An Efficient Private GPT Never Autoregressively Decodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15259v1"&gt;ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15263v1"&gt;gen2seg: Generative Models Enable Generalizable Instance Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15284v1"&gt;Kernel PCA for Out-of-Distribution Detection: Non-Linear Kernel Selections and Approximations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15348v1"&gt;The Super Emotion Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15354v1"&gt;Human in the Loop Adaptive Optimization for Improved Time Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15381v1"&gt;Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15417v1"&gt;Robust Multimodal Learning via Entropy-Gated Contrastive Fusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15437v1"&gt;Adaptive Temperature Scaling with Conformal Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15488v1"&gt;Machine Learning Derived Blood Input for Dynamic PET Images of Rat Heart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15496v1"&gt;Fast Rate Bounds for Multi-Task and Meta-Learning with Different Sample Sizes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15503v1"&gt;Coloring Between the Lines: Personalization in the Null Space of Planning Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15506v1"&gt;Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15557v1"&gt;Modular Jump Gaussian Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15560v1"&gt;Impact of Data Sparsity on Machine Learning for Fault Detection in Power System Protection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15576v1"&gt;Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15579v1"&gt;Federated Learning with Unlabeled Clients: Personalization Can Happen in Low Dimensions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15623v1"&gt;Can LLMs $\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15624v1"&gt;Mechanistic Insights into Grokking from the Embedding Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15626v1"&gt;Aligning Explanations with Human Communication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15634v1"&gt;Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15641v1"&gt;A Simple Approximation Algorithm for Optimal Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15648v1"&gt;Learning Small Decision Trees with Few Outliers: A Parameterized Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15659v1"&gt;FLARE: Robot Learning with Implicit World Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15692v1"&gt;Thought-Augmented Policy Optimization: Bridging External Guidance and Internal Capabilities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15696v1"&gt;MaxPoolBERT: Enhancing BERT Classification via Layer- and Token-Wise Aggregation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15710v1"&gt;Advancing LLM Safe Alignment with Safety Representation Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15721v1"&gt;Privacy-Preserving Conformal Prediction Under Local Differential Privacy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15769v1"&gt;Transfer of Structural Knowledge from Synthetic Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15774v1"&gt;Beyond Hard and Soft: Hybrid Context Compression for Balancing Local and Global Information Retention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15788v1"&gt;Fair Supervised Learning Through Constraints on Smooth Nonconvex Unfairness-Measure Surrogates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15791v1"&gt;VARD: Efficient and Dense Fine-Tuning for Diffusion Models with Value-based RL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15793v1"&gt;HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15813v1"&gt;Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15064v1"&gt;Generalization Through Growth: Hidden Dynamics Controls Depth Dependence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15072v1"&gt;MoTime: A Dataset Suite for Multimodal Time Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15101v1"&gt;Cost-aware LLM-based Online Dataset Annotation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15120v1"&gt;Lung Nodule-SSM: Self-Supervised Lung Nodule Detection and Classification in Thoracic CT Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15175v1"&gt;A Linear Approach to Data Poisoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15195v1"&gt;Self-Boost via Optimal Retraining: An Analysis via Approximate Message Passing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15215v1"&gt;Clustering and Pruning in Causal Data Fusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15228v1"&gt;Degree-Optimized Cumulative Polynomial Kolmogorov-Arnold Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15244v1"&gt;Reliable Vertical Federated Learning in 5G Core Network Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15342v1"&gt;Policy Testing in Markov Decision Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15407v1"&gt;Efficient Differentiable Approximation of Generalized Low-rank Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15462v1"&gt;AI-based Decision Support System for Heritage Aircraft Corrosion Prevention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15497v1"&gt;Certified Neural Approximations of Nonlinear Dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15585v1"&gt;MIRB: Mathematical Information Retrieval Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15636v1"&gt;Distance Adaptive Beam Search for Provably Accurate Graph-Based Nearest Neighbor Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15638v1"&gt;Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15643v1"&gt;Optimal Best-Arm Identification under Fixed Confidence with Multiple Optima&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15661v1"&gt;Deep greedy unfolding: Sorting out argsorting in greedy sparse recovery algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15688v1"&gt;A packing lemma for VCN${}_k$-dimension and learning high-dimensional data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15701v1"&gt;HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15728v1"&gt;Are machine learning interpretations reliable? A stability study on global interpretations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15802v1"&gt;A Deep Learning Framework for Two-Dimensional, Multi-Frequency Propagation Factor Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15807v1"&gt;The Atlas of In-Context Learning: How Attention Heads Shape In-Context Retrieval Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15355v1"&gt;Decoding Phone Pairs from MEG Signals Across Speech Modalities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15423v1"&gt;SplitWise Regression: Stepwise Modeling with Adaptive Dummy Encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15602v1"&gt;Deep Learning for Continuous-time Stochastic Control with Jumps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15024v1"&gt;Diagnosing our datasets: How does my language model learn clinical information?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15045v1"&gt;Diffusion vs. Autoregressive Language Models: A Text Embedding Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15050v1"&gt;Improving the fact-checking performance of language models by relying on their entailment ability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15055v1"&gt;Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15063v1"&gt;UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15069v1"&gt;In-Domain African Languages Translation Using LLMs and Multi-armed Bandits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15071v1"&gt;Can Large Language Models Understand Internet Buzzwords Through User-Generated Content&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15087v1"&gt;HopWeaver: Synthesizing Authentic Multi-Hop Questions Across Text Corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15110v1"&gt;RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15196v1"&gt;EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15209v1"&gt;DUSK: Do Not Unlearn Shared Knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15214v1"&gt;R-TOFU: Unlearning in Large Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15255v1"&gt;MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15257v1"&gt;When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15261v1"&gt;AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15277v1"&gt;Web-Shepherd: Advancing PRMs for Reinforcing Web Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15291v1"&gt;Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15297v1"&gt;Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15299v1"&gt;Multi-Hop Question Generation via Dual-Perspective Keyword Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15316v1"&gt;Emotional Supporters often Use Multiple Strategies in a Single Turn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15323v1"&gt;Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15347v1"&gt;FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15353v1"&gt;Revealing Language Model Trajectories via Kullback-Leibler Divergence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15356v1"&gt;NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15372v1"&gt;X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15392v1"&gt;An Empirical Study of the Anchoring Effect in LLMs: Existence, Mechanism, and Potential Mitigations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15404v1"&gt;How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15422v1"&gt;Trends and Challenges in Authorship Analysis: A Review of ML, DL, and LLM Approaches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15424v1"&gt;Gated Integration of Low-Rank Adaptation for Continual Learning of Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15426v1"&gt;NeoN: A Tool for Automated Detection, Linguistic and LLM-Driven Analysis of Neologisms in Polish&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15428v1"&gt;Likelihood Variance as Text Importance for Resampling Texts to Map Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15431v1"&gt;Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15442v1"&gt;On the Generalization vs Fidelity Paradox in Knowledge Distillation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15456v1"&gt;Teaching Language Models to Evolve with Users: Dynamic Profile Modeling for Personalized Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15471v1"&gt;CoLA: Collaborative Low-Rank Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15472v1"&gt;PhysicsArena: The First Multimodal Physics Reasoning Benchmark Exploring Variable, Process, and Solution Dimensions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15480v1"&gt;KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15490v1"&gt;Collaborative Problem-Solving in an Optimization Game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15508v1"&gt;Multilingual Test-Time Scaling via Initial Thought Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15556v1"&gt;A Survey on Multilingual Mental Disorders Detection from Social Media Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15563v1"&gt;Semantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15656v1"&gt;Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15682v1"&gt;The Representational Alignment between Humans and Language Models is implicitly driven by a Concreteness Effect&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15684v1"&gt;ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15695v1"&gt;Can Large Language Models be Effective Online Opinion Miners?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15702v1"&gt;LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15712v1"&gt;TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15715v1"&gt;Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15727v1"&gt;VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15781v1"&gt;dKV-Cache: The Cache for Diffusion Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15795v1"&gt;Reverse Engineering Human Preferences with Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15805v1"&gt;Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15817v1"&gt;Learning to Reason via Mixture-of-Thought for Logical Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15070v1"&gt;An Alternative to FLOPS Regularization to Effectively Productionize SPLADE-Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15158v1"&gt;ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15210v1"&gt;Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15229v1"&gt;Multilingual Prompting for Improving LLM Generation Diversity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15249v1"&gt;Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15282v1"&gt;Exploring In-Image Machine Translation with Real-World Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15365v1"&gt;AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15443v1"&gt;AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15466v1"&gt;A Participatory Strategy for AI Ethics in Education and Rehabilitation grounded in the Capability Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15510v1"&gt;Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15561v1"&gt;Do RAG Systems Suffer From Positional Bias?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15700v1"&gt;"Alexa, can you forget me?" Machine Unlearning Benchmark in Spoken Language Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15773v1"&gt;ToxicTone: A Mandarin Audio Dataset Annotated for Toxicity and Toxic Utterance Tonality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15776v1"&gt;ConvSearch-R1: Enhancing Query Reformulation for Conversational Search with Reasoning via Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15298v1"&gt;AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15389v1"&gt;Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15489v1"&gt;Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15646v1"&gt;Word Level Timestamp Generation for Automatic Speech Recognition and Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15667v1"&gt;Segmentation-Variant Codebooks for Preservation of Paralinguistic and Prosodic Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15670v1"&gt;Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.15772v1"&gt;MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech Paralinguistic and Affect Labeling&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-05-22</guid><pubDate>Thu, 22 May 2025 12:14:54 +0900</pubDate></item><item><title>Evolutionary Computation and Large Language Models: A Survey of Methods, Synergies, and Applications</title><link>http://arxiv.org/abs/2505.15741v1</link><description>大規模言語モデル（LLM）と進化計算（EC）の統合は、強力な自然言語理解と最適化および探索能力を組み合わせることで、人工知能を進歩させる有望な道筋を示しています。本稿では、LLMとECの相乗効果の可能性を探求し、それらの交差点、補完的な強み、および新たな応用例をレビューします。ECがLLMのトレーニング、ファインチューニング、プロンプトエンジニアリング、およびアーキテクチャ探索を強化できる主要な機会を特定し、一方、LLMはECの設計、分析、および解釈の自動化を支援できます。本稿では、ECとLLMの相乗的な統合を探求し、人工知能の進歩に対する双方向の貢献を強調します。まず、プロンプトエンジニアリング、ハイパーパラメータチューニング、アーキテクチャ探索などの主要なコンポーネントを最適化することにより、EC技術がLLMをどのように強化するかを検証し、進化的手法がこれらのプロセスを自動化および洗練する方法を示します。次に、この調査では、LLMがメタヒューリスティック設計の自動化、進化アルゴリズムのチューニング、および適応型ヒューリスティクスの生成を通じてECをどのように改善し、それによって効率とスケーラビリティを向上させるかを調査します。新たな共進化フレームワークについて議論し、計算コスト、解釈可能性、アルゴリズムの収束などの課題を認識しながら、多様な分野にわたる応用例を紹介します。この調査は、未解決の研究課題を特定し、ECとLLMの強みを組み合わせたハイブリッドアプローチを提唱することで締めくくられます。

&lt;img src="https://arxiv.org/html/2505.15741v1/extracted/6463832/intro.png"/&gt;&lt;p&gt;Anupam Yadav, Bapi Dutta, Dikshit Chauhan, Indu Bala, Niki van Stein, Thomas Bäck&lt;/p&gt;&lt;p&gt;1 Department of Electrical and Computer Engineering, National University of Singapore, 119077
2 Department of Computer Science, Universidad de Jaén, Spain
3 School of Computer and Mathematical Sciences, University of Adelaide - 5005, Australia
4 Leiden Institute of Advanced Computer Science,
University Leiden,
Leiden, Netherlands
5 Department of Mathematics and Computing,
Dr. B. R. Ambedkar National Institute of Technology,
Jalandhar - 144011, INDIA&lt;/p&gt;</description><guid isPermaLink="false">2505.15741v1</guid><pubDate>Wed, 21 May 2025 16:48:28 +0000</pubDate></item><item><title>SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models</title><link>http://arxiv.org/abs/2505.15094v1</link><description>大規模言語モデル（LLM）は、文脈理解と推論において目覚ましい能力を示しています。しかし、既存のベンチマークは主に一般的な領域に焦点を当てており、科学データの複雑さを捉えきれていないため、多様な科学領域におけるLLMの性能評価は十分に探求されていません。このギャップを埋めるために、LLMの科学的文脈理解能力を評価するために調整された包括的なベンチマークデータセットであるSciCUEvalを構築しました。これは、生物学、化学、物理学、生物医学、材料科学に及ぶ10個のドメイン固有のサブデータセットで構成され、構造化されたテーブル、知識グラフ、非構造化テキストを含む多様なデータモダリティを統合しています。SciCUEvalは、関連情報の特定、情報欠如の検出、複数ソースからの情報統合、文脈を考慮した推論という4つの主要な能力を、さまざまな質問形式を通じて体系的に評価します。SciCUEval上で最先端のLLMの広範な評価を実施し、科学的文脈理解におけるLLMの強みと限界の詳細な分析を提供し、科学ドメインLLMの将来の開発に貴重な洞察を提供します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15094v1</guid><pubDate>Wed, 21 May 2025 04:33:26 +0000</pubDate></item><item><title>Steering Generative Models with Experimental Data for Protein Fitness Optimization</title><link>http://arxiv.org/abs/2505.15093v1</link><description>タンパク質適合性最適化とは、可能な配列の組み合わせ論的に巨大な設計空間において、望ましい定量的特性を最大化するタンパク質配列を見つけることである。タンパク質生成モデル（例：拡散モデル、言語モデル）を誘導する最近の発展は、有望なアプローチを提供する。しかし、概して、過去の研究では、代用報酬を最適化したり、誘導のために大量のラベル付きデータを利用したりしており、既存の方法が、適合性が低スループットのウェットラボアッセイで測定される現実世界の最適化キャンペーンで、どの程度うまく機能し、互いに比較できるかは不明確である。本研究では、少量の（数百の）ラベル付き配列-適合性ペアを用いた適合性最適化を検討し、タンパク質配列の異なる離散拡散モデルからの生成を誘導するための、分類器ガイダンスや事後分布サンプリングなどの戦略を包括的に評価する。また、ガイダンスをベイズ最適化におけるトンプソンサンプリングと同様の適応的配列選択に統合する方法を示し、プラグアンドプレイのガイダンス戦略が、タンパク質言語モデルを用いた強化学習などの代替手段と比較して利点を提供することを示す。

&lt;img src="https://arxiv.org/html/2505.15093v1/extracted/6461156/figures/background.png"/&gt;&lt;p&gt;Jason Yang Caltech &amp;Wenda Chu Caltech &amp;Daniel Khalil Caltech &amp;Raul Astudillo Caltech &amp;Bruce J. Wittmann Microsoft Corporation &amp;Frances H. Arnold Caltech &amp;Yisong Yue Caltech&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15093v1</guid><pubDate>Wed, 21 May 2025 04:30:48 +0000</pubDate></item><item><title>HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement</title><link>http://arxiv.org/abs/2505.15740v1</link><description>形式手法は、厳密な数学的証明を通じて、重要なシステムの信頼性を検証するために極めて重要です。しかし、その導入は、労力を要する手動証明と、定理証明器の使用に必要な専門知識によって妨げられています。大規模言語モデル（LLM）の最近の進歩は、自動定理証明のための新たな機会を提供します。有望なアプローチとして、戦術を段階的に生成する方法と、LLMを用いて証明全体を直接生成する方法の2つがあります。しかし、既存の研究では、これら2つのアプローチを組み合わせる試みはなされていません。本研究では、戦術ベースの生成と証明全体の合成を組み合わせ、両方のアプローチの利点を活用する、デュアルモデル証明合成フレームワークHybridProverを提案します。HybridProverは、評価のために証明全体の候補を直接生成し、それらの候補から証明のスケッチを抽出します。次に、自動化ツールを統合した戦術ベースの生成モデルを使用して、段階的な洗練を通じてスケッチを完成させます。Isabelle定理証明器のためにHybridProverを実装し、最適化されたIsabelleデータセットでLLMをファインチューンします。miniF2Fデータセットでの評価は、HybridProverの有効性を示しています。miniF2Fで59.4%の成功率を達成し、これは以前のSOTAである56.1%を上回ります。アブレーション研究の結果、このSOTAの結果は、証明全体の生成と戦術ベースの生成を組み合わせたことによるものであることが示されています。さらに、データセットの品質、トレーニングパラメータ、サンプリングの多様性が、LLMを用いた自動定理証明における最終結果にどのように影響するかを示します。私たちのコード、データセット、LLMはすべてオープンソースです。

&lt;img src="https://arxiv.org/html/2505.15740v1/extracted/6463789/framework2.png"/&gt;&lt;p&gt;China &amp;Jianyu Zhang College of Computer Science, China &amp;Talia Ringer Siebel Center for Computer Science University of Illinois at Urbana-Champaign Champaign, China Yongwang Zhao College of Computer Science, Jilin Hu College of Computer Science, Technology Zhejiang University Hangzhou, United States&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15740v1</guid><pubDate>Wed, 21 May 2025 16:45:43 +0000</pubDate></item><item><title>Neural Quantum Digital Twins for Optimizing Quantum Annealing</title><link>http://arxiv.org/abs/2505.15662v1</link><description>量子アニーラは、特定の組み合わせ最適化問題への取り組みにおいて可能性を示していますが、その性能はスケーラビリティとエラー率によって制限されることがよくあります。本研究では、量子アニーリングに関連する量子多体システムのエネルギー地形を再構築する、ニューラル量子デジタルツイン（NQDT）フレームワークを提案します。このデジタルツインは、基底状態と励起状態の両方のダイナミクスをモデル化し、断熱進化プロセスの詳細なシミュレーションを可能にします。既知の解析解を持つシステムでNQDTをベンチマークし、量子臨界性や相転移を含む主要な量子現象を正確に捉えることを実証します。このフレームワークを活用することで、励起に関連するエラーを最小限に抑える最適なアニーリングスケジュールを特定できます。これらの発見は、ニューラルネットワークベースのデジタルツインが、量子アニーラの性能を向上させるための診断および最適化ツールとして有用であることを強調しています。

&lt;img src="https://arxiv.org/html/2505.15662v1/extracted/6461345/nnqs_annealing.jpg"/&gt;&lt;p&gt;Hanqiu Peng, Jianlong Lu, Ying Chen&lt;/p&gt;&lt;p&gt;Department of Mathematics, Faculty of Science, National University of Singapore&lt;/p&gt;</description><guid isPermaLink="false">2505.15662v1</guid><pubDate>Wed, 21 May 2025 15:38:55 +0000</pubDate></item><item><title>ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection</title><link>http://arxiv.org/abs/2505.15182v1</link><description>LLMエージェントにおける最近の進歩は、複雑な環境で思考と行動を交互に行うReActのような推論バックボーンに大きく依存している。しかし、ReActはしばしば根拠のない、または一貫性のない推論ステップを生み出し、エージェントの実際の状態と目標との間にずれが生じる。我々の分析では、これはReActが一貫した内部信念と目標整合性を維持できないことに起因し、複合的なエラーとハルシネーションを引き起こしていることがわかった。これに対処するため、我々はReflActという新しいバックボーンを導入する。これは、推論を単に次の行動を計画するだけでなく、エージェントの状態を目標との関係で継続的に反映させるようにシフトさせる。決定を明示的に状態に基づいて行い、継続的な目標整合性を強制することで、ReflActは戦略的な信頼性を劇的に向上させる。この設計は、大幅な経験的利益をもたらす。ReflActは平均してReActを27.7%上回り、ALFWorldで93.3%の成功率を達成している。特に、ReflActは追加の強化モジュール（例：Reflexion、WKM）を備えたReActさえも凌駕しており、信頼性の高いエージェントパフォーマンスには、コアとなる推論バックボーンの強化が重要であることを示している。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15182v1</guid><pubDate>Wed, 21 May 2025 06:57:39 +0000</pubDate></item><item><title>R&amp;D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization</title><link>http://arxiv.org/abs/2505.15155v1</link><description>金融市場は、その高次元性、非定常性、そして持続的なボラティリティのために、資産収益率の予測において根本的な課題を突きつけています。大規模言語モデルやマルチエージェントシステムの進歩にもかかわらず、現在の定量的な研究パイプラインは、自動化の限界、解釈可能性の弱さ、そしてファクターマイニングやモデル革新といった主要な構成要素間の連携の分断に苦しんでいます。本論文では、定量戦略のフルスタックな研究開発を、協調的なファクターモデルの共同最適化を通じて自動化するために設計された、初のデータ中心型マルチエージェントフレームワークである、定量金融向けR&amp;Dエージェント、略してRD-Agent(Q)を提案します。RD-Agent(Q)は、定量プロセスを2つの反復的な段階に分解します。1つは、目標に沿ったプロンプトを動的に設定し、ドメインの事前知識に基づいて仮説を立て、それらを具体的なタスクにマッピングする研究段階、もう1つは、タスク固有のコードを実装するためにコード生成エージェントであるCo-STEERを使用し、それが実際の市場でのバックテストで実行される開発段階です。2つの段階は、実験結果を徹底的に評価し、その後の反復に情報を提供するフィードバック段階を通じて接続されており、適応的な方向選択のためのマルチアームバンディットスケジューラが用いられています。実証的に、RD-Agent(Q)は、古典的なファクターライブラリよりも最大2倍高い年間収益率を、70%少ないファクターで達成し、実際の市場において最先端の深層時系列モデルを上回ります。その共同ファクターモデル最適化は、予測精度と戦略のロバスト性の間に強力なバランスをもたらします。私たちのコードは、https://github.com/microsoft/RD-Agent で入手できます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15155v1</guid><pubDate>Wed, 21 May 2025 06:20:56 +0000</pubDate></item><item><title>An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents</title><link>http://arxiv.org/abs/2505.15117v1</link><description>強化学習（RL）は、現実世界の問題解決のために複雑な推論が可能な大規模言語モデル（LLM）の訓練において、強力な可能性を示してきました。近年では、RLは、推論と検索エンジンの使用を巧みに組み合わせた、洗練されたLLMベースの検索エージェントの作成に活用されています。検索エージェントの訓練にRLを使用することは有望ですが、そのようなエージェントの最適な設計はまだ完全には理解されていません。特に、（1）報酬の定式化、（2）基盤となるLLMの選択と特性、（3）RLプロセスにおける検索エンジンの役割といった重要な要素については、さらなる調査が必要です。本研究では、これらの要素を体系的に調査し、実用的な洞察を提供するために、包括的な実証研究を実施します。主な発見として、フォーマット報酬は最終的なパフォーマンスの向上に効果的ですが、中間的な検索報酬の効果は限定的であること、LLMの規模と初期化（汎用目的か推論特化か）がRLの結果に大きな影響を与えること、検索エンジンの選択がRLの訓練ダイナミクスと推論時の訓練済みエージェントのロバスト性を形成する上で重要な役割を果たすことを強調します。これらの知見は、現実世界のアプリケーションにおけるLLMベースの検索エージェントの構築と展開を成功させるための重要な指針となります。コードはhttps://github.com/PeterGriffinJin/Search-R1で入手可能です。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15117v1</guid><pubDate>Wed, 21 May 2025 05:09:43 +0000</pubDate></item><item><title>StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization</title><link>http://arxiv.org/abs/2505.15107v1</link><description>効率的なマルチホップ推論を行うには、大規模言語モデル（LLM）ベースのエージェントが、価値の高い外部知識を反復的に獲得する必要があります。従来の研究では、検索ベースの文書検索を実行するためにLLMを訓練する強化学習（RL）が検討され、QAパフォーマンスにおいて著しい改善が見られましたが、グローバルな信号のみからの疎な報酬に起因する複雑なマルチホップQAでは性能が劣ります。既存の研究におけるこのギャップに対処するため、ステップワイズ近接方策最適化法で訓練された検索LLMのためのフレームワークであるStepSearchを導入します。これは、より豊富で詳細な中間検索報酬と、各検索ステップをより良く導くための情報ゲインと冗長性ペナルティに基づくトークンレベルのプロセス監視で構成されています。一連のデータパイプラインメソッドを通じて、オープンソースデータセットに基づいて、サブ質問レベルの検索軌跡を含む詳細な質問応答データセットを構築しました。標準的なマルチホップQAベンチマークでは、グローバル報酬ベースラインを大幅に上回り、わずか19kのトレーニングデータを使用して、さまざまな検索とRLベースラインに対して3Bおよび7Bモデルでそれぞれ11.2％および4.2％の絶対的な改善を達成し、深層検索LLMの最適化における詳細なステップワイズ監視の有効性を示しています。実装は、https://github.com/zxh20001117/StepSearch で公開されています。

&lt;img src="https://arxiv.org/html/2505.15107v1/x1.png"/&gt;&lt;p&gt;Kang An, SenseTime Nanjing University Shenzhen University, Xuhui Zheng, Ziliang Wang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15107v1</guid><pubDate>Wed, 21 May 2025 05:01:31 +0000</pubDate></item><item><title>MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation</title><link>http://arxiv.org/abs/2505.15054v1</link><description>正確な分子の認識、編集、生成は、化学者と、さまざまな化学的課題に取り組むAIシステムの両方にとって不可欠な前提条件です。

我々は、言語プロンプトによる分子構造の認識、編集、生成という、基本的な分子-言語インターフェースのタスクを評価するために設計された包括的なベンチマークであるMolLangBenchを発表します。高品質で曖昧さのない、決定論的な出力を保証するために、認識タスクは自動化されたケモインフォマティクスツールを使用して構築し、編集および生成タスクは厳格な専門家によるアノテーションと検証を通じてキュレーションします。MolLangBenchは、線形文字列、分子画像、分子グラフなど、さまざまな分子表現と言語をインターフェースするモデルの評価をサポートします。最先端モデルの評価では、重大な限界が明らかになっています。最も強力なモデル（o3）でも、認識および編集タスクでそれぞれ79.2％と78.5％の精度しか達成していません。これらは人間にとっては直感的に簡単なタスクであり、生成タスクではさらに性能が悪く、わずか29.0％の精度しか達成していません。これらの結果は、現在のAIシステムが、予備的な分子認識および操作タスクでさえ、処理する上で欠点があることを浮き彫りにしています。MolLangBenchが、化学アプリケーション向けのより効果的で信頼性の高いAIシステムに向けたさらなる研究を促進することを願っています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15054v1</guid><pubDate>Wed, 21 May 2025 03:22:01 +0000</pubDate></item><item><title>PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration</title><link>http://arxiv.org/abs/2505.15047v1</link><description>大規模言語モデル（LLM）に基づくマルチエージェントシステム（MAS）は、科学的発見において目覚ましい可能性を示しています。しかし、既存のアプローチは、合理性の制約を欠いた事前定義されたワークフローを使用して科学的発見を自動化することが多く、これがしばしば目的のない仮説立てや、仮説と証拠の一貫した関連付けの失敗につながり、体系的な不確実性の低減を妨げています。これらの制限を克服するには、根本的に体系的な不確実性の低減が必要です。そこで、情報理論的フレームワークである\texttt{PiFlow}を導入し、自動化された科学的発見を、原理（例えば、科学法則）に導かれた構造化された不確実性低減問題として扱います。ナノマテリアル構造、生体分子、および標的特性を持つ超伝導体候補の発見という、3つの異なる科学分野にわたる評価において、我々の手法は発見効率を大幅に向上させ、探索ステップに対する特性値の曲線下面積（AUC）が73.55％増加し、バニラエージェントシステムと比較してソリューションの品質が94.06％向上しました。全体として、\texttt{PiFlow}はプラグアンドプレイ方式として機能し、非常に効率的な自動化された科学的発見における新たなパラダイムシフトを確立し、より堅牢で加速されたAI主導の研究への道を開きます。コードは、\href{https://github.com/amair-lab/PiFlow}{GitHub}で公開されています。

&lt;img src="https://arxiv.org/html/2505.15047v1/x1.png"/&gt;&lt;p&gt;Yingming Pu Tao Lin Hongyu Chen Westlake University Zhejiang University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15047v1</guid><pubDate>Wed, 21 May 2025 03:09:39 +0000</pubDate></item><item><title>Analysis and Simulation of Generalized Langevin Equations with Non-Gaussian Orthogonal Forces</title><link>http://arxiv.org/abs/2505.15665v1</link><description>一般化ランジュバン方程式（GLE）は、多体系のダイナミクスを低次元の反応座標で分析およびモデル化するための有用な枠組みであり、その具体的な形式は射影形式の選択によって決定されます。ブタンの二面角ダイナミクスの分子動力学シミュレーションを用いて、異なるGLE定式化から導出されたパラメータを比較します。我々の分析により、異なるGLEにおける直交力の非ガウス的寄与が明らかになり、特にすべての非線形性が直交力に委ねられるMori-GLEで最も顕著になります。二面角の平均初回通過時間を正確に予測するために重要な、非ガウス的な直交力を正しく考慮するシミュレーション技術を確立します。GLEシミュレーションの精度は、選択されたGLE形式に大きく依存することを見出しました。Mori-GLEは、正しい非ガウス的な直交力分布が使用される限り、二面角ダイナミクスの統計的観測量を捉えるための最も数値的にロバストな枠組みを提供します。

&lt;img src="https://arxiv.org/html/2505.15665v1/x1.png"/&gt;&lt;p&gt;Benjamin A. Dalton, Benjamin J. A. Héry, Cihan Ayaz, Henrik Kiefer, Lucas Tepper, Roland R. Netz&lt;/p&gt;&lt;p&gt;Department of Physics, Freie Universität Berlin, Arnimallee 14, 14195 Berlin, Germany.&lt;/p&gt;</description><guid isPermaLink="false">2505.15665v1</guid><pubDate>Wed, 21 May 2025 15:41:07 +0000</pubDate></item><item><title>Tailoring the Electronic Configurations of YPc$_2$ on Cu(111): Decoupling Strategies for Molecular Spin Qubits Platforms</title><link>http://arxiv.org/abs/2505.15539v1</link><description>分子スピン量子ビットの候補の中で、イットリウムフタロシアニン二重層(YPc$_2$)は、分子構造を安定化させる反磁性の金属イオンコアを特徴とし、その磁気特性は主にフタロシアニン(Pc)配位子上に非局在化した不対電子(S = 1/2)に由来する。金属電極近傍でのその特性を理解することは、分子スピン量子ビットアーキテクチャにおける潜在的な利用を評価する上で重要である。本研究では、走査型トンネル顕微鏡を用いて、金属Cu(111)表面に吸着したこの分子の形態と電子構造を調べた。その表面上では、YPc$_2$は平らに吸着し、孤立した分子は(111)結晶軸に沿った優先的な配向を示す。Cu(111)上に分子パッチを成長させる際に、2種類の異なる自己組織化分子パッキングを観察した。Cu(111)と直接接触しているYPc$_2$の場合、走査型トンネル分光法により、広く分離した最高被占分子軌道(HOMO)と最低空分子軌道(LUMO)が明らかになり、不対スピンの消滅が示唆された。逆に、YPc$_2$が数層の厚さの反磁性ZnPc層によって基板から分離されている場合、HOMOが単占分子軌道(SOMO)と単空分子軌道(SUMO)に分裂することを見出した。YPc$_2$における2つの分子間の混合とスピン消滅を避けるためには、2層以上のZnPcが必要であることがわかった。密度汎関数理論により、スピン消滅はYPc$_2$とCu(111)状態間の混成によるものであることが明らかになり、不対分子スピンを維持するために適切なデカップリング層を使用することの重要性が確認された。我々の結果は、安定かつ効果的な分子スピン量子ビットプラットフォームとしてのYPc$_2$/ZnPcヘテロ構造の可能性を示唆し、この分子スピン量子ビット候補を将来の量子論理デバイスに統合する可能性を検証するものである。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15539v1</guid><pubDate>Wed, 21 May 2025 14:00:29 +0000</pubDate></item><item><title>Energy transfer between localized emitters in photonic cavities from first principles</title><link>http://arxiv.org/abs/2505.15752v1</link><description>欠陥間の放射および非放射共鳴結合は、古典および量子情報技術アプリケーションで使用されるフォトニックデバイスにおいて遍在する現象です。本研究では、双極子-双極子近似を超えて、電子状態の多体性を含め、フォトニックキャビティ内の欠陥間のエネルギー移動を定量的に予測するための第一原理アプローチを提示します。例として、球状キャビティ内のMgO中のF中心への双極子様エミッタからのエネルギー移動について議論します。キャビティを使用して、特定のスピンスリップおよびスピン保存遷移を制御可能に強化または抑制できることを示します。具体的には、Q〜400という比較的穏やかなキャビティによって、MgO中のF中心の場合、非放射共鳴エネルギー移動速度が約10〜100倍向上し、電子励起とキャビティモードの間に大きなエネルギーミスマッチを組み込むことで、速度を同程度に抑制できると予測しています。私たちのフレームワークは一般的であり、局在エミッタがマイクロ球、コアシェルナノ粒子、および誘電体ミー共振器に埋め込まれている幅広いデバイスに容易に適用できます。したがって、私たちのアプローチは、量子メモリおよび超高密度光メモリ、そしてさまざまな量子情報プラットフォームにおけるエネルギー移動を制御する方法を予測するための道を開きます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15752v1</guid><pubDate>Wed, 21 May 2025 16:57:55 +0000</pubDate></item><item><title>First-principles calculations of transport coefficients in Weyl semimetal TaAs</title><link>http://arxiv.org/abs/2505.15522v1</link><description>トポロジカルワイル半金属TaAsにおける電荷および熱輸送を第一原理計算によって研究する。密度汎関数摂動理論を用いて電子-フォノン結合行列要素を計算し、電気伝導度、ゼーベック係数、電子熱伝導度、ペルチェ係数を含む熱電輸送係数を導出する。自己エネルギーおよび運動量緩和時間近似をボルツマン輸送方程式の反復解法と比較し、化学ポテンシャルが正確に扱われる限り、TaAsに対して同様の結果が得られることを確認する。反復法では、熱勾配と電位勾配の両方下での輸送を完全に解くために必要な追加の方程式を導出する。興味深いことに、$S$と$\Pi$の間のオンサーガーの相反性はもはや課されず、時間反転対称性を破る系、特に磁性材料を扱うことができる。TaAsに関する利用可能な実験データと我々の結果を比較する。$\sigma_{xx}$については一致度が非常に高いが、$\sigma_{zz}$は過大評価されており、これは実験的なキャリア濃度の違いによるものと考えられる。ゼーベック係数は理論と実験で同程度の大きさであり、その低温挙動もドーピングレベルに強く依存することがわかった。

&lt;img src="https://arxiv.org/html/2505.15522v1/x2.png"/&gt;&lt;p&gt;Guillaume E. Allemand, Matteo Giantomassi, Matthieu J. Verstraete&lt;/p&gt;&lt;p&gt;European Theoretical Spectroscopic Facility (ETSF)
ITP, Physics Department, Utrecht University 3508 TA Utrecht, The Netherlands
Institute of Condensed Matter and Nanosciences,
Université Catholique de Louvain, Louvain-la-Neuve, Belgium
Nanomat group, Q-MAT, University of Liège, and European Theoretical Spectroscopy Facility&lt;/p&gt;</description><guid isPermaLink="false">2505.15522v1</guid><pubDate>Wed, 21 May 2025 13:47:54 +0000</pubDate></item><item><title>Lithium Intercalation in the Anisotropic van der Waals Magnetic Semiconductor CrSBr</title><link>http://arxiv.org/abs/2505.15663v1</link><description>アルカリ金属のインターカレーションは、ファンデルワールス物質をドーピングするための重要な戦略である。特にリチウムは、電気的、光学的、磁気的な物質の基本的な特性が強く変化し始めるレベルに達する、非常に高い電荷キャリア密度を実現することが示されている。リチウムは揮発性が高いことが知られているが、異方性層状結晶におけるその移動ダイナミクスは十分に理解されていない。本研究では、異方性磁性半導体CrSBrの層間にリチウムをインターカレーションすることを調査する。剥離した結晶を用いて、光学的および電気的特性評価法により、インターカレーションプロセスのダイナミクスをリアルタイムでモニタリングできる。我々の測定により、リチウムの高度に異方的な移動が明らかになり、拡散係数はa軸方向とb軸方向で1桁以上異なる。この結果は、リチウム原子の軌跡が主にa軸方向のBr鎖に沿うことを示す分子動力学シミュレーションとよく一致する。さらに、CrSBr結晶を薄い六方晶窒化ホウ素（hBN）フレークで部分的に覆うことがインターカレーションプロセスに大きな影響を与え、リチウムがa軸方向の電気伝導率を大幅に向上させることを発見した。我々の手法は、リチウム拡散研究のための新しいプラットフォームを提供し、リチウムドープデバイスの製造を追求するためのさらなる研究を促進する。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15663v1</guid><pubDate>Wed, 21 May 2025 15:39:35 +0000</pubDate></item><item><title>Triplet Excitons Reconcile Charge Generation and Recombination in Low-Offset Organic Solar Cells: Efficiency Limits from a 5-State Model</title><link>http://arxiv.org/abs/2505.15603v1</link><description>有機太陽電池の電力変換効率は最近、20%を超えて向上している。これらのデバイスの活性層は、少なくとも2つの有機半導体で構成され、タイプIIヘテロ接合を形成する。これにより、デバイスの性能は、局在励起子、電荷移動状態、電荷分離状態を含む様々な種の速度論的な相互作用によって決定される。しかし、関連するすべての光起電力測定を記述するモデルはまだ開発されていない。本稿では、一重項および三重項電荷移動状態の両方を含み、局所三重項状態の形成、再分裂、および崩壊を、それぞれのエネルギーオフセットをパラメータとして考慮した、包括的な5状態速度モデルを提示する。このモデルが、電荷生成効率、フォトルミネッセンス、エレクトロルミネッセンス、ランジュバン減少因子などの主要なデバイス特性を同時に記述するだけでなく、D:A界面エネルギーオフセットのみに基づいて、これらの特性が材料の組み合わせによってどのように変化するかを解明することを示す。エレクトロルミネッセンスとランジュバン減少因子は三重項特性に強く依存し、三重項崩壊が中程度のオフセットを持つシステムにおいて支配的な電荷再結合経路になることを発見した。これは、以前の実験結果と完全に一致する。文献データとの検証により、デバイス効率を正確に予測するモデルの能力が実証される。続いて、一重項励起子から電荷移動状態へのエネルギーオフセットが約150meVの材料の組み合わせが特に有望であることを特定する。我々のモデルはさらに、光子および電荷キャリアの収集を改善するためのさらなる手段が講じられない場合、バイナリーブレンドの最近の認証済み効率記録が約20%にとどまる理由を説明する。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15603v1</guid><pubDate>Wed, 21 May 2025 14:58:40 +0000</pubDate></item><item><title>Exciton Bohr radius of lead halide perovskites for photovoltaic and light-emitting applications</title><link>http://arxiv.org/abs/2505.15565v1</link><description>金属ハロゲン化物ペロブスカイトのエキシトンボーア半径 (a_B) とエキシトン結合エネルギー (E_b) は、発光ダイオードディスプレイと太陽光発電デバイスの両方への応用において、2つの重要な量です。我々は、バルクバンドギャップを超える正味のエキシトンエネルギーに基づいて、a_B と {\epsilon}_r^c (誘電率) を同時に見つける信頼性の高い理論的手法を開発します。誘電体閉じ込め下での a_B は、誘電体閉じ込めがない場合よりも大幅に小さいと推定されます。CH3NH3PbBr3 の場合、4.36 nm 対 5.61 nm です。我々は、a_B の増強を {\epsilon}_r^c の変動と電子-正孔相関エネルギーに起因すると考えています。また、同じ正味のエキシトンエネルギーに基づいて E_b を見つける簡単な方法も開発します。これを用いて、有機臭化物ペロブスカイトとヨウ化物ペロブスカイトの間の E_b のよく知られた違いを {\epsilon}_r^c に起因させ、ヨウ化物ペロブスカイトが、効率的な電荷キャリア輸送のために小さい E_b を必要とする太陽光発電用途において、臭化物ペロブスカイトよりも適していることを説明します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15565v1</guid><pubDate>Wed, 21 May 2025 14:19:39 +0000</pubDate></item><item><title>Exciton-defect interaction and optical properties from a first-principles T-matrix approach</title><link>http://arxiv.org/abs/2505.15523v1</link><description>励起子と欠陥の相互作用を理解することは、多くの材料における光電子および量子情報応用の最適化に不可欠です。しかし、欠陥を持つ材料特性の第一原理シミュレーションは、しばしば高い欠陥密度に限定されます。本研究では、第一原理T行列法を用いて、単層MoS2における励起子と欠陥の相互作用が光吸収およびフォトルミネッセンススペクトルに及ぼす影響を調べます。励起子-欠陥束縛状態が、T行列近似を用いた無秩序平均化されたグリーン関数によって捉えられることを示し、さらにそれらの光学特性を分析します。我々のアプローチは、実験とよく一致するフォトルミネッセンススペクトルをもたらし、第一原理からの無秩序な2D材料の光学特性をシミュレートするための、計算効率の高い新しいフレームワークを提供します。

&lt;img src="https://arxiv.org/html/2505.15523v1/x1.png"/&gt;&lt;p&gt;Diana Y. Qiu, Felipe H. da Jornada, Jonah B. Haber, Mit H. Naik, Yang-hao Chan&lt;/p&gt;&lt;p&gt;Department of Materials Science and Engineering, Stanford University, Stanford, CA 94305, USA
Department of Materials Science, Yale University, New Haven, CT 06520
Department of Physics, University of Texas at Austin, Austin, TX, 78712, USA
Institute of Atomic and Molecular Sciences, Academia Sinica, Taipei 10617, Taiwan&lt;/p&gt;</description><guid isPermaLink="false">2505.15523v1</guid><pubDate>Wed, 21 May 2025 13:49:03 +0000</pubDate></item><item><title>Chemical design of monolayer altermagnets</title><link>http://arxiv.org/abs/2505.15484v1</link><description>オルターマグネットにおける異なる磁性サブ格子を結びつける固有の結晶対称性から生じる結晶対称性ペアスピン運動量ロッキング（CSML）は、非従来型のピエゾ磁性や非共線スピン流など、多くのエキゾチックなスピントロニクス特性を可能にする。しかし、単層オルターマグネットの不足は、次元的に閉じ込められた現象やナノ構造デバイスの応用に関するさらなる探求を制限している。本研究では、層状オルターマグネットV$_2$(Se,Te)$_2$Oのサブ格子対称性から着想を得て、対称性を保持する構造修飾と原子価適応化学置換を通じて、一般的な化学設計原理を提案する。合計で、M$_2$A$_2$B$_{1,0}$とそのヤヌス誘導体という4つの構造フレームワークにわたって2600個の候補を構築する。ハイスループット計算により、N\'eel秩序基底状態を持つ670個の潜在的なオルターマグネットが特定され、そのうち91個はスピン偏極超高速輸送を可能にするCSMLディラックコーンを示す。これらの材料はまた、異なる基底状態磁気秩序を持ち、半導体、金属、ハーフメタル、ディラック半金属に至るまで、多様な電子挙動を示す。本研究は、豊富な単層オルターマグネットを明らかにするだけでなく、その設計のための合理的な原理を確立し、原子的に薄いシステムにおける閉じ込められた磁性とスピントロニクスの探求への扉を開く。

&lt;img src="https://arxiv.org/html/2505.15484v1/extracted/6461596/figures/fig1_v7.jpg"/&gt;&lt;p&gt;Junwei Liu, Runzhang Xu, Yifan Gao&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15484v1</guid><pubDate>Wed, 21 May 2025 13:01:45 +0000</pubDate></item><item><title>Bonding relay for room-temperature oxide plasticity like metals</title><link>http://arxiv.org/abs/2505.15266v1</link><description>酸化物は、その強い指向性のあるイオン結合または共有結合のために、本質的に脆いと考えられてきた。これは、非局在化した電子共有が容易な転位すべりによる塑性を可能にする金属の延性挙動とは対照的である。本研究では、SrTiO3やMgOのような典型的な酸化物が、顕著な結晶学的異方性を持つ室温塑性を示すことを実証することで、このパラダイムに挑戦する。第一原理計算、大規模分子動力学シミュレーション、実験的なナノインデンテーションを組み合わせた統合的なアプローチを通じて、室温での酸化物塑性を可能にする普遍的な構造的基準を特定した。それは、ペロブスカイトおよび岩塩型酸化物における(1-10)[110]方位に特有な、特定のすべり方向に沿った正と負に帯電した原子層の交互配置の存在である。この電荷交互配置は、結合リレー機構を可能にする。この機構では、すべり面に沿った連続的な結合の切断と再形成が、層間の持続的な結合を伴いながら、金属における多中心相互作用を模倣し、それによって壊滅的な破壊なしに転位運動を促進する。本研究の発見は、酸化物において金属のような塑性を実現するための、これまで認識されていなかった経路を明らかにし、柔軟で機械的に回復力のある酸化物材料を設計するための構造設計原理を確立する。

&lt;img src="https://arxiv.org/html/2505.15266v1/extracted/6461877/Fig1.png"/&gt;&lt;p&gt;Shi Liu, Xiangkai Chen, Xiaofei Zhu, Yuhong Li, Yun-Long Tang&lt;/p&gt;&lt;p&gt;Department of Physics, School of Science, Westlake University, Hangzhou 310030, China
Institute of Natural Sciences, Westlake Institute for Advanced Study, Hangzhou 310024, China
School of Materials Science and Engineering, University of Science and Technology of China, Shenyang 110016, China
Shenyang National Laboratory for Materials Science, Institute of Metal Research, Chinese Academy of Sciences, Shenyang 110016, China&lt;/p&gt;</description><guid isPermaLink="false">2505.15266v1</guid><pubDate>Wed, 21 May 2025 08:46:02 +0000</pubDate></item><item><title>Multicrossmodal Automated Agent for Integrating Diverse Materials Science Data</title><link>http://arxiv.org/abs/2505.15132v1</link><description>高解像度顕微鏡画像や動的シミュレーション動画から、表形式の実験ログや広範な文献アーカイブまで、材料科学データの量と多様性が増大していることに動機づけられ、マルチクロスモーダルLLMエージェントフレームワークを導入します。近年のAIの取り組みは、物性予測や画像分類といった個々のタスクを加速させていますが、通常は各モダリティを個別に扱い、豊富なクロスモーダル相関関係が未開拓のまま残り、研究者は手間のかかる手動統合を余儀なくされています。さらに、既存のマルチモーダル基盤モデルは、ドメインデータでの高価な再トレーニングやファインチューニングを必要とすることが多く、材料情報学における現在のマルチエージェントシステムは、狭いサブタスクのみに対処しています。これらの障害を克服するために、専門化されたLLMエージェントの協調チームを設計し、各エージェントはドメインに適応したプロンプトと、出力を共有埋め込み空間に投影するプラグインを備えています。次に、動的なゲーティングメカニズムがこれらの洞察に重み付けして統合し、基盤となるLLMの重みを変更することなく、異種入力に対する統一された推論を可能にします。困難なケーススタディで我々のアプローチを検証し、単一モダリティおよびゼロショットベースラインと比較して、検索精度（85％）、キャプションの忠実度、および統合されたカバレッジ（35％）において大幅な改善を示します。我々の研究は、データサイロを橋渡しし、材料発見サイクルを加速できるAIデジタル研究者への道を開きます。コードはhttps://github.com/adibgpt/Multicrossmodal-Autonomous-Materials-Science-Agentで入手できます。

&lt;img src="https://arxiv.org/html/2505.15132v1/extracted/6461020/Picture8.png"/&gt;&lt;p&gt;Adib Bazgir University of Missouri-Columbia Columbia, MO 65211, NY 10012, Rama chandra Praneeth Madugula New York University New York, USA, Yuwen Zhang University of Missouri-Columbia Columbia&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.15132v1</guid><pubDate>Wed, 21 May 2025 05:37:03 +0000</pubDate></item></channel></rss>