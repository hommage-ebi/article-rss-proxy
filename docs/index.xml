<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Fri, 16 May 2025 03:17:20 +0000</lastBuildDate><item><title>other arxiv papers 2025-05-16</title><link>https://arxiv.org/2025-05-16</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10029v1"&gt;Enhanced coercive force of nanoparticles of special morphology in the Stoner-Wohlfarth model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10563v1"&gt;Low-temperature structural instabilities of the halide double perovskite Cs$_2$AgBiBr$_6$ investigated via x-ray diffraction and infrared phonons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09958v1"&gt;Ultrafast excitation of polar skyrons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10041v1"&gt;QR$^2$-code: An open-source program for double resonance Raman spectra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10204v1"&gt;Dynamics of reactive oxygen species produced by the COST microplasma jet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10227v1"&gt;Giant spin-to-charge conversion in germanium tin epilayers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10269v1"&gt;Metal oxide decoration on Si-FETs for selective gas sensing at room temperature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10363v1"&gt;Deciphering the role of LiBr as redox mediator in Li-O2 Aprotic Batteries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10166v1"&gt;Cavity-Mediated Electron-Electron Interactions: Renormalizing Dirac States in Graphene&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10531v1"&gt;Magnon Nesting in Driven Two-Dimensional Quantum Magnets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10516v1"&gt;Shift of nanodroplet and nanocluster size distributions induced by dopant pick-up statistics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10523v1"&gt;Magnetic deflection of high-spin sodium dimers formed on helium nanodroplets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10211v1"&gt;PyLIT: Reformulation and implementation of the analytic continuation problem using kernel representation methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10299v1"&gt;Nature-inspired optimization, the Philippine Eagle, and cosmological parameter estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10450v1"&gt;Genetic algorithm demystified for cosmological parameter estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10511v1"&gt;Learning Nonlinear Dynamics in Physical Modelling Synthesis using Neural Ordinary Differential Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09923v1"&gt;"There Is No Such Thing as a Dumb Question," But There Are Good Ones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09970v1"&gt;Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10034v1"&gt;The First MPDD Challenge: Multimodal Personality-aware Depression Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10188v1"&gt;A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10278v1"&gt;MASS: Multi-Agent Simulation Scaling for Portfolio Construction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09925v1"&gt;Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09926v1"&gt;AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09952v1"&gt;Task-Core Memory Management and Consolidation for Long-term Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09955v1"&gt;TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09969v1"&gt;A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09974v1"&gt;Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10016v1"&gt;Application of YOLOv8 in monocular downward multiple Car Target detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10027v1"&gt;ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10043v1"&gt;Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10050v1"&gt;Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10055v1"&gt;PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10073v1"&gt;Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10074v1"&gt;Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10105v1"&gt;EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10128v1"&gt;Robust Federated Learning on Edge Devices with Domain Heterogeneity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10172v1"&gt;Does Scaling Law Apply in Time Series Forecasting?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10183v1"&gt;KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10185v1"&gt;The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10197v1"&gt;Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10201v1"&gt;A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10212v1"&gt;Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10260v1"&gt;Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10261v1"&gt;The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10300v1"&gt;AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10315v1"&gt;Private Transformer Inference in MLaaS: A Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10321v1"&gt;AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10330v1"&gt;Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10331v1"&gt;Emergence of Structure in Ensembles of Random Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10347v1"&gt;Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10361v1"&gt;Plasticity as the Mirror of Empowerment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10392v1"&gt;Schreier-Coset Graph Propagation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10399v1"&gt;Evaluating Model Explanations without Ground Truth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10420v1"&gt;Learned Lightweight Smartphone ISP with Unpaired Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10442v1"&gt;IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10443v1"&gt;Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10453v1"&gt;Vision language models have difficulty recognizing virtual objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10482v1"&gt;Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10483v1"&gt;UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10515v1"&gt;PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10537v1"&gt;LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10543v1"&gt;Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10547v1"&gt;Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10551v1"&gt;Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09901v1"&gt;Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09907v1"&gt;Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09920v1"&gt;Offline Reinforcement Learning for Microgrid Voltage Regulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09932v1"&gt;Demystifying AI Agents: The Final Generation of Intelligence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09935v1"&gt;VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09945v1"&gt;Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09989v1"&gt;AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10037v1"&gt;Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10066v1"&gt;Dark LLMs: The Growing Threat of Unaligned AI Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10134v1"&gt;Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10167v1"&gt;QuXAI: Explainers for Hybrid Quantum Machine Learning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10169v1"&gt;Modeling Saliency Dataset Bias&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10191v1"&gt;LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10231v1"&gt;On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10264v1"&gt;Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10273v1"&gt;AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10297v1"&gt;Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10309v1"&gt;Empirically evaluating commonsense intelligence in large language models with large-scale human judgments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10320v1"&gt;J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10328v1"&gt;A Comparative Study of SMT and MILP for the Nurse Rostering Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10352v1"&gt;SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10360v1"&gt;FactsR: A Safer Method for Producing High Quality Healthcare Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10371v1"&gt;ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10375v1"&gt;Are Sparse Autoencoders Useful for Java Function Bug Detection?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10387v1"&gt;Multi-Agent Path Finding For Large Agents Is Intractable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10394v1"&gt;Inconsistency Handling in DatalogMTL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10405v1"&gt;Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10441v1"&gt;PIF: Anomaly detection via preference embedding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10457v1"&gt;SEAL: Searching Expandable Architectures for Incremental Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10522v1"&gt;Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10101v1"&gt;LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09922v1"&gt;Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09959v1"&gt;Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09983v1"&gt;Sybil-based Virtual Data Poisoning Attacks in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10040v1"&gt;Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10057v1"&gt;JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10125v1"&gt;Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10198v1"&gt;A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10262v1"&gt;Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10296v1"&gt;Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10307v1"&gt;Negative Metric Learning for Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10325v1"&gt;A Representation Learning Approach to Feature Drift Detection in Wireless Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10344v1"&gt;An Introduction to Discrete Variational Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10407v1"&gt;Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10422v1"&gt;Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10423v1"&gt;The Power of Random Features and the Limits of Distribution-Free Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10425v1"&gt;Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10472v1"&gt;Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10484v1"&gt;Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09972v1"&gt;Who Said What WSW 2.0? Enhanced Automated Analysis of Preschool Classroom Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10003v1"&gt;AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10030v1"&gt;DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10033v1"&gt;Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10117v1"&gt;Learning Virtual Machine Scheduling in Cloud Computing through Language Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10147v1"&gt;Near Optimal Best Arm Identification for Clustered Bandits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10160v1"&gt;One-Stage Top-$k$ Learning-to-Defer: Score-Based Surrogates with Theoretical Guarantees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10182v1"&gt;Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10213v1"&gt;Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10222v1"&gt;ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10223v1"&gt;Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10267v1"&gt;HandReader: Advanced Techniques for Efficient Fingerspelling Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10271v1"&gt;RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10279v1"&gt;Estimating the number of household TV profiles based in customer behaviour using Gaussian mixture model averaging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10319v1"&gt;Deconstructing Subset Construction -- Reducing While Determinizing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10322v1"&gt;Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10432v1"&gt;Score-based diffusion nowcasting of GOES imagery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10448v1"&gt;Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10475v1"&gt;Parallel Scaling Law for Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10495v1"&gt;RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10533v1"&gt;Enhancing Multi-Image Question Answering via Submodular Subset Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10556v1"&gt;An AI-driven framework for the prediction of personalised health response to air pollution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09949v1"&gt;Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10007v1"&gt;Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10099v1"&gt;A Scalable Gradient-Based Optimization Framework for Sparse Minimum-Variance Portfolio Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10272v1"&gt;Spike-timing-dependent Hebbian learning as noisy gradient descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10367v1"&gt;A Hybrid Strategy for Aggregated Probabilistic Forecasting and Energy Trading in HEFTCom2024&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10438v1"&gt;Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10444v1"&gt;Inferring entropy production in many-body systems using nonequilibrium MaxEnt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10466v1"&gt;FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10526v1"&gt;MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10080v1"&gt;Role of scrambling and noise in temporal information processing with quantum systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10498v1"&gt;Batched Nonparametric Bandits via k-Nearest Neighbor UCB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10398v1"&gt;AutoCam: Hierarchical Path Planning for an Autonomous Auxiliary Camera in Surgical Robotics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09902v1"&gt;Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10013v1"&gt;DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10063v1"&gt;CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10081v1"&gt;Designing and Contextualising Probes for African Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10089v1"&gt;XRAG: Cross-lingual Retrieval-Augmented Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10113v1"&gt;What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10143v1"&gt;GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10202v1"&gt;VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10218v1"&gt;RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10282v1"&gt;From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10354v1"&gt;LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10356v1"&gt;Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10389v1"&gt;Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10409v1"&gt;Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10413v1"&gt;Hierarchical Document Refinement for Long-context Retrieval-augmented Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10493v1"&gt;CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10507v1"&gt;The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10527v1"&gt;WorldPM: Scaling Human Preference Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09921v1"&gt;PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.09924v1"&gt;From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10118v1"&gt;Why 1 + 1 &lt; 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2505.10292v1"&gt;StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-05-16</guid><pubDate>Fri, 16 May 2025 12:15:28 +0900</pubDate></item><item><title>Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models</title><link>http://arxiv.org/abs/2505.10554v1</link><description>大規模推論モデル（LRM）は、すでに潜在的に長い思考連鎖推論能力を備えている。先行研究では、結果に基づいた強化学習（RL）が、自己修正、バックトラッキング、検証現象といった高度な推論行動を偶然に引き出すことができることが示されており、これらはしばしばモデルの「アハ体験」と呼ばれる。しかし、これらの創発的な行動のタイミングと一貫性は予測不可能で制御不能なままであり、LRMの推論能力のスケーラビリティと信頼性を制限している。これらの制限に対処するために、我々はプロンプトと偶然の「アハ体験」への依存から脱却する。代わりに、自動生成された自己検証可能なタスクを用いて、演繹、帰納、アブダクションという3つのメタ能力にモデルを明示的に適合させる。我々の3段階パイプライン（個別アライメント、パラメータ空間のマージ、ドメイン固有の強化学習）は、命令チューニングされたベースラインと比較して10%以上パフォーマンスを向上させる。さらに、アライメントされたチェックポイントからのドメイン固有のRLは、数学、コーディング、科学のベンチマーク全体でパフォーマンスの天井を平均2%向上させ、明示的なメタ能力アライメントが推論のためのスケーラブルで信頼できる基盤を提供することを示している。コードはhttps://github.com/zhiyuanhubj/Meta-Ability-Alignmentで入手可能である。

&lt;img src="https://arxiv.org/html/2505.10554v1/x2.png"/&gt;&lt;p&gt;Zhiyuan Hu Yibo Wang Hanze Dong Yuhui Xu National University of Singapore Tsinghua University Salesforce AI Research&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10554v1</guid><pubDate>Thu, 15 May 2025 17:58:33 +0000</pubDate></item><item><title>Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective</title><link>http://arxiv.org/abs/2505.10494v1</link><description>コードのセキュリティとユーザビリティは、大規模言語モデル（LLM）によって駆動される様々なコーディングアシスタントアプリケーションにとって不可欠です。現在のコードセキュリティベンチマークは、コード補完や生成といった単一の評価タスクとパラダイムにのみ焦点を当てており、安全なコード生成、脆弱性修復、脆弱性識別といった側面を網羅した包括的な評価が不足しています。本論文では、まず、LLMのコードセキュリティを包括的に評価するために、コード補完、脆弱性修復、脆弱性検出、分類など、様々なタスクを網羅したマルチタスクベンチマークCoV-Evalを提案します。さらに、人間の専門家と密接に連携し、より効率的かつ信頼性の高い方法でLLMが生成したプログラムの脆弱性をレビューできる、改善された判断モデルVC-Judgeを開発しました。20のプロプライエタリおよびオープンソースのLLMについて包括的な評価を実施しました。全体として、ほとんどのLLMは脆弱なコードをうまく識別できるものの、依然として安全でないコードを生成する傾向があり、特定の脆弱性タイプを認識したり、修復を実行したりすることに苦労しています。広範な実験と定性的な分析により、主要な課題と最適化の方向性が明らかになり、LLMコードセキュリティにおける今後の研究のための洞察を提供します。

&lt;img src="https://arxiv.org/html/2505.10494v1/x15.png"/&gt;&lt;p&gt;China, Peking University, Shikun Zhang, Wei Ye National Engineering Research Center for Software Engineering, Xiao Deng, Yutao Mou, Yuxiao Luo&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10494v1</guid><pubDate>Thu, 15 May 2025 16:53:41 +0000</pubDate></item><item><title>Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models</title><link>http://arxiv.org/abs/2505.10446v1</link><description>拡散言語モデルのための推論フレームワークである\emph{Diffusion Chain of Lateral Thought (DCoLT)}を紹介します。DCoLTは、逆拡散プロセスにおける各中間ステップを潜在的な「思考」行動として扱い、結果に基づく強化学習（RL）を用いて最終的な回答の正確性に対する報酬を最大化するように、推論軌跡全体を最適化します。因果的で線形な思考プロセスに従う従来のChain-of-Thought（CoT）手法とは異なり、DCoLTは双方向で非線形な推論を可能にし、思考の中間ステップにおける文法的な正しさに関する厳格なルールはありません。DCoLTを2つの代表的な拡散言語モデル（DLM）に実装します。まず、代表的な連続時間離散拡散モデルとしてSEDDを選択し、その具体的なスコアは、中間拡散ステップのシーケンス全体にわたってRL報酬を最大化する確率的ポリシーを導き出します。さらに、離散時間マスク拡散言語モデルであるLLaDAを検討し、トークンを予測してマスクを解除する順序が、Plackett-Luceモデルによって定義されるランキングベースのUnmasking Policy Module（UPM）から得られるRLアクションを最適化する上で重要な役割を果たすことを発見しました。数学およびコード生成タスクに関する実験では、公開データと16個のH800 GPUのみを使用して、DCoLTで強化されたDLMが、SFTまたはRL、あるいはその両方でトレーニングされた他のDLMよりも優れた性能を発揮することを示しています。特に、DCoLTで強化されたLLaDAは、GSM8K、MATH、MBPP、およびHumanEvalにおいて、推論精度をそれぞれ+9.8%、+5.7%、+11.4%、+19.5%向上させます。

&lt;img src="https://arxiv.org/html/2505.10446v1/x1.png"/&gt;&lt;p&gt;Westlake University, Zemin Huang Zhiyang Chen   Zijun Wang   Tiancheng Li   Guo-Jun Qi MAPLE Lab&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10446v1</guid><pubDate>Thu, 15 May 2025 16:06:32 +0000</pubDate></item><item><title>Rethinking Prompt Optimizers: From Prompt Merits to Optimization</title><link>http://arxiv.org/abs/2505.09930v1</link><description>プロンプト最適化（PO）は、大規模言語モデル（LLM）をファインチューニングする実用的な代替手段を提供し、モデルの重みを変更せずにパフォーマンスを向上させます。既存の手法は通常、最適化されたプロンプトを生成するために、GPT-4のような高度な大規模LLMに依存しています。しかし、下位互換性の制限により、高度なLLMからの冗長で指示過多なプロンプトは、軽量な推論モデルを圧倒し、応答品質を低下させる可能性があります。本研究では、解釈可能な設計という観点からプロンプト最適化を再考します。まず、モデルに依存しないプロンプト品質のメリットを特定し、プロンプトと応答の品質向上における有効性を経験的に検証します。次に、軽量なLLMによって生成されたメリットに沿ったプロンプトから構築された、独自の選好データセットで訓練された、メリット誘導型で軽量かつローカルに展開可能なプロンプト最適化ツールであるMePOを紹介します。従来の研究とは異なり、MePOはオンライン最適化への依存を避け、コストとプライバシーの懸念を軽減し、明確で解釈可能なメリットを学習することで、大規模および軽量な推論モデルの両方に効果的に汎化します。実験により、MePOが多様なタスクとモデルタイプにおいてより良い結果を達成し、現実世界での展開のためのスケーラブルで堅牢なソリューションを提供することが示されています。私たちのモデルとデータセットは、https://github.com/MidiyaZhu/MePO で入手できます。

&lt;img src="https://arxiv.org/html/2505.09930v1/x1.png"/&gt;&lt;p&gt;Electronic Engineering, Nanyang Technological University, Singapore, Singapore Home Team Science, Technology Agency, Zixiao Zhu Hanzhang Zhou Zijian Feng Tianjiao Li School of Electrical&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.09930v1</guid><pubDate>Thu, 15 May 2025 03:31:37 +0000</pubDate></item><item><title>Path Gradients after Flow Matching</title><link>http://arxiv.org/abs/2505.10139v1</link><description>ボルツマン生成器は、正規化フローと重点サンプリングを用いて分子系の平衡分布からサンプルを生成するための有望な機械学習ツールとして登場しました。近年、フローマッチングは、連続正規化フロー（CNF）の高速化、より複雑な分子系へのスケールアップ、およびフロー積分軌跡の長さを最小化するのに役立っています。本研究では、目標エネルギーが既知である設定において、フローマッチングによって初期トレーニングされたCNFを微調整するために、パス勾配を使用することの利点を調査します。実験の結果、このハイブリッドアプローチは、分子系のサンプリング効率を最大3倍向上させることができ、すべて同じモデル、同様の計算コスト、および追加のサンプリングを必要とせずに実現できることが示されました。さらに、微調整中のフロー軌跡の長さを測定することにより、パス勾配がフローの学習された構造を大きく維持することを示します。

&lt;img src="https://arxiv.org/html/2505.10139v1/x1.png"/&gt;&lt;p&gt;Lorenz Vaitl &amp;Leon Klein Freie Universität Berlin&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10139v1</guid><pubDate>Thu, 15 May 2025 10:13:45 +0000</pubDate></item><item><title>Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design</title><link>http://arxiv.org/abs/2505.10545v1</link><description>生物活性分子の開発は、創薬において依然として中心的で、時間とコストのかかる課題であり、特に構造データや機能データが不足している新規ターゲットにおいては困難です。ファーマコフォアモデリングは、生物学的ターゲットに対する分子の生物活性に必要な主要な特徴を捉えるための代替手段となります。本研究では、3D分子生成のためのファーマコフォア条件付き拡散モデルであるPharmaDiffを提案します。PharmaDiffは、トランスフォーマーベースのアーキテクチャを採用し、3Dファーマコフォアの原子ベースの表現を生成プロセスに統合することで、事前に定義されたファーマコフォア仮説に合致する3D分子グラフの正確な生成を可能にします。包括的なテストを通じて、PharmaDiffは、リガンドベースのドラッグデザイン手法と比較して、3Dファーマコフォア制約への適合において優れた性能を示しています。さらに、ターゲットタンパク質の構造を必要とせずに、構造ベースのドラッグデザインにおいて、広範囲のタンパク質にわたってより高いドッキングスコアを達成しています。ファーマコフォアモデリングと3D生成技術を統合することにより、PharmaDiffは、合理的なドラッグデザインのための強力かつ柔軟なフレームワークを提供します。

&lt;img src="https://arxiv.org/html/2505.10545v1/extracted/6443069/Figures/fig2.png"/&gt;&lt;p&gt;Amira Alakhdar Department of Chemistry Carnegie Mellon University Pittsburgh, Biomedical Engineering Carnegie Mellon University Pittsburgh, PA 15213, USA, USA
&amp;Barnabas Poczos Department of Machine Learning Carnegie Mellon University Pittsburgh, USA
&amp;Newell Washburn Departments of Chemistry&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10545v1</guid><pubDate>Thu, 15 May 2025 17:54:29 +0000</pubDate></item><item><title>SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices</title><link>http://arxiv.org/abs/2505.10259v1</link><description>リソース制約のあるデバイス上での効率的なLLM推論は、計算量とメモリ使用量において大きな課題を抱えています。GPUメモリの制限により、既存のシステムはモデルの重みをCPUメモリにオフロードしますが、CPUとGPU間のI/Oオーバーヘッドが大幅に発生します。これにより、主に2つの非効率が生じます。（1）GPUコアは十分に活用されず、データのロード待ちでアイドル状態になることがよくあります。（2）GPUメモリはパフォーマンスへの影響が小さく、その容量を減らしても全体的なスループットへの影響は最小限です。本論文では、投機的デコーディングをオフロードに組み込んだ、高スループットな推論エンジンであるSpecOffloadを提案します。私たちの主要なアイデアは、投機的デコーディングに使用されるドラフトモデルを保存および実行するために、潜在的なGPUリソースを解放し、ほぼ追加コストなしで推論を高速化することです。これをサポートするために、オフロードパイプライン内で投機的デコーディングにおけるターゲットモデルとドラフトモデルのインターリーブされた実行を注意深く調整し、テンソル配置を管理し、最適なパラメータを選択するためのプランナーを提案します。最高のベースラインと比較して、SpecOffloadはGPUコアの使用率を4.49倍向上させ、推論スループットを2.54倍向上させます。私たちのコードはhttps://github.com/MobiSense/SpecOffload で入手できます。

&lt;img src="https://arxiv.org/html/2505.10259v1/x1.png"/&gt;&lt;p&gt;Dangyang Li, Fang Dang, Shen Xu, Telecommunications, Tsinghua University Beijing Jiaotong University Beijing University of Posts, Xiangwen Zhuge, Xuan Ding, Zeyu Wang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10259v1</guid><pubDate>Thu, 15 May 2025 13:10:31 +0000</pubDate></item><item><title>Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data</title><link>http://arxiv.org/abs/2505.10192v1</link><description>半導体製造に不可欠なフォトリソグラフィー工程では、EUVパターニング中に様々な種類の欠陥が発生します。パターンサイズの縮小化に伴い、これらの欠陥は極めて小さく、検査中に誤検出や検出漏れを引き起こします。特に、より小さな欠陥を適切に表現した欠陥アノテーション付きの高品質なデータが不足しているため、製造ラインへの深層学習ベースの欠陥検出モデルの導入が妨げられています。データ不足の問題を解決するために、既知の欠陥分布を持つラインパターンの走査型電子顕微鏡（SEM）画像を人工的に生成し、自動的にアノテーションを付与します。次に、最先端の物体検出モデルを用いて、ピッチ幅よりもはるかに小さい欠陥サイズの関数として欠陥検出性能を調査します。リアルタイム物体検出器であるYOLOv8は、EfficientNetの83％、SSDの77％と比較して、96％という最高の平均適合率を持ち、より小さな欠陥を検出する能力があることがわかりました。確実に検出できる最小の欠陥サイズを報告します。実際のSEMデータでテストしたところ、YOLOv8モデルは、関連するすべてのインスタンスにおいて、ブリッジ欠陥の84.6％、ブレーク欠陥の78.3％を正しく検出しました。これらの有望な結果は、ロバストな機械学習モデルを開発するために、合成データが現実世界のデータの代替として使用できることを示唆しています。

&lt;img src="https://arxiv.org/html/2505.10192v1/extracted/6441586/FigA1.png"/&gt;&lt;p&gt;Changmin Park, Heeyoung Go, K. Subramanya Mayya, Myungsoo Hwang, Prashant P. Shinde, Priyadarshini P. Pai, Shashishekar P. Adiga, Yongbeom Seo&lt;/p&gt;&lt;p&gt;Foundry Process Development Team, Semiconductor R&amp;D Center, Samsung Electronics, Seoul, Korea
NextGen Projects (SAIT-India), Samsung Semiconductor India Research, Bangalore, 560048, India&lt;/p&gt;</description><guid isPermaLink="false">2505.10192v1</guid><pubDate>Thu, 15 May 2025 11:50:02 +0000</pubDate></item><item><title>ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data</title><link>http://arxiv.org/abs/2505.10083v1</link><description>従来の予測手法は、単一の種類の時系列データに依存しており、豊富なテキスト情報を活用する能力が制限されています。近年、大規模言語モデル（LLM）と時系列基盤モデル（TSFM）は、それぞれテキスト推論と時間モデリングにおいて強力な能力を示しています。時間情報とテキスト情報の両方を同時に活用して将来の推論を行うマルチモーダルモデルを構築するために、両者の強みを統合することが重要な研究課題として浮上しています。イベントと時系列のペアデータの不足に対処するため、我々はデカップリングされたフレームワークを提案します。LLMを用いてテキストイベントを修正指示に変換し、それを用いてTSFMの出力を誘導します。このフレームワークを実装するために、テキストによる修正指示を通じて誘導できるマルチモーダルTSFMであるChronoSteerを導入し、LLMとTSFMを効果的に橋渡しします。さらに、クロスモーダルな指示と時系列のペアデータの不足を緩和するために、合成データに基づいた二段階のトレーニング戦略を考案します。加えて、評価時の情報漏洩の懸念に対処するために、高品質なマルチモーダル時系列予測ベンチマークを構築します。LLMと統合後、合成データのみでトレーニングされたChronoSteerは、単一モーダルのバックボーンと比較して予測精度が25.7%向上し、以前の最先端のマルチモーダル手法と比較して22.5%向上しました。

&lt;img src=""/&gt;&lt;p&gt;Chengsen Wang, Jianxin Liao Beijing University of Posts, Jingyu Wang, Lujia Pan, Qi Qi, Telecommunications Huawei Noah’s Ark Lab, Zhongwen Rao&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10083v1</guid><pubDate>Thu, 15 May 2025 08:37:23 +0000</pubDate></item><item><title>Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates</title><link>http://arxiv.org/abs/2505.10039v1</link><description>回路発見は、メカニズム解釈可能性のための主要な手法の一つとして徐々に台頭しており、回路の完全性に関する研究もますます注目を集めている。完全性を保証しない回路発見の手法は、実行ごとに回路が固定されないだけでなく、重要なメカニズムが省略される原因となる。不完全性の本質は、回路内にORゲートが存在することに起因し、これらは標準的な回路発見手法では部分的にしか検出されないことが多い。そこで、我々はAND、OR、ADDERの3種類の論理ゲートを体系的に導入し、回路をこれらの論理ゲートの組み合わせに分解する。これらのゲートの概念を通して、忠実性と完全性を達成するために必要な最小限の要件を導き出す。さらに、ノイズ付加とノイズ除去に基づく介入を組み合わせたフレームワークを提案する。このフレームワークは、計算複雑性を大幅に増加させることなく、既存の回路発見手法に容易に統合できる。このフレームワークは、論理ゲートを完全に識別し、回路内で区別することができる。このフレームワークを用いて、回路の忠実性、完全性、およびスパース性を復元する能力を広範な実験で検証するだけでなく、3つの論理ゲートの割合や出力への貢献度など、基本的な特性を明らかにし、言語モデルの機能の中でそれらがどのように振る舞うかを調査する。

&lt;img src="https://arxiv.org/html/2505.10039v1/x1.png"/&gt;&lt;p&gt;Engineering Nanyang Technological University, Engineering The Chinese University of Hong Kong Xinyu Yang School of Computer Science, Hang Chen School of Computer Science, Technology Xi’an Jiaotong University &amp;Jiaying Zhu School of Computer Science, Technology Xi’an Jiaotong University &amp;Wenya Wang School of Computer Science&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10039v1</guid><pubDate>Thu, 15 May 2025 07:35:14 +0000</pubDate></item><item><title>ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts</title><link>http://arxiv.org/abs/2505.10010v1</link><description>強化学習（RL）における中心的な課題は、タスク固有のポリシーを学習するために、広範な実世界とのインタラクションデータに依存していることである。近年の研究では、大規模言語モデル（LLM）が、新しいタスクを習得するために合成経験（仮想的なロールアウトとして知られる）を生成することで、この制限を緩和できることが示されているが、この新興分野の進歩は、標準的なベンチマークの欠如によって妨げられている。このギャップを埋めるために、我々はImagineBenchを導入する。これは、実ロールアウトとLLMによる仮想ロールアウトの両方を活用するオフラインRLアルゴリズムを評価するための、初の包括的なベンチマークである。ImagineBenchの主な特徴は以下の通りである。（1）環境によって収集されたロールアウトとLLMによる仮想ロールアウトで構成されるデータセット、（2）歩行、ロボット操作、ナビゲーションタスクを網羅する多様な環境ドメイン、（3）言語条件付きポリシー学習を促進するための、さまざまな複雑さレベルの自然言語タスク指示。最先端のオフラインRLアルゴリズムの体系的な評価を通じて、既存のオフラインRLアルゴリズムを単純に適用するだけでは、未見のタスクで最適以下のパフォーマンスとなり、難しいタスクでの成功率は35.44%にとどまるのに対し、実ロールアウトで学習した手法では64.37%の成功率となることがわかった。この結果は、LLMによる仮想ロールアウトをより有効に活用するためのアルゴリズムの進歩の必要性を強調している。さらに、仮想ロールアウトのより良い活用、高速なオンライン適応と継続学習、マルチモーダルタスクへの拡張など、今後の研究における重要な機会を特定する。我々のコードは、https://github.com/LAMDA-RL/ImagineBench で公開されている。

&lt;img src="https://arxiv.org/html/2505.10010v1/x1.png"/&gt;&lt;p&gt;China &amp; School of Artificial Intelligence, China Polixir.ai The University of Hong Kong Equal contribution Corresponding: yuy@nju.edu.cn, Jing-Cheng Pang*, Kaiyuan Li*, Nanjing University, Shengyi Jiang, Si-Hang Yang, Yang Yu National Key Laboratory for Novel Software Technology, Yidi Wang*&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10010v1</guid><pubDate>Thu, 15 May 2025 06:45:37 +0000</pubDate></item><item><title>Neural Thermodynamic Laws for Large Language Model Training</title><link>http://arxiv.org/abs/2505.10559v1</link><description>ニューラルスケーリング則を超えて、大規模言語モデル（LLM）の根底にある法則についてはほとんど知られていません。本稿では、LLMの学習ダイナミクスに新たな洞察を提供する新しいフレームワークであるニューラル熱力学法則（NTL）を紹介します。理論面では、主要な熱力学量（例：温度、エントロピー、熱容量、熱伝導）と古典的な熱力学の原理（例：熱力学の三法則とエネルギー均分則）が、河川谷状の損失地形の仮定の下で自然に現れることを示します。実践面では、この科学的な視点から、学習率スケジュールの設計に関する直感的な指針が得られます。

&lt;img src="https://arxiv.org/html/2505.10559v1/x1.png"/&gt;&lt;p&gt;Jeff Gore, Max Tegmark Massachusetts Institute of Technology, Yizhou Liu, Ziming Liu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10559v1</guid><pubDate>Thu, 15 May 2025 17:59:22 +0000</pubDate></item><item><title>MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning</title><link>http://arxiv.org/abs/2505.10557v1</link><description>大規模マルチモーダルモデルの訓練に広く使用されている自然言語画像キャプションデータセットは、主に自然なシナリオに焦点を当てており、問題解決に不可欠な数学図形の複雑な詳細を見落としています。これにより、現在のLMMのマルチモーダル数学的推論における進歩が妨げられています。この目的のために、コードをクロスモーダルアライメントの教師あり信号として活用することを提案します。なぜなら、コードは本質的に対応する図形を生成するために必要なすべての情報をエンコードしており、2つのモダリティ間の正確な接続を確立するからです。具体的には、モデルインザループのアプローチで画像からコードへのモデルとデータセットを共同開発し、画像からコードへのモデルであるFigCodifierと、現在最大の画像-コードデータセットであるImgCode-8.6Mデータセットを作成しました。さらに、FigCodifierを利用して新しい数学図形を合成し、高品質なマルチモーダル数学インストラクションファインチューニングデータセットであるMM-MathInstruct-3Mを構築しました。最後に、クロスモーダルアライメントのためにImgCode-8.6Mで訓練し、その後マルチモーダル数学問題解決のためにMM-MathInstruct-3MでファインチューニングしたMathCoder-VLを発表します。私たちのモデルは、6つのすべての指標で新しいオープンソースSOTAを達成しています。特に、MathVistaの幾何学問題解決サブセットにおいて、GPT-4oおよびClaude 3.5 Sonnetを上回り、それぞれ8.9％および9.2％の改善を達成しています。データセットとモデルは、https://github.com/mathllm/MathCoder で公開されます。

&lt;img src="https://arxiv.org/html/2505.10557v1/x1.png"/&gt;&lt;p&gt;CPII under InnoHK wangk@link.cuhk.edu.hk hsli@ee.cuhk.edu.hk, Ke Wang &amp;Junting Pan &amp;Linda Wei &amp;Aojun Zhou &amp;Weikang Shi &amp;Zimu Lu Han Xiao &amp;Yunqiao Yang &amp;Houxing Ren &amp;Mingjie Zhan &amp;Hongsheng Li Multimedia Laboratory (MMLab), The Chinese University of Hong Kong&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10557v1</guid><pubDate>Thu, 15 May 2025 17:59:21 +0000</pubDate></item><item><title>Multi-Token Prediction Needs Registers</title><link>http://arxiv.org/abs/2505.10518v1</link><description>マルチトークン予測は、言語モデルの事前学習を改善するための有望な目標として登場しましたが、その利点はファインチューニングなどの他の設定には一貫して一般化されていません。本論文では、MuToRという、シンプルかつ効果的なマルチトークン予測手法を提案します。これは、学習可能なレジスタトークンを入力シーケンスにインターリーブし、各トークンが将来のターゲットを予測する役割を担います。既存の手法と比較して、MuToRはいくつかの重要な利点を提供します。追加のパラメータ数がごくわずかであること、アーキテクチャの変更を必要としないこと（既製の事前学習済み言語モデルとの互換性を保証）、そしてネクストトークン事前学習の目標と整合性が保たれているため、教師ありファインチューニングに特に適していることです。さらに、スケーラブルな予測ホライズンを自然にサポートします。言語および視覚ドメインの両方における困難な生成タスクにおいて、教師ありファインチューニング、パラメータ効率の良いファインチューニング（PEFT）、および事前学習を含む、さまざまなユースケースでMuToRの有効性と汎用性を示します。私たちのコードは、https://github.com/nasosger/MuToR で公開されます。

&lt;img src="https://arxiv.org/html/2505.10518v1/extracted/6442709/figures/multiple_token_prediction_needs_registers-v3.1.drawio.png"/&gt;&lt;p&gt;Anastasios Gerontopoulos, Nikos Komodakis, Spyros Gidaris&lt;/p&gt;&lt;p&gt;Archimedes, Athena Research Center
IACM-Forth
University of Crete
valeo.ai&lt;/p&gt;</description><guid isPermaLink="false">2505.10518v1</guid><pubDate>Thu, 15 May 2025 17:25:03 +0000</pubDate></item><item><title>Superposition Yields Robust Neural Scaling</title><link>http://arxiv.org/abs/2505.10465v1</link><description>現代の巨大言語モデル（LLM）の成功は、より大きなモデルほど性能が良いという観察に基づいています。しかし、このニューラルスケーリング則、つまり損失がモデルサイズに対してべき乗則で減少するという発見の起源は、依然として不明です。LLMはモデルの次元（幅）よりも多くのものを表現している（つまり、表現が重ね合わされている）、そして言語における単語や概念は様々な頻度で出現するという2つの経験的原則から出発し、モデルサイズに対する損失のスケーリングを研究するためのトイモデルを構築しました。その結果、重ね合わせが弱い場合、つまり最も頻繁な特徴のみが干渉なしに表現される場合、モデルサイズに対する損失のスケーリングは、基礎となる特徴の頻度に依存することがわかりました。特徴の頻度がべき乗則に従う場合、損失も同様です。対照的に、強い重ね合わせの下では、すべての特徴が表現されるが互いに重複する場合、損失は幅広い特徴頻度分布にわたってモデルの次元に反比例します。このロバストなスケーリング挙動は幾何学的に説明できます。より多くのベクトルがより低い次元空間に詰め込まれると、ベクトル間の干渉（二乗された重複）はその次元に反比例してスケーリングされます。次に、4つのオープンソースLLMのファミリーを分析し、それらが強い重ね合わせを示し、トイモデルの予測と定量的に一致することを発見しました。Chinchillaスケーリング則も私たちの結果と一致することがわかりました。結論として、表現の重ね合わせは、観察されたニューラルスケーリング則の根底にある重要なメカニズムです。これらの洞察が、より少ない計算量とパラメータでより良いパフォーマンスを達成するための新しいトレーニング戦略とモデルアーキテクチャを刺激することを期待しています。

&lt;img src="https://arxiv.org/html/2505.10465v1/x1.png"/&gt;&lt;p&gt;Jeff Gore Massachusetts Institute of Technology Cambridge, MA 02139, Yizhou Liu, Ziming Liu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10465v1</guid><pubDate>Thu, 15 May 2025 16:18:13 +0000</pubDate></item><item><title>Rethinking Repetition Problems of LLMs in Code Generation</title><link>http://arxiv.org/abs/2505.10402v1</link><description>ニューラル言語モデルの登場により、コード生成の性能は大幅に向上しました。しかし、生成過程における繰り返し（反復）の問題は依然として残っています。これまでの研究は主に内容の繰り返しに焦点を当ててきましたが、これはコード生成におけるより広範な繰り返し問題のほんの一部に過ぎません。より一般的で困難な問題は、構造的な繰り返しです。構造的な繰り返しでは、繰り返されるコードは様々なパターンで現れますが、固定された構造を持ち、それは文法に本質的に反映されます。本論文では、構造的な繰り返しを正式に定義し、LLM（大規模言語モデル）におけるコード生成の繰り返し問題を軽減するための、文法に基づく繰り返しペナルティ（Repetition Penalization based on Grammar）であるRPGと呼ばれる効率的なデコード手法を提案します。具体的には、RPGはまず文法規則を利用してコード生成中の繰り返し問題を特定し、次に繰り返しに寄与する重要なトークンの尤度を戦略的に減衰させることで、コード生成における繰り返しを軽減します。この研究を促進するために、コード生成における繰り返し問題を軽減するためのアプローチを包括的に評価するための新しいデータセットCodeRepetEvalを構築します。広範な実験結果は、RPGがCodeRepetEvalデータセットだけでなく、HumanEvalおよびMBPPベンチマークにおいても、最高の性能を発揮するベースラインを大幅に上回り、繰り返しを効果的に削減し、生成されたコードの品質を向上させることを示しています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10402v1</guid><pubDate>Thu, 15 May 2025 15:26:32 +0000</pubDate></item><item><title>Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training</title><link>http://arxiv.org/abs/2505.10393v1</link><description>我々は、計算の簡便さと物理に基づいた戦略を組み合わせ、合成データで訓練された人工ニューラルネットワークを用いて、磁性相の効率的な学習を調査する。厳密な解析解を持たない希釈イジングモデルに焦点を当て、単純な密なニューラルネットワークを用いた教師あり分類と、理想化されたスピン配置のみで訓練された畳み込みオートエンコーダを用いた教師なし相転移検出という、2つの相補的なアプローチを探求する。

モデルの性能を向上させるために、2つの重要な物理に基づいたガイダンスを取り入れる。第一に、対称性の破れに関連する特徴を優先的に増幅するアーキテクチャバイアスを利用する。第二に、$\mathbb{Z}_2$対称性を明示的に破る訓練構成を含め、ネットワークが秩序相を検出する能力を強化する。これらのメカニズムは、連携して動作することで、明示的なラベルがない場合でも、ネットワークの相構造に対する感度を高める。機械学習による予測は、臨界温度とパーコレーション閾値の直接的な数値推定との比較を通じて検証する。

我々の結果は、合成的で構造化された、計算効率の高い訓練スキームが、複雑なシステムにおいても物理的に意味のある相境界を明らかにできることを示している。このフレームワークは、従来のメソッドに代わる低コストでロバストな代替手段を提供し、より広範な凝縮系物理学および統計物理学の分野での応用が期待される。

&lt;img src="https://arxiv.org/html/2505.10393v1/extracted/6442579/Figures2/myNN.png"/&gt;&lt;p&gt;A. Medina, C. A. Lamas, M. Arlego&lt;/p&gt;&lt;p&gt;Facultad de Ciencias Exactas, Universidad Nacional de La Plata, La Plata, Argentina.
Facultad de Ciencias Exactas, Universidad Nacional del Centro de la Provincia de Buenos Aires, Tandil, Argentina.
IFLP - CIC, Departamento de Física, Universidad Nacional de La Plata, Diagonal 113 entre 63 y 64, 1900 La Plata, Argentina.
IFLP - CONICET, Departamento de Física, Universidad Nacional de La Plata, Diagonal 113 entre 63 y 64, 1900 La Plata, Argentina.
Institute for Theoretical Physics, Technical University Braunschweig, Braunschweig, Germany&lt;/p&gt;</description><guid isPermaLink="false">2505.10393v1</guid><pubDate>Thu, 15 May 2025 15:16:16 +0000</pubDate></item><item><title>All You Need Is Synthetic Task Augmentation</title><link>http://arxiv.org/abs/2505.10120v1</link><description>ランダムフォレストのようなルールベースモデルを微分可能なニューラルネットワークフレームワークに組み込むことは、機械学習における未解決の課題である。近年の進歩により、事前学習済みモデルが効率的な分子埋め込みを生成できることが示されている。しかし、これらのアプローチは、性能を向上させるために、多くの場合、大規模な事前学習や、事後確率の組み込みなどの追加の技術を必要とする。本研究では、疎なマルチタスク分子特性実験ターゲットと、Osmordred分子記述子で学習されたXGBoostモデルから導出された合成ターゲットの両方で、単一のグラフ変換ニューラルネットワークを共同で学習する新しい戦略を提案する。これらの合成タスクは、独立した補助タスクとして機能する。我々の結果は、19の分子特性予測タスクすべてにおいて、一貫した有意な性能向上を示す。19のターゲットのうち16個において、マルチタスクグラフ変換器はXGBoostのシングルタスク学習器を上回る性能を示す。これは、合成タスク拡張が、特徴注入や事前学習を必要とせずに、マルチタスク分子特性予測におけるニューラルモデルの性能を向上させる効果的な方法であることを示している。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2505.10120v1</guid><pubDate>Thu, 15 May 2025 09:46:27 +0000</pubDate></item><item><title>From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI</title><link>http://arxiv.org/abs/2505.10093v1</link><description>台湾における中国研究（CS）は、独自の地政学的な位置と中国本土との長年にわたる学術的な関わりによって形成され、豊かで学際的な研究分野へと発展しました。本研究は、台湾を拠点とする数十年にわたるCS研究を体系的に再検討し、再編成する必要性の高まりに応え、非構造化テキストを構造化されたインタラクティブな知識表現に変換するAI支援アプローチを提案します。生成AI（GAI）技術と大規模言語モデル（LLM）を適用し、1996年から2019年の間に発表された査読付きCS論文1,367件からエンティティ関係トリプルを抽出し、標準化します。これらのトリプルは、軽量なD3.jsベースのシステムを通じて可視化され、この分野に特化した知識グラフとベクトルデータベースの基盤を形成します。このインフラストラクチャにより、ユーザーはコーパス全体の概念ノードと意味的関係を探求し、これまで未踏であった知的軌跡、テーマクラスター、および研究のギャップを明らかにすることができます。テキストコンテンツをグラフ構造化された知識ユニットに分解することにより、当社のシステムは、線形テキスト消費からネットワークベースの知識ナビゲーションへのパラダイムシフトを可能にします。そうすることで、CS文献への学術的なアクセスを強化すると同時に、従来のオントロジー構築に代わる、スケーラブルでデータ駆動型のアプローチを提供します。本研究は、生成AIが地域研究やデジタルヒューマニティをどのように強化できるかを示すだけでなく、地域知識システムのための再構築された学術インフラストラクチャをサポートする可能性も強調しています。

&lt;img src=""/&gt;&lt;p&gt;Hsuan-Lei Shao&lt;/p&gt;&lt;p&gt;Graduate Institute of Health and Biotechnology Law, Taipei Medical University Taiwan&lt;/p&gt;</description><guid isPermaLink="false">2505.10093v1</guid><pubDate>Thu, 15 May 2025 08:51:53 +0000</pubDate></item><item><title>Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering</title><link>http://arxiv.org/abs/2505.10012v1</link><description>人工知能（AI）と量子コンピューティングの最近の進歩は、科学およびエンジニアリングプロセスにおける自動化を加速させ、研究方法論を根本的に再構築しています。本稿では、科学的自動化と確立されたコンピュータ支援エンジニアリング（CAE）の実践との類似点を強調し、エンジニアリング設計におけるシミュレーション、最適化、および機械学習のために量子アルゴリズムを活用するフレームワークとして、量子CAEを紹介します。量子CAEの実用的な実装は、組み合わせ最適化問題のケーススタディを通じて示されます。さらに、より高い自動化レベルに向けた進歩について議論し、量子アルゴリズム設計に精通した特殊なAIエージェントの重要な役割を強調します。量子コンピューティングとAIの統合は、人間の科学者やエンジニア、AIシステム、および量子計算リソース間の協調的なダイナミクスについて重要な疑問を提起し、自動化された発見とイノベーションの変革的な未来を強調しています。

&lt;img src="https://arxiv.org/html/2505.10012v1/x1.png"/&gt;&lt;p&gt;Tadashi Kadowaki&lt;/p&gt;&lt;p&gt;1 Global R&amp;D Center for Business by Quantum-AI Technology, National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan 2 DENSO CORPORATION, Tokyo, Japan&lt;/p&gt;</description><guid isPermaLink="false">2505.10012v1</guid><pubDate>Thu, 15 May 2025 06:53:30 +0000</pubDate></item><item><title>AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge</title><link>http://arxiv.org/abs/2505.10468v1</link><description>本研究は、AIエージェントとエージェント型AIを明確に区別し、その異なる設計思想と能力を明らかにするために、構造化された概念分類、応用マッピング、および課題分析を提供します。まず、検索戦略と基礎となる定義を概説し、AIエージェントを、大規模言語モデル（LLM）および大規模画像モデル（LIM）によって駆動される、狭くタスク固有の自動化のためのモジュール式システムとして特徴づけます。生成AIは前駆体として位置づけられ、AIエージェントはツール統合、プロンプトエンジニアリング、および推論の強化を通じて進化します。対照的に、エージェント型AIシステムは、マルチエージェントコラボレーション、動的なタスク分解、永続的なメモリ、およびオーケストレーションされた自律性を特徴とするパラダイムシフトを表します。アーキテクチャの進化、運用メカニズム、インタラクションスタイル、および自律性レベルの順次評価を通じて、両方のパラダイムにわたる比較分析を提示します。顧客サポート、スケジューリング、およびデータ要約などの応用分野は、研究自動化、ロボット協調、および医療意思決定支援におけるエージェント型AIの展開と比較されます。さらに、幻覚、脆弱性、創発的行動、および協調の失敗など、各パラダイムにおける固有の課題を検証し、ReActループ、RAG、オーケストレーションレイヤー、および因果モデリングなどの的を絞ったソリューションを提案します。本研究は、堅牢でスケーラブルかつ説明可能なAIエージェントおよびエージェント型AI駆動型システムを開発するための明確なロードマップを提供することを目的としています。&gt;AIエージェント、エージェント駆動型、ビジョン-言語モデル、エージェント型AI意思決定支援システム、エージェント型AIアプリケーション

&lt;img src="https://arxiv.org/html/2505.10468v1/x1.png"/&gt;&lt;p&gt;Konstantinos I. Roumeliotis2, Manoj Karkee13, Ranjan Sapkota13&lt;/p&gt;&lt;p&gt;1Cornell University, Department of Environmental and Biological Engineering, USA
2Department of Informatics and Telecommunications, University of the Peloponnese, 22131 Tripoli, Greece&lt;/p&gt;</description><guid isPermaLink="false">2505.10468v1</guid><pubDate>Thu, 15 May 2025 16:21:33 +0000</pubDate></item><item><title>Weighted Active Space Protocol for Multireference Machine-Learned Potentials</title><link>http://arxiv.org/abs/2505.10505v1</link><description>多配置ペア密度汎関数理論（MC-PDFT）のような多参照法は、多配置的性格が強い系における電子相関を捉える効果的な手段を提供する。しかし、触媒ダイナミクスのための機械学習ベースの原子間ポテンシャル（MLP）を訓練するための応用は、多参照計算が基底となる活性空間に敏感であるため、困難であった。これは、多様な原子核配置にわたって一貫したエネルギーと勾配を達成することを複雑にする。この制限を克服するために、我々は、無相関な配置にわたって与えられた系に対して一貫した活性空間を割り当てるための体系的なアプローチである、重み付け活性空間プロトコル（WASP）を導入する。WASPをMLPおよび拡張サンプリング技術と統合することにより、多参照データに基づいてMLPの訓練を可能にする、データ効率の高いアクティブラーニングサイクルを提案する。メタンのTiC+触媒によるC-H活性化において、この方法を実証する。この反応は、その顕著な多参照的性格のために、コーン-シャム密度汎関数理論にとって課題となる。このフレームワークは、触媒ダイナミクスの正確かつ効率的なモデリングを可能にし、従来の電子構造法の限界を超えた複雑な反応過程をシミュレートするための新しいパラダイムを確立する。

&lt;img src="https://arxiv.org/html/2505.10505v1/extracted/6442459/figures_combined/Figure_1_modified.png"/&gt;&lt;p&gt;Andrew L. Ferguson, Aniruddha Seal, Laura Gagliardi, Luigi Bonati, Matthew R. Hennefarth, Michele Parrinello, Simone Perego, Umberto Raucci&lt;/p&gt;&lt;p&gt;Atomistic Simulations, Italian Institute of Technology, 16156 Genova, Italy
Department of Chemistry and Chicago Center for Theoretical Chemistry, University of Chicago, Chicago, IL 60637, USA
Pritzker School of Molecular Engineering, University of Chicago, Chicago, IL 60637, USA&lt;/p&gt;</description><guid isPermaLink="false">2505.10505v1</guid><pubDate>Thu, 15 May 2025 17:09:43 +0000</pubDate></item><item><title>A High Throughput Virtual Screening Approach for Identifying Thermally Activated Delayed Fluorescence-Based Emitters</title><link>http://arxiv.org/abs/2505.10127v1</link><description>熱活性化遅延蛍光（TADF）は、前世代のOLEDで必要とされた重金属を必要とせずに、高効率な有機発光ダイオード（OLED）を実現する可能性を秘めています。しかし、新しいTADF発光体の設計は、相反する設計戦略を必要とする競合する要件によって複雑になっています。しかし、ハイスループットバーチャルスクリーニング（HTVS）アプローチは、既存の設計ルールに必ずしも依存せずに、新しいTADF発光体を特定する可能性を提供します。本研究では、STONEDアルゴリズム[A. Nigam et al., Chem. Sci., 2021, 12, 7079]を用いて、従来のドナー-アクセプター型および多重共鳴TADF発光体を含む20個の親分子のセットから開始して、ランダムな構造変異を付与します。その後、原子構造の特徴から時間依存密度汎関数理論計算まで、連続的なフィルターが適用されます。ランダム化されたアプローチは既存のTADF発光体の再発見には不向きであることが判明しましたが、結果として得られたワークフローは、幅広い発光色にわたって、TADFに有望な特性を持つ多数の分子の特定につながります。

&lt;img src="https://arxiv.org/html/2505.10127v1/extracted/6438290/funnel_TXO-TPA.png"/&gt;&lt;p&gt;Jennifer I. Jones, Kritam Thapa, Laura E. Ratcliff&lt;/p&gt;&lt;p&gt;Centre for Computational Chemistry, School of Chemistry, University of Bristol, Bristol BS8 1TS, United Kingdom
Department of Materials, Imperial College London, London SW7 2AZ, United Kingdom
Hylleraas Centre for Quantum Molecular Sciences, Department of Chemistry, UiT The Arctic University of Norway, N-9037 Tromsø, Norway
These authors contributed equally to this work&lt;/p&gt;</description><guid isPermaLink="false">2505.10127v1</guid><pubDate>Thu, 15 May 2025 09:52:44 +0000</pubDate></item><item><title>Sensing a magnetic rare-earth surface alloy by proximity effect with an open-shell nanographene</title><link>http://arxiv.org/abs/2505.10313v1</link><description>オープンシェルナノグラフェンは、構造的に調整可能なスピン基底状態を持つため、大きな注目を集めています。ほとんどの特性評価は、貴金属などの弱く相互作用する基板上で行われてきましたが、磁性表面の影響はほとんど探求されていません。本研究では、希土類元素ベースの表面合金であるTbAu2が、最小のスピン1/2ナノグラフェンであるフェナレニル（または[2]トリアングレン（2T））の磁気特性にどのように影響するかを調査します。走査型トンネル分光法（STS）測定により、顕著な対照が明らかになりました。Au(111)上の2Tは、ゼロバイアス近藤共鳴を示し、これは基礎となる金属の伝導電子によって遮蔽されたスピン1/2不純物の特徴ですが、TbAu2への蒸着は、この特徴を約20 mV対称的に分裂させます。この分裂は、TbAu2の強磁性面外磁化との強い近接誘起相互作用に起因すると考えられます。さらに、実験と第一原理計算を組み合わせた分析により、この相互作用が空間的に変調され、TbAu2表面超構造の周期性に従うことが示されています。これらの発見は、TbAu2がスピン1/2ナノグラフェンの磁気特性を安定化およびプローブするための実行可能なプラットフォームとして機能し、π磁性材料と磁性基板の統合のための新たな道を開くことを強調しています。

&lt;img src="https://arxiv.org/html/2505.10313v1/extracted/6442133/1_TbAu2and2T.png"/&gt;&lt;p&gt;Carlo A. Pignedoli, Elia Turco, Feifei Xiang, Jan Wilhelm, Michal Juríček, Nicolò Bassi, Nils Krane, Patrícia Čmelová, Pierluigi Gargiani, Richard Korytár, Roman Fasel&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2505.10313v1</guid><pubDate>Thu, 15 May 2025 13:56:23 +0000</pubDate></item><item><title>Computational screening and experimental validation of promising Wadsley-Roth Niobates</title><link>http://arxiv.org/abs/2505.10549v1</link><description>高効率かつ大容量のエネルギー貯蔵システムに対する需要の高まりは、リチウムイオン電池用の先進材料の研究を大きく推進しています。様々な候補材料の中でも、ワズリー・ロス（WR）ニオブ酸塩は、ReO3に似たブロック内での迅速なイオン拡散と、せん断面に沿った良好な電子伝導性の組み合わせにより、高速Li+貯蔵のための有望な材料群として注目されています。WR相の優れた特徴にもかかわらず、現在知られている構造は30未満であり、性能向上のための構造-物性相関の特定や、より地球上に豊富な元素を持つ相の特定が制限されています。本研究では、密度汎関数理論（DFT）を用いたハイスループットスクリーニングにより、潜在的に（準）安定な組成（ΔHd &lt; 22 meV/atom）のセットを1301（3283のうち）まで劇的に拡大しました。この広大な化合物空間は、周期表の48元素を用いて、10個の既知のWRニオブ酸塩プロトタイプへの単一および二重サイト置換によって生成されました。構造予測を確認するために、新しい材料であるMoWNb24O66の合成に成功し、X線回折で検証しました。MoWNb24O66で測定されたリチウム拡散係数は、Li/Li+に対して1.45 Vで1.0x10-16 m2/sのピーク値を持ち、5Cで225 mAh/gを達成しました。このように、計算によって予測された相が実験的に実現され、最近のWRベンチマークであるNb16W5O55を超える性能を示しました。全体として、潜在的に安定な新規化合物の計算データセットと、競争力のある性能を持つことが実現された1つの化合物は、実験者が新しい耐久性のあるバッテリー材料を発見するための貴重な指針となります。

&lt;img src="https://arxiv.org/html/2505.10549v1/x1.png"/&gt;&lt;p&gt;CJ Sturgill, Christopher Sutton, Hans-Conrad zur Loye, Iva Milisavljevic, Manish Kumar, Morgan Stefik, Scott Misture, Zachary J. L. Bare&lt;/p&gt;&lt;p&gt;Department of Chemistry and Biochemistry, University of South Carolina, South Carolina
29208, United States
Department of Chemistry and Biochemistry, University of South Carolina, South Carolina 29208, United States
Inamori School of Engineering, Alfred University, New York 14802, United States&lt;/p&gt;</description><guid isPermaLink="false">2505.10549v1</guid><pubDate>Thu, 15 May 2025 17:56:25 +0000</pubDate></item><item><title>First-Principles Calculation of Spin-Relaxation Due to Alloy and Electron-Phonon Scattering in Strained GeSn</title><link>http://arxiv.org/abs/2505.10350v1</link><description>GeSnは、長いスピン寿命、シリコン技術との互換性、高い移動度、調整可能な電子特性により、スピントロニクスの有望な材料として登場しました。特に興味深いのは、Sn含有量の増加に伴う間接バンドギャップから直接バンドギャップへの転移であり、これは光学特性、電子輸送を向上させ、スピントロニクスアプリケーションに不可欠なスピン輸送挙動にも影響を与えることがわかりました。第一原理電子構造理論を用いて、n型GeSn合金におけるスピンフリップ電子合金散乱パラメータを決定します。また、以前には決定されていなかった$L$バレーと$\Gamma$バレー間の谷間間電子スピン-フォノン散乱パラメータも計算します。これらのパラメータを使用して、合金含有量と温度の関数として、GeSnのn型スピン緩和に対する電子合金および電子フォノン散乱の寄与を決定します。フォノン散乱の場合と同様に、合金散乱はスピン緩和時間を短縮します。ただし、Snを十分に添加してスピン輸送をGeの典型的な$L$バレーから$\Gamma$バレーに切り替えることで、緩和時間を大幅に延長できます。歪みのない室温のGeSnの場合、Geよりも長いスピン緩和時間を達成するには、少なくとも10％のSn濃度が必要であり、スピン緩和時間をナノ秒範囲からマイクロ秒範囲に増やすには17％のSnが必要であることがわかりました。低温（30K）では、10％のSnを追加すると、スピン緩和時間を$10^{-7}$秒から0.1秒に増やすことができます。GeSnに二軸引張歪みを加えると、スピン緩和時間がさらに長くなり、歪みのないGeSnよりも低いSn含有量で済みます。

&lt;img src="https://arxiv.org/html/2505.10350v1/extracted/6442233/Lflips.png"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;*&lt;/p&gt;</description><guid isPermaLink="false">2505.10350v1</guid><pubDate>Thu, 15 May 2025 14:41:28 +0000</pubDate></item><item><title>Alkali Intercalation of Moire Heterostructures for Low-Loss Plasmonics</title><link>http://arxiv.org/abs/2505.10225v1</link><description>二次元金属は一般的に、同じ周波数の自由空間放射の波長よりもはるかに短い波長のギャップレスプラズモンを支持する。しかし、通常、この電磁エネルギーの実質的な閉じ込めは、相応に高い損失を伴い、そのような損失の軽減は、フェルミ準位付近での慎重なバンド構造エンジニアリングによってのみ達成される可能性がある。清浄な系では、十分に高いキャリア密度を持つフェルミ準位の孤立した適度にフラットなバンドは、電子-フォノン相互作用のある次数まで伝播損失を受けにくいプラズモンを支持できる。しかし、これらの基準を満たすと提案されている材料は、強磁性、構造的に不安定、または製造が困難であった。本稿では、これらの典型的な落とし穴を回避するバンド構造エンジニアリングされた材料のクラス、すなわちアルカリ原子が挿入された六方晶窒化ホウ素のモアレヘテロ構造を提案する。ナトリウム原子のみが、電子-フォノン相互作用の一次で損失のないプラズモンを持つ十分に孤立したバンドを生じさせることを見出した。高次の電子-フォノン損失を計算した結果、約1eVの周波数では、電子-フォノン崩壊機構は無視でき、狭い周波数範囲で約10^7 Hzの崩壊率への寄与となることがわかった。次に、電子-電子相互作用による損失を計算した結果、これが支配的なプロセスであり、プラズモンが約10^14 Hzの速度でより低い周波数のプラズモンに崩壊することがわかった。

&lt;img src="https://arxiv.org/html/2505.10225v1/x1.png"/&gt;&lt;p&gt;Ali Ghorashi, Efthimios Kaxiras, John Joannopoulos, Marin Soljačić, Nicholas Rivera, Ravishankar Sundararaman&lt;/p&gt;&lt;p&gt;Department of Physics, Harvard University, Cambridge, MA 02138, USA
Department of Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA
Institute for Soldier Nanotechnologies, Massachusetts Institute of Technology, Cambridge, MA 02139, USA
Materials Science and Engineering, Rensselaer Polytechnic Institute, Troy, NY 12180, USA
School of Applied and Engineering Physics, Cornell University, Ithaca, NY 14853, USA
School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USA&lt;/p&gt;</description><guid isPermaLink="false">2505.10225v1</guid><pubDate>Thu, 15 May 2025 12:33:38 +0000</pubDate></item><item><title>Theoretical investigations of electronic and optical properties of double perovskite Cs$_2$Tl$BX_6$ ($B=$ Bi, In; $X=$ Cl, Br, I) for photovoltaic application</title><link>http://arxiv.org/abs/2505.09982v1</link><description>鉛フリーのダブルペロブスカイトは、長いキャリア寿命、調整可能なバンドギャップ、および低い毒性のため、太陽光発電（PV）用途で注目を集めています。第一原理計算を用いて、Cs$_2$Tl$BX_6$ ($B=$ Bi, In; $X=$ Cl, Br, I) の構造的、電子的、および光学的特性を研究しました。立方晶相（空間群Fm3m）を、射影増強波（PAW）法を用いて解析しました。計算の結果、Cs$_2$TlBi$X_6$に対して1.9〜1.2 eVの直接バンドギャップ、Cs$_2$TlIn$X_6$に対して2.4〜0.8 eVの間接バンドギャップが予測されました。特に、バンドギャップエネルギーは、アニオン置換がClからIに変わるにつれて減少し、これらの材料は近赤外から可視光の範囲で非常に活性になります。Cs$_2$TlBi$X_6$は最高の光吸収を示し、入射光子エネルギー3 eVでピーク値が$5\times10^5$ cm$^{-1}$に達することを示しました。さらに、ボルツマン輸送方程式を用いて輸送特性を評価しました。その結果、Cs$_2$TlBi$X_6$は高い電気伝導度（$8\times10^6$ S/mに達する）と高い電子移動度（120 cm$^2/$V.s）を示すことが示されました。PV性能分析により、最大42％の有望な電力変換効率（PCE）が明らかになり、Cs$_2$TlBi$X_6$はCs$_2$TlIn$X_6$よりも大幅に高いPCEを示しています。これらの報告は、高度な太陽光発電デバイスに対するCs$_2$TlBi$X_6$の可能性を強調しています。

&lt;img src="https://arxiv.org/html/2505.09982v1/x1.png"/&gt;&lt;p&gt;Ardimas, Edi Suprayoga&lt;/p&gt;&lt;p&gt;Research Center for Quantum Physics, National Research and Innovation Agency (BRIN), South Tangerang 15314, Indonesia&lt;/p&gt;</description><guid isPermaLink="false">2505.09982v1</guid><pubDate>Thu, 15 May 2025 05:40:10 +0000</pubDate></item><item><title>Coupling between magnetism and band structure in a 2D semiconductor</title><link>http://arxiv.org/abs/2505.09946v1</link><description>ファンデルワールス半導体磁性体は、その半導体特性と磁気特性の相互作用に起因する豊富な物理現象を示す。しかし、半導体プロセスと磁性がどのように結合しているかについての包括的な理解は不足している。我々は、磁性半導体CrPS$_4$に対して走査型トンネル分光法（STS）測定を行い、その結果をフォトルミネッセンス実験および密度汎関数理論（DFT）計算と比較することにより、この問題に取り組む。磁気転移温度以下では、STSは常磁性状態には存在しない複数の特徴を示す。これは、大きな（$\simeq 0.5$ eV）交換エネルギーを持つスピン分裂による電子バンドの増加が原因である。STSによって決定されたバンド端間のエネルギー差は、観測されたすべてのフォトルミネッセンス遷移と一致し、これらの遷移も磁性状態で増加する。DFT計算は、検出されたすべてのバンドの相対的な位置を定量的に予測し、どのバンドのペアが放射遷移につながるかを説明し、電子波動関数の測定された空間依存性も再現する。我々の結果は、CrPS$_4$で観測されるすべての基本的な光電子プロセスが、磁性状態に入る際の電子バンド構造の進化という観点からどのように理解できるかを明らかにし、個々のバンドが広いエネルギー間隔にわたって完全にスピン偏極していると結論付けることを可能にする。

&lt;img src="https://arxiv.org/html/2505.09946v1/x1.png"/&gt;&lt;p&gt;Alberto F. Morpurgo, Alessandro Scarfato, Christoph Renner, Fan Wu, Lihuan Sun, Marco Gibertini, Menghan Liao&lt;/p&gt;&lt;p&gt;Centro S3, CNR-Istituto Nanoscienze, 41125 Modena, Italy
Department of Quantum Matter Physics, University of Geneva, 1211 Geneva, Switzerland
Dipartimento di Scienze Fisiche, Informatiche e Matematiche, University of Modena and Reggio Emilia, 41125 Modena, Italy
Group of Applied Physics, University of Geneva, 1211 Geneva, Switzerland
Zhangjiang Laboratory, 201210 Shanghai, China&lt;/p&gt;</description><guid isPermaLink="false">2505.09946v1</guid><pubDate>Thu, 15 May 2025 04:02:44 +0000</pubDate></item></channel></rss>