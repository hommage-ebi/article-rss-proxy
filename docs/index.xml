<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Wed, 18 Jun 2025 03:21:16 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-18</title><link>https://arxiv.org/2025-06-18</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14156v1"&gt;Enhancing gate control and mitigating short channel effects in 20-50 nm channel length single-gate amorphous oxide Thin Film Transistors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14332v1"&gt;Unraveling structural and magnetic information during growth of nanocrystalline SrFe12O19&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14452v1"&gt;Polarization switching on the open surfaces of the wurtzite ferroelectric nitrides: ferroelectric subsystems and electrochemical reactivity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14499v1"&gt;In situ growth of a type-II ZnO/ZnS heterostructure:From stability to band-offset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14590v1"&gt;250 Magnetic Tunnel Junctions-Based Probabilistic Ising Machine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14127v1"&gt;Resolving Phonons in Superconductor Bi2Sr2CaCu2O8+δ at Sub-Unit-Cell Resolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14687v1"&gt;Complex single-site magnetism and magnetotransport in single-crystalline Gd$_{2}$AlSi$_{3}$&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14733v1"&gt;High-efficiency WSe$_2$ photovoltaics enabled by ultra-clean van der Waals contacts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14314v1"&gt;Noncentrosymmetric High-Temperature Superconductivity in doped $d^9$ Multiferroics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14383v1"&gt;Reconfigurable three dimensional magnetic nanoarchitectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14726v1"&gt;About explosive delayed desorption from methane-doped argon matrices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14658v1"&gt;First-passage time to capture for diffusion in a 3D harmonic potential&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14500v1"&gt;Versatile SPH Open Boundary Conditions for Multiphase Flows in Extreme Condition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14424v1"&gt;Higher-Oder Splitting Schemes for Fluids with Variable Viscosity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14722v1"&gt;A stochastic noise model based excess noise factor expressions for staircase avalanche photodiodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14125v1"&gt;Situational-Constrained Sequential Resources Allocation via Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14212v1"&gt;What's in the Box? Reasoning about Unseen Objects from Multimodal Cues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14224v1"&gt;From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14246v1"&gt;Mxplainer: Explain and Learn Insights by Imitating Mahjong Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14299v1"&gt;ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14336v1"&gt;AviationLLM: An LLM-based Knowledge System for Aviation Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14387v1"&gt;Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14477v1"&gt;GUI-Robust: A Comprehensive Dataset for Testing GUI Agent Robustness in Real-World Anomalies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14496v1"&gt;LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14502v1"&gt;Toward Safety-First Human-Like Decision Making for Autonomous Vehicles in Time-Varying Traffic Flow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14568v1"&gt;QUEST: Quality-aware Semi-supervised Table Extraction for Business Documents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14570v1"&gt;From Points to Places: Towards Human Mobility-Driven Spatiotemporal Foundation Models via Understanding Places&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14122v1"&gt;CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14126v1"&gt;Less is More: Undertraining Experts Improves Model Upcycling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14138v1"&gt;NeuroCoreX: An Open-Source FPGA-Based Spiking Neural Network Emulator with On-Chip Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14144v1"&gt;SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14158v1"&gt;S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14168v1"&gt;VideoMAR: Autoregressive Video Generatio with Continuous Tokens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14175v1"&gt;GRAM: A Generative Foundation Reward Model for Reward Generalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14196v1"&gt;Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14217v1"&gt;TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14229v1"&gt;HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14231v1"&gt;ImpReSS: Implicit Recommender System for Support Conversations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14239v1"&gt;Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14245v1"&gt;Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14276v1"&gt;Don't throw the baby out with the bathwater: How and why deep learning for ARC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14337v1"&gt;LLM-Powered Intent-Based Categorization of Phishing Emails&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14356v1"&gt;EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14375v1"&gt;IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14382v1"&gt;DepthSeg: Depth prompting in remote sensing semantic segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14386v1"&gt;ResNets Are Deeper Than You Think&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14391v1"&gt;HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14399v1"&gt;Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14404v1"&gt;Causally Steered Diffusion for Automated Video Counterfactual Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14407v1"&gt;ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14418v1"&gt;Compositional Attribute Imbalance in Vision Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14425v1"&gt;Is Selection All You Need in Differential Evolution?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14438v1"&gt;sHGCN: Simplified hyperbolic graph convolutional neural networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14451v1"&gt;Adapting Lightweight Vision Language Models for Radiological Visual Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14456v1"&gt;Hamiltonian Formalism for Comparing Quantum and Classical Intelligence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14470v1"&gt;AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14472v1"&gt;Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14539v1"&gt;Doppelgänger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14540v1"&gt;Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14569v1"&gt;Enhancing Symbolic Machine Learning by Subsymbolic Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14577v1"&gt;Object-Centric Neuro-Argumentative Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14583v1"&gt;Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14596v1"&gt;PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14625v1"&gt;Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14627v1"&gt;ACM Survey Draft on Formalising Software Requirements with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14640v1"&gt;Navigating the growing field of research on AI for software testing -- the taxonomy for AI-augmented software testing and an ontology-driven literature survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14648v1"&gt;SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14670v1"&gt;StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14677v1"&gt;Design an Editable Speech-to-Sign-Language Transformer System: A Human-Centered AI Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14723v1"&gt;Adaptive Accompaniment with ReaLchords&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14727v1"&gt;Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14731v1"&gt;Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14750v1"&gt;Exploring Speaker Diarization with Mixture of Experts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14755v1"&gt;Optimizing Length Compression in Large Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14761v1"&gt;From Bytes to Ideas: Language Modeling with Autoregressive U-Nets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14111v1"&gt;Essential-Web v1.0: 24T tokens of organized web data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14113v1"&gt;SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14130v1"&gt;KDMOS:Knowledge Distillation for Motion Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14159v1"&gt;StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14170v1"&gt;A multi-stage augmented multimodal interaction network for fish feeding intensity quantification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14177v1"&gt;Can we train ASR systems on Code-switch without real code-switch data? Case study for Singapore's languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14202v1"&gt;DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14209v1"&gt;Latent Anomaly Detection: Masked VQ-GAN for Unsupervised Segmentation in Medical CBCT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14262v1"&gt;Knowledge Adaptation as Posterior Correction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14280v1"&gt;Improving LoRA with Variational Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14287v1"&gt;Steering Robots with Inference-Time Interactions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14294v1"&gt;Uncertainty-Driven Radar-Inertial Fusion for Instantaneous 3D Ego-Velocity Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14303v1"&gt;orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14411v1"&gt;Adaptive Reinforcement Learning for Unobservable Random Delays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14412v1"&gt;RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14434v1"&gt;Unifying Streaming and Non-streaming Zipformer-based ASR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14440v1"&gt;Model compression using knowledge distillation with integrated gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14464v1"&gt;A Scalable Hybrid Training Approach for Recurrent Spiking Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14513v1"&gt;GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14534v1"&gt;Complete Characterization for Adjustment in Summary Causal Graphs of Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14562v1"&gt;AlphaDecay:Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14574v1"&gt;TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14623v1"&gt;Low-code to fight climate change: the Climaborough project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14634v1"&gt;AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14641v1"&gt;Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14652v1"&gt;Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14684v1"&gt;Refining music sample identification with a self-supervised graph neural network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14329v1"&gt;Adjustment for Confounding using Pre-Trained Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14767v1"&gt;A Variational Framework for Improving Naturalness in Generative Spoken Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14530v1"&gt;Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14114v1"&gt;Evaluating Loss Functions for Graph Neural Networks: Towards Pretraining and Generalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14143v1"&gt;Leveraging Predictive Equivalence in Decision Trees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14162v1"&gt;Common Benchmarks Undervalue the Generalization Power of Programmatic Policies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14167v1"&gt;Structured and Informed Probabilistic Modeling with the Thermodynamic Kolmogorov-Arnold Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14194v1"&gt;A Variational Information Theoretic Approach to Out-of-Distribution Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14220v1"&gt;Can Large Language Models Improve Spectral Graph Neural Networks?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14261v1"&gt;RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14420v1"&gt;Unsupervised Skill Discovery through Skill Regions Differentiation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14436v1"&gt;MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14439v1"&gt;A General Framework for Off-Policy Learning with Partially-Observed Reward&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14457v1"&gt;Dataset distillation for memorized data: Soft labels can leak held-out teacher knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14459v1"&gt;A Model-Mediated Stacked Ensemble Approach for Depression Prediction Among Professionals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14460v1"&gt;Zeroth-Order Optimization is Secretly Single-Step Policy Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14521v1"&gt;Towards Improved Research Methodologies for Industrial AI: A case study of false call reduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14563v1"&gt;Single-Example Learning in a Mixture of GPDMs with Latent Geometries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14587v1"&gt;SCISSOR: Mitigating Semantic Bias through Cluster-Aware Siamese Networks for Robust Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14619v1"&gt;Feasibility-Driven Trust Region Bayesian Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14110v1"&gt;Universal Rates of ERM for Agnostic Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14164v1"&gt;Light Aircraft Game : Basic Implementation and training results analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14251v1"&gt;Convergence-Privacy-Fairness Trade-Off in Personalized Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14263v1"&gt;Towards Robust Learning to Optimize with Theoretical Guarantees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14306v1"&gt;Fair for a few: Improving Fairness in Doubly Imbalanced Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14322v1"&gt;FRIDU: Functional Map Refinement with Guided Image Diffusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14374v1"&gt;Excessive Reasoning Attack on Reasoning LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14390v1"&gt;Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14400v1"&gt;One Size Fits None: Rethinking Fairness in Medical AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14435v1"&gt;MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14449v1"&gt;Detecting immune cells with label-free two-photon autofluorescence and deep learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14473v1"&gt;Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14479v1"&gt;Adaptive Data Augmentation for Thompson Sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14488v1"&gt;Reimagining Target-Aware Molecular Generation through Retrieval-Enhanced Aligned Diffusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14515v1"&gt;Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14518v1"&gt;Two-Player Zero-Sum Games with Bandit Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14560v1"&gt;Risk Estimation of Knee Osteoarthritis Progression via Predictive Multi-task Modelling from Efficient Diffusion Model using X-ray Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14603v1"&gt;Align Your Flow: Scaling Continuous-Time Flow Map Distillation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14607v1"&gt;Expressive Score-Based Priors for Distribution Matching with Geometry-Preserving Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14673v1"&gt;Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14698v1"&gt;Towards Desiderata-Driven Design of Visual Counterfactual Explainers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14702v1"&gt;Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14746v1"&gt;On the Hardness of Bandit Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14753v1"&gt;Cost-Aware Routing for Efficient Text-To-Image Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14123v1"&gt;Sampling from Your Language Model One Byte at a Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14186v1"&gt;Hard Contacts with Soft Gradients: Refining Differentiable Simulators for Learning and Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14198v1"&gt;AMPLIFY: Actionless Motion Priors for Robot Learning from Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14291v1"&gt;Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14293v1"&gt;SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14571v1"&gt;The Perception of Phase Intercept Distortion and its Application in Data Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14582v1"&gt;Busting the Paper Ballot: Voting Meets Adversarial Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14605v1"&gt;Unsupervised Imaging Inverse Problems with Diffusion Distribution Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14762v1"&gt;Markov Regime-Switching Intelligent Driver Model for Interpretable Car-Following Behavior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14157v1"&gt;DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14161v1"&gt;MIST: Towards Multi-dimensional Implicit Bias and Stereotype Evaluation of LLMs via Theory of Mind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14199v1"&gt;MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14203v1"&gt;Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14205v1"&gt;AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14206v1"&gt;CausalDiffTab: Mixed-Type Causal-Aware Diffusion for Tabular Data Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14211v1"&gt;Explainable Detection of Implicit Influential Patterns in Conversations via Data Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14213v1"&gt;Chaining Event Spans for Temporal Relation Grounding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14235v1"&gt;A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14285v1"&gt;From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14302v1"&gt;Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14335v1"&gt;Evaluation Should Not Ignore Variation: On the Impact of Reference Set Choice on Summarization Metrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14370v1"&gt;Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14397v1"&gt;Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14429v1"&gt;LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14448v1"&gt;How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14532v1"&gt;M2BeamLLM: Multimodal Sensing-empowered mmWave Beam Prediction with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14613v1"&gt;When Does Meaning Backfire? Investigating the Role of AMRs in NLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14646v1"&gt;GuiLoMo: Allocating Expert Number and Rank for LoRA-MoE via Bilevel Optimization with GuidedSelection Vectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14681v1"&gt;Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14704v1"&gt;Capacity Matters: a Proof-of-Concept for Transformer Memorization on Real-World Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14758v1"&gt;Reasoning with Exploration: An Entropy Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14142v1"&gt;RadFabric: Agentic AI System with Reasoning Capability for Radiology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14200v1"&gt;ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14371v1"&gt;ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14474v1"&gt;LexiMark: Robust Watermarking via Lexical Substitutions to Enhance Membership Verification of an LLM's Textual Training Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14493v1"&gt;LingoLoop Attack: Trapping MLLMs via Linguistic Context and State Entrapment into Endless Loops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14602v1"&gt;Computational Studies in Influencer Marketing: A Systematic Literature Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14629v1"&gt;VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14645v1"&gt;Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14766v1"&gt;ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14148v1"&gt;Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14153v1"&gt;Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14190v1"&gt;AsyncSwitch: Asynchronous Text-Speech Adaptation for Code-Switched ASR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14204v1"&gt;Improving Practical Aspects of End-to-End Multi-Talker Speech Recognition for Online and Offline Scenarios&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.14223v1"&gt;Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-18</guid><pubDate>Wed, 18 Jun 2025 12:19:31 +0900</pubDate></item><item><title>A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis</title><link>http://arxiv.org/abs/2506.14345v1</link><description>大規模言語モデル（LLM）の登場は情報アクセスを変革し、現在のLLMは、計画的な反復検索、検索、推論を通じて、包括的なレポート形式の回答を生成できる高度な研究システムも動かしています。しかし、現在の高度な研究システムは、地理的および/または時間的な制約を含む、文脈に富んだ質問に答えるために不可欠な地理時間的機能が不足しており、これは公衆衛生、環境科学、社会経済分析などの分野で頻繁に発生します。本稿では、次世代システムに向けた我々のビジョンを報告し、地理時間的推論を高度な研究パイプラインに統合する上での重要な技術的、インフラストラクチャ的、および評価的な課題を特定します。我々は、オープンで再現可能なインフラストラクチャと厳格な評価プロトコルに支えられ、地理時間的制約を処理する能力で検索および合成プロセスを強化することを主張します。我々のビジョンは、より高度で地理時間的に認識された高度な研究システムへの道筋を示しており、AI主導の情報アクセスの将来に潜在的な影響を与える可能性があります。

&lt;img src=""/&gt;&lt;p&gt;Bruno Martins, Piotr Gramacki, Piotr Szymański&lt;/p&gt;&lt;p&gt;Instituto Superior Técnico and INESC-ID Univesrity of Lisbon Lisbon Portugal
Wrocław University of Science and Technology Wrocław Poland&lt;/p&gt;</description><guid isPermaLink="false">2506.14345v1</guid><pubDate>Tue, 17 Jun 2025 09:38:45 +0000</pubDate></item><item><title>Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees</title><link>http://arxiv.org/abs/2506.14606v1</link><description>ハードウェアのエコシステムは急速に進化しており、既存のコードの移植性と寿命を向上させるために、異なる命令セットアーキテクチャ（ISA）間で低レベルプログラムを迅速、柔軟、かつ正確に変換することへの関心が高まっています。このトランスパイル問題の中でも特に困難なのは、命令の複雑さ、メモリモデル、実行パラダイムにおける根本的な違いから、複合命令セットコンピュータ（CISC）と縮小命令セットコンピュータ（RISC）のハードウェアアーキテクチャ間の変換です。本研究では、事前学習済みの大規模言語モデル（LLM）の翻訳能力と、確立されたソフトウェアテスト構造の厳密さを組み合わせた、ISA中心のトランスパイルパイプラインであるGG（Guaranteed Guess）を紹介します。我々の手法は、LLMを使用してあるISAから別のISAへの候補翻訳を生成し、そのような翻訳をソフトウェアテストフレームワークに組み込むことで、翻訳に対する定量化可能な信頼を構築します。我々は、2つの多様なデータセットでGGアプローチを評価し、ユニットテスト全体で高いコードカバレッジ（&gt;98%）を強制し、HumanEvalプログラムで99%、BringupBenchプログラムで49%の機能的/意味的正確性を達成しました。さらに、Apple Silicon上の最先端のRosetta 2フレームワークと我々のアプローチを比較し、トランスパイルされたコードにおいて1.73倍高速なランタイムパフォーマンス、1.47倍優れたエネルギー効率、2.41倍優れたメモリ使用量を示し、GGが現実世界のCISC-to-RISC変換タスクに有効であることを実証しました。ISAレベルのコード翻訳研究のための共通基盤を確立するために、我々のコード、データ、モデル、およびベンチマークをオープンソース化する予定です。

&lt;img src="https://arxiv.org/html/2506.14606v1/x1.png"/&gt;&lt;p&gt;Ahmed Heakl, Chaimaa Abi MBZUAI Cornell University https://ahmedheakl.github.io/Guaranteed-Guess/, Sarim Hashmi&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14606v1</guid><pubDate>Tue, 17 Jun 2025 15:06:54 +0000</pubDate></item><item><title>Deep Learning Surrogates for Real-Time Gas Emission Inversion</title><link>http://arxiv.org/abs/2506.14597v1</link><description>過渡的な大気条件下での温室効果ガス排出量のリアルタイムな特定と定量化は、環境モニタリングにおける重要な課題です。本研究では、動的な流れ場における排出速度と発生源位置の両方をベイズ推定するために、計算流体力学（CFD）の深層学習サロゲートを逐次モンテカルロアルゴリズムに組み込んだ時空間インバージョンフレームワークを導入します。高忠実度CFD出力で訓練された多層パーセプトロンでコストのかかる数値ソルバーを代替することにより、本サロゲートはガス拡散の空間的な不均一性と時間的な変化を捉え、ほぼリアルタイムの予測を実現します。チルボルトンメタン放出データセットでの検証では、完全なCFDソルバーやガウスプルームモデルと同等の精度を示し、実行時間は桁違いに高速です。シミュレーションされた障害物のある流れのシナリオ下でのさらなる実験により、複雑な環境におけるロバスト性が確認されました。本研究は、物理的な忠実性と計算上の実現可能性を両立させ、産業排出量モニタリングや、環境および科学モデリングにおけるその他の時間制約のある時空間インバージョンタスクのためのスケーラブルなソリューションを提供します。

&lt;img src="https://arxiv.org/html/2506.14597v1/extracted/6548776/source1_densities.png"/&gt;&lt;p&gt;1031 HW &amp;Philip Jonathan School of Mathematical Sciences Lancaster University Lancaster, LA1 4YF, LA1 4YF &amp;Christopher Nemeth School of Mathematical Sciences Lancaster University Lancaster, LA1 4YF Matthew Jones Shell Global Solutions International BV Amsterdam, Thomas Newman School of Mathematical Sciences Lancaster University Lancaster&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14597v1</guid><pubDate>Tue, 17 Jun 2025 15:03:21 +0000</pubDate></item><item><title>NeuralPDR: Neural Differential Equations as surrogate models for Photodissociation Regions</title><link>http://arxiv.org/abs/2506.14270v1</link><description>計算天体化学モデルは、様々な天体物理学的環境の観測を解釈し理解する上で不可欠です。JWSTやALMAのような高解像度望遠鏡の時代において、多くの天体のサブ構造が分解能を持つようになり、より小さなスケールでの天体化学モデリングの必要性が高まっています。つまり、これらの天体のシミュレーションは、観測を正確にモデル化するために物理学と化学の両方を含める必要があります。三次元流体力学と化学を組み合わせたシミュレーションの計算コストは膨大であり、化学ソルバーを効果的に代替できる代替モデルの機会が生まれます。本研究では、元の化学コードを置き換えることができる代替モデル、すなわち潜在拡張ニューラル常微分方程式を提示します。これらの代替アーキテクチャを、物理的複雑さが増す3つのデータセットでトレーニングします。最後のデータセットは、光解離領域（PDR）コードである3D-PDRを使用した分子雲の三次元シミュレーションから直接導出されます。これらの代替モデルが高速化を提供し、データセットの元の観測可能なカラム密度マップを再現できることを示します。これにより、（GPU上で）化学の迅速な推論が可能になり、観測のより高速な統計的推論や、天体物理学的環境の流体力学的シミュレーションにおける解像度の向上が可能になります。

&lt;img src="https://arxiv.org/html/2506.14270v1/x1.png"/&gt;&lt;p&gt;Gijs Vermariën, Rahul Ravichandran, Serena Viti, Thomas G. Bisbas, Xuefei Tang, Yue Zhao&lt;/p&gt;&lt;p&gt;1 Leiden Observatory, Leiden University, P.O. Box 9513, 2300 RA Leiden, The Netherlands
2 SURF, Amsterdam, The Netherlands
3 Research Center for Astronomical Computing, Zhejiang Lab, Hangzhou 311100, China
4 Transdisciplinary Research Area (TRA) ‘Matter’/Argelander-Institut für Astronomie, University of Bonn, Bonn, Germany
5 Department of Physics and Astronomy, University College London, Gower Street, London, UK&lt;/p&gt;</description><guid isPermaLink="false">2506.14270v1</guid><pubDate>Tue, 17 Jun 2025 07:35:02 +0000</pubDate></item><item><title>Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution</title><link>http://arxiv.org/abs/2506.14529v1</link><description>ネットワーク上での効果的な意思決定は、グラフ構造化データからの学習に依存することが多く、そこではグラフニューラルネットワーク（GNN）が中心的な役割を果たしますが、設定や調整には労力がかかります。このデモでは、大規模言語モデルを通じてGNNを自動化する方法を示すLLMNetを提案します。私たちのシステムは、グラフ関連の知識ベースを構築する一連のエージェントを開発し、知識に基づいた進化プロセスを通じてGNNモデルの自動構成と改良をサポートするために、検索拡張生成（RAG）を活用します。これらのエージェントは、専門的な知識ベースを備えており、知識ベースと対話することで、タスクとグラフ構造に関する洞察を抽出します。実験結果は、LLMNetが3つのグラフ学習タスクにわたる12のデータセットで優れており、GNNモデル設計の有効性を検証していることを示しています。

&lt;img src="https://arxiv.org/html/2506.14529v1/extracted/6509157/system_arch_v2.png"/&gt;&lt;p&gt;Lanning Wei, Quanming Yao
Department of Electronic Engineering, Tsinghua University
zhengxh23@mails.tsinghua.edu.cn, Xiaohan Zheng, Yong Li, liyong07@tsinghua.edu.cn, qyaoaa@tsinghua.edu.cn, weilanning@163.com&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14529v1</guid><pubDate>Tue, 17 Jun 2025 13:53:48 +0000</pubDate></item><item><title>Automatic Qiskit Code Refactoring Using Large Language Models</title><link>http://arxiv.org/abs/2506.14535v1</link><description>量子ソフトウェアフレームワークが進化するにつれて、開発者は急速に変化するAPIとの互換性を維持する上でますます困難な課題に直面しています。本研究では、大規模言語モデル（LLM）を用いてQiskitコードをリファクタリングするための新しい方法論を提示します。まず、公式Qiskitドキュメント（リリースノートなど）のさまざまなソースから移行シナリオの分類法を抽出し、異なるモジュールへの機能の移行や非推奨の使用法などの一般的なパターンを捉えます。この分類法と元のPythonソースコードをLLMへの入力として提供し、コード内の移行シナリオのインスタンスを特定し、適切なリファクタリングソリューションを提案するようにLLMに指示します。私たちのアプローチは、入力と推論プロセスをターゲットを絞った効率的な方法で構造化することにより、現在のLLMのコンテキスト長の制限に対処するように設計されています。結果は、ドメイン固有の移行知識によって導かれると、LLMがQiskitコードの移行を自動化する上で効果的に役立つことを示しています。本研究は、以前のバージョンからバージョン0.46へのQiskitコード移行のための実証済みのプロンプトと分類法、および量子コードの移行を支援するLLMの能力を評価するための方法論の両方に貢献します。

&lt;img src="https://arxiv.org/html/2506.14535v1/x1.png"/&gt;&lt;p&gt;1 José Manuel Suárez, 2 Luis Mariano Bibbó, 3 Joaquin Bogado, 4 Alejandro Fernandez&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14535v1</guid><pubDate>Tue, 17 Jun 2025 14:00:48 +0000</pubDate></item><item><title>Unified Software Engineering agent as AI Software Engineer</title><link>http://arxiv.org/abs/2506.14683v1</link><description>大規模言語モデル（LLM）技術の成長は、自動コーディングへの期待を高めています。しかし、ソフトウェアエンジニアリングは単なるコーディングにとどまらず、プロジェクトの保守や進化といった活動も含まれます。この文脈において、LLMを推論エンジンとして利用し、外部ツールを自律的に呼び出すLLMエージェントという概念が注目を集めています。しかし、LLMエージェントはAIソフトウェアエンジニアと同じなのでしょうか？本論文では、Unified Software Engineering agent（USEagent）を開発することで、この疑問を理解しようと試みます。テスト、デバッグ、修正など、特定のソフトウェアタスクに特化したエージェントを構築する既存の研究とは異なり、私たちの目標は、複数の機能を連携させ、処理できる統合エージェントを構築することです。これにより、不完全なパッチの修正、新機能の追加、他者が書いたコードの引き継ぎなど、ソフトウェア開発における複雑なシナリオを処理できる可能性が生まれます。私たちはUSEagentを、AIと人間が協力する将来のソフトウェア開発チームの一員となりうる、未来のAIソフトウェアエンジニアの最初の草案と捉えています。USEagentの有効性を評価するために、コーディング、テスト、パッチ適用など、多岐にわたるタスクで構成されるUnified Software Engineering bench（USEbench）を構築します。USEbenchは、SWE-bench、SWT-bench、REPOCODなどの既存のベンチマークからタスクを適切に組み合わせています。1,271件のリポジトリレベルのソフトウェアエンジニアリングタスクで構成されるUSEbenchでの評価において、USEagentはOpenHands CodeActAgentなどの既存の汎用エージェントと比較して、改善された有効性を示しています。USEagentの能力には、特定のコーディングタスクにおいてギャップが存在し、これは将来のAIソフトウェアエンジニアをさらに発展させるためのヒントとなります。

&lt;img src="https://arxiv.org/html/2506.14683v1/extracted/6549587/resources/react-hierarchy-v3.png"/&gt;&lt;p&gt;Abhik Roychoudhury, Leonhard Applis, Lin Tan, Nan Jiang, Shanchao Liang, Yuntong Zhang&lt;/p&gt;&lt;p&gt;0000-0001-8518-2576
0000-0002-4341-8840
0000-0002-6690-8332
0000-0002-7127-1137
0009-0001-4127-2382
0009-0005-1664-7110
National University of Singapore Singapore
Purdue University Street Address West Lafayette Indiana 47907 USA&lt;/p&gt;</description><guid isPermaLink="false">2506.14683v1</guid><pubDate>Tue, 17 Jun 2025 16:19:13 +0000</pubDate></item><item><title>GenerationPrograms: Fine-grained Attribution with Executable Programs</title><link>http://arxiv.org/abs/2506.14580v1</link><description>最近の大規模言語モデル（LLM）は、ソースを条件としたテキスト生成において目覚ましい性能を発揮しますが、出力に対する詳細な帰属を正確に提供できないことが多く、検証可能性と信頼性を損なっています。さらに、既存の帰属手法は、モデルが提供されたソースドキュメントをどのように、そしてなぜ活用して最終的な応答を生成するのかを説明しておらず、解釈可能性が制限されています。これらの課題を克服するために、実行可能な「コードエージェント」アーキテクチャにおける最近の進歩に触発された、モジュール式の生成フレームワークであるGenerationProgramsを導入します。従来の出力と帰属を同時に生成する生成手法や、事後的な帰属に依存する手法とは異なり、GenerationProgramsはプロセスを2つの異なる段階に分解します。まず、クエリに合わせて明示的に調整されたモジュール式のテキスト操作（言い換え、圧縮、融合など）で構成される実行可能なプログラム計画を作成し、次に、プログラムで指定された指示に従ってこれらの操作を実行し、最終的な応答を生成します。実証的な評価により、GenerationProgramsは、2つの長文質問応答タスクと複数ドキュメント要約タスクにおいて、ドキュメントレベルと文レベルの両方で帰属の質を大幅に向上させることが示されています。さらに、GenerationProgramsが効果的な事後帰属手法として機能し、正確な帰属の回復において従来の手法を上回ることを示します。加えて、GenerationProgramsによって生成される解釈可能なプログラムは、モジュールレベルの改善を通じて局所的な改良を可能にし、全体的な帰属の質をさらに向上させます。

&lt;img src="https://arxiv.org/html/2506.14580v1/x1.png"/&gt;&lt;p&gt;David Wan Eran Hirsch Elias Stengel-Eskin Ido Dagan Mohit Bansal UNC Chapel Hill Bar-Ilan University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14580v1</guid><pubDate>Tue, 17 Jun 2025 14:37:09 +0000</pubDate></item><item><title>Controlling Context: Generative AI at Work in Integrated Circuit Design and Other High-Precision Domains</title><link>http://arxiv.org/abs/2506.14567v1</link><description>生成AIツールは、特にチャットボットやコードアシスタントを通じて、エンジニアリングのワークフローでますます普及しています。これらのツールの認識される精度が向上するにつれて、高精度な分野で働く人々がどのようにエラーに対する警戒心を維持できるのか、また、そのようなツールの使用における他のどのような側面が彼らの仕事に支障をきたす可能性があるのかという疑問が生じます。本論文では、集積回路設計に携わるハードウェアおよびソフトウェアエンジニアとその協力者へのインタビューを分析し、生成AIツールの使用において精度が果たす役割と、彼らが直面するその他の問題点を特定します。本論文は、これらの問題点を列挙し、それらを生成AIシステムの要素にマッピングすることで、エンジニアと生成AIツール間のインタラクションのコンテキストを制御することが、彼らが直面する最大の課題の一つであると結論付けています。本論文は、インタラクティブにコンテキストを制御する能力を高めることで、この種の問題を軽減するための提言で締めくくられています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14567v1</guid><pubDate>Tue, 17 Jun 2025 14:25:32 +0000</pubDate></item><item><title>Re-Initialization Token Learning for Tool-Augmented Large Language Models</title><link>http://arxiv.org/abs/2506.14248v1</link><description>大規模言語モデルは優れた性能を示していますが、数値推論や計画生成といった複雑なタスクには苦戦しています。計算機やデータベースなどの外部ツールを大規模言語モデル（LLM）に統合することは、問題解決能力を高める上で非常に重要です。現在の手法では、各ツールに固有のトークンを割り当て、LLMがトークン予測（単語生成と同様）を通じてツールを呼び出せるようにしています。しかし、このアプローチではツールと単語トークンの関係が考慮されておらず、事前学習済みLLM内での適応性が制限されます。この問題に対処するため、初期化の観点からツールトークンを既存の単語埋め込み空間に整合させる新しいトークン学習手法を提案し、モデルの性能を向上させます。まず、ツールの名前または説明に基づいて各ツールの事前トークン埋め込みを構築し、学習可能なツールトークン埋め込みを初期化および正則化するために使用します。これにより、学習された埋め込みが単語トークン空間と適切に整合され、ツール呼び出しの精度が向上します。GSM8K-XL、FuncQA、KAMEL、VirtualHomeデータセットを使用して、数値推論、知識ベースの質問応答、および具体化された計画生成などのタスクでこの手法を評価します。その結果、CoT、REACT、ICL、ToolkenGPTなどの最近のベースラインと比較して明確な改善が見られ、我々のアプローチが多様なドメインにわたる関連トークンを通じてLLMをツールで効果的に拡張することを示しています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14248v1</guid><pubDate>Tue, 17 Jun 2025 07:11:00 +0000</pubDate></item><item><title>Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team</title><link>http://arxiv.org/abs/2506.14234v1</link><description>複雑な推論において目覚ましい進歩が見られるにもかかわらず、現在の巨大言語モデル（LLM）は通常、孤立して動作し、各問題を独立した試みとして扱い、経験的な知識を蓄積または統合することはありません。対照的に、オリンピックやプログラミングコンテストのチームなどの熟練した問題解決者は、コーチからの指導を受け、過去の問題から直感を養い、ツールの使い方やライブラリの機能を活用し、同僚の専門知識や経験に基づいて戦略を適応させ、試行錯誤を通じて推論を継続的に洗練し、競技中であっても他の関連する問題から学ぶなど、豊富な経験を活用します。私たちは、ブラックボックスLLMに、全体的な経験の永続的で進化する記憶を装備する、トレーニング不要のマルチエージェント推論フレームワークであるXolverを紹介します。Xolverは、外部および自己検索、ツール使用、協調的インタラクション、エージェント主導の評価、反復的な洗練など、多様な経験モダリティを統合します。推論時に、関連する戦略、コード断片、抽象的な推論パターンから学習することで、Xolverはゼロからソリューションを生成することを回避し、孤立した推論から経験を認識する言語エージェントへの移行を示します。オープンウェイトモデルとプロプライエタリモデルの両方に基づいて構築されたXolverは、一貫して専門的な推論エージェントを上回ります。軽量なバックボーン（例：QWQ-32B）であっても、Qwen3-235B、Gemini 2.5 Pro、o3、o4-mini-highなどの高度なモデルをしばしば凌駕します。o3-mini-highを使用すると、GSM8K（98.1％）、AIME'24（94.4％）、AIME'25（93.7％）、Math-500（99.8％）、LiveCodeBench-V5（91.6％）で新たな最高の結果を達成し、全体的な経験学習が、専門家レベルの推論が可能な汎用エージェントへの重要なステップであることを強調しています。コードとデータはhttps://kagnlp.github.io/xolver.github.io/で入手できます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14234v1</guid><pubDate>Tue, 17 Jun 2025 06:47:19 +0000</pubDate></item><item><title>AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes</title><link>http://arxiv.org/abs/2506.14728v1</link><description>知識蒸留は、大規模言語モデル（LLM）の出力や内部表現を整合させることで、より小さなモデルに圧縮するための成熟した分野となっていますが、計画、記憶、ツール利用を伴うLLMベースのエージェントの蒸留は、比較的未開拓のままです。既存のエージェント蒸留手法は、通常、教師エージェントの完全な軌跡を再生したり、教師のツール使用をステップごとに模倣したりしますが、学生エージェントが新しい環境で動的に計画し、行動するように訓練するには苦労することがよくあります。そこで、我々はAgentDistillという、教師エージェントが自律的に生成する構造化された再利用可能なタスク解決モジュールであるModel-Context-Protocols（MCP）を直接再利用することで、効率的かつスケーラブルな知識伝達を可能にする、新しいトレーニング不要のエージェント蒸留フレームワークを提案します。蒸留されたMCPの再利用により、学生エージェントはドメインを超えて能力を一般化し、最小限の監督や人的介入で新しい問題を解決できます。生物医学および数学のベンチマークでの実験では、小規模言語モデル上に構築された蒸留された学生エージェントが、OctoTools（GPT-4o）のような大規模LLMを使用する高度なシステムに匹敵する性能を達成できることを示しており、スケーラブルで費用対効果の高いインテリジェントエージェントを構築する上での我々のフレームワークの有効性を強調しています。

&lt;img src="https://arxiv.org/html/2506.14728v1/x1.png"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14728v1</guid><pubDate>Tue, 17 Jun 2025 17:08:32 +0000</pubDate></item><item><title>Collaborative Editable Model</title><link>http://arxiv.org/abs/2506.14146v1</link><description>垂直ドメイン大規模言語モデル（LLM）は、金融、医療、法律などの専門的なシナリオで重要な役割を果たしますが、その学習は大規模なアノテーション付きデータと相当な計算資源に依存することが多く、迅速な開発と継続的な反復を妨げています。これらの課題に対処するため、私たちは協調編集可能モデル（CoEM）を導入します。これは、ユーザーが提供したドメインスニペットから候補知識プールを構築し、インタラクティブなユーザーモデル対話とユーザー評価および帰属分析を活用して、価値の高い知識の断片を特定し、これらの断片をインコンテキストプロンプトを介して注入することで、軽量なドメイン適応を実現します。価値の高い知識により、LLMはより正確でドメイン固有のコンテンツを生成できます。金融情報シナリオでは、約120人のユーザーから15,000件のフィードバックを収集し、生成された洞察の質を評価するためにユーザー評価でCoEMを検証し、従来のファインチューニングワークフローの時間と計算コストを回避しながら、ドメイン固有の生成における大幅な改善を実証します。

&lt;img src="https://arxiv.org/html/2506.14146v1/x1.png"/&gt;&lt;p&gt;Aitong Wu, Guangda Sun, Kaiwen Tang, Yao Lu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14146v1</guid><pubDate>Tue, 17 Jun 2025 03:20:41 +0000</pubDate></item><item><title>Accurate and scalable exchange-correlation with deep learning</title><link>http://arxiv.org/abs/2506.14665v1</link><description>密度汎関数理論（DFT）は、分子や物質の特性を予測するために最も広く使用されている電子構造計算法です。DFTは、原理的にはシュレーディンガー方程式の厳密な再構成ですが、実際の応用では、未知の交換相関（XC）汎関数に対する近似に依存しています。既存のXC汎関数のほとんどは、計算効率を犠牲にして精度を向上させる、ますます複雑な手作りの特徴の限られたセットを使用して構築されています。しかし、現在の近似法では、化学精度（通常、1 kcal/mol未満の誤差として定義される）で実験室実験を予測的にモデル化するための精度と汎用性を実現していません。本研究では、データから直接表現を学習することにより、高価な手設計の特徴を回避する、最新の深層学習ベースのXC汎関数であるSkalaを紹介します。Skalaは、半局所DFTの典型的な計算効率を維持しながら、小分子の原子化エネルギーに対して化学精度を達成します。この性能は、計算負荷の高い波動関数ベースの方法を使用して生成された、前例のない量の高精度参照データでトレーニングすることによって実現されています。特に、Skalaは、多様な化学をカバーする追加のトレーニングデータによって体系的に改善されます。原子化エネルギーを超えた化学に合わせた適度な量の追加の高精度データを組み込むことで、Skalaは、半局所DFTのコストで、一般的な主族化学全体で最高の性能を発揮するハイブリッド汎関数に匹敵する精度を達成します。トレーニングデータセットが拡大し続けるにつれて、Skalaは第一原理シミュレーションの予測能力をさらに強化する態勢を整えています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14665v1</guid><pubDate>Tue, 17 Jun 2025 15:56:56 +0000</pubDate></item><item><title>Shake-down spectroscopy as state- and site-specific probe of ultrafast chemical dynamics</title><link>http://arxiv.org/abs/2506.14498v1</link><description>光化学反応中に分子内で起こる多岐にわたる超高速な電子および構造変化を追跡することは、時間分解技術における最近の実験的および計算的進歩の恩恵を受ける困難な試みである。分子の結合構造の全体像を提供する価電子状態の測定と、局所環境に関する洞察を提供する内殻電子状態の測定は、従来異なるアプローチを必要とし、しばしば別々に研究されてきた。本研究では、シード型自由電子レーザー（FEL）からのX線パルスにより、価電子励起分子におけるシェイクダウン過程に起因する微弱なサテライト状態を捉える高分解能時間分解X線光電子分光（XPS）の測定が可能になることを実証する。このアプローチは、価電子状態と内殻状態の両方の研究の利点を効果的に組み合わせるものである。この手法を、解離前ダイナミクスを決定する上での内部転換（IC）と項間交差（ISC）の役割が議論の余地がある光励起CS$_2$分子の調査に適用した。FERMI FELで取得した光励起CS$_2$のXPSスペクトルを示す。高分解能測定を、対応する高精度多参照量子化学計算から得られたスペクトルと比較した結果、シェイクダウンサテライトチャネルが価電子の電子状態と幾何学的変化の両方に非常に敏感であることが明らかになった。解離前ダイナミクスの以前の研究では、一重項励起状態と三重項励起状態の分岐に関して不明確な割り当てが生じていた。シェイクダウンのスピン選択性を示す傾向則を導き出した。この選択性により、解離前ダイナミック経路に沿って追跡された集団を持つ、明るい一重項励起状態と暗い一重項励起状態からの寄与を明確に割り当てることができる。

&lt;img src="https://arxiv.org/html/2506.14498v1/x1.png"/&gt;&lt;p&gt;Alberto Simoncig, Alexander D. Brynes, Alexander Demidovich, Bruno N. C. Tenorio, Carlo Callegari, Caterina Vozzi, Cesare Grazioli, Daniel Rolles, David M. P. Holland, Davide Faccialà, Felix Allum, Henry Thompson, Jacob Pedersen, Kevin C. Prince, Marcello Coreno, Marco Zangrando, Matteo Bonanomi, Michael S. Schuurman, Michele Devetta, Michele Di Fraia, Miltcho B. Danailov, Nitish Pal, Oksana Plekan, Paolo Piseri, Piero Decleva, Raimund Feifel, Richard J. Squibb, Ruharid J. G. Forbes, Russell S. Minns, Sonia Coriani&lt;/p&gt;&lt;p&gt;Department of Chemistry, Technical University of Denmark, Kgs. Lyngby, DK-2800, Denmark
Dipartimento di Fisica “Aldo Pontremoli”, Universitá degli Studi di
Milano, 20133, Milano, Italy
Dipartimento di Fisica, Politecnico di Milano, 20133, Milano, Italy
Dipartimento di Science Chimiche e Farmaceutiche, Universitá degli
Studi di Trieste, Trieste, 34127, Italy
National Research Council Canada, Ottawa, K1A0R6, Ontario, Canada
[&lt;/p&gt;</description><guid isPermaLink="false">2506.14498v1</guid><pubDate>Tue, 17 Jun 2025 13:23:12 +0000</pubDate></item><item><title>Accurate Chemistry Collection: Coupled cluster atomization energies for broad chemical space</title><link>http://arxiv.org/abs/2506.14492v1</link><description>化学計算手法の開発と改善には、サブ化学精度（すなわち、十分に正確な実験または理論的参照データから$\pm$1 kcal mol$^{-1}$以内）の正確な熱化学データが不可欠です。生成熱や総原子化エネルギー（TAE）のような、挑戦的な熱化学的特性は、複数の結合再配列を伴う複雑な化学変換を正確に記述する計算化学的手法の能力を厳密にテストするため、特に関心を集めています。しかし、このレベルの精度を確実に達成できる既存の熱化学データセットは、サイズまたは範囲のいずれかで制限されています。非常に正確な参照値を持つデータセットはデータポイント数が少なく、より大きなデータセットは精度が低いデータを提供するか、化学空間の狭い部分のみをカバーします。したがって、既存のデータセットは、広い化学空間にわたって予測精度を持つデータ駆動型手法を開発するには不十分です。Microsoft Research Accurate Chemistry Collection（MSR-ACC）は、この課題に対処します。ここでは、W1-F12熱化学プロトコルを介してCCSD(T)/CBSレベルで得られた76,879個の総原子化エネルギーのMSR-ACC/TAE25データセットを提供します。このデータセットは、化学グラフを列挙およびサンプリングすることにより、アルゴンまでのすべての元素の化学空間を網羅的にカバーするように構築されており、特定の化学空間のサブスペース（医薬品のような、有機、または実験的に観察された分子など）への偏りを回避しています。MSR-ACCの最初のデータセットにより、前例のない精度と範囲で予測的な計算化学的手法を開発するためのデータ駆動型アプローチが可能になります。

&lt;img src="https://arxiv.org/html/2506.14492v1/x3.png"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14492v1</guid><pubDate>Tue, 17 Jun 2025 13:12:43 +0000</pubDate></item><item><title>Thermal Conductivity Of Monolayer Hexagonal Boron Nitride: Four-Phonon Scattering And Quantum Sampling Effects</title><link>http://arxiv.org/abs/2506.14547v1</link><description>単層六方晶窒化ホウ素は、典型的な平面2次元系材料であり、その優れた振動特性、分光特性、輸送特性について多くの研究が行われてきた。格子熱伝導率は依然として不確かであり、理論的および実験的な報告では218～1060 Wm-1K-1の間でばらつきがある。温度依存性が強く、ひずみ効果や同位体濃度に敏感である。同位体散乱の影響は広く研究され、よく理解されているが、核量子効果と4フォノン散乱はこれまで無視されてきた。単層六方晶窒化ホウ素は軽元素で構成されており、さらに3フォノン散乱の位相空間が鏡面対称性によって制限されているため、これらの効果は同位体散乱と同程度の大きさになる可能性があり、この系の格子熱伝導率を制限する基本的なプロセスに対する全く異なる理解につながる可能性がある。本研究では、古典分子動力学と経路積分分子動力学の両方を、温度依存有効ポテンシャル法と組み合わせて使用し、同位体散乱、3フォノン散乱、4フォノン散乱、核量子効果を含む温度依存の再規格化されたフォノンを計算する。後者2つが広い温度範囲にわたって格子熱伝導率に与える影響と、フォノン寿命に与える影響を示す。全体として、本研究は固体中の格子熱伝導率の計算のための堅牢なフレームワークを提供し、文献に見られる様々な結果を説明するのに役立つ定量的な改善と物理的な理解を提供する。

&lt;img src="https://arxiv.org/html/2506.14547v1/x1.png"/&gt;&lt;p&gt;Aloïs Castellano, José Pedro Alvarinhas Batista, Matthieu J. Verstraete&lt;/p&gt;&lt;p&gt;ITP, Physics Department, Utrecht University 3508 TA Utrecht, The Netherlands
Nanomat group, Q-MAT center, CESAM research unit and European Theoretical Spectroscopy Facility, Université de Liège, allée du 6 août, 19, B-4000 Liège, Belgium&lt;/p&gt;</description><guid isPermaLink="false">2506.14547v1</guid><pubDate>Tue, 17 Jun 2025 14:04:50 +0000</pubDate></item><item><title>A Spintronic Battery with Reversible Modulation of Spin Polarization through Li Charge/Discharge: A First Principles Computational Modelling Case Study for an Antiperovskite System</title><link>http://arxiv.org/abs/2506.14401v1</link><description>現代エレクトロニクス、再生可能エネルギー、スマートシステムといった新興分野の進歩を定義する重要な概念は電荷蓄積であり、これは主に様々な電池化学およびシステムに具現化されています。電荷特性に加えて、電子はスピン特性も持っており、これはスピントロニクスの分野で利用され、従来の電子工学ではアクセスできない斬新な磁気制御デバイス動作を実現します。興味深い疑問は、デバイス設計と応用の範囲を拡大するために、これら2つを単一のデバイス概念に統合できるかどうかです。本稿では、公称化学量論組成がLixFe3SnC (x = 1, 2, 3, 4)で表される、リチウム化されていない状態とリチウム化された状態の導電性金属間アンチペロブスカイトの実験的および理論的研究を組み合わせ、可逆的かつ同時的な電荷およびスピン偏極蓄積の原理を確立します。これは、スピントロニクス電池の概念を表す「イオノスピントロニクス」と適切に名付けることができます。しかし、実験結果は、リチウム化により、系が（SnとLiの高い親和性により）スズ-リチウム合金とリチウム化されたFe3Cからなる二相状態になることを示しました。このプロセスは、複数回のサイクル性（再充電可能性）を示します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14401v1</guid><pubDate>Tue, 17 Jun 2025 11:02:41 +0000</pubDate></item><item><title>Isostructural electronic transition in MoS$_2$ probed by solid-state high harmonic generation spectroscopy</title><link>http://arxiv.org/abs/2506.14215v1</link><description>ダイヤモンドアンビルセル（DAC）内で極限的な圧力下にある物質を研究することは、物質の新しい状態を発見するための鍵ですが、現在、この環境下で電子構造を直接測定できる方法はありません。固体高次高調波発生（sHHG）は、物質の電子構造への新しい全光学的窓を提供します。我々は、30 GPaまでの$2H$-MoS$_2$を調べることにより、DAC内部でのsHHG分光法を実証し、最低直接バンドギャップが$\textbf{K}$点から$\Gamma$点への圧力誘起クロスオーバーを明らかにしました。この遷移は、構造相変化がないにもかかわらず、高調波強度の鋭い極小値とsHHG偏光異方性の30度の回転として現れます。第一原理シミュレーションは、これらの特徴をブリルアンゾーン内の異なる点における競合する励起経路間の干渉に帰属します。我々の結果は、sHHGを高圧下での電子遷移に対する高感度なプローブとして確立し、従来の技術では検出を免れる量子現象へのアクセスを可能にします。

&lt;img src="https://arxiv.org/html/2506.14215v1/x1.png"/&gt;&lt;p&gt;Bailey R. Nebgen, Craig P. Schwartz, Dean Smith, Diana Y. Qiu, Jacob A. Spies, Michael W. Zuerch, Randy M. Sterbentz, Victor Chang Lee&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.14215v1</guid><pubDate>Tue, 17 Jun 2025 06:10:33 +0000</pubDate></item></channel></rss>