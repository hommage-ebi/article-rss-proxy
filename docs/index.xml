<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Tue, 17 Jun 2025 03:22:31 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-17</title><link>https://arxiv.org/2025-06-17</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13169v1"&gt;Hydrogen bond symmetrization in high-pressure ice clathrates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13236v1"&gt;Penta-twinned gold nanoparticles under pressure: a comprehensive study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13381v1"&gt;Crystal field tuned spin-flip luminescence in NiPS3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13454v1"&gt;A first-principles investigation of altermagnetism in CrSb2 under applied pressure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13526v1"&gt;On the ambient conditions crystal structure of AgSbTe2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13540v1"&gt;Extrinsic Dopants as Growth Modifiers in Cu-Cr-O delafossites: A Study of Incorporation Limits and Film Properties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13550v1"&gt;Faceting transition in aluminum as a grain boundary phase transition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13696v1"&gt;Photomagnetic-Chiral Anisotropy mediated by Chirality-Driven Asymmetric Spin Splitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13411v1"&gt;2D MXene-Based Photocatalysts for Efficient Water Splitting and Hydrogen Evolution: A brief review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13427v1"&gt;Sodium induced beneficial effects in wide bandgap Cu(In,Ga)S2 solar cell with 15.7% efficiency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13448v1"&gt;Electronic Correlations Control Interlayer Coupling and Magnetic Transition in MnBi$_2$Te$_4$/MnBr$_3$ Heterostructure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13493v1"&gt;Nonlinear bulk photocurrent probe Z2 topological phase transition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13399v1"&gt;Role of topotactic hydrogen in Superconductivity of Infinite-layer Nickelate NdNiO$_{2}$: A first-principles and variational Monte Carlo study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13719v1"&gt;Direct visualization of visible-light hyperbolic plasmon polaritons in real space and time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13721v1"&gt;Catalogue of chiral phonon materials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13675v1"&gt;Significant role of first-principles electron-phonon coupling in the electronic and thermoelectric properties of LiZnAs and ScAgC semiconductors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13644v1"&gt;Assignment of collision-induced four-level double-resonance transitions in the 3$ν$${_3}$ ${\Leftarrow}$ $ν$${_3}$ spectral region of methane&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13377v1"&gt;Uncovering the nanoscopic phase behavior of ternary solutions in the presence of electrolytes: from pre-Ouzo to Ouzo region&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13332v1"&gt;Efficient algorithms for quantum chemistry on modular quantum processors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13176v1"&gt;An advanced heat transfer model for Eulerian-Lagrangian simulations of industrial gas-solid flow systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13350v1"&gt;Reactions of abiogenic hydrocarbons in Earth's upper mantle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13738v1"&gt;Quantized local reduced-order modeling in time (ql-ROM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13299v1"&gt;Non-reciprocal interactions reshape cells in a model for symbiosis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13745v1"&gt;Numerical approach to second-order canonical perturbation theory in the planetary 3-body problem. Application to exoplanets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13362v1"&gt;Mitigating loss of variance in ensemble data assimilation: machine learning-based and distance-free localizations for better covariance estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13037v1"&gt;MAGIC: Multi-Agent Argumentation and Grammar Integrated Critiquer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13082v1"&gt;Discerning What Matters: A Multi-Dimensional Assessment of Moral Competence in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13223v1"&gt;Towards Explaining Monte-Carlo Tree Search by Using Its Enhancements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13249v1"&gt;Generalized Proof-Number Monte-Carlo Tree Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13276v1"&gt;Navigating the Black Box: Leveraging LLMs for Effective Text-Level Graph Injection Attacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13404v1"&gt;A Technical Study into Small Reasoning Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13600v1"&gt;The ASP-based Nurse Scheduling System at the University of Yamanashi Hospital&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13044v1"&gt;Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13049v1"&gt;Beyond the First Read: AI-Assisted Perceptual Error Detection in Chest Radiography Accounting for Interobserver Variability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13058v1"&gt;DualFast: Dual-Speedup Framework for Fast Sampling of Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13060v1"&gt;Rethinking Explainability in the Era of Multimodal AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13065v1"&gt;MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13092v1"&gt;A Memetic Walrus Algorithm with Expert-guided Strategy for Adaptive Curriculum Sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13099v1"&gt;Dynamic Graph Condensation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13111v1"&gt;Overcoming Overfitting in Reinforcement Learning via Gaussian Process Diffusion Policy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13134v1"&gt;Quantum AGI: Ontological Foundations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13148v1"&gt;Adapting LLMs for Minimal-edit Grammatical Error Correction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13164v1"&gt;Real Time Self-Tuning Adaptive Controllers on Temperature Control Loops using Event-based Game Theory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13171v1"&gt;Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13182v1"&gt;From Empirical Evaluation to Context-Aware Enhancement: Repairing Regression Errors with LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13192v1"&gt;Breaking Thought Patterns: A Multi-Dimensional Reasoning Framework for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13205v1"&gt;Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13222v1"&gt;NeuroPhysNet: A FitzHugh-Nagumo-Based Physics-Informed Neural Network Framework for Electroencephalograph (EEG) Analysis and Motor Imagery Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13252v1"&gt;Vector Ontologies as an LLM world view extraction method&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13268v1"&gt;Energy-Efficient Digital Design: A Comparative Study of Event-Driven and Clock-Driven Spiking Neurons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13292v1"&gt;Automatic Multi-View X-Ray/CT Registration Using Bone Substructure Contours&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13298v1"&gt;Fair Generation without Unfair Distortions: Debiasing Text-to-Image Generation with Entanglement-Free Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13307v1"&gt;Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Image Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13322v1"&gt;Active Multimodal Distillation for Few-shot Action Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13340v1"&gt;Probabilistic Modeling of Spiking Neural Networks with Contract-Based Verification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13356v1"&gt;StoryBench: A Dynamic Benchmark for Evaluating Long-Term Memory with Multi Turns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13403v1"&gt;Deflating Deflationism: A Critical Perspective on Debunking Arguments Against LLM Mentality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13406v1"&gt;CALM: Consensus-Aware Localized Merging for Multi-Task Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13450v1"&gt;A Neural Model for Word Repetition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13453v1"&gt;Towards a Formal Specification for Self-organized Shape Formation in Swarm Robotics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13456v1"&gt;Block-wise Adaptive Caching for Accelerating Diffusion Policy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13464v1"&gt;Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13468v1"&gt;An Interdisciplinary Approach to Human-Centered Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13469v1"&gt;A Two-stage Optimization Method for Wide-range Single-electron Quantum Magnetic Sensing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13472v1"&gt;ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13479v1"&gt;Position: Pause Recycling LoRAs and Prioritize Mechanisms to Uncover Limits and Effectiveness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13529v1"&gt;Seismic Acoustic Impedance Inversion Framework Based on Conditional Latent Generative Diffusion Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13559v1"&gt;Understand the Implication: Learning to Think for Pragmatic Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13566v1"&gt;A Production Scheduling Framework for Reinforcement Learning Under Real-World Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13599v1"&gt;CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13638v1"&gt;DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13654v1"&gt;Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13666v1"&gt;We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13674v1"&gt;Prefix-Tuning+: Modernizing Prefix-Tuning through Attention Independent Prefix Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13690v1"&gt;Meta-learning how to Share Credit among Macro-Actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13692v1"&gt;Balancing Knowledge Delivery and Emotional Comfort in Healthcare Conversational Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13702v1"&gt;Value-Free Policy Optimization via Reward Partitioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13705v1"&gt;TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13730v1"&gt;BanditWare: A Contextual Bandit-based Framework for Hardware Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13741v1"&gt;PB$^2$: Preference Space Exploration via Population-Based Methods in Preference-Based Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13751v1"&gt;LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13752v1"&gt;Steering LLM Thinking with Budget Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13759v1"&gt;Discrete Diffusion in Large Language and Multimodal Models: A Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13056v1"&gt;Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13070v1"&gt;CHILL at SemEval-2025 Task 2: You Can't Just Throw Entities and Hope -- Make Your LLM to Get Them Right&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13087v1"&gt;IKDiffuser: Fast and Diverse Inverse Kinematics Solution Generation for Multi-arm Robotic Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13102v1"&gt;Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13113v1"&gt;Dynamic Reinsurance Treaty Bidding via Multi-Agent Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13130v1"&gt;ZINA: Multimodal Fine-grained Hallucination Detection and Editing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13157v1"&gt;Machine Learning as Iterated Belief Change a la Darwiche and Pearl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13160v1"&gt;CertDW: Towards Certified Dataset Ownership Verification via Conformal Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13187v1"&gt;Dynamic Context-oriented Decomposition for Task-aware Low-rank Adaptation with Less Forgetting and Faster Convergence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13195v1"&gt;ViT-NeBLa: A Hybrid Vision Transformer and Neural Beer-Lambert Framework for Single-View 3D Reconstruction of Oral Anatomy from Panoramic Radiographs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13206v1"&gt;Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13244v1"&gt;No-Regret Learning Under Adversarial Resource Constraints: A Spending Plan Is All You Need!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13245v1"&gt;A Game-Theoretic Negotiation Framework for Cross-Cultural Consensus in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13246v1"&gt;On Immutable Memory Systems for Artificial Agents: A Blockchain-Indexed Automata-Theoretic Framework Using ECDH-Keyed Merkle Chains&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13253v1"&gt;Distinct Computations Emerge From Compositional Curricula in In-Context Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13265v1"&gt;Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13277v1"&gt;SeqPE: Transformer with Sequential Position Encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13300v1"&gt;Seewo's Submission to MLC-SLM: Lessons learned from Speech Reasoning Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13313v1"&gt;Large Language Models as 'Hidden Persuaders': Fake Product Reviews are Indistinguishable to Humans and Machines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13318v1"&gt;Vine Copulas as Differentiable Computational Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13323v1"&gt;Tady: A Neural Disassembler without Structural Constraint Violations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13342v1"&gt;Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13384v1"&gt;Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13415v1"&gt;Simple is what you need for efficient and accurate medical image segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13474v1"&gt;Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13476v1"&gt;ESRPCB: an Edge guided Super-Resolution model and Ensemble learning for tiny Printed Circuit Board Defect detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13505v1"&gt;UAV Object Detection and Positioning in a Mining Industrial Metaverse with Custom Geo-Referenced Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13579v1"&gt;Flexible-length Text Infilling for Discrete Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13583v1"&gt;Can you see how I learn? Human observers' inferences about Reinforcement Learning agents' learning processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13590v1"&gt;Agent Capability Negotiation and Binding Protocol (ACNBP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13609v1"&gt;Avoiding Obfuscation with Prover-Estimator Debate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13611v1"&gt;A Hybrid Artificial Intelligence Method for Estimating Flicker in Power Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13612v1"&gt;EBS-CFL: Efficient and Byzantine-robust Secure Clustered Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13628v1"&gt;Graph-Convolution-Beta-VAE for Synthetic Abdominal Aorta Aneurysm Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13679v1"&gt;ROSA: Harnessing Robot States for Vision-Language and Action Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13717v1"&gt;Contrastive Self-Supervised Learning As Neural Manifold Packing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13726v1"&gt;Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13727v1"&gt;Attribution-guided Pruning for Compression, Circuit Discovery, and Targeted Correction in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13734v1"&gt;Instruction Following by Boosting Attention of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13746v1"&gt;Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13754v1"&gt;VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13763v1"&gt;Diagnosing and Improving Diffusion Models by Estimating the Optimal Loss Value&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13119v1"&gt;PhenoKG: Knowledge Graph-Driven Gene Discovery and Patient Insights from Phenotypes Alone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13344v1"&gt;LapDDPM: A Conditional Graph Diffusion Model for scRNA-seq Generation with Spectral Adversarial Perturbations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13642v1"&gt;Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13584v1"&gt;From Data-Driven to Purpose-Driven Artificial Intelligence: Systems Thinking for Data-Analytic Automation of Patient Care&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13036v1"&gt;Forecast-Then-Optimize Deep Learning Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13048v1"&gt;The Space Complexity of Learning-Unlearning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13083v1"&gt;Uncertainty-Aware Graph Neural Networks: A Multi-Hop Evidence Fusion Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13163v1"&gt;Efficient Algorithms for Logistic Contextual Slate Bandits with Bandit Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13196v1"&gt;KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13203v1"&gt;Fatigue-Aware Adaptive Interfaces for Wearable Devices Using Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13234v1"&gt;The Butterfly Effect: Neural Network Training Trajectories Are Highly Sensitive to Initial Conditions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13331v1"&gt;Mixture of Cognitive Reasoners: Modular Reasoning with Brain-Like Specialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13345v1"&gt;Learning to Explore in Diverse Reward Settings via Temporal-Difference-Error Maximization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13400v1"&gt;Realtime-Capable Hybrid Spiking Neural Networks for Neural Decoding of Cortical Activity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13410v1"&gt;Training Neural Networks by Optimizing Neuron Positions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13416v1"&gt;Spiking Neural Networks for Low-Power Vibration-Based Predictive Maintenance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13608v1"&gt;Assessing the Limits of In-Context Learning beyond Functions using Partially Ordered Relation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13651v1"&gt;xbench: Tracking Agents Productivity Scaling with Profession-Aligned Real-World Evaluations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13672v1"&gt;The Courage to Stop: Overcoming Sunk Cost Fallacy in Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13678v1"&gt;A Gravity-informed Spatiotemporal Transformer for Human Activity Intensity Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13715v1"&gt;Sharpness-Aware Machine Unlearning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13755v1"&gt;MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13758v1"&gt;AI reconstruction of European weather from the Euro-Atlantic regimes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13045v1"&gt;A Comprehensive Survey on Continual Learning in Generative Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13059v1"&gt;Multipole Attention for Efficient Long Context Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13064v1"&gt;CoIFNet: A Unified Framework for Multivariate Time Series Forecasting with Missing Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13086v1"&gt;Fast and Furious Symmetric Learning in Zero-Sum Games: Gradient Descent as Fictitious Play&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13104v1"&gt;Equitable Electronic Health Record Prediction with FAME: Fairness-Aware Multimodal Embedding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13107v1"&gt;Honesty in Causal Forests: When It Helps and When It Hurts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13116v1"&gt;Crime Hotspot Prediction Using Deep Graph Convolutional Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13123v1"&gt;SAGDA: Open-Source Synthetic Agriculture Data for Africa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13125v1"&gt;Stochastic Multi-Objective Multi-Armed Bandits: Regret Definition and Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13139v1"&gt;Random Matrix Theory for Deep Learning: Beyond Eigenvalues of Linear Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13153v1"&gt;Dynamic Preference Multi-Objective Reinforcement Learning for Internet Network Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13181v1"&gt;Align-then-Unlearn: Embedding Alignment for LLM Unlearning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13239v1"&gt;Restarted contractive operators to learn at equilibrium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13243v1"&gt;Lightweight Task-Oriented Semantic Communication Empowered by Large-Scale AI Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13259v1"&gt;An Explainable and Interpretable Composite Indicator Based on Decision Rules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13274v1"&gt;AdaLRS: Loss-Guided Adaptive Learning Rate Search for Efficient Foundation Model Pretraining&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13320v1"&gt;Action Dubber: Timing Audible Actions via Inflectional Flow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13390v1"&gt;Experimental Design for Semiparametric Bandits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13452v1"&gt;Balancing Intensity and Focality in Directional DBS Under Uncertainty: A Simulation Study of Electrode Optimization via a Metaheuristic L1L1 Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13485v1"&gt;Curriculum Learning for Biological Sequence Prediction: The Case of De Novo Peptide Sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13533v1"&gt;Learning Augmented Graph $k$-Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13536v1"&gt;What Matters in Learning from Large-Scale Datasets for Robot Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13541v1"&gt;Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13575v1"&gt;Machine Learning-Driven Compensation for Non-Ideal Channels in AWG-Based FBG Interrogator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13585v1"&gt;MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13613v1"&gt;Variational Inference with Mixtures of Isotropic Gaussians&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13652v1"&gt;PeakWeather: MeteoSwiss Weather Station Measurements for Spatiotemporal Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13657v1"&gt;Lecture Video Visual Objects (LVVO) Dataset: A Benchmark for Visual Object Detection in Educational Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13680v1"&gt;Hybrid Meta-learners for Estimating Heterogeneous Treatment Effects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13681v1"&gt;Turning Down the Heat: A Critical Analysis of Min-p Sampling in Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13688v1"&gt;What Happens During the Loss Plateau? Understanding Abrupt Learning in Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13710v1"&gt;Gradient-Normalized Smoothness for Optimization with Approximate Hessians&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13061v1"&gt;Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13150v1"&gt;Federated ADMM from Bayesian Duality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13173v1"&gt;Efficient Approximate Temporal Triangle Counting in Streaming with Predictions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13217v1"&gt;Polyra Swarms: A Shape-Based Approach to Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13286v1"&gt;The impact of uncertainty on regularized learning in games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13380v1"&gt;Decompositional Reasoning for Graph Retrieval with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13408v1"&gt;HELENA: High-Efficiency Learning-based channel Estimation using dual Neural Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13488v1"&gt;Imaging at the quantum limit with convolutional neural networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13496v1"&gt;Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13514v1"&gt;TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13561v1"&gt;Perfect Privacy for Discriminator-Based Byzantine-Resilient Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13593v1"&gt;Calibrated Predictive Lower Bounds on Time-to-Unsafe-Sampling in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13614v1"&gt;Exploiting the Exact Denoising Posterior Score in Training-Free Guidance of Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13649v1"&gt;EUNIS Habitat Maps: Enhancing Thematic and Spatial Resolution for Europe through Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13687v1"&gt;Enforcing tail calibration when training probabilistic forecast models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13712v1"&gt;Understanding Lookahead Dynamics Through Laplace Transform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13714v1"&gt;Understanding Learning Invariance in Deep Linear Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13498v1"&gt;A Survey on Imitation Learning for Contact-Rich Tasks in Robotics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13055v1"&gt;CFBenchmark-MM: Chinese Financial Assistant Benchmark for Multimodal Large Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13066v1"&gt;FinLMM-R1: Enhancing Financial Reasoning in LMM through Scalable Data and Reward Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13143v1"&gt;CMU's IWSLT 2025 Simultaneous Speech Translation System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13178v1"&gt;Enhancing Large Language Models with Reliable Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13180v1"&gt;Dynamic Acoustic Model Architecture Optimization in Training for ASR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13216v1"&gt;Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13229v1"&gt;IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13285v1"&gt;Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13328v1"&gt;Document-Level Tabular Numerical Cross-Checking: A Coarse-to-Fine Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13329v1"&gt;EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13363v1"&gt;Efficient Medical VIE via Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13366v1"&gt;Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13405v1"&gt;RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13467v1"&gt;Enhancing Omics Cohort Discovery for Research on Neurodegeneration through Ontology-Augmented Embedding Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13470v1"&gt;Abstract, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13487v1"&gt;TurBLiMP: A Turkish Benchmark of Linguistic Minimal Pairs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13502v1"&gt;BOW: Bottlenecked Next Word Exploration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13513v1"&gt;K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13569v1"&gt;Characterizing Linguistic Shifts in Croatian News via Diachronic Word Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13610v1"&gt;A Structured Bangla Dataset of Disease-Symptom Associations to Improve Diagnostic Accuracy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13639v1"&gt;An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13641v1"&gt;EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13063v1"&gt;PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13199v1"&gt;Do Music Preferences Reflect Cultural Values? A Cross-National Analysis Using Music Embedding and World Values Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13339v1"&gt;NTU Speechlab LLM-Based Multilingual ASR System for Interspeech MLC-SLM Challenge 2025&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13396v1"&gt;Bi-directional Context-Enhanced Speech Large Language Models for Multilingual Conversational ASR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13458v1"&gt;Leveraging Vision-Language Pre-training for Human Activity Recognition in Still Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13743v1"&gt;LTRR: Learning To Rank Retrievers for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13188v1"&gt;SPOT: Bridging Natural Language and Geospatial Search for Investigative Journalists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.13596v1"&gt;Qwen vs. Gemma Integration with Whisper: A Comparative Study in Multilingual SpeechLLM Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-17</guid><pubDate>Tue, 17 Jun 2025 12:20:38 +0900</pubDate></item><item><title>Development of the user-friendly decision aid Rule-based Evaluation and Support Tool (REST) for optimizing the resources of an information extraction task</title><link>http://arxiv.org/abs/2506.13177v1</link><description>ルールは、持続可能性、転送可能性、解釈可能性、開発負担の点で、MLやLLMと比較して、情報抽出（IE）のデフォルトオプションとなり得る。我々は、IE手法として、ルールとMLを持続可能かつ組み合わせて使用することを提案する。我々のアプローチは、データコーパスの代表的なサブセットに対する、徹底的な専門家による手動ハイライトを、単一の作業セッションで行うことから始まる。アノテーターが、デフォルトオプションとしてのルールと、IEタスクの各エンティティに対するMLのどちらを選択するかを支援するために、REST決定ツールの実現可能性とパフォーマンス指標を開発し、検証した。RESTは、アノテーターが自由記述テキストにおける各エンティティの形式化の特徴と、予想されるルール開発の実現可能性およびIEパフォーマンス指標を視覚化できるようにする。MLはバックアップのIEオプションと見なされ、トレーニングのための手動アノテーションは最小限に抑えられる。12エンティティのユースケースにおけるRESTの外部妥当性は、良好な再現性を示した。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13177v1</guid><pubDate>Mon, 16 Jun 2025 07:38:04 +0000</pubDate></item><item><title>Global Convergence of Adjoint-Optimized Neural PDEs</title><link>http://arxiv.org/abs/2506.13633v1</link><description>多くの工学および科学分野では近年、偏微分方程式（PDE）の項をニューラルネットワークでモデル化することに関心が集まっています。結果として得られるニューラルネットワークPDEモデルは、ニューラルネットワークのパラメータの関数であり、随伴PDEを解くことによって計算効率の良い方法で勾配を評価し、勾配降下法を用いてPDEを最適化することで、利用可能なデータに適合させることができます。これらのニューラルネットワークPDEモデルは、科学的機械学習における重要な研究分野として台頭してきました。本論文では、隠れユニットの数と学習時間の両方が無限大に近づく極限において、ニューラルネットワークPDEモデルを訓練するための随伴勾配降下最適化法の収束について研究します。具体的には、ソース項にニューラルネットワークが埋め込まれた一般的なクラスの非線形放物型PDEに対して、訓練されたニューラルネットワークPDE解がターゲットデータ（すなわち、グローバルミニマイザー）に収束することを証明します。このグローバル収束の証明は、有限次元のニューラルネットワーク収束解析では遭遇しない、独特の数学的課題を提起します。その理由は、（1）無限幅の隠れ層の極限において、ニューラルネットワークのカーネル演算子が非局所的であり、その固有値に対してスペクトルギャップがないこと、そして（2）極限PDE系の非線形性により、無限幅の隠れ層の極限においても非凸最適化問題となるためです（ニューロン数が大きい極限で最適化問題が凸になる典型的なニューラルネットワークの訓練ケースとは異なります）。理論的な結果は、数値研究によって示され、経験的に検証されます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13633v1</guid><pubDate>Mon, 16 Jun 2025 16:00:00 +0000</pubDate></item><item><title>Stability Analysis of Physics-Informed Neural Networks via Variational Coercivity, Perturbation Bounds, and Concentration Estimates</title><link>http://arxiv.org/abs/2506.13554v1</link><description>我々は、変分解析、演算子の強制性、および明示的な摂動理論に基づいた、物理情報ニューラルネットワーク（PINN）のための厳密な安定性フレームワークを開発します。PINNは、サンプリングされた配置点における残差ベースの損失を最小化することにより、偏微分方程式（PDE）の解を近似します。ネットワーク出力における有界な摂動が、残差損失と教師あり損失の両方の成分をどのように伝播するかを定量化する、決定論的な安定性限界を導出します。確率的安定性は、McDiarmidの不等式を介して確立され、最小限の仮定の下で、サンプリングの変動性を経験的損失の変動に結び付ける非漸近的な集中限界が得られます。Sobolevノルムの訓練損失から一様近似への一般化は、強制性とSobolev埋め込みを用いて分析され、点ごとの誤差制御につながります。理論的な結果は、スカラーおよびベクトル値のPDEの両方に適用され、複合損失の定式化をカバーします。数値実験は、摂動感受性、サンプル複雑性の推定、およびSobolevから一様への一般化限界を検証します。本研究は、PINNのための数学的に根拠があり、実用的に適用可能な安定性フレームワークを提供し、ロバストな訓練における演算子構造、サンプリング設計、および関数的規則性の役割を明らかにします。

&lt;img src="https://arxiv.org/html/2506.13554v1/extracted/6546020/fig1.png"/&gt;&lt;p&gt;Ronald Katende&lt;/p&gt;&lt;p&gt;Department of Mathematics, Kabale University; Kikungiri Hill, P.O Box 317 Kabale, Uganda&lt;/p&gt;</description><guid isPermaLink="false">2506.13554v1</guid><pubDate>Mon, 16 Jun 2025 14:41:15 +0000</pubDate></item><item><title>Inverse design of the transmission matrix in a random system using Reinforcement Learning</title><link>http://arxiv.org/abs/2506.13057v1</link><description>本研究では、強化学習を用いて伝達行列を修正することにより、散乱系の逆設計を行う手法を提案する。Proximal Policy Optimizationを用いて、目的関数の高度に非凸な地形を探索し、以下の3種類の伝達行列を実現する。(1) ランク1行列における固定比率電力変換とゼロ透過モード、(2) 縮退した固有値と一方向モード変換を持つ例外点、(3) 透過固有値が縮退している場合に、均一なチャネル参加を強制する。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13057v1</guid><pubDate>Mon, 16 Jun 2025 02:58:56 +0000</pubDate></item><item><title>Adversarial Disentanglement by Backpropagation with Physics-Informed Variational Autoencoder</title><link>http://arxiv.org/abs/2506.13658v1</link><description>物理システムの部分的な知識下での推論と予測は、特に複数の交絡因子が測定された応答に影響を与える場合に困難です。物理ベースのモデルでこれらの影響を明示的に考慮することは、認識論的不確実性、コスト、または時間的制約のためにしばしば実行不可能であり、その結果、システムの挙動を正確に記述できないモデルが生じます。一方、変分自己符号化器のようなデータ駆動型の機械学習モデルは、簡潔な表現を識別することが保証されていません。その結果、限られたノイズの多いデータ領域において、汎化性能と再構成精度が低下する可能性があります。本稿では、物理ベースのモデルの解釈可能性とデータ駆動型モデルの柔軟性を組み合わせた、物理情報に基づく変分自己符号化器アーキテクチャを提案します。既知の物理と交絡因子の分離を促進するために、潜在空間は、物理ベースのモデルをパラメータ化する物理的に意味のある変数と、物理システムのドメインとクラスの変動を捉えるデータ駆動型の変数に分割されます。エンコーダは、物理ベースのコンポーネントとデータ駆動型のコンポーネントを統合するデコーダと結合され、データ駆動型のコンポーネントが既知の物理を上書きするのを防ぎ、物理に基づいた潜在変数が解釈可能な状態を維持することを保証する敵対的学習目的によって制約されます。本モデルが、クラスとドメインの観測値の形式で教師あり学習を使用し、入力信号の特徴を分離し、既知の物理を交絡因子から分離できることを示します。本モデルは、エンジニアリング構造に関連する一連の合成ケーススタディで評価され、提案されたアプローチの実現可能性を実証します。

&lt;img src="https://arxiv.org/html/2506.13658v1/extracted/6546232/figures/beam_latent_2a.png"/&gt;&lt;p&gt;Alice Cicirello, Ioannis-Christoforos Koune&lt;/p&gt;&lt;p&gt;\orgdiv Department of Civil Engineering and Geosciences, \orgname Technical University of Delft, \orgaddress \city Delft, \postcode 2628 CN, \country Netherlands.
\orgdiv Department of Engineering, \orgname University of Cambridge, \orgaddress \city Cambridge, \postcode CB2 1PZ, \country United Kingdom.&lt;/p&gt;</description><guid isPermaLink="false">2506.13658v1</guid><pubDate>Mon, 16 Jun 2025 16:18:25 +0000</pubDate></item><item><title>GeoRecon: Graph-Level Representation Learning for 3D Molecules via Reconstruction-Based Pretraining</title><link>http://arxiv.org/abs/2506.13174v1</link><description>事前学習とファインチューニングのパラダイムは、自然言語処理やコンピュータビジョンなどの分野で著しい進歩を遂げており、その代表的な事前学習パラダイムとしては、マスクされた言語モデリングや次のトークン予測などが挙げられます。しかし、分子表現学習においては、タスク設計は依然としてノードレベルのノイズ除去に大きく限定されており、これは局所的な原子環境のモデリングには有効ですが、エネルギー推定や分子回帰などのグラフレベルの特性予測タスクに必要なグローバルな分子構造の捕捉には不十分かもしれません。本研究では、個々の原子から分子全体へと焦点を移す、新しいグラフレベルの事前学習フレームワークであるGeoReconを提案します。GeoReconは、グラフレベルの再構築タスクを導入します。事前学習中に、モデルは分子の幾何構造の再構築を正確に導くことができる、情報量の多いグラフ表現を生成するように訓練されます。これにより、モデルは孤立した原子の詳細ではなく、一貫性のあるグローバルな構造的特徴を学習することが促進されます。追加の監督や外部データに頼ることなく、GeoReconは複数の分子ベンチマーク（例：QM9、MD17）でノード中心のベースラインを上回り、より全体的で幾何学的に認識された分子埋め込みを学習するためのグラフレベルの再構築の組み込みの利点を示しています。

&lt;img src="https://arxiv.org/html/2506.13174v1/x1.png"/&gt;&lt;p&gt;Peking University, Peking University School of Intelligence Science, Peking University Yuanpei College, Shaoheng Yan Zian Li Muhan Zhang Institute for Artificial Intelligence, Technology&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13174v1</guid><pubDate>Mon, 16 Jun 2025 07:35:49 +0000</pubDate></item><item><title>Accelerating PDE-Constrained Optimization by the Derivative of Neural Operators</title><link>http://arxiv.org/abs/2506.13120v1</link><description>PDE制約最適化（PDECO）問題は、従来の数値解法と比較して、ニューラルオペレータのような代替モデルを用いた勾配ベースの手法を用いることで大幅に高速化できます。しかし、このアプローチは2つの主要な課題に直面しています。（1）**データ効率の悪さ**：特に最適化を目的とした場合、ニューラルオペレータの効率的なデータサンプリングと効果的な学習が不足しています。（2）**不安定性**：不正確なニューラルオペレータの予測と勾配により、最適化が脱線するリスクが高いです。これらの課題に対処するために、我々は新しいフレームワークを提案します。（1）**最適化指向の学習**：従来の最適化アルゴリズムのフルステップからのデータを活用し、ニューラルオペレータのための特殊な学習方法を採用します。（2）**強化された微分学習**：ニューラルオペレータ内の微分学習を強化するために、*Virtual-Fourier*レイヤーを導入します。これは勾配ベースの最適化にとって重要な側面です。（3）**ハイブリッド最適化**：ニューラルオペレータと数値解法を統合したハイブリッドアプローチを実装し、最適化プロセスに堅牢な正則化を提供します。広範な実験結果は、我々のモデルがオペレータとその微分を正確に学習する上で効果的であることを示しています。さらに、我々のハイブリッド最適化アプローチは、堅牢な収束を示します。

&lt;img src="https://arxiv.org/html/2506.13120v1/x1.png"/&gt;&lt;p&gt;Hang Su, Jianing Huang, Xiaoqiang Wang, Ze Cheng, Zhizhou Zhang, Zhongkai Hao, Zhuoyu Li&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13120v1</guid><pubDate>Mon, 16 Jun 2025 05:58:36 +0000</pubDate></item><item><title>Socratic RL: A Novel Framework for Efficient Knowledge Acquisition through Iterative Reflection and Viewpoint Distillation</title><link>http://arxiv.org/abs/2506.13358v1</link><description>大規模言語モデル(LLM)に対する現在の強化学習(RL)手法は、単純な結果ベースの報酬信号（例：最終的な回答の正しさ）に依存することが多く、各インタラクションからの学習の深さを制限しています。本論文では、この制限に対処するために設計された、新しいプロセス指向のフレームワークであるソクラテス式強化学習(Socratic-RL)を紹介します。Socratic-RLは、推論プロセス自体におけるエラーと成功の因果関係を考察することによって、より深い理解が得られるという原則に基づいて動作します。このフレームワークは、分離された「教師-生徒」アーキテクチャを採用しており、「教師AI」がインタラクション履歴を分析し、因果的な洞察を抽出し、それらを構造化された「視点」にまとめます。これらの視点は、蒸留されたガイダンスとして機能し、「生徒AI」がその後の推論を強化するために使用されます。重要なイノベーションは、教師AIの反省能力がメタ学習ループを通じて進化することを可能にする、教師AIの反復的な自己改善です。知識の蓄積を管理するために、蒸留メカニズムが学習された視点を生徒のパラメータに圧縮します。結果だけでなくプロセスに焦点を当てることで、Socratic-RLは、サンプル効率の向上、優れた解釈可能性、および自己改善型AIシステムのためのよりスケーラブルなアーキテクチャへの道筋を示します。本論文では、この提案されたフレームワークの基礎概念、正式なメカニズム、相乗効果、課題、および具体的な研究ロードマップについて詳述します。

&lt;img src="https://arxiv.org/html/2506.13358v1/x1.png"/&gt;&lt;p&gt;Xiangfan Wu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13358v1</guid><pubDate>Mon, 16 Jun 2025 10:57:58 +0000</pubDate></item><item><title>Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks</title><link>http://arxiv.org/abs/2506.13351v1</link><description>大規模言語モデル（LLM）における最近の進歩は、数学やプログラミングのような構造化されたタスクにおいて目覚ましい推論能力を示しており、その多くは検証可能な報酬による強化学習（RLVR）によって推進されています。RLVRは、スケーラブルで効果的、かつ報酬ハッキングに対して堅牢な結果ベースのシグナルを使用します。しかし、同様の手法をオープンエンドの長文推論タスクに適用することは、汎用的で検証可能な報酬シグナルが存在しないため、依然として困難です。これに対処するため、我々はDirect Reasoning Optimization（DRO）を提案します。これは、オープンエンド、特に長文の推論タスクにおいて、LLMをファインチューニングするための強化学習フレームワークであり、新しい報酬シグナルであるReasoning Reflection Reward（R3）によって導かれます。R3の中核は、モデルの先行する思考連鎖推論の影響を反映する参照結果のキーとなるトークンを選択的に識別し、強調することで、推論と参照結果の一貫性をきめ細かいレベルで捉えることです。重要なことに、R3は最適化されているのと同じモデルを使用して内部的に計算されるため、完全に自己完結型のトレーニング設定が可能になります。さらに、オープンエンドの推論タスクのために、R3に基づいた動的なデータフィルタリング戦略を導入し、コストを削減しながら、下流のパフォーマンスを向上させます。我々は、2つの多様なデータセット（長文の段落修正タスクであるParaRevと、数学指向のQAベンチマークであるFinQA）でDROを評価し、オープンエンドと構造化されたドメインの両方で広く適用可能でありながら、一貫して強力なベースラインを上回ることを示します。

&lt;img src="https://arxiv.org/html/2506.13351v1/x1.png"/&gt;&lt;p&gt;Leonardo Nunes, Los Angeles, Microsoft University of California, Srinagesh Sharma, Tusher Chakraborty, Yifei Xu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13351v1</guid><pubDate>Mon, 16 Jun 2025 10:43:38 +0000</pubDate></item><item><title>AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy</title><link>http://arxiv.org/abs/2506.13284v1</link><description>本研究では、強力な推論モデルの開発における教師ありファインチューニング（SFT）と強化学習（RL）の相乗効果について調査します。まず、収集するプロンプトの数と、プロンプトごとに生成される応答の数を増やすという2つのスケーリング戦略を通じて、SFTトレーニングデータをキュレーションします。どちらのアプローチも推論性能の顕著な向上をもたらしますが、プロンプトの数をスケーリングする方がより大きな効果をもたらします。次に、SFTとRLの相乗効果に関して、以下の質問を探求します。（i）より強力なSFTモデルは、大規模なRLトレーニング後も一貫してより良い最終性能につながるか？（ii）与えられたSFT初期化に対して、探索と活用のバランスを効果的に取るために、RLトレーニング中に適切なサンプリング温度をどのように決定できるか？我々の発見は、（i）が真であることを示唆しています。特に、サンプリング温度を慎重に選択し、温度調整されたエントロピーを0.3付近に維持することで、効果的なRLトレーニングが実施される場合に当てはまります。これは、探索と活用のバランスが取れた設定です。注目すべきは、初期SFTモデル間の性能差が、RLプロセス全体を通して大幅に縮小することです。強力なSFT基盤と、SFTとRLの相乗的な相互作用に関する洞察を活用することで、我々のAceReason-Nemotron-1.1 7Bモデルは、AceReason-Nemotron-1.0を大幅に上回り、Qwen2.5-7Bベースの推論モデルの中で、困難な数学およびコードベンチマークにおいて、新たな最先端の性能を達成し、我々のポストトレーニングレシピの有効性を示しています。モデルとデータは、https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B で公開しています。

&lt;img src="https://arxiv.org/html/2506.13284v1/x2.png"/&gt;&lt;p&gt;Bryan Catanzaro, Chankyu Lee, Mohammad Shoeybi, Wei Ping, Yang Chen, Zhuolin Yang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13284v1</guid><pubDate>Mon, 16 Jun 2025 09:27:48 +0000</pubDate></item><item><title>AlphaEvolve: A coding agent for scientific and algorithmic discovery</title><link>http://arxiv.org/abs/2506.13131v1</link><description>本ホワイトペーパーでは、最先端のLLMの能力を大幅に向上させ、未解決の科学的問題への取り組みや、重要な計算インフラの最適化といった非常に困難なタスクを可能にする、進化的コーディングエージェントAlphaEvolveを紹介します。AlphaEvolveは、コードに直接変更を加えることでアルゴリズムを改善することをタスクとするLLMの自律的なパイプラインを構築します。進化的アプローチを用いて、1つまたは複数の評価者から継続的にフィードバックを受け取ることで、AlphaEvolveはアルゴリズムを反復的に改善し、新たな科学的および実用的な発見につながる可能性があります。このアプローチの幅広い適用可能性を、いくつかの重要な計算問題に適用することで実証します。Googleの大規模計算スタックの重要なコンポーネントを最適化するために適用したところ、AlphaEvolveはデータセンター向けのより効率的なスケジューリングアルゴリズムを開発し、ハードウェアアクセラレータの回路設計において機能的に同等の簡略化を発見し、AlphaEvolve自体を支えるLLMのトレーニングを加速しました。さらに、AlphaEvolveは、数学およびコンピュータサイエンスにおける一連の問題において、最先端のソリューションを凌駕する、証明可能な新しいアルゴリズムを発見し、以前の自動発見手法の範囲を大幅に拡大しました（Romera-Paredes et al., 2023）。特に、AlphaEvolveは、2つの4×4複素数値行列を48回のスカラー乗算で乗算する手順を見つける検索アルゴリズムを開発しました。これは、この設定において、シュトラッセンのアルゴリズム以来56年ぶりの改善です。AlphaEvolveおよび同様のコーディングエージェントは、科学と計算の多くの分野における問題の解決策を改善する上で大きな影響を与える可能性があると信じています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13131v1</guid><pubDate>Mon, 16 Jun 2025 06:37:18 +0000</pubDate></item><item><title>The Price of Freedom: Exploring Expressivity and Runtime Tradeoffs in Equivariant Tensor Products</title><link>http://arxiv.org/abs/2506.13523v1</link><description>$E(3)$同変ニューラルネットワークは、広範な3Dモデリングタスクで成功を収めています。これらのネットワークにおける基本的な演算はテンソル積であり、これは2つの幾何学的特徴を同変な方法で相互作用させ、新しい特徴を作成します。テンソル積の高い計算複雑性のため、この演算の実行時を最適化するために多大な努力が払われてきました。例えば、Luoら（2024）は最近、大幅な高速化を約束するGauntテンソル積（GTP）を提案しました。本研究では、いくつかのテンソル積演算について、注意深く体系的な分析を提供します。特に、異なるテンソル積は同じ演算を実行しているわけではないことを強調します。報告されている高速化は通常、表現力の低下を伴います。これらの違いを特徴づけるために、表現力と相互作用性の尺度を導入します。さらに、GTPの元の実装は、漸近的な実行時間にコストをかけることなく、球面グリッドを直接使用することで大幅に簡略化できることに気づきました。この球面グリッドアプローチは、当社のベンチマークおよびMACE原子間ポテンシャルの実際のトレーニングにおいて、30％高速です。最後に、さまざまなテンソル積演算の最初の体系的なマイクロベンチマークを提供します。理論的な実行時間保証は経験的なパフォーマンスと大きく異なる場合があり、アプリケーション固有の慎重なベンチマークの必要性を示しています。コードは\href{https://github.com/atomicarchitects/PriceofFreedom}{https://github.com/atomicarchitects/PriceofFreedom}で入手できます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13523v1</guid><pubDate>Mon, 16 Jun 2025 14:15:18 +0000</pubDate></item><item><title>Towards Pervasive Distributed Agentic Generative AI -- A State of The Art</title><link>http://arxiv.org/abs/2506.13324v1</link><description>インテリジェントエージェントと大規模言語モデル（LLM）の急速な進歩は、ユビキタスコンピューティングの分野を再構築しています。自然言語理解を通じて認識、推論、行動する能力により、異種センサー、デバイス、データの管理を含む、複雑なユビキタス環境における自律的な問題解決が可能になります。本調査では、LLMエージェントのアーキテクチャコンポーネント（プロファイリング、メモリ、計画、アクション）の概要を説明し、さまざまなシナリオにおける展開と評価を検証します。次に、ユビキタスコンピューティングにおける計算およびインフラストラクチャの進歩（クラウドからエッジまで）と、AIがこの分野でどのように進んでいるかをレビューします。リソース制約のあるデバイス上でのローカルおよび分散実行を含む、最先端のエージェント展開戦略とアプリケーションを強調します。本調査では、アーキテクチャ、エネルギー、プライバシーの制限など、ユビキタスコンピューティングにおけるこれらのエージェントの主要な課題を特定します。最後に、コンテキスト認識、モジュール性、セキュリティ、効率、有効性を重視した、ユビキタスエージェントAIの概念的フレームワークである「ツールとしてのエージェント」を提案します。

&lt;img src="https://arxiv.org/html/2506.13324v1/extracted/6539008/transformer.png"/&gt;&lt;p&gt;Fabio Ciravegna, Gianni Molinari&lt;/p&gt;&lt;p&gt;0000-0001-5817-4810
0009-0000-5660-3407
University of Turin Turin Italy&lt;/p&gt;</description><guid isPermaLink="false">2506.13324v1</guid><pubDate>Mon, 16 Jun 2025 10:15:06 +0000</pubDate></item><item><title>Ai-Facilitated Analysis of Abstracts and Conclusions: Flagging Unsubstantiated Claims and Ambiguous Pronouns</title><link>http://arxiv.org/abs/2506.13172v1</link><description>我々は、学術論文の高レベルな意味論的および言語学的分析において大規模言語モデル（LLM）を導きながら、人間のような階層的推論を引き出すように設計された、概念実証（PoC）の構造化されたワークフロープロンプトのスイートを提示し、評価します。これらのプロンプトは、要約における根拠のない主張の特定（情報的完全性）と、曖昧な代名詞参照のフラグ付け（言語的明瞭性）という、2つの非自明な分析タスクを対象としています。我々は、さまざまなコンテキスト条件下で、2つの最先端モデル（Gemini Pro 2.5 ProとChatGPT Plus o3）に対して、体系的な複数回の評価を実施しました。情報的完全性タスクの結果は、モデルのパフォーマンスに大きな乖離があることを示しています。両方のモデルが名詞句の根拠のない主要部を特定することに成功した（成功率95％）一方で、ChatGPTは、Geminiが正しくフラグを立てた（成功率95％）根拠のない形容詞修飾語を特定することに一貫して失敗しました（成功率0％）。これは、ターゲットの統語的役割の潜在的な影響に関する疑問を提起します。言語分析タスクでは、両方のモデルが完全な原稿コンテキストで良好なパフォーマンス（成功率80〜90％）を示しました。しかし、要約のみの設定では、ChatGPTが完璧な（100％）成功率を達成したのに対し、Geminiのパフォーマンスは大幅に低下しました。我々の発見は、構造化されたプロンプトが複雑なテキスト分析のための実行可能な方法論であることを示唆していますが、プロンプトのパフォーマンスは、モデル、タスクの種類、およびコンテキスト間の相互作用に大きく依存する可能性があることを示しており、厳密なモデル固有のテストの必要性を強調しています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13172v1</guid><pubDate>Mon, 16 Jun 2025 07:34:31 +0000</pubDate></item><item><title>Leveraging In-Context Learning for Language Model Agents</title><link>http://arxiv.org/abs/2506.13109v1</link><description>動的に選択されたデモンストレーションを用いたインコンテキスト学習（ICL）は、大規模言語モデル（LLM）の柔軟性と、パフォーマンスを向上させるための訓練データの活用能力を組み合わせたものです。ICLは予測や生成タスクで非常に成功していますが、逐次的な意思決定を必要とするエージェントタスクに活用することは困難です。大規模な軌跡にアノテーションを付与する方法、デモンストレーションを選択する方法だけでなく、何がデモンストレーションを構成するのか、いつ、どこでそれらを示すべきかについても考慮する必要があります。これに対処するため、まず、LLMとリトライ、そしてデモンストレーションを活用して、エージェントタスクにソリューション軌跡を自動的かつ効率的にアノテーションするアルゴリズムを提案します。次に、同様のタスクの軌跡をデモンストレーションとして集合選択することで、LLMエージェントのパフォーマンス、信頼性、ロバスト性、効率が大幅に向上することを示します。しかし、軌跡デモンストレーションは推論コストのオーバーヘッドが大きくなります。追加の軌跡の代わりに、各ステップで小さな軌跡スニペットを使用することで、これを軽減できることを示します。アノテーションフェーズでより大きなモデルから得られたデモンストレーションは、より小さなモデルも改善し、ICLエージェントはよりコストのかかる訓練済みエージェントに匹敵することさえあります。したがって、私たちの結果は、ICLは注意深く使用すれば、エージェントタスクにとっても非常に強力であることを明らかにしています。

&lt;img src="https://arxiv.org/html/2506.13109v1/extracted/6540930/figures/agent-demos.png"/&gt;&lt;p&gt;Shivanshu Gupta Sameer Singh Ashish Sabharwal Tushar Khot Ben Bogin University of California Irvine Allen Institute for AI&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13109v1</guid><pubDate>Mon, 16 Jun 2025 05:37:49 +0000</pubDate></item><item><title>Leveraging active learning-enhanced machine-learned interatomic potential for efficient infrared spectra prediction</title><link>http://arxiv.org/abs/2506.13486v1</link><description>赤外（IR）分光法は、材料構造へのリアルタイムな分子レベルの洞察を提供し、反応中間体のその場観察を可能にするため、極めて重要な分析ツールです。しかし、IRスペクトルの解釈には、密度汎関数理論に基づく第一原理分子動力学のような高精度なシミュレーションが必要となることが多く、これは計算コストが高く、扱える系のサイズと複雑さに制限があります。本研究では、触媒反応に関連する小さな有機分子のIRスペクトルを効率的に予測するための、オープンソースソフトウェアパッケージPALIRSに実装された、新しいアクティブラーニングに基づくフレームワークを紹介します。PALIRSは、アクティブラーニングを活用して機械学習された原子間ポテンシャルを訓練し、それを機械学習支援分子動力学シミュレーションに使用してIRスペクトルを計算します。PALIRSは、第一原理分子動力学で計算されたIRスペクトルを、計算コストを大幅に削減して正確に再現します。さらに、PALIRSは、IRピークの位置だけでなく、その振幅についても、利用可能な実験データとよく一致します。PALIRSによるこの進歩により、IRスペクトルのハイスループット予測が可能になり、より大きく複雑な触媒系の探索が促進され、新しい反応経路の特定に役立ちます。

&lt;img src="https://arxiv.org/html/2506.13486v1/extracted/6545755/Figures/Workflow_AL.png"/&gt;&lt;p&gt;Nitik Bhatia, Ondřej Krejčí&lt;/p&gt;&lt;p&gt;*
[&lt;/p&gt;</description><guid isPermaLink="false">2506.13486v1</guid><pubDate>Mon, 16 Jun 2025 13:44:44 +0000</pubDate></item><item><title>Entanglement-minimized orbitals enable faster quantum simulation of molecules</title><link>http://arxiv.org/abs/2506.13386v1</link><description>量子計算は、量子位相推定（QPE）などのアルゴリズムを通じて、分子や材料のシミュレーションを加速する大きな可能性を秘めている。しかし、基底状態エネルギー推定における期待される高速化は、真の基底状態との高いオーバーラップを持つ初期状態を効率的に準備できる能力に大きく依存する。鉄硫黄クラスターのような強相関分子の場合、このオーバーラップは系サイズとともに指数関数的に減少することが示されている。この問題を軽減するために、我々は、小さな結合次元を持つスピン適合行列積状態（MPS）を用いて、エンタングルメント最小化軌道（EMO）を見つけるための効率的な古典アルゴリズムを導入する。EMO基底は、よりコンパクトな基底状態表現をもたらし、困難な系に対する初期状態の準備を大幅に容易にする。我々のアルゴリズムは、4つの鉄を持つ鉄硫黄クラスターにおいて、従来の軌道最適化手法と比較して、初期状態のオーバーラップをほぼ1桁向上させ、窒素固定酵素中のPクラスターやFeMo補因子など、多数の不対電子を持つより大きな系にも拡張可能である（8つの遷移金属中心を持つ）。これらの系に対して、局在化軌道を用いた結果と比較して、初期状態のオーバーラップをそれぞれ$O(10^2)$および$O(10^5)$倍向上させることに成功した。我々の結果は、これらの困難な系に対する初期状態の準備が、以前の推定よりもはるかに少ないリソースで済むことを示している。

&lt;img src="https://arxiv.org/html/2506.13386v1/x1.png"/&gt;&lt;p&gt;Zhendong Li&lt;/p&gt;&lt;p&gt;Key Laboratory of Theoretical and Computational Photochemistry, Ministry of Education, College of Chemistry, Beijing Normal University, Beijing 100875, China&lt;/p&gt;</description><guid isPermaLink="false">2506.13386v1</guid><pubDate>Mon, 16 Jun 2025 11:49:20 +0000</pubDate></item><item><title>Multireference equation-of-motion driven similarity renormalization group: theoretical foundations and applications to ionized states</title><link>http://arxiv.org/abs/2506.13693v1</link><description>我々は、イオン化ポテンシャル（IP-EOM-DSRG）のための多参照駆動相似性繰り込み群（MR-DSRG）形式の運動方程式（EOM）拡張の定式化と実装を示す。IP-EOM-DSRG形式は、エルミートの一般化された固有値問題をもたらし、強く相関した基底状態および励起状態を持つ系の正確なイオン化ポテンシャルを提供する。EOMステップは、基底関数サイズNに対してO(N^5)でスケールし、遷移エネルギーや強度などの分光学的特性の効率的な計算を可能にする。IP-EOM-DSRG形式は、親MR-DSRG理論の3つの打ち切りスキームと組み合わされる：最大2体励起を伴う反復非摂動法[MR-LDSRG(2)]、および2次および3次の摂動近似[DSRG-MRPT2/3]。これらの変種を、1) 平衡および伸長された構造における一連の小分子の垂直価電子イオン化ポテンシャル、2) OH、CN、N2+、およびCO+ラジカルのいくつかの低エネルギー電子状態の分光定数、および3) CNラジカルの低エネルギー電子状態の結合曲線、を計算することによって評価する。実験データおよび理論的結果との比較は、3つのIP-EOM-DSRG法すべてが、これらの系の垂直イオン化ポテンシャルおよび分光定数を正確に再現することを示している。特に、DSRG-MRPT3およびMR-LDSRG(2)バージョンは、同等またはより高いコストのいくつかの最先端の多参照法よりも優れた性能を発揮する。

&lt;img src="https://arxiv.org/html/2506.13693v1/x2.png"/&gt;&lt;p&gt;Francesco A. Evangelista, Shuhang Li, Zijun Zhao&lt;/p&gt;&lt;p&gt;Department of Chemistry and Cherry Emerson Center for Scientific Computation, Emory University, Atlanta, Georgia, 30322, United States&lt;/p&gt;</description><guid isPermaLink="false">2506.13693v1</guid><pubDate>Mon, 16 Jun 2025 16:55:43 +0000</pubDate></item><item><title>A deep learning model for chemical shieldings in molecular organic solids including anisotropy</title><link>http://arxiv.org/abs/2506.13146v1</link><description>核磁気共鳴（NMR）化学シフトは、粉末または非晶質の分子性固体の構造を解明するために使用できる、局所的な原子および電子構造の強力なプローブです。化学シフト駆動型の構造決定は、化学遮蔽の正確かつ高速な予測に大きく依存しており、遮蔽予測のための機械学習（ML）モデルは、要求の厳しいab initio計算のスケーラブルで効率的な代替手段としてますます使用されています。しかし、現在のMLモデルの予測精度は、特に$^{13}$Cや$^{15}$Nなどの原子核において、近似するDFT参照法の精度にまだ遅れをとっています。本稿では、分子性固体中の等方性化学遮蔽の予測精度を向上させる深層学習モデルであるShiftML3.0を紹介します。ShiftML3.0は、完全な遮蔽テンソルも予測します。実験的なベンチマークセットにおいて、ShiftML3.0の実験に対する二乗平均平方根誤差は、DFT参照計算の誤差に近づき、それぞれ$^{1}$Hで0.53 ppm、$^{13}$Cで2.4 ppm、$^{15}$Nで7.2 ppmであり、DFTの値はそれぞれ0.49 ppm、2.3 ppm、5.8 ppmです。

&lt;img src="https://arxiv.org/html/2506.13146v1/x1.png"/&gt;&lt;p&gt;Florian Viscosi, Jacob B. Holmes, Lyndon Emsley, Matthias Kellner, Michele Ceriotti, Ruben Rodriguez-Madrid, Yuxuan Zhang&lt;/p&gt;&lt;p&gt;Laboratory of Computational Science and Modeling, Institut des Matériaux, École Polytechnique Fédérale de Lausanne, 1015 Lausanne, Switzerland
Laboratory of Magnetic Resonance, Institut des Sciences et Ingénierie Chimiques, École Polytechnique Fédérale de Lausanne, 1015 Lausanne, Switzerland&lt;/p&gt;</description><guid isPermaLink="false">2506.13146v1</guid><pubDate>Mon, 16 Jun 2025 06:59:01 +0000</pubDate></item><item><title>Stress-Testing Multimodal Foundation Models for Crystallographic Reasoning</title><link>http://arxiv.org/abs/2506.13051v1</link><description>結晶学的推論のための基盤モデルを評価するには、物理的制約を強制しながら汎化性能を分離するベンチマークが必要です。本研究では、マルチモーダル生成モデルをストレステストするための、物理的に根拠のある2つの評価プロトコルを備えたマルチスケール・マルチ結晶データセットを紹介します。空間排除ベンチマークは、多様なデータセットから特定の半径のすべてのスーパーセルを保留し、空間的な内挿と外挿の制御された評価を可能にします。組成排除ベンチマークは、特定の化学組成のすべてのサンプルを省略し、化学量論を超えた汎化を調査します。9つの視覚-言語基盤モデルに、結晶学的画像とテキストコンテキストを与えて、構造アノテーションを生成させます。応答は、(i)格子定数と密度の相対誤差、(ii)体積違反を罰する物理的整合性指標、(iii)幾何学的外れ値と無効な空間群予測を捉えるハルシネーションスコアによって評価されます。これらのベンチマークは、大規模なマルチモーダルモデルにおける汎化、整合性、信頼性を評価するための、再現可能で物理的に情報に基づいたフレームワークを確立します。データセットとコードは、https://github.com/KurbanIntelligenceLab/StressTestingMMFMinCR で入手できます。

&lt;img src="https://arxiv.org/html/2506.13051v1/x1.png"/&gt;&lt;p&gt;Can Polat, Erchin Serpedin, Hasan Kurban, Mustafa Kurban&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13051v1</guid><pubDate>Mon, 16 Jun 2025 02:40:33 +0000</pubDate></item><item><title>Inferring Material Parameters from Current-Voltage Curves in Organic Solar Cells via Neural-Network-Based Surrogate Models</title><link>http://arxiv.org/abs/2506.13308v1</link><description>機械学習は、太陽電池の材料パラメータを推定するための有望なアプローチとして登場しました。従来のパラメータ抽出方法は、パラメータ空間の複雑さを十分に捉えられず、最適でないシミュレーションからの貴重な情報を破棄してしまう、時間のかかる数値シミュレーションに依存することがよくあります。本研究では、数値シミュレーションとニューラルネットワークの組み合わせに基づいた、有機太陽電池におけるパラメータ推定のための新しいワークフローを紹介します。このワークフローは、適切な実験データの選択から始まり、次に実験を正確に記述するデバイスモデルの定義へと進みます。計算の複雑さを軽減するために、可変パラメータの数を慎重に選択し、各パラメータに妥当な範囲を設定します。数値モデルを使用して実験データを直接フィッティングする代わりに、シミュレーション結果の大規模なデータセットでニューラルネットワークをトレーニングし、高次元パラメータ空間の効率的な探索を可能にしました。このアプローチは、パラメータ推定プロセスを加速するだけでなく、推定されたパラメータの尤度と不確実性に関する貴重な洞察も提供します。PBDB-TF-T1:BTP-4F-12材料系に基づく有機太陽電池でこの手法の有効性を示し、新しい太陽光発電材料の迅速かつ包括的な特性評価における機械学習の可能性を実証します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.13308v1</guid><pubDate>Mon, 16 Jun 2025 09:48:45 +0000</pubDate></item><item><title>Ab initio functional-independent calculations of the clamped Pockels tensor of tetragonal barium titanate</title><link>http://arxiv.org/abs/2506.13209v1</link><description>我々は、密度汎関数理論、電気エンタルピー汎関数を利用した現代的な分極理論、そして分極とヘルマン-ファインマン力の自動化された一次および二次有限差分微分から、強誘電体材料のクランプされたポッケルス・テンソルを計算するための第一原理計算手法を提示する。我々のアプローチの汎関数に依存しない能力のおかげで、例えばPBEsolのような任意の交換相関(XC)汎関数を用いて、局所密度近似(LDA)を超えて正方晶チタン酸バリウム(BTO)のポッケルス・テンソルを決定することができる。後者は、RRKJ超ソフト擬ポテンシャル(PP)と、局所的なチタンのオフセンターを示すスーパーセルと組み合わせることで、LDAとノルム保存PPを組み合わせた場合に正方晶BTOで遭遇する負の光学的フォノンモードを安定化することができる。その結果、BTOの最大の実験的ポッケルス係数である$r_{51}$の正しい値の範囲が回復される。また、この材料において、$r_{51}$はチタンのオフセンターが減少するにつれて増加することを明らかにする。BTOの構造、誘電、および振動に関する調査から得られた教訓は、ポッケルス効果に基づく次世代の電気光学変調器を設計する上で不可欠となるだろう。

&lt;img src="https://arxiv.org/html/2506.13209v1/extracted/6529969/Figures/phonon_unstable_modes.png"/&gt;&lt;p&gt;Lorenzo Bastonero, Marko Mladenović, Mathieu Luisier, Michele Kotiuga, Nicola Marzari, Virginie de Mestral&lt;/p&gt;&lt;p&gt;1 Integrated Systems Laboratory, ETH Zurich, Zurich, Switzerland 2 U Bremen Excellence Chair, Bremen Center for Computational Materials Science, MAPEX Center for Materials and Processes, University of Bremen, D-28359 Bremen, Germany 3 Theory and Simulation of Materials (THEOS), and National Centre for Computational Design and Discovery of Novel Materials (MARVEL), École Polytechnique Fédérale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland 4 Materials Design SARL, Montrouge, France 5 Laboratory for Materials Simulations, Paul Scherrer Institut, 5232, Villigen PSI&lt;/p&gt;</description><guid isPermaLink="false">2506.13209v1</guid><pubDate>Mon, 16 Jun 2025 08:12:20 +0000</pubDate></item></channel></rss>