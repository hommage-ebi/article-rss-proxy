<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Fri, 04 Jul 2025 03:22:42 +0000</lastBuildDate><item><title>other arxiv papers 2025-07-04</title><link>https://arxiv.org/2025-07-04</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02528v1"&gt;Triboelectric charge transfer theory driven by interfacial thermoelectric effect&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02579v1"&gt;Electron-hole tunnelling probed in de Haas - van Alphen oscillations in the (double) Dirac semimetal NbTe$_4$&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02612v1"&gt;Mechanical enhancement of quantum oscillations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02629v1"&gt;Pressure-induced band gap energy increase in crystalline lactose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02658v1"&gt;Spatiotemporal Mapping of Anisotropic Thermal Transport in GaN Thin Films via Ultrafast X-ray Diffraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02329v1"&gt;Nodal-line semimetals and their variance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02516v1"&gt;Magnetic octupole Hall effect in heavy transition metals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02534v1"&gt;Radiation stability of nanocomposite scintillators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02296v1"&gt;Symmetries of electron interactions in Hubbard models of unconventional superconductors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02371v1"&gt;Time- and Polarization-Resolved Extreme Ultraviolet Momentum Microscopy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02571v1"&gt;Intriguing kagome topological materials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02623v1"&gt;Interplay of frustration and quantum fluctuations in a spin-1/2 anisotropic square lattice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02642v1"&gt;Optimal boron-doped graphene substrate for glucose Raman signal enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02480v1"&gt;Intrinsic Dimensionality of Molecular Properties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02696v1"&gt;3D-Printed Enclosure Wire-Guided Liquid Microfilm for Versatile Spectroscopy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02704v1"&gt;Super high capacity of silicon carbon anode over 6500 mAh g-1 for lithium battery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02509v1"&gt;A Multi-Level Monte Carlo Tree Search Method for Configuration Generation in Crystalline Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02242v1"&gt;Predicting Flow-Induced Vibration in Isolated and Tandem Cylinders Using Hypergraph Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02765v1"&gt;Spin Caloritronics in irradiated chiral ferromagnetic systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02353v1"&gt;OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02541v1"&gt;Clarifying Before Reasoning: A Coq Prover with Structural Context&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02582v1"&gt;Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02616v1"&gt;DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02663v1"&gt;Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02703v1"&gt;Time-critical and confidence-based abstraction dropping methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02825v1"&gt;Establishing Best Practices for Building Rigorous Agentic Benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02244v1"&gt;Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02252v1"&gt;SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02265v1"&gt;Multi-Label Classification Framework for Hurricane Damage Assessment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02306v1"&gt;Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02314v1"&gt;MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02319v1"&gt;Iterated belief revision: from postulates to abilities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02322v1"&gt;Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02331v1"&gt;Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02337v1"&gt;ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02342v1"&gt;DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02349v1"&gt;Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02356v1"&gt;Offline Reinforcement Learning with Penalized Action Noise Injection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02358v1"&gt;Holistic Tokenizer for Autoregressive Image Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02390v1"&gt;Evaluating Language Models For Threat Detection in IoT Security Logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02398v1"&gt;Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02409v1"&gt;S2FGL: Spatial Spectral Federated Graph Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02424v1"&gt;CyberRAG: An agentic RAG cyber attack classification and reporting tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02436v1"&gt;Toward a Robust and Generalizable Metamaterial Foundation Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02479v1"&gt;CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02493v1"&gt;Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02503v1"&gt;Continual Gradient Low-Rank Projection Fine-Tuning for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02537v1"&gt;Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02550v1"&gt;Position: A Theory of Deep Learning Must Include Compositional Sparsity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02595v1"&gt;MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02598v1"&gt;AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02602v1"&gt;Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02620v1"&gt;FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02681v1"&gt;Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02687v1"&gt;APT: Adaptive Personalized Training for Diffusion Models with Limited Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02714v1"&gt;FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02735v1"&gt;Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02754v1"&gt;Fast and Simplex: 2-Simplicial Attention in Triton&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02755v1"&gt;Multi-agent Auditory Scene Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02788v1"&gt;Moral Responsibility or Obedience: What Do We Want from AI?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02827v1"&gt;USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02271v1"&gt;Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02282v1"&gt;Content filtering methods for music recommendation: A review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02291v1"&gt;Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02302v1"&gt;DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02310v1"&gt;Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02376v1"&gt;VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02403v1"&gt;Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02442v1"&gt;The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02506v1"&gt;IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02517v1"&gt;Detecting Multiple Diseases in Multiple Crops Using Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02618v1"&gt;Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02652v1"&gt;Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02666v1"&gt;ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02737v1"&gt;Early Signs of Steganographic Capabilities in Frontier LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02748v1"&gt;Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02771v1"&gt;Grounding Intelligence in Movement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02773v1"&gt;KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02778v1"&gt;Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02822v1"&gt;SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02824v1"&gt;DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02841v1"&gt;StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02855v1"&gt;Subtyping in DHOL -- Extended preprint&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02856v1"&gt;Answer Matching Outperforms Multiple Choice for Language Model Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02861v1"&gt;LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02863v1"&gt;Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02443v1"&gt;Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02606v1"&gt;De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02851v1"&gt;MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02365v1"&gt;Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02406v1"&gt;Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02466v1"&gt;Variational Kolmogorov-Arnold Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02559v1"&gt;Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02624v1"&gt;A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02628v1"&gt;Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02634v1"&gt;High-Order Deep Meta-Learning with Category-Theoretic Interpretation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02639v1"&gt;On Efficient Bayesian Exploration in Model-Based Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02710v1"&gt;Fluid Democracy in Federated Data Aggregation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02712v1"&gt;A Forget-and-Grow Strategy for Deep Reinforcement Learning Scaling in Continuous Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02715v1"&gt;A Comprehensive Machine Learning Framework for Micromobility Demand Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02782v1"&gt;Understanding and Improving Length Generalization in Recurrent Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02807v1"&gt;In-Training Multicalibrated Survival Analysis for Healthcare via Constrained Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02814v1"&gt;Replicable Distribution Testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02843v1"&gt;LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02847v1"&gt;MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02248v1"&gt;Transfer Learning for Matrix Completion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02255v1"&gt;Listwise Preference Alignment Optimization for Tail Item Recommendation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02264v1"&gt;NLP4Neuro: Sequence-to-sequence learning for neural population decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02288v1"&gt;Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02315v1"&gt;Improving Constrained Generation in Language Models via Self-Distilled Twisted Sequential Monte Carlo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02320v1"&gt;Transformer-based EEG Decoding: A Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02328v1"&gt;Path Planning using a One-shot-sampling Skeleton Map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02377v1"&gt;Sparse Gaussian Processes: Structured Approximations and Power-EP Revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02399v1"&gt;TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02494v1"&gt;MC-INR: Efficient Encoding of Multivariate Scientific Simulation Data using Meta-Learning and Clustered Implicit Neural Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02585v1"&gt;Scalable Interconnect Learning in Boolean Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02619v1"&gt;L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02645v1"&gt;Fair Deepfake Detectors Can Generalize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02659v1"&gt;OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02670v1"&gt;Guided Generation for Developable Antibodies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02686v1"&gt;Learning few-step posterior samplers by unfolding and distillation of diffusion models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02690v1"&gt;RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02698v1"&gt;Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02724v1"&gt;Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02762v1"&gt;Contextual Online Pricing with (Biased) Offline Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02834v1"&gt;ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02391v1"&gt;Posterior Transition Modeling for Unsupervised Diffusion-Based Speech Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02407v1"&gt;Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02416v1"&gt;Determination Of Structural Cracks Using Deep Learning Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02510v1"&gt;TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02599v1"&gt;Padé Approximant Neural Networks for Enhanced Electric Motor Fault Diagnosis Using Vibration and Acoustic Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02607v1"&gt;Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02671v1"&gt;Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02791v1"&gt;Self-Steering Deep Non-Linear Spatially Selective Filters for Efficient Extraction of Moving Speakers under Weak Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02801v1"&gt;Learning to Coordinate Bidders in Non-Truthful Auctions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02819v1"&gt;Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02850v1"&gt;LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02496v1"&gt;Online Conformal Prediction with Efficiency Guarantees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02732v1"&gt;Classification by Separating Hypersurfaces: An Entropic Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02275v1"&gt;It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02357v1"&gt;Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02378v1"&gt;Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02428v1"&gt;A Cookbook for Community-driven Data Collection of Impaired Speech in LowResource Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02679v1"&gt;Exploring Gender Bias Beyond Occupational Titles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02744v1"&gt;Measurement of the Granularity of Vowel Production Space By Just Producible Different (JPD) Limens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02799v1"&gt;Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02804v1"&gt;Multimodal Mathematical Reasoning with Diverse Solving Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02833v1"&gt;Generalizing Verifiable Instruction Following&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02364v1"&gt;QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02790v1"&gt;From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02846v1"&gt;Legal Requirements Translation from Law&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02858v1"&gt;Requirements Elicitation Follow-Up Question Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02287v1"&gt;Seeing Through Green: Text-Based Classification and the Firm's Returns from Green Patents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02380v1"&gt;JoyTTS: LLM-based Spoken Chatbot With Voice Cloning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02768v1"&gt;DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.02844v1"&gt;Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-07-04</guid><pubDate>Fri, 04 Jul 2025 12:21:04 +0900</pubDate></item><item><title>Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers</title><link>http://arxiv.org/abs/2507.02694v1</link><description>査読は科学研究の根幹ですが、出版物の増加に伴い、専門知識を要するこのプロセスにおける課題が深刻化しています。LLM（大規模言語モデル）は様々な科学的タスクで有望視されていますが、査読、特に論文の限界を特定する上での可能性は、まだ十分に研究されていません。まず、AIに焦点を当て、科学研究における限界の種類を包括的に分類します。この分類に基づき、限界の研究のために、LLMが初期段階のフィードバックを支援し、人間の査読を補完する能力を評価するための初の包括的なベンチマークであるLimitGenを提示します。私たちのベンチマークは、LimitGen-Syn（高品質な論文を意図的に改変して作成された合成データセット）とLimitGen-Human（人間が実際に書いた限界のコレクション）という2つのサブセットで構成されています。LLMシステムが限界を特定する能力を向上させるために、先行研究に基づいた限界の特定に不可欠な文献検索を導入し、LLMシステムを強化します。私たちのアプローチは、研究論文における限界を生成するLLMシステムの能力を高め、より具体的で建設的なフィードバックを提供できるようにします。

&lt;img src="https://arxiv.org/html/2507.02694v1/x3.png"/&gt;&lt;p&gt;0.1640625, 0.3359375}\bm{Y}}} start_FLOATSUPERSCRIPT bold_italic_Y end_FLOATSUPERSCRIPT Manasi Patwardhan 𝑻 𝑻 \hskip 1.00006pt{}^{{\color[rgb]{0.00390625, 0.3359375}\bm{Y}}} start_FLOATSUPERSCRIPT bold_italic_Y end_FLOATSUPERSCRIPT Yilun Zhao 𝒀 𝒀 \hskip 1.00006pt{}^{{\color[rgb]{0.0625, 0.4921875, 0.78125}\bm{T}}} start_FLOATSUPERSCRIPT bold_italic_T end_FLOATSUPERSCRIPT, Zhijian Xu 𝒀 𝒀 \hskip 1.00006pt{}^{{\color[rgb]{0.0625&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02694v1</guid><pubDate>Thu, 03 Jul 2025 15:04:38 +0000</pubDate></item><item><title>Revisiting Active Learning under (Human) Label Variation</title><link>http://arxiv.org/abs/2507.02593v1</link><description>高品質なラベル付きデータへのアクセスは、応用的な教師あり学習における依然として制約要因である。ラベルのバリエーション（LV）、つまり同じインスタンスに対する異なるラベルは、特に自然言語処理において一般的であるが、アノテーションフレームワークは依然として単一の正解を前提としていることが多い。これは、人間によるラベルのバリエーション（HLV）、つまりアノテーションにおけるもっともらしい差異の発生を、有益なシグナルとして見過ごしている。同様に、アクティブラーニング（AL）は、MLモデルのトレーニングにおける限られたアノテーション予算の利用を最適化するための一般的なアプローチであるが、HLVを認識する際には、実際にはほとんど当てはまらない、いくつかの単純化された仮定の少なくとも1つに依存していることが多い。本論文では、真実とラベルの性質に関する基本的な仮定を検証し、観測されたLVをシグナル（例：HLV）とノイズ（例：アノテーションエラー）に分解する必要性を強調する。ALと（H）LVのコミュニティがこれらの区別をどのように扱ってきたか（または無視してきたか）を調査し、インスタンス選択、アノテーターの選択、ラベル表現など、ALループ全体にHLVを組み込むための概念的フレームワークを提案する。さらに、大規模言語モデル（LLM）をアノテーターとして統合することについても議論する。我々の研究は、現実世界のアノテーションの複雑さをより良く反映した、HLVを考慮したアクティブラーニングのための概念的な基盤を築くことを目的としている。

&lt;img src="https://arxiv.org/html/2507.02593v1/extracted/6593237/figures/AL_loop_2.png"/&gt;&lt;p&gt;Center for Information, Cornelia Gruber Helen Alber Bernd Bischl LMU Munich, Department of Statistics, Germany Equal contribution cornelia.gruber@lmu.de, Germany LMU Munich, Germany Munich Center for Machine Learning (MCML), Language Processing (CIS), helen.alber@stat.uni-muenchen.de&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02593v1</guid><pubDate>Thu, 03 Jul 2025 12:59:28 +0000</pubDate></item><item><title>Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation</title><link>http://arxiv.org/abs/2507.02608v1</link><description>拡散モデルの推論時の高い計算コストは、高速な物理エミュレーターとしての利用を妨げている。画像や動画生成の分野では、この計算上の欠点は、ピクセル空間ではなくオートエンコーダーの潜在空間で生成することで対処されてきた。本研究では、同様の戦略を動的システムのシミュレーションに効果的に適用できるかどうか、そしてそのコストはどの程度かを調査する。潜在空間でのシミュレーションの精度は、驚くほど広範囲な圧縮率（最大1000倍）に対して頑健であることがわかった。また、拡散モデルに基づくエミュレーターは、非生成的なエミュレーターよりも一貫して精度が高く、予測の不確実性をより多様性で補償することを示す。最後に、潜在空間エミュレーターの学習に不可欠であることがわかった、アーキテクチャから最適化手法に至るまでの実践的な設計上の選択肢について説明する。

&lt;img src="https://arxiv.org/html/2507.02608v1/x1.png"/&gt;&lt;p&gt;AIM, CEA, CNRS, François Rozet Ruben Ohana Michael McCabe Polymathic AI Flatiron Institute University of Liège New York University Princeton University Université Paris-Saclay, Université Paris Cité&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02608v1</guid><pubDate>Thu, 03 Jul 2025 13:32:50 +0000</pubDate></item><item><title>Uncertainty-aware Reward Design Process</title><link>http://arxiv.org/abs/2507.02256v1</link><description>効果的な報酬関数の設計は強化学習（RL）の基礎ですが、従来の報酬設計手法に内在する非効率性と矛盾のために、依然として困難なプロセスです。最近の進歩では、大規模言語モデル（LLM）を活用して報酬関数の設計を自動化することが探求されています。しかし、数値最適化におけるLLMの最適とは言えない性能は、しばしば満足のいく報酬品質をもたらさず、進化探索パラダイムはシミュレーションリソースの非効率な利用を示し、その結果、法外に長い設計サイクルと不均衡な計算オーバーヘッドが生じます。これらの課題に対処するために、我々は、大規模言語モデルを統合してRL環境における報酬関数の設計と評価を効率化する、新しいフレームワークである不確実性認識報酬設計プロセス（URDP）を提案します。URDPは、自己整合性分析に基づいて候補報酬関数の不確実性を定量化し、シミュレーションなしで効果のない報酬コンポーネントを特定すると同時に、新しい報酬コンポーネントを発見することを可能にします。さらに、不確実性認識ベイズ最適化（UABO）を導入し、不確実性推定を組み込むことで、ハイパーパラメータ構成の効率を大幅に向上させます。最後に、報酬コンポーネントの最適化とハイパーパラメータの調整を分離することにより、二段階最適化アーキテクチャを構築します。URDPは、LLMの報酬ロジック推論とベイズ最適化の数値最適化の強みを相乗的に連携させます。3つのベンチマーク環境にまたがる35の多様なタスクにわたって、URDPの包括的な評価を実施します。実験結果は、URDPがより高品質な報酬関数を生成するだけでなく、既存のアプローチと比較して、自動報酬設計の効率において大幅な改善を達成することを示しています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02256v1</guid><pubDate>Thu, 03 Jul 2025 03:09:17 +0000</pubDate></item><item><title>RetrySQL: text-to-SQL training with retry data for self-correcting query generation</title><link>http://arxiv.org/abs/2507.02529v1</link><description>テキストからSQLへの変換タスクは、自然言語処理における活発な課題です。既存のソリューションの多くは、カスタマイズされたエンドツーエンドのテキストからSQLへのパイプライン内で、特殊なコンポーネントで拡張されたブラックボックス言語モデルの使用に焦点を当てています。これらのソリューションは、クローズドソースのプロプライエタリな言語モデルとコーディング指向のオープンソースモデルの両方を使用していますが、SQL固有の生成モデルに関する研究は不足しています。同時に、自己修正生成戦略における最近の進歩は、既存のアーキテクチャの能力を向上させる可能性を示しています。これらの概念のテキストからSQLへのタスクへの適用は、まだ探求されていません。本稿では、テキストからSQLへの生成モデルをトレーニングするための新しいアプローチであるRetrySQLを紹介します。参照SQLクエリの推論ステップを準備し、それらを破損させて、不正なステップと修正されたステップの両方を含むリトライデータを作成し、特殊なトークンで区切ります。このデータを使用して、オープンソースのコーディングモデルを継続的に事前トレーニングし、リトライステップが、リトライデータなしの事前トレーニングと比較して、全体的および困難な実行精度メトリクスで最大4パーセントポイントの改善をもたらすことを示します。さらに、LoRAを使用した教師ありファインチューニングは、リトライデータからの学習には効果がなく、フルパラメータの事前トレーニングがそのタスクに必要な要件であることを確認します。自己修正の挙動がモデルによって学習され、ダウンストリームの精度メトリクスの向上は、この追加スキルの結果であることを示します。最後に、RetrySQLでトレーニングされたモデルを完全なテキストからSQLへのパイプラインに組み込み、それらが、桁違いに多くのパラメータを含むプロプライエタリなモデルと実行精度に関して競争力があることを示します。RetrySQLは、自己修正がテキストからSQLへのタスクで学習可能であることを示し、SQL指向の言語モデルの生成精度を向上させるための新しい方法を提供します。

&lt;img src="https://arxiv.org/html/2507.02529v1/x1.png"/&gt;&lt;p&gt;Alicja Rączkowska, Joanna Baran, Paweł Olszewski, Piotr Zieliński, Riccardo Belluzzo&lt;/p&gt;&lt;p&gt;0000-0001-5901-4595
0000-0001-6792-7028
0009-0001-8669-3826
0009-0006-8906-7659
0009-0009-1307-2496
Allegro.com Poland&lt;/p&gt;</description><guid isPermaLink="false">2507.02529v1</guid><pubDate>Thu, 03 Jul 2025 11:00:49 +0000</pubDate></item><item><title>VERBA: Verbalizing Model Differences Using Large Language Models</title><link>http://arxiv.org/abs/2507.02241v1</link><description>現在の機械学習の状況において、私たちは「モデルの湖」現象に直面しています。あるタスクが与えられたとき、異なる挙動を示すにもかかわらず、類似した性能を持つ学習済みモデルが大量に存在します。モデルを利用するユーザーがモデルをナビゲートし、選択しようとする場合、モデルのペアを比較したドキュメントが役立ちます。しかし、N個のモデルごとにO(N^2)個のペアワイズ比較が存在する可能性があり、これはモデル開発者が手動でペアワイズ比較を実行し、ドキュメントを作成するには手に負えない数です。モデル間の詳細なペアワイズ比較を容易にするために、私たちは$\textbf{VERBA}$を導入しました。私たちのアプローチは、大規模言語モデル（LLM）を活用して、2つのモデルからサンプリングすることにより、モデルの差異を言語化します。シミュレーションを通じて言語化の情報量を評価するプロトコルを確立しました。また、一般的に使用される多様な機械学習モデルをベンチマークとしてまとめたスイートを構築しました。性能差が最大5％、挙動差が20〜25％の決定木モデルのペアの場合、$\textbf{VERBA}$は最大80％の全体的な精度で効果的にそれらのバリエーションを言語化します。モデルの構造情報を含めると、言語化の精度はさらに90％に向上しました。$\textbf{VERBA}$は、事後的に機械学習モデルの透明性と比較可能性を向上させるための新しい研究分野を開拓します。

&lt;img src="https://arxiv.org/html/2507.02241v1/x1.png"/&gt;&lt;p&gt;NJ, Shashidhar Reddy Javaji, Shravan Doda, USA, Zining Zhu Stevens Institute of Technology Hoboken&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02241v1</guid><pubDate>Thu, 03 Jul 2025 02:25:24 +0000</pubDate></item><item><title>Solving the Hubbard model with Neural Quantum States</title><link>http://arxiv.org/abs/2507.02644v1</link><description>ニューラル量子状態（NQS）の急速な発展により、量子多体系を研究するための有望な枠組みとして確立されました。本研究では、最先端のTransformerベースのアーキテクチャを活用し、高度に効率的な最適化アルゴリズムを開発することで、高温超伝導の最小モデルと言える、ドープされた二次元（2D）ハバードモデルにおいて、最先端の結果を達成しました。興味深いことに、NQS ansatzにおける異なるアテンションヘッドが、異なるスケールでの相関を直接エンコードできることがわかりました。これにより、強相関系における長距離相関とエンタングルメントを捉えることが可能になります。これらの進歩により、我々は、次近接ホッピングを持つ2Dハバードモデルの基底状態におけるハーフフィルドストライプを確立しました。これは、銅酸化物における実験的観測と一致します。我々の研究は、NQSが困難な多フェルミオン系を解くための強力なツールであることを確立します。

&lt;img src="https://arxiv.org/html/2507.02644v1/x1.png"/&gt;&lt;p&gt;Bo Zhan, Di He, Dingshun Lv, Heng Lin, Liwei Wang, Mingpu Qin, Ruichen Li, Tao Xiang, Wenrui Li, Yantao Wu, Yifei Huang, Yuntian Gu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02644v1</guid><pubDate>Thu, 03 Jul 2025 14:08:25 +0000</pubDate></item><item><title>MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent</title><link>http://arxiv.org/abs/2507.02259v1</link><description>長さの外挿、効率的な注意機構、メモリモジュールによる改善にもかかわらず、外挿時の性能劣化なしに、線形計算量で無限に長いドキュメントを処理することは、長文処理における究極の課題であり続けています。我々は、エンドツーエンドで長文タスクを直接最適化し、テキストをセグメントごとに読み込み、上書き戦略を用いてメモリを更新する新しいエージェントワークフロー、MemAgentを導入します。独立したコンテキストでの複数会話生成による学習を促進するために、DAPOアルゴリズムを拡張しました。MemAgentは優れた長文コンテキスト能力を示し、32Kテキストで学習した8Kコンテキストから3.5MのQAタスクへ外挿した場合でも、性能損失が5%未満に抑えられ、512KのRULERテストでは95%以上の精度を達成しました。

&lt;img src="https://arxiv.org/html/2507.02259v1/x1.png"/&gt;&lt;p&gt;Hao Zhou, Hongli Yu, Jiangjie Chen, Jiangtao Feng, Jingjing Liu, Mingxuan Wang, Qiying Yu, Tinghong Chen, Wei-Ying Ma, Weinan Dai, Ya-Qin Zhang&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2507.02259v1</guid><pubDate>Thu, 03 Jul 2025 03:11:50 +0000</pubDate></item><item><title>Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving</title><link>http://arxiv.org/abs/2507.02726v1</link><description>大規模言語モデル(LLM)にとって、推論は依然として困難な課題であり、特に自動定理証明(ATP)のような論理的に制約された環境においては、報酬の疎性と証明の膨大な規模が原因で困難さが増幅される。これらの課題は、複雑な多段階推論を必要とする大学レベルの問題を含むPutnamBenchのようなベンチマークで顕著になる。これに対処するため、自己生成ゴール条件付きMDP(sG-MDP)という新しいフレームワークを導入する。このフレームワークでは、エージェントは進化する証明状態に基づいてサブゴールを生成し、追求する。このように構造化されたゴールの生成により、結果として生じる問題は探索が容易になる。次に、モンテカルロ木探索(MCTS)のようなアルゴリズムを適用してsG-MDPを解き、サブゴールの生成と戦術の合成のために複数の7B LLMをアンサンブルできるモジュール式システムであるBourbaki (7B)に我々のアプローチを実装する。PutnamBenchにおいて、Bourbaki (7B)は26問を解き、この規模のモデルで最先端の結果を達成した。

&lt;img src="https://arxiv.org/html/2507.02726v1/x1.png"/&gt;&lt;p&gt;Matthieu Zimmer Huawei Noah’s Ark Lab &amp;Xiaotong Ji Huawei Noah’s Ark Lab Imperial College London &amp;Rasul Tutunov Huawei Noah’s Ark Lab &amp;Anthony Bordg Huawei Lagrange Center &amp;Jun Wang UCL Centre for AI &amp;Haitham Bou Ammar Huawei Noah’s Ark Lab UCL Centre for AI&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02726v1</guid><pubDate>Thu, 03 Jul 2025 15:41:38 +0000</pubDate></item><item><title>Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design &amp; Verification</title><link>http://arxiv.org/abs/2507.02660v1</link><description>現代の集積回路（IC）はますます複雑化しており、その開発プロセスも同様です。ハードウェア設計検証は、機能的に正しいハードウェア設計の計画、開発、実行、およびサインオフに対する、系統的かつ規律あるアプローチを伴います。この退屈なプロセスには、バグのないテープアウトを保証するために多大な労力と時間が必要です。自然言語処理の分野は、大規模言語モデル（LLM）の出現により大きな変革を遂げました。生成AI（GenAI）とも呼ばれるこれらの強力なモデルは、機械が人間の言語を理解し生成する方法に革命をもたらし、ハードウェア設計検証を含む幅広いアプリケーションにおいて前例のない進歩を可能にしました。本稿では、ハードウェア設計検証に対するエージェントAIベースのアプローチを紹介します。これは、人間参加型（HITL）介入と連携して、AIエージェントがより動的で反復的、かつ自己反省的なプロセスに関与できるようにし、最終的にエンドツーエンドのハードウェア設計と検証を実行します。この手法を5つのオープンソース設計で評価した結果、95%を超えるカバレッジを達成し、検証時間を短縮しながら、優れた性能、適応性、および構成可能性を実証しました。

&lt;img src="https://arxiv.org/html/2507.02660v1/x1.png"/&gt;&lt;p&gt;Aman Kumar, Deepak Narayan Gadde, Djones Lettnin, Keerthan Kopparam Radhakrishna, Sebastian Simon, Vaisakh Naduvodi Viswambharan, Wolfgang Kunz&lt;/p&gt;&lt;p&gt;1 Infineon Technologies Dresden GmbH &amp; Co. KG, Germany 2 Infineon Technologies India Pvt. Ltd., India 3 Infineon Technologies AG, Germany 4 Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Germany&lt;/p&gt;</description><guid isPermaLink="false">2507.02660v1</guid><pubDate>Thu, 03 Jul 2025 14:20:57 +0000</pubDate></item><item><title>WebSailor: Navigating Super-human Reasoning for Web Agent</title><link>http://arxiv.org/abs/2507.02592v1</link><description>人間の認知能力の限界を超えることは、LLMトレーニングにおける重要なフロンティアです。DeepResearchのような独自の自律型システムは、BrowseCompのような非常に複雑な情報探索ベンチマークにおいて、これまで達成不可能だった超人的な能力を実証しました。我々は、彼らの成功は、オープンソースモデルには見られない洗練された推論パターン、すなわち、広大な情報環境をナビゲートする際に極端な不確実性を体系的に軽減する能力にかかっていると仮定します。この洞察に基づき、この重要な能力を植え付けるように設計された完全なポストトレーニング手法であるWebSailorを紹介します。我々のアプローチは、構造化されたサンプリングと情報難読化、RFTコールドスタート、および効率的な自律型RLトレーニングアルゴリズムであるDuplicating Sampling Policy Optimization（DUPO）を通じて、斬新で不確実性の高いタスクを生成することを含みます。この統合されたパイプラインにより、WebSailorは複雑な情報探索タスクにおいてすべてのオープンソースエージェントを大幅に上回り、独自の自律型エージェントのパフォーマンスに匹敵し、能力のギャップを埋めます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02592v1</guid><pubDate>Thu, 03 Jul 2025 12:59:07 +0000</pubDate></item><item><title>AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench</title><link>http://arxiv.org/abs/2507.02554v1</link><description>AI研究エージェントは、機械学習モデルの設計、実装、トレーニングを自動化することで、科学の進歩を加速させる大きな可能性を示しています。本研究では、エージェントがKaggleコンペティションに参加して現実世界の機械学習問題を解決する、難易度の高いベンチマークであるMLE-benchにおけるエージェントの性能向上に焦点を当てます。AI研究エージェントを、候補解の空間をナビゲートし、オペレーターを用いて反復的に修正する探索ポリシーとして形式化します。異なるオペレーターセットと探索ポリシー（Greedy、MCTS、Evolutionary）を設計し、体系的に変化させることで、それらの相互作用が高性能を達成するために重要であることを示します。探索戦略とオペレーターセットの最適な組み合わせにより、MLE-bench liteで最先端の結果を達成し、Kaggleメダルを獲得する成功率を39.6%から47.7%に向上させました。本研究は、自動機械学習を進歩させる上で、探索戦略、オペレーター設計、評価方法論を共同で検討することの重要性を強調しています。

&lt;img src="https://arxiv.org/html/2507.02554v1/x1.png"/&gt;&lt;p&gt;Abhishek Charnalia, Alexander H. Miller, Alexis Audran-Reiss, Alisia Maria Lupidi, Andrei Lupu, Carole Jean Wu, Derek Dunfield, Despoina Magka, Edan Toledo, Jakob Nicolaus Foerster, Jean-Christophe Gagnon-Audet, Karen Hambardzumyan, Kelvin Niu, Martin Josifoski, Michael Kuchnik, Michael Shvartsman, Minqi Jiang, Nicola Cancedda, Nicolas Baldwin, Pontus Stenetorp, Rishi Hazra, Roberta Raileanu, Shagun Sodhani, Tatiana Shavrina, Yoram Bachrach&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2507.02554v1</guid><pubDate>Thu, 03 Jul 2025 11:59:15 +0000</pubDate></item><item><title>An AI-native experimental laboratory for autonomous biomolecular engineering</title><link>http://arxiv.org/abs/2507.02379v1</link><description>複雑な実験を自律的に行い、専門家以外にも役立つ自律的な科学研究は、長年の願望です。それを実現するには、人工知能（AI）によって推進される根本的なパラダイムシフトが必要です。自律的な実験システムは登場しつつありますが、化学合成や触媒など、単一の目的と明確で単純な実験ワークフローを特徴とする分野に限定されています。本稿では、自律的な生体分子工学のような応用に向けて、非常に複雑な科学実験を対象としたAIネイティブな自律ラボを紹介します。このシステムは、機器を自律的に管理し、実験固有の手順と最適化ヒューリスティクスを策定し、複数のユーザー要求を同時に処理します。モデル、実験、機器の共同設計哲学に基づいて構築されたこのプラットフォームは、AIモデルと自動化システムの共進化をサポートします。これにより、多様な機器にわたる複雑な多目的実験を処理する、エンドツーエンドのマルチユーザー自律ラボが確立されます。当社の自律ラボは、合成、転写、増幅、シーケンスなど、核酸の基本的な機能をサポートしています。また、疾患診断、医薬品開発、情報ストレージなどの分野での応用も可能です。人間の介入なしに、実験パフォーマンスを自律的に最適化し、人間の科学者が達成した最先端の結果に匹敵するレベルに到達します。マルチユーザーシナリオでは、このプラットフォームは機器の利用率と実験効率を大幅に向上させます。このプラットフォームは、専門家への依存やリソースの障壁を克服し、大規模なScience-as-a-Serviceの青写真となる、高度な生体材料研究への道を開きます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02379v1</guid><pubDate>Thu, 03 Jul 2025 07:21:19 +0000</pubDate></item><item><title>HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3</title><link>http://arxiv.org/abs/2507.02345v1</link><description>抗体エンジニアリングは、治療薬の開発と生物医学研究の進歩に不可欠です。従来の手法では、時間とリソースを消費する実験的スクリーニングに頼ることがよくあります。このプロセスを強化し効率化するために、高精度な構造予測モデルであるHelixFold3を活用した、HelixFold3とHelixDesign-Antibodyを基盤とする、プロダクショングレードのハイスループットプラットフォームを導入します。このプラットフォームは、抗体候補配列の大規模な生成を促進し、抗原との相互作用を評価します。統合された高性能コンピューティング（HPC）サポートにより、断片化されたツールチェーンや高い計算需要といった課題に対処し、ハイスループットスクリーニングを可能にします。複数の抗原での検証により、このプラットフォームが多様で高品質な抗体を生成する能力が示され、より大きな配列空間を探索することで最適な結合物質を特定できる可能性が高まるというスケーリング則が確認されました。このプラットフォームは、大規模な抗体設計のためのシームレスでアクセス可能なソリューションを提供し、PaddleHelixプラットフォームの抗体設計ページから利用可能です。

&lt;img src="https://arxiv.org/html/2507.02345v1/x1.png"/&gt;&lt;p&gt;Baidu Inc., Jie Gao, Jing Hu, Kunrui Zhu, Shanzhuo Zhang, Sheng Qian, Xiaomin Fang PaddleHelix Team, Xiaonan Zhang, Yueyang Huang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02345v1</guid><pubDate>Thu, 03 Jul 2025 06:13:23 +0000</pubDate></item><item><title>Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work</title><link>http://arxiv.org/abs/2507.02760v1</link><description>大規模言語モデル（LLM）の能力は、複雑な、ドメイン固有の知識との対話に新たなフロンティアを開きました。しかし、検索拡張生成（RAG）や汎用的なエージェント型AIのような一般的な手法は、強力である一方で、専門分野に固有の、深く、手続き的で、方法論的な推論を必要とするタスクには苦戦することがよくあります。RAGは事実的な文脈を提供しますが、論理的な枠組みを伝えることができません。自律エージェントは、ドメイン固有のヒューリスティクスがないと非効率的で予測不可能になる可能性があります。このギャップを埋めるために、私たちは知識プロトコルエンジニアリング（KPE）という新しいパラダイムを導入します。KPEは、人間の専門家の知識（多くの場合、自然言語文書で表現される）を、機械実行可能な知識プロトコル（KP）に体系的に変換することに焦点を当てています。KPEは、LLMを断片的な情報で単に補強するのではなく、ドメイン固有の論理、運用戦略、および方法論的原則をLLMに与えることに重点を置いています。適切に設計された知識プロトコルにより、汎用的なLLMが専門家として機能し、抽象的なクエリを分解し、複雑な多段階タスクを実行できるようになると主張します。このポジションペーパーでは、KPEの中核となる原則を定義し、関連する概念との違いを明確にし、法律やバイオインフォマティクスなどの多様な分野における潜在的な適用可能性を示し、人間とAIのコラボレーションの未来のための基礎的な方法論として位置づけます。

&lt;img src=""/&gt;&lt;p&gt;Guangwei Zhang zhangguangwei@snnu.edu.cn&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02760v1</guid><pubDate>Thu, 03 Jul 2025 16:21:14 +0000</pubDate></item><item><title>Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation</title><link>http://arxiv.org/abs/2507.02253v1</link><description>大規模言語モデル（LLM）の計画および推論能力の向上における進歩は、スケーラブルで信頼性の高いデータ生成と評価のボトルネックによって著しく妨げられています。これを克服するために、私はNL2FLOWという、自然言語、構造化された中間表現、および形式的なPDDLで表現された計画問題をパラメトリックに生成し、生成された計画の品質を厳密に評価するための、完全に自動化されたシステムを紹介します。自動化されたワークフロー生成ドメインで2296個の問題のデータセットを生成し、複数のオープンソースのインストラクトチューニングされたLLMを評価することで、NL2FLOWの能力を実証します。私の結果は、最高のパフォーマンスを発揮するモデルが、実行可能なソリューションを持つ問題に対して、有効な計画の生成で86％、最適な計画の生成で69％の成功を収めたことを明らかにしています。回帰分析は、計画生成に対する問題特性の影響が、モデルとプロンプト設計の両方に依存することを示しています。特に、自然言語を計画のJSON表現に翻訳する際の最高の成功率は、有効な計画を直接生成する際の最高の成功率よりも低いことが観察されました。これは、不必要に推論タスクを分解すること（中間翻訳ステップを導入すること）が、実際にはパフォーマンスを低下させる可能性があり、自然言語から直接行動を推論できるモデルに利点があることを示唆しています。LLMの推論をますます複雑な問題にスケールするにつれて、これらのシステム内のボトルネックとエラーの原因は必然的に変化します。したがって、これらの制限事項の動的な理解と、それらを体系的に明らかにするためのツールは、インテリジェントな問題解決者としてのLLMの可能性を最大限に引き出すために不可欠です。

&lt;img src="https://arxiv.org/html/2507.02253v1/extracted/6591812/img/nl2flow_overview.png"/&gt;&lt;p&gt;Jungkoo Kang IBM Research 314 Main St Cambridge, MA 02142&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02253v1</guid><pubDate>Thu, 03 Jul 2025 03:02:49 +0000</pubDate></item><item><title>Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation</title><link>http://arxiv.org/abs/2507.02752v1</link><description>望ましい特性を持つAI生成分子と、それらの合成可能性との間の乖離は、計算創薬および材料発見における重大なボトルネックであり続けています。生成AIは候補分子の提案を加速化しましたが、これらの構造の多くは、確立された化学反応を用いた合成が困難であるか、不可能です。本稿では、SynTwinsという、逆合成解析に基づいた新しい分子アナログ設計フレームワークを紹介します。これは、逆合成、類似ビルディングブロックの探索、仮想合成という3段階のプロセスを通じて、専門家の化学者の戦略を模倣し、合成可能な分子アナログを設計します。比較評価において、SynTwinsは、最先端の機械学習モデルと比較して、合成可能なアナログの生成において優れた性能を示し、元の標的分子との高い構造的類似性を維持しています。さらに、既存の分子最適化フレームワークと統合すると、私たちのハイブリッドアプローチは、制約のない分子ジェネレーターと同等の特性プロファイルを持つ、合成可能な分子を生成し、その合成可能性が保証されます。多様な分子データセットにわたる包括的なベンチマークにより、SynTwinsは計算設計と実験合成の間のギャップを効果的に埋め、幅広いアプリケーションにおいて、望ましい特性を持つ合成可能な分子の発見を加速するための実用的なソリューションを提供することが示されています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02752v1</guid><pubDate>Thu, 03 Jul 2025 16:14:57 +0000</pubDate></item><item><title>Prediction of synthesis parameters for N, Si, Ge and Sn diamond vacancy centers using machine learning</title><link>http://arxiv.org/abs/2507.02808v1</link><description>ダイヤモンドとダイヤモンドカラーセンターは、量子情報・計算、光学、フォトニクス、そして（バイオ）センシングにおける固体ベース技術の主要なハードウェア候補となっています。したがって、特定の特性を持つダイヤモンド材料の合成と、内包されるカラーセンターの精密な制御は、高度なアプリケーションの要求を満たすために不可欠です。しかし、これらのセンターの濃度、均一な分布、および品質の向上には依然として課題が残っています。本稿では、N-, Si-, Ge-, Sn-空孔カラーセンターの合成のための主要なダイヤモンド合成法とそのパラメータに関するレビューとメタ分析を行い、製造技術とプロセスにおける世界的な動向を含めて考察します。60件以上の実験論文から定量的なデータを抽出し、大規模なデータベース（170のデータセットと1692のエントリ）に整理します。次に、このデータベースを使用して、2つの機械学習アルゴリズムを訓練し、合成パラメータの慎重な組み合わせから特定の特性を持つダイヤモンド材料の製造に関するロバストな予測を行います。従来の統計的指標を用いてアルゴリズムの性能を評価し、ダイヤモンドカラーセンターとその応用に取り組む研究者や材料科学者にとって、強力でリソース効率の高いツールであることを示します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02808v1</guid><pubDate>Thu, 03 Jul 2025 17:16:14 +0000</pubDate></item><item><title>Tailoring the Electronic Properties of Monoclinic (InxAl1-x)2O3 Alloys via Substitutional Donors and Acceptors</title><link>http://arxiv.org/abs/2507.02805v1</link><description>β-Ga2O3のような超広バンドギャップ半導体は、次世代パワーエレクトロニクスデバイスに理想的な材料です。β-Ga2O3の電気的および機械的特性は、他のセスキオキサイド、特にAl2O3およびIn2O3との合金化によって調整できます。さらに、(InxAl1-x)2O3合金のIn含有量を調整することで、大きな伝導帯オフセットを維持しながら、その格子定数をGa2O3の格子定数に一致させることができます。β-Ga2O3ベースのヘテロ構造への潜在的な応用を考慮して、密度汎関数理論を用いて(InxAl1-x)2O3合金の原子モデリングを行い、従来のIV族ドーパント（Si、Sn、C、Ge）、代替金属ドナー（Ta、Zr、Hf）、およびアクセプター（Mg、Zn、Cu）の熱力学的および電気的特性を調査しました。ハイブリッドHeyd-Scuseria-Ernzerhof汎関数（HSE06）を使用して、酸素化学ポテンシャルと温度の実験的に関連する広範囲の条件下で、欠陥形成エネルギー、イオン化レベル、および濃度を正確に定量化します。私たちの原子モデルでは、HfとZrは、特に酸素不足の条件下で、Siや他のIV族不純物の代替ドナーとして有利な特性を示しています。私たちの調査結果はまた、アクセプターであるMg、Zn、およびCuは、p型ドーピングを促進することはできませんが、意図しないn型ドープ材料の補償、例えば、半絶縁層の生成や整流の改善に依然として役立つ可能性があることを示唆しています。

&lt;img src="https://arxiv.org/html/2507.02805v1/extracted/6593300/Figures/Fig_1.png"/&gt;&lt;p&gt;Lorenzo Stella, Mohamed Abdelilah Fadla, Myrta Grüning&lt;/p&gt;&lt;p&gt;European Theoretical Spectroscopy Facility
School of Mathematics and Physics, Queen’s University Belfast, University Road, Belfast BT7 1NN, UK&lt;/p&gt;</description><guid isPermaLink="false">2507.02805v1</guid><pubDate>Thu, 03 Jul 2025 17:10:40 +0000</pubDate></item><item><title>High-Throughput NEB for Li-Ion Conductor Discovery via Fine-Tuned CHGNet Potential</title><link>http://arxiv.org/abs/2507.02334v1</link><description>全固体電池の開発において、固体電解質は不可欠である。密度汎関数理論（DFT）に基づくNudged Elastic Band（NEB）法や第一原理分子動力学（AIMD）法は、リチウムイオンの移動障壁やイオン伝導度に関する基礎的な知見を提供するが、その計算コストの高さから、大規模な材料探索は困難である。本研究では、高速イオン伝導体の効率的な発見のために、遷移状態理論に基づいた移動障壁の加速予測を可能にする、微調整された汎用機械学習原子間ポテンシャル（uMLIPs）と統合されたハイスループットNEB計算フレームワークを開発した。このフレームワークは、初期状態/最終状態および移動経路の構築を自動化し、高エネルギー状態に関する十分なトレーニングデータがないために、事前学習済みポテンシャルにおける不正確な障壁予測を軽減する。微調整されたCHGNetモデルをNEB/MD計算に採用し、二重CHGNet-NEB/MDは、NASICON型Li$_{1+x}$Al$_x$Ti$_{2-x}$(PO$_4$)$_3$ (LATP)構造で検証されたように、計算速度と精度のバランスを実現する。ハイスループットスクリーニングを通じて、高速イオン伝導体の有望なフレームワークとして機能する斜方晶Pnma群構造（LiMgPO$_4$、LiTiPO$_5$など）を特定した。それらの異種原子価ドープされた変異体であるLi$_{0.5}$Mg$_{0.5}$Al$_{0.5}$PO$_4$およびLi$_{0.5}$TiPO$_{4.5}$F$_{0.5}$は、低い活性化エネルギーと、それぞれ0.19 mS/cmおよび0.024 mS/cmの高いイオン伝導度を持つと予測された。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.02334v1</guid><pubDate>Thu, 03 Jul 2025 05:58:35 +0000</pubDate></item></channel></rss>