<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Thu, 05 Jun 2025 03:20:55 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-05</title><link>https://arxiv.org/2025-06-05</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03494v1"&gt;Propylenidene: A New Carbon Two-dimensional Material Featuring Tilted Dirac Cones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03742v1"&gt;Ultrafast switching of photoinduced phonon chirality in the antiferrochiral BPO$_{4}$ crystal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03871v1"&gt;Large Berry curvature effects induced by extended nodal structures: Rational design strategy and high-throughput materials predictions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04137v1"&gt;Atomic scale structure and dynamical properties of (TeO$_2$)$_{1-x}$-(Na$_2$O)$_{x}$ glasses through first-principles modeling and XRD measurements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03611v1"&gt;Gefitinib-Induced Interface Engineering Enhances the Defect Formation Energy for Highly Efficient and Stable Perovskite Solar Cells&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03730v1"&gt;Direct laser ablation of 2D material films for fabricating multi-functional flexible and transparent devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03748v1"&gt;Magic of nonlocal geometric force: lighting up optical transition and transporting angular momentum by chiral phonons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03810v1"&gt;Molecular Dynamics Simulations on Nuclear Recoils in Silicon Crystals towards Single Electron-Hole Pair Ionization Yields&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04000v1"&gt;Note on the interpretation of magnetic diffraction in NdAlSi: helical or fan?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03499v1"&gt;High-pressure Induced Phase Transition and Laser Characterization Response of MAPbBr3 Thin Films&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04155v1"&gt;Signatures of the Fermi surface reconstruction of a doped Mott insulator in a slab geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03811v1"&gt;Delayed photoisomerisation of the trans-PSB3 retinal toy model using on-the-fly quantum dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04160v1"&gt;Interplay between ultrafast electronic and librational dynamics in liquid nitrobenzene probed with two-color four-wave mixing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03529v1"&gt;Ultralong Room-Temperature Qubit Lifetimes of Covalent Organic Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03732v1"&gt;Physics-Based Compact Modeling for the Drain Current Variability in Single-Layer Graphene FETs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03905v1"&gt;Lattice Boltzmann wall boundary conditions for RANS-based simulations with wall functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04017v1"&gt;Experimental and simulative study on laser irradiation of 3D-printed micro-structures at intensities relevant for inertial confinement fusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03518v1"&gt;Two self-starting single-solve third-order explicit integration algorithms for second-order nonlinear dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03833v1"&gt;Technical report on a quantum-inspired solver for simulating compressible flows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03503v1"&gt;Computational Architects of Society: Quantum Machine Learning for Social Rule Genesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03548v1"&gt;SUMO-MCP: Leveraging the Model Context Protocol for Autonomous Traffic Simulation and Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03610v1"&gt;Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03915v1"&gt;Causal Explanations Over Time: Articulated Reasoning for Interactive Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04133v1"&gt;TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03501v1"&gt;Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03511v1"&gt;POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03516v1"&gt;SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03568v1"&gt;Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03571v1"&gt;DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03598v1"&gt;Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03613v1"&gt;Training Cross-Morphology Embodied AI Agents: From Practical Challenges to Theoretical Foundations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03618v1"&gt;GCFL: A Gradient Correction-based Federated Learning Framework for Privacy-preserving CPSS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03621v1"&gt;Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03642v1"&gt;Spatial Understanding from Videos: Structured Prompts Meet Simulation Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03654v1"&gt;MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03667v1"&gt;Accelerating SfM-based Pose Estimation with Dominating Set&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03710v1"&gt;OSGNet @ Ego4D Episodic Memory Challenge 2025&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03723v1"&gt;Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03737v1"&gt;ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03740v1"&gt;SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03755v1"&gt;Misalignment or misuse? The AGI alignment tradeoff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03758v1"&gt;Scaling CrossQ with Weight Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03762v1"&gt;AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03828v1"&gt;AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03872v1"&gt;JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03880v1"&gt;RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03933v1"&gt;DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03964v1"&gt;Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03997v1"&gt;A framework for Conditional Reasoning in Answer Set Programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04001v1"&gt;CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04022v1"&gt;Interpretability by Design for Efficient Multi-Objective Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04036v1"&gt;Privacy and Security Threat for OpenAI GPTs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04044v1"&gt;Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04050v1"&gt;Explainability-Based Token Replacement on LLM-Generated Text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04078v1"&gt;LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04132v1"&gt;Plant Bioelectric Early Warning Systems: A Five-Year Investigation into Human-Plant Electromagnetic Communication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04143v1"&gt;Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04168v1"&gt;Horizon Reduction Makes RL Scalable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04210v1"&gt;Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04217v1"&gt;OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04226v1"&gt;Efficient Knowledge Editing via Minimal Precomputation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03525v1"&gt;Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03543v1"&gt;CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating &amp; Hiring Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03546v1"&gt;From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation in High-Stakes Healthcare Context&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03566v1"&gt;POSS: Position Specialist Generates Better Draft for Speculative Decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03582v1"&gt;ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03586v1"&gt;Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03588v1"&gt;A Class Inference Scheme With Dempster-Shafer Theory for Learning Fuzzy-Classifier Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03589v1"&gt;BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03595v1"&gt;Purifying Shampoo: Investigating Shampoo's Heuristics by Decomposing its Preconditioner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03602v1"&gt;Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03606v1"&gt;Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03614v1"&gt;VLMs Can Aggregate Scattered Training Patches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03637v1"&gt;RewardAnything: Generalizable Principle-Following Reward Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03682v1"&gt;How PARTs assemble into wholes: Learning the relative composition of images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03735v1"&gt;Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03784v1"&gt;When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03827v1"&gt;Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03941v1"&gt;Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03954v1"&gt;HtFLlib: A Comprehensive Heterogeneous Federated Learning Library and Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04006v1"&gt;TransClean: Finding False Positives in Multi-Source Entity Matching under Real-World Conditions via Transitive Consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04013v1"&gt;Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive Voice Conversion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04018v1"&gt;AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04039v1"&gt;Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04058v1"&gt;Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04079v1"&gt;EuroLLM-9B: Technical Report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04088v1"&gt;Multimodal Tabular Reasoning with Privileged Structured Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04089v1"&gt;AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04098v1"&gt;TextAtari: 100K Frames Game Playing with Language Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04116v1"&gt;A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04121v1"&gt;A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04129v1"&gt;Recent Advances in Medical Image Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04131v1"&gt;CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04147v1"&gt;SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04207v1"&gt;Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04215v1"&gt;Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally Interdependent Multi-Agent MDPs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04218v1"&gt;Pseudo-Simulation for Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04043v1"&gt;Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04227v1"&gt;Object-centric 3D Motion Field for Robot Learning from Human Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03542v1"&gt;Learning Monotonic Probabilities with a Generative Cost Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03556v1"&gt;Optimizing FPGA and Wafer Test Coverage with Spatial Sampling and Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03590v1"&gt;VCDiag: Classifying Erroneous Waveforms for Failure Triage Acceleration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03674v1"&gt;Out-of-Distribution Graph Models Merging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03696v1"&gt;Comprehensive Attribute Encoding and Dynamic LSTM HyperModels for Outcome Oriented Predictive Business Process Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03777v1"&gt;FedFACT: A Provable Framework for Controllable Group-Fairness Calibration in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03790v1"&gt;Attention-Only Transformers via Unrolled Subspace Denoising&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03802v1"&gt;Learning Equilibria in Matching Games with Bandit Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03817v1"&gt;Survey of Active Learning Hyperparameters: Insights from a Large-Scale Experimental Grid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03850v1"&gt;Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03910v1"&gt;Enhancing Experimental Efficiency in Materials Design: A Comparative Study of Taguchi and Machine Learning Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03914v1"&gt;Learning equivariant models by discovering symmetries with learnable augmentations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04026v1"&gt;On the Usage of Gaussian Process for Efficient Data Valuation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04178v1"&gt;OpenThoughts: Data Recipes for Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04190v1"&gt;How to Use Graph Data in the Wild to Help Graph Anomaly Detection?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04205v1"&gt;EPiC: Towards Lossless Speedup for Reasoning Training through Edge-Preserving CoT Condensation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04206v1"&gt;A Few Moments Please: Scalable Graphon Learning via Moment Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03522v1"&gt;Path Generation and Evaluation in Video Games: A Nonparametric Statistical Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03531v1"&gt;Conformal Mixed-Integer Constraint Learning with Feasibility Guarantees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03657v1"&gt;SubSearch: Robust Estimation and Outlier Detection for Stochastic Block Models via Subgraph Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03670v1"&gt;Position: There Is No Free Bayesian Uncertainty Quantification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03672v1"&gt;Latent Guided Sampling for Combinatorial Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03697v1"&gt;RhoDARTS: Differentiable Quantum Architecture Search with Density Matrix Simulations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03719v1"&gt;On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03725v1"&gt;Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03757v1"&gt;PPO in the Fisher-Rao geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03764v1"&gt;Infinitesimal Higher-Order Spectral Variations in Rectangular Real Random Matrices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03796v1"&gt;Geoff: The Generic Optimization Framework &amp; Frontend for Particle Accelerator Controls&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03813v1"&gt;Graph Neural Networks for Resource Allocation in Multi-Channel Wireless Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03819v1"&gt;Spatially Resolved Meteorological and Ancillary Data in Central Europe for Rainfall Streamflow Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03839v1"&gt;Revisiting Unbiased Implicit Variational Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03849v1"&gt;Algorithm- and Data-Dependent Generalization Bounds for Score-Based Generative Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03857v1"&gt;Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03863v1"&gt;STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03870v1"&gt;Evaluating Apple Intelligence's Writing Tools for Privacy Against Large Language Model-Based Inference Attacks: Insights from Early Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03889v1"&gt;Temporal horizons in forecasting: a performance-learnability trade-off&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03898v1"&gt;A kernel conditional two-sample test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03911v1"&gt;Learning Fair And Effective Points-Based Rewards Programs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03913v1"&gt;When Fairness Isn't Statistical: The Limits of Machine Learning in Evaluating Legal Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03931v1"&gt;Do Neural Networks Need Gradient Descent to Generalize? A Theoretical Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03938v1"&gt;FPGA-Enabled Machine Learning Applications in Earth Observation: A Systematic Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03943v1"&gt;Lower Ricci Curvature for Hypergraphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03951v1"&gt;Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03956v1"&gt;Adapt before Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03978v1"&gt;Structured Pruning for Diverse Best-of-N Reasoning Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03988v1"&gt;RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03996v1"&gt;Optimal Spiking Brain Compression: Improving One-Shot Post-Training Pruning and Quantization for Spiking Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04040v1"&gt;Autonomous Vehicle Lateral Control Using Deep Reinforcement Learning with MPC-PID Demonstration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04045v1"&gt;Similarity-based fuzzy clustering scientific articles: potentials and challenges from mathematical and computational perspectives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04063v1"&gt;Crowd-SFT: Crowdsourcing for LLM Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04071v1"&gt;Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04118v1"&gt;Guided Speculative Inference for Efficient Test-Time Alignment of LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04126v1"&gt;Incremental Gradient Descent with Small Epoch Counts is Surprisingly Slow on Ill-Conditioned Problems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04165v1"&gt;Faster Approx. Top-K: Harnessing the Full Power of Two Stages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04172v1"&gt;Does Prompt Design Impact Quality of Data Imputation by LLMs?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04204v1"&gt;A Kernel-Based Approach for Accurate Steady-State Detection in Performance Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03515v1"&gt;BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03664v1"&gt;Intersectional Bias in Pre-Trained Image Recognition Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03746v1"&gt;Dropout-Robust Mechanisms for Differentially Private and Fully Decentralized Mean Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03779v1"&gt;Towards Quantum Operator-Valued Kernels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03780v1"&gt;High-Dimensional Learning in Finance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03801v1"&gt;From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03974v1"&gt;A Generic Branch-and-Bound Algorithm for $\ell_0$-Penalized Problems with Supplementary Material&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04053v1"&gt;Curse of Slicing: Why Sliced Mutual Information is a Deceptive Measure of Statistical Dependence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04166v1"&gt;N$^2$: A Unified Python Package and Test Bench for Nearest Neighbor-Based Matrix Completion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04193v1"&gt;Understanding challenges to the interpretation of disaggregated evaluations of algorithmic fairness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03594v1"&gt;SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04214v1"&gt;Sounding that Object: Interactive Object-Aware Image to Audio Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03979v1"&gt;Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04194v1"&gt;What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03490v1"&gt;Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03510v1"&gt;Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03519v1"&gt;An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03523v1"&gt;TokAlign: Efficient Vocabulary Adaptation via Token Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03533v1"&gt;Go-Browse: Training Web Agents with Structured Exploration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03557v1"&gt;BPO: Revisiting Preference Modeling in Direct Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03558v1"&gt;ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03569v1"&gt;MiMo-VL Technical Report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03570v1"&gt;FreePRM: Training Process Reward Models Without Ground Truth Process Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03573v1"&gt;Exchange of Perspective Prompting Enhances Reasoning in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03580v1"&gt;Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03592v1"&gt;From Understanding to Generation: An Efficient Shortcut for Evaluating Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03593v1"&gt;Is linguistically-motivated data augmentation worth it?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03616v1"&gt;Learning to Insert [PAUSE] Tokens for Better Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03619v1"&gt;Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03659v1"&gt;Trustworthy Medical Question Answering: An Evaluation-Centric Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03690v1"&gt;Robust Preference Optimization via Dynamic Target Margins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03700v1"&gt;AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03704v1"&gt;ScoreRAG: A Retrieval-Augmented Generation Framework with Consistency-Relevance Scoring and Structured Summarization for News Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03761v1"&gt;Act-as-Pet: Benchmarking the Abilities of Large Language Models as E-Pets in Social Network Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03763v1"&gt;ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03781v1"&gt;Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03793v1"&gt;Mark My Words: A Robust Multilingual Model for Punctuation in Text and Speech Transcripts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03820v1"&gt;Automatic Correction of Writing Anomalies in Hausa Texts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03861v1"&gt;PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03867v1"&gt;EuroGEST: Investigating gender stereotypes in multilingual language models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03887v1"&gt;Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03901v1"&gt;Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03902v1"&gt;The Harmonic Structure of Information Contours&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03916v1"&gt;Compositional Generalisation for Explainable Hate Speech Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03922v1"&gt;HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03923v1"&gt;More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03949v1"&gt;TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03968v1"&gt;From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03980v1"&gt;Voice Activity Projection Model with Multimodal Encoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03984v1"&gt;Around the World in 24 Hours: Probing LLM Knowledge of Time and Place&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03989v1"&gt;Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04020v1"&gt;QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04032v1"&gt;AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04041v1"&gt;LexTime: A Benchmark for Temporal Ordering of Legal Events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04042v1"&gt;Unveiling and Eliminating the Shortcut Learning for Locate-Then-Edit Knowledge Editing via Both Subject and Relation Awareness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04047v1"&gt;On Support Samples of Next Word Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04065v1"&gt;Progressive Mastery: Customized Curriculum Learning with Guided Prompting for Mathematical Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04108v1"&gt;Rectified Sparse Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04139v1"&gt;Are Lexicon-Based Tools Still the Gold Standard for Valence Analysis in Low-Resource Flemish?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04142v1"&gt;Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04156v1"&gt;A Dataset for Addressing Patient's Information Needs related to Clinical Course of Hospitalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04179v1"&gt;SkipGPT: Dynamic Layer Pruning Reinvented with Token Awareness and Module Decoupling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04180v1"&gt;SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04182v1"&gt;Long or short CoT? Investigating Instance-level Switch of Large Reasoning Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04185v1"&gt;R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03487v1"&gt;ProRank: Prompt Warmup via Reinforcement Learning for Small Language Models Reranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03665v1"&gt;ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03741v1"&gt;PromptCanvas: Composable Prompting Workspaces Using Dynamic Widgets for Exploration and Iteration in Creative Writing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03884v1"&gt;Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03990v1"&gt;DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03993v1"&gt;Words of Warmth: Trust and Sociability Norms for over 26k English Words&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03994v1"&gt;Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04037v1"&gt;The mutual exclusivity bias of bilingual visually grounded speech models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04070v1"&gt;LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04072v1"&gt;Controlling Difficulty of Generated Text for AI-Assisted Language Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04141v1"&gt;MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03681v1"&gt;Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03722v1"&gt;MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03832v1"&gt;Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04076v1"&gt;Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.04077v1"&gt;A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-05</guid><pubDate>Thu, 05 Jun 2025 12:19:07 +0900</pubDate></item><item><title>CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents</title><link>http://arxiv.org/abs/2506.03822v1</link><description>出版データベースは、多様なウェブソースからの正確なメタデータ抽出に依存していますが、ウェブレイアウトやデータ形式のばらつきがメタデータプロバイダーにとって課題となっています。本論文では、リンクされたウェブドキュメントの文脈的ランキングのための新しい手法であるCRAWLDocを紹介します。CRAWLDocは、デジタルオブジェクト識別子などの出版物のURLから開始し、ランディングページと、PDF、ORCIDプロファイル、補足資料を含むすべてのリンクされたウェブリソースを取得します。これらのリソースを、アンカーテキストとURLとともに、統一された表現に埋め込みます。CRAWLDocの評価のために、コンピュータサイエンス分野のトップ出版社6社から600件の出版物で構成される、手動でラベル付けされた新しいデータセットを作成しました。我々の手法CRAWLDocは、出版社やデータ形式を超えて、関連ドキュメントの堅牢でレイアウトに依存しないランキングを示しています。これは、さまざまなレイアウトと形式を持つウェブドキュメントからのメタデータ抽出の改善のための基盤を築きます。ソースコードとデータセットは、https://github.com/FKarl/CRAWLDoc でアクセスできます。

&lt;img src="https://arxiv.org/html/2506.03822v1/x1.png"/&gt;&lt;p&gt;Ansgar Scherp, Fabian Karl&lt;/p&gt;&lt;p&gt;Universität Ulm, Germany&lt;/p&gt;</description><guid isPermaLink="false">2506.03822v1</guid><pubDate>Wed, 04 Jun 2025 10:52:55 +0000</pubDate></item><item><title>Preface to the Special Issue of the TAL Journal on Scholarly Document Processing</title><link>http://arxiv.org/abs/2506.03587v1</link><description>学術文献の急速な増加により、研究者が新しい知識に追いつくことはますます困難になっています。この膨大な情報をナビゲートし、解釈するのに役立つ自動化ツールは、これまで以上に不可欠になっています。科学論文は、その複雑な言語、専門用語、多様な形式により、独特の難しさをもたらし、信頼性が高く実用的な洞察を抽出するには高度な手法が必要です。大規模言語モデル（LLM）は、文献レビュー、執筆支援、研究のインタラクティブな探索などのタスクを可能にし、新たな機会を提供します。TALジャーナルのこの特集号では、これらの課題に取り組む研究、そしてより広く、学術および科学文書のための自然言語処理と情報検索に関する研究に焦点を当てています。

&lt;img src=""/&gt;&lt;p&gt;Florian Boudin Akiko Aizawa&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03587v1</guid><pubDate>Wed, 04 Jun 2025 05:35:39 +0000</pubDate></item><item><title>Seed-Coder: Let the Code Model Curate Data for Itself</title><link>http://arxiv.org/abs/2506.03524v1</link><description>大規模言語モデル（LLM）の事前学習におけるコードデータは、コード関連のタスクだけでなく、LLMの一般的な知能を高めるためにも重要であると認識されています。現在のオープンソースLLMは、多くの場合、個々のプログラミング言語に合わせた手作りのフィルタリングルールを採用したり、人間が注釈を付けたデータを使用して品質フィルタをトレーニングするなど、コード事前学習データの作成に人間の努力に大きく依存しています。しかし、これらのアプローチは本質的にスケーラビリティに限界があり、主観的な偏りが生じやすく、多様なプログラミング言語に拡張および維持するのにコストがかかります。これらの課題に対処するために、Seed-Coderという、データ構築における人間の関与を最小限に抑えた、8Bサイズのベースモデル、インストラクトモデル、推論モデルからなる一連のオープンソースLLMを紹介します。私たちのコード事前学習データは、モデル中心のデータパイプラインによって生成され、主にLLMを活用してコードデータのスコアリングとフィルタリングを行います。インストラクトモデルは、教師ありファインチューニングとpreference optimizationによってさらにトレーニングされ、推論モデルは、Long-Chain-of-Thought（LongCoT）強化学習を活用して、多段階のコード推論を改善します。Seed-Coderは、同サイズのオープンソースモデルの中で最先端の結果を達成し、さらに一部のはるかに大きなモデルを凌駕し、コード生成、コード補完、コード編集、コード推論、およびソフトウェアエンジニアリングタスクにおいて優れたパフォーマンスを発揮することを示しています。

&lt;img src="https://arxiv.org/html/2506.03524v1/x3.png"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03524v1</guid><pubDate>Wed, 04 Jun 2025 03:17:19 +0000</pubDate></item><item><title>Estimation of the reduced density matrix and entanglement entropies using autoregressive networks</title><link>http://arxiv.org/abs/2506.04170v1</link><description>古典的な二次元スピン系との対応を利用して、自己回帰ニューラルネットワークを量子スピン鎖のモンテカルロシミュレーションに応用した事例を紹介します。連続するスピンの条件付き確率を推定できるニューラルネットワークの階層構造を用いて、縮約密度行列の要素を直接評価します。イジング鎖を例にとり、最大5つのスピンで構成された区間の基底状態におけるフォンノイマンおよびレニーの二部エンタングルメントエントロピーの連続体極限を計算します。我々のアーキテクチャは、固定された時間離散化と格子体積に対して、単一のトレーニングだけで必要なすべての行列要素を推定できることを示します。我々の手法は、欠陥のある可能性のある他のタイプのスピン鎖や、非ゼロ温度での熱状態のエンタングルメントエントロピーの推定にも適用できます。

&lt;img src="https://arxiv.org/html/2506.04170v1/x1.png"/&gt;&lt;p&gt;Dawid Zapolski, Piotr Białas, Piotr Korcyl, Tomasz Stebel&lt;/p&gt;&lt;p&gt;Doctoral School of Exact and Natural Sciences, Jagiellonian University, Jagiellonian University, ul. Łojasiewicza 11, 30-348 Kraków, Poland
Institute of Applied Computer Science, Jagiellonian University, ul. Łojasiewicza 11, 30-348 Kraków, Poland
Institute of Theoretical Physics, Jagiellonian University, ul. Łojasiewicza 11, 30-348 Kraków, Poland&lt;/p&gt;</description><guid isPermaLink="false">2506.04170v1</guid><pubDate>Wed, 04 Jun 2025 17:08:19 +0000</pubDate></item><item><title>CETBench: A Novel Dataset constructed via Transformations over Programs for Benchmarking LLMs for Code-Equivalence Checking</title><link>http://arxiv.org/abs/2506.04019v1</link><description>LLM（大規模言語モデル）は、自動コード生成のタスクに広く使用されてきました。本研究では、LLMの、関連するものの比較的未開拓なタスクであるコード等価性チェック、つまり、与えられた2つのプログラムが機能的に等価であるかどうか、への適用可能性を検証します。コード等価性のベンチマークは、コードのリライトやコード翻訳などのタスクにおけるLLMの能力を評価する上で重要な役割を果たすため、これは重要な問題です。この目的のために、CETBench（変換を用いたコード等価性ベンチマーク）を提示します。これは、プログラムのリポジトリを通じて構築され、リポジトリ内の2つのプログラムは同じタスクまたは異なるタスクを解決する可能性があります。データセット内の各インスタンスは、リポジトリ内のプログラムのペアを取得し、事前定義されたコード変換のランダムなシーケンスを適用することによって取得され、(非)等価なペアが生成されます。このデータセットの分析により、基盤となるプログラムのペアにおける非常に単純なコード変換が、コード等価性チェックのタスクにおけるSOTA（最先端）LLMのパフォーマンスの大幅な低下につながるという驚くべき発見が明らかになりました。これを改善するために、変換されたプログラムのペアに対するLLMのパフォーマンスを向上させるための、単純なファインチューニングベースのアプローチを提示します。データセット生成のための私たちのアプローチは汎用的であり、プログラムの難易度が異なるリポジトリで使用でき、さまざまな数と種類の変換を適用できます。実験では、元のプログラムの難易度と、等価性チェックのためにペアを生成する際に使用される変換の種類について、アブレーションを行います。私たちの分析は、コード等価性のタスクにおけるLLMの動作に関する深い洞察を提供し、それらが基盤となるコードのセマンティックな理解と呼べるものからはまだ程遠い可能性があることを示唆しています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04019v1</guid><pubDate>Wed, 04 Jun 2025 14:47:14 +0000</pubDate></item><item><title>Dreaming up scale invariance via inverse renormalization group</title><link>http://arxiv.org/abs/2506.04016v1</link><description>我々は、最小限のニューラルネットワークが、二次元イジング模型における繰り込み群（RG）の粗視化手順を反転させ、粗視化された状態から効果的に微視的な配置を「夢見る」ことができるかを調査する。このタスクは、形式的には配置レベルでは不可能だが、確率論的にアプローチすることで、機械学習モデルが微視的な入力に頼らずにスケール不変な分布を再構築することを可能にする。我々は、わずか3つの学習可能なパラメータを持つニューラルネットワークでさえ、臨界配置を生成し、磁化率、熱容量、バインダー比などの観測量のスケーリング挙動を再現できることを示す。生成された配置の実空間繰り込み群解析により、モデルがスケール不変性だけでなく、RG変換の非自明な固有値も再現することが確認される。驚くべきことに、複数の層を導入してネットワークの複雑さを増しても、有意な利点は得られないことがわかった。これらの発見は、フラクタル構造を生成するような単純な局所ルールが、臨界現象の普遍性をエンコードするのに十分であり、物理学における統計的アンサンブルの効率的な生成モデルへの扉を開くことを示唆している。

&lt;img src="https://arxiv.org/html/2506.04016v1/x1.png"/&gt;&lt;p&gt;Adam Rançon, Ivan Balog, Tomislav Ivek, Ulysse Rançon&lt;/p&gt;&lt;p&gt;CerCo UMR 5549, CNRS – Université Toulouse III, Toulouse, France
Institute of Physics, Bijenička cesta 46, HR-10001 Zagreb, Croatia
Univ. Lille, CNRS, UMR 8523 – PhLAM – Laboratoire de
Physique des Lasers Atomes et Molécules, F-59000 Lille, France&lt;/p&gt;</description><guid isPermaLink="false">2506.04016v1</guid><pubDate>Wed, 04 Jun 2025 14:46:22 +0000</pubDate></item><item><title>Weisfeiler and Leman Go Gambling: Why Expressive Lottery Tickets Win</title><link>http://arxiv.org/abs/2506.03919v1</link><description>宝くじ仮説（LTH）は畳み込みニューラルネットワークではよく研究されているが、グラフニューラルネットワーク（GNN）では経験的にのみ検証されており、理論的な知見はほとんどない。本論文では、疎なサブネットワークの表現力、すなわち非同型グラフを区別する能力を、予測性能を維持する当選チケットを見つけるために重要であると特定する。特にWeisfeiler-Lemanテストと比較して、疎に初期化されたGNNの表現力がフルネットワークの表現力と一致する条件を確立し、その文脈において、強い表現力を持つ宝くじ仮説を提唱し、証明する。さらに、初期化における表現力の向上が、モデルの収束を加速させ、汎化性能を向上させる可能性を示す。我々の発見は、LTHとGNN研究の両方に対して、新たな理論的基盤を確立し、疎に初期化されたGNNにおいて表現力を維持することの重要性を強調する。我々は、創薬の例を用いて、我々の結果を説明する。

&lt;img src=""/&gt;&lt;p&gt;Anatol Ehrlich, Franka Bause, Lorenz Kummer, Nikolaus Suess, Nils M. Kriege, Samir Moustafa, Wilfried N. Gansterer&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03919v1</guid><pubDate>Wed, 04 Jun 2025 13:10:59 +0000</pubDate></item><item><title>Learning task-specific predictive models for scientific computing</title><link>http://arxiv.org/abs/2506.03835v1</link><description>我々は、モデル評価へのアクセスを必要とする所与のダウンストリームタスク（アルゴリズムによって記述される）のために、後で使用される予測モデルの学習を検討する。このタスクは予測である必要はなく、この状況は機械学習によって拡張された科学計算で頻繁に遭遇する。我々は、この設定が古典的な教師あり学習とは異なり、一般的に、文献で頻繁に行われているように、モデル予測の平均二乗誤差を最小化することでは解決できないことを示す。代わりに、ダウンストリームタスクアルゴリズムのサポートにおける最大予測誤差が、後続のタスクパフォーマンスの有効な推定値として機能することを見出す。この洞察に基づき、所与のサンプリング測度に基づいてタスク固有の教師あり学習問題を定式化し、その解がダウンストリームタスクの信頼できる代替モデルとして機能する。次に、トレーニングデータに基づいて経験リスクを離散化し、タスク固有の教師あり学習問題を解決するための反復アルゴリズムを開発する。軌道予測、最適制御、および最小エネルギー経路計算に関する3つの説明的な数値例が、アプローチの有効性を示す。

&lt;img src="https://arxiv.org/html/2506.03835v1/x1.png"/&gt;&lt;p&gt;Jianyuan Yin, Qianxiao Li&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03835v1</guid><pubDate>Wed, 04 Jun 2025 11:02:53 +0000</pubDate></item><item><title>Physics-Constrained Flow Matching: Sampling Generative Models with Hard Constraints</title><link>http://arxiv.org/abs/2506.04171v1</link><description>深層生成モデルは近年、偏微分方程式（PDE）によって支配される物理システムに応用され、スケーラブルなシミュレーションと不確実性を考慮した推論を提供している。しかし、保存則（線形および非線形）や物理的な整合性などの物理的制約を強制することは依然として困難である。既存の手法は、ハードな制約を保証できないソフトなペナルティやアーキテクチャ上のバイアスに依存することが多い。本研究では、事前学習済みのフローベース生成モデルにおいて、任意の非線形制約を強制するゼロショット推論フレームワークであるPhysics-Constrained Flow Matching（PCFM）を提案する。PCFMは、学習されたフローとの整合性を保ちながら、物理的制約を満たしつつ、中間的な解の状態に物理ベースの修正を適用することで、サンプリングプロセスを継続的にガイドする。実験的に、PCFMは、衝撃波、不連続性、およびシャープな特徴を持つものを含む、さまざまなPDEにおいて、制約なしおよび制約ありのベースラインを上回り、最終的な解において正確な制約の充足を保証する。我々の手法は、科学分野および汎用生成モデルの両方において、ハードな制約を強制するための一般的なフレームワークを提供し、特に制約の充足が不可欠なアプリケーションにおいて有効である。

&lt;img src="https://arxiv.org/html/2506.04171v1/x1.png"/&gt;&lt;p&gt;Utkarsh Massachusetts Institute of Technology Pengfei Cai Massachusetts Institute of Technology Alan Edelman Massachusetts Institute of Technology Rafael Gomez-Bombarelli Massachusetts Institute of Technology Christopher Vincent Rackauckas Massachusetts Institute of Technology&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04171v1</guid><pubDate>Wed, 04 Jun 2025 17:12:37 +0000</pubDate></item><item><title>TracLLM: A Generic Framework for Attributing Long Context LLMs</title><link>http://arxiv.org/abs/2506.04202v1</link><description>長文コンテキスト大規模言語モデル（LLM）は、RAG、エージェント、および広範なLLM統合アプリケーションなど、多くの現実世界のアプリケーションに展開されています。指示と長文コンテキスト（例：ドキュメント、PDFファイル、ウェブページ）が与えられた場合、長文コンテキストLLMは、提供されたコンテキストに基づいて出力を生成し、より正確で最新の、検証可能な出力を提供すると同時に、ハルシネーションや根拠のない主張を減らすことを目指します。これにより、LLMによって生成された出力に最も貢献する、または責任を負うコンテキスト内のテキスト（例：文、段落、またはパラグラフ）を特定する方法という研究課題が提起されます。コンテキストトレースバックと呼ぶこのプロセスには、1）LLMベースのシステムのデバッグ、2）LLMに対する攻撃（例：プロンプトインジェクション攻撃、知識汚染攻撃）に対する攻撃後のフォレンジック分析の実施、3）LLMによって生成された出力に対するユーザーの信頼を高めるための知識源の強調表示など、さまざまな現実世界のアプリケーションがあります。長文コンテキストLLMのコンテキストトレースバックに適用する場合、Shapleyなどの既存のフィーチャーアトリビューション手法は、最適とは言えないパフォーマンスを発揮したり、大きな計算コストが発生したりします。本研究では、長文コンテキストLLMに特化した最初の汎用コンテキストトレースバックフレームワークであるTracLLMを開発します。当社のフレームワークは、既存のフィーチャーアトリビューション手法の有効性と効率を向上させることができます。効率を向上させるために、TracLLMに情報に基づいた検索ベースのアルゴリズムを開発しました。また、TracLLMの精度を向上させるために、貢献度スコアのアンサンブル/ノイズ除去技術も開発しました。評価結果は、TracLLMがLLMの出力につながる長文コンテキスト内のテキストを効果的に識別できることを示しています。当社のコードとデータは、https://github.com/Wang-Yanting/TracLLM にあります。

&lt;img src="https://arxiv.org/html/2506.04202v1/x1.png"/&gt;&lt;p&gt;Jinyuan Jia Pennsylvania State University {yanting, Runpeng Geng, Wei Zou, Yanting Wang, jinyuan}@psu.edu, kevingeng, weizou&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04202v1</guid><pubDate>Wed, 04 Jun 2025 17:48:16 +0000</pubDate></item><item><title>VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation</title><link>http://arxiv.org/abs/2506.03930v1</link><description>大規模言語モデル（LLM）は、図やグラフのプロットなど、コードの正確性と視覚的な意味論の両方に依存する視覚化タスクで苦戦することが多い。既存のインストラクションチューニングデータセットは、実行に基づいた教師あり学習が不足しており、反復的なコード修正に対するサポートが限られているため、脆弱で信頼性の低いプロット生成につながる。我々は、Pythonベースの視覚化と自己修正のための大規模なインストラクションチューニングデータセットであるVisCode-200Kを提案する。これは、2つのソースからの20万件以上の例を含む。（1）オープンソースリポジトリからの検証済みのプロットコードと、自然言語の指示およびレンダリングされたプロットのペア。（2）Code-Feedbackからの4万5千件のマルチターンの修正対話で、モデルがランタイムフィードバックを使用して誤ったコードを修正できるようにする。VisCode-200KでQwen2.5-Coder-InstructをファインチューンしてVisCoderを作成し、PandasPlotBenchで評価する。VisCoderは、強力なオープンソースのベースラインを大幅に上回り、GPT-4o-miniのようなプロプライエタリモデルのパフォーマンスに近づく。さらに、反復的な修正を評価するために自己デバッグ評価プロトコルを採用し、実行可能で視覚的に正確なコード生成のためのフィードバック駆動型学習の利点を示す。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03930v1</guid><pubDate>Wed, 04 Jun 2025 13:24:44 +0000</pubDate></item><item><title>MACS: Multi-Agent Reinforcement Learning for Optimization of Crystal Structures</title><link>http://arxiv.org/abs/2506.04195v1</link><description>原子構造の形状最適化は、計算化学および材料設計において一般的かつ重要なタスクです。最適化学習のパラダイムに従い、周期的な結晶構造の最適化に取り組むための、Multi-Agent Crystal Structure optimization (MACS) と呼ばれる新しいマルチエージェント強化学習法を提案します。MACSは、形状最適化を部分的に観測可能なマルコフゲームとして扱い、原子は、安定した構造を共同で発見するために自身の位置を調整するエージェントとして機能します。報告されている様々な組成の結晶材料を用いてMACSを訓練し、トレーニング組成からの構造だけでなく、より大きなサイズや未知の組成の構造も最適化できるポリシーを獲得し、その優れたスケーラビリティとゼロショット転移性を確認しました。最先端の最適化手法と比較してベンチマークを行い、MACSが周期的な結晶構造を大幅に高速に、より少ないエネルギー計算で、そして最も低い失敗率で最適化することを示しました。

&lt;img src="https://arxiv.org/html/2506.04195v1/extracted/6503825/figures/marl_scheme_final.png"/&gt;&lt;p&gt;Elena Zamaraeva Christopher M. Collins George R. Darling Matthew S. Dyer &amp;Bei Peng Rahul Savani Dmytro Antypov Vladimir V. Gusev Judith Clymo &amp;Paul G. Spirakis Matthew J. Rosseinsky Leverhulme Research Centre for Functional Materials Design, London, UK, UK Department of Chemistry, UK Department of Computer Science, UK The Alan Turing Institute, University of Liverpool&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04195v1</guid><pubDate>Wed, 04 Jun 2025 17:40:57 +0000</pubDate></item><item><title>High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning</title><link>http://arxiv.org/abs/2506.04051v1</link><description>大規模言語モデル（LLM）は現在、すべてのプロンプトに応答します。しかし、知識や能力が不足している場合、誤った回答を生成する可能性があり、これはハルシネーションとして知られる問題です。そこで、LLMがその正しさに自信がある場合にのみコンテンツを生成し、そうでない場合は（部分的に）棄権するように、LLMを事後学習させることを提案します。具体的には、私たちの手法であるHALTは、モデルが確実に生成できるものとできないものをエンコードする、能力に合わせた事後学習データを生成します。このデータは、事前学習されたLLMの応答を事実の断片（原子的なステートメントまたは推論ステップ）に分割し、正誤情報を使用して誤った断片を特定することで生成します。誤った断片を削除するか、「ここからは不明」に置き換えることで、能力に合わせたファインチューニング応答を実現します。この置き換えは、応答の完全性と応答の断片の平均的な正しさのバランスを取るための調整可能な閾値に従って行われます。HALTを用いて、伝記作成、数学、コーディング、医学の4つの分野で、3つの異なるトレードオフ閾値で、4つのオープンソースモデルをファインチューニングしました。HALTは、応答の完全性と正しさを効果的にトレードオフし、応答の断片の平均的な正しさを平均で15%向上させると同時に、関連するベースラインと比較してF1スコア（応答の完全性と正しさの平均）を4%向上させます。HALTを最高の正しさに調整することで、単一の信頼性の高いLlama3-70Bモデルをトレーニングし、4つのドメインすべてで正しさを51%から87%に向上させながら、標準的なファインチューニングで達成された応答の完全性の53%を維持します。

&lt;img src="https://arxiv.org/html/2506.04051v1/x1.png"/&gt;&lt;p&gt;Archie Sravankumar, Jakob Foerster, Lijuan Liu, Luke Zettlemoyer, Madian Khabsa, Rui Hou, Sinong Wang, Tim Franzmeyer, Yuning Mao&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2506.04051v1</guid><pubDate>Wed, 04 Jun 2025 15:16:21 +0000</pubDate></item><item><title>Generating Automotive Code: Large Language Models for Software Development and Verification in Safety-Critical Systems</title><link>http://arxiv.org/abs/2506.04038v1</link><description>安全クリティカルな自動車ソフトウェアの開発は、システム複雑性の増大と厳格な規制要求により、重大な課題を抱えています。本論文では、生成AI（GenAI）をソフトウェア開発ライフサイクル（SDLC）に統合する新しいフレームワークを提案します。このフレームワークは、大規模言語モデル（LLM）を使用して、C++などの言語でのコード生成を自動化し、静的検証、テスト駆動開発、反復的な改良などの安全重視の実践を取り入れています。フィードバック駆動型のパイプラインにより、安全基準への準拠のためにテスト、シミュレーション、検証の統合が保証されます。このフレームワークは、アダプティブクルーズコントロール（ACC）システムの開発を通じて検証されます。LLMの比較ベンチマークにより、精度と信頼性に対する最適なモデル選択が保証されます。結果は、このフレームワークが安全クリティカルな要件への準拠を保証しながら、自動コード生成を可能にし、GenAIを自動車ソフトウェアエンジニアリングに体系的に統合することを示しています。本研究は、安全クリティカルな分野におけるAIの利用を促進し、最先端の生成モデルと現実世界の安全要件との間のギャップを埋めます。

&lt;img src="https://arxiv.org/html/2506.04038v1/x1.png"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04038v1</guid><pubDate>Wed, 04 Jun 2025 15:01:59 +0000</pubDate></item><item><title>Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning</title><link>http://arxiv.org/abs/2506.03939v1</link><description>グラフ検索拡張生成（GraphRAG）は、知識関係を明示的にモデル化することで、外部知識統合能力を効果的に強化し、専門分野における大規模言語モデル（LLM）の事実の正確性と生成品質を向上させます。しかし、既存の手法には、1）非効率的な情報集約：単一のエージェントと固定された反復パターンに依存しており、グラフデータ内の多層的なテキスト、構造、および次数情報を適応的に捉えることが困難である、2）硬直的な推論メカニズム：事前に設定された推論スキームを採用しており、推論の深さを動的に調整したり、正確な意味的修正を達成したりできない、という2つの固有の制限があります。これらの制限を克服するために、マルチエージェントコラボレーションに基づくGraphRAG手法であるGraph Counselorを提案します。この手法は、適応型グラフ情報抽出モジュール（AGIEM）を使用し、プランニング、思考、および実行エージェントが連携して複雑なグラフ構造を正確にモデル化し、情報抽出戦略を動的に調整することで、多層的な依存関係のモデリングと適応的な推論の深さという課題に対処します。さらに、多角的自己反省（SR）モジュールは、自己反省と後方推論メカニズムを通じて、推論結果の精度と意味的一貫性を向上させます。実験の結果、Graph Counselorは複数のグラフ推論タスクにおいて既存の手法を上回り、より高い推論精度と汎化能力を示すことが実証されました。コードはhttps://github.com/gjq100/Graph-Counselor.gitで入手できます。

&lt;img src="https://arxiv.org/html/2506.03939v1/x1.png"/&gt;&lt;p&gt;Biqing Qi, Dong Li, Engineering, Harbin Institute of Technology, Harbin Institute of Technology Department of Control Science, Jianxing Liu Shanghai Artificial Intelligence Laboratory School of Mathematics, Junqi Gao, Xiang Zou, Yichen Niu, Ying Ai&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03939v1</guid><pubDate>Wed, 04 Jun 2025 13:31:21 +0000</pubDate></item><item><title>Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons</title><link>http://arxiv.org/abs/2506.03785v1</link><description>大規模言語モデル（LLM）は、機械翻訳や科学分野など、様々な領域で効果的な評価者であることが示されています。現在のLLMを審査員として利用するアプローチは、主に個別の評価や一回のペアワイズ評価に依存しており、審査員LLMがグローバルなランキング視点を養うことを妨げています。これに対処するため、我々はノックアウトトーナメントシステムと反復的なペアワイズ比較を用いた、LLMを審査員とするノックアウト評価を提案します。3つのLLMと2つのデータセットを用いた実験により、ノックアウト評価はスコアリング精度を向上させ、大学レベルの試験採点と機械翻訳評価において、専門家による評価とのピアソン相関係数を平均で0.07向上させ、LLMによる評価を人間の採点により近づけることが示されました。

&lt;img src="https://arxiv.org/html/2506.03785v1/extracted/6511464/latex/images/tournament.png"/&gt;&lt;p&gt;Isik Baran Sandan, Jan Niehues Karlsruhe Institute of Technology, Tu Anh Dinh&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03785v1</guid><pubDate>Wed, 04 Jun 2025 09:46:43 +0000</pubDate></item><item><title>Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks</title><link>http://arxiv.org/abs/2506.03627v1</link><description>大規模言語モデル（LLM）は、プロンプティング戦略を効果的に活用することで、様々なタスクにおいて目覚ましい性能を示してきました。しかし、タイプミスやわずかな文字順序の誤りなど、入力の摂動に非常に敏感であり、それらが性能を大幅に低下させる可能性があります。プロンプティング技術の進歩にもかかわらず、そのような摂動の悪影響を明示的に軽減するプロンプティング戦略の開発は、依然として未解決の課題です。このギャップを埋めるために、我々はLLMのロバスト性を高めるために特別に設計された、新しいプロンプティング戦略であるRobustness of Prompting（RoP）を提案します。RoPは、エラー訂正とガイダンスの2つの段階で構成されています。エラー訂正段階では、RoPは多様な摂動手法を適用して敵対的な例を生成し、それらを使用して入力エラーを自動的に修正するプロンプトを構築します。ガイダンス段階では、RoPは修正された入力に基づいて最適なガイダンスプロンプトを生成し、モデルをよりロバストで正確な推論へと導きます。算術、常識、論理的推論タスクにわたる包括的な実験を通じて、RoPが敵対的な摂動に対するLLMのロバスト性を大幅に向上させることを示します。特に、クリーンな入力シナリオと比較して、モデルの精度は最小限の低下しか伴わず、RoPが現実世界のアプリケーションにおけるLLMのロバスト性を高めるための実用的かつ効果的なアプローチであることを確立します。

&lt;img src="https://arxiv.org/html/2506.03627v1/extracted/6511082/figures/introduction.png"/&gt;&lt;p&gt;Anhui University, Hefei University, Technology of China, University of Science&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03627v1</guid><pubDate>Wed, 04 Jun 2025 07:13:27 +0000</pubDate></item><item><title>KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models</title><link>http://arxiv.org/abs/2506.03576v1</link><description>知識表現学習（KRL）における最近の進歩は、より豊かな意味理解のために、シンボリックな知識グラフ（KG）と言語モデル（LM）を統合する必要性が急務であることを強調しています。しかし、既存のアプローチは通常、グラフ構造またはテキストの意味のいずれかを優先しており、グローバルなKG接続性、ニュアンスのある言語的文脈、および識別的な推論セマンティクスを同時に捉える統一されたフレームワークというギャップが残されています。このギャップを埋めるために、KG-BiLMを導入します。これは、KGからの構造的な手がかりと生成的なトランスフォーマーの意味表現力を融合する双方向LMフレームワークです。KG-BiLMは、3つの主要なコンポーネントを組み込んでいます。（i）双方向知識アテンション：すべてのトークンとエンティティ間の完全な相互作用を可能にするために、因果マスクを削除します。（ii）知識マスク予測：モデルがローカルな意味的文脈とグローバルなグラフ接続性の両方を活用することを奨励します。（iii）コントラストグラフ意味集約：サンプリングされたサブグラフ表現のコントラストアライメントを通じてKG構造を保持します。標準的なベンチマークでの広範な実験により、KG-BiLMはリンク予測、特に複雑なマルチホップ関係を持つ大規模グラフにおいて、強力なベースラインを上回ることが示されており、構造情報とテキストの意味を統合する上での有効性が検証されています。

&lt;img src="https://arxiv.org/html/2506.03576v1/x1.png"/&gt;&lt;p&gt;Computing Tianjin University, Dongxiao He College of Intelligence, Wenbin Guo, Xin Wang, Zhao Li, Zirui Chen&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03576v1</guid><pubDate>Wed, 04 Jun 2025 04:47:24 +0000</pubDate></item><item><title>Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement</title><link>http://arxiv.org/abs/2506.03541v1</link><description>大規模言語モデル（LLM）は、知識集約的で複雑な推論タスクにおいて新たな基準を打ち立て続けていますが、その高い計算コストが広範な普及を妨げています。大規模モデルをより小さなモデルに蒸留することは持続可能な解決策となりますが、静的知識蒸留、リソースを大量に消費する人間からのフィードバックによる強化学習、または限定的な自己反省といった現在の技術では、実質的かつ持続的なパフォーマンス向上をもたらすのに苦労しています。本論文では、より小さなモデルとより強力な教師モデル間の複数ターンの議論を調整し、学生モデルを導くための実行可能なフィードバック（例：エラー分析、修正戦略）を引き出す、新しい Debate and Reflect (D&amp;R) フレームワークを提案します。さらに、これらの議論ログを効率的に活用するために、Tree-structured Direct Preference Optimization (T-DPO) を導入し、インタラクションを効果的なトレーニングのための階層形式に整理します。多様なNLPベンチマークにわたる実証的評価により、我々のアプローチがより小さなモデルの精度、ロバスト性、および汎化性能を大幅に向上させ、従来のベースラインを大幅に上回ることが示されています。

&lt;img src="https://arxiv.org/html/2506.03541v1/x1.png"/&gt;&lt;p&gt;Beijing Institute of Technology, Singapore Management University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03541v1</guid><pubDate>Wed, 04 Jun 2025 03:52:20 +0000</pubDate></item><item><title>EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding</title><link>http://arxiv.org/abs/2506.03489v1</link><description>大規模言語モデル（LLM）の目覚ましい性能は、豊富で高品質な学習データの利用に大きく依存しています。しかし、アノテーションされたデータの取得コストが高いことが、モデルが下流タスクに取り組む能力を獲得するのを妨げることがよくあります。本論文では、追加の学習なしにデータ不足のシナリオでモデルの性能を向上させる新しい手法、EpiCoDeを紹介します。まず、モデル外挿を用いて、ファインチューニングされたモデルをその劣ったバージョンで強化し、次に、外挿されたモデルと元のファインチューニングされたモデルによって与えられたロジットスコアを比較することにより、コントラストデコーディングを採用して予測誤差をさらに削減します。4つの異なるLLMにわたる3つのタスクにわたる実験は、EpiCoDeが既存の手法を一貫して上回り、有意かつ堅牢な改善を示すことを示しています。また、データ不足のシナリオにおけるコントラストデコーディングの背後にあるメカニズムを明らかにする新しい理論的フレームワークを提案し、EpiCoDeの有効性をより良く理解するのに役立ちます。

&lt;img src="https://arxiv.org/html/2506.03489v1/x1.png"/&gt;&lt;p&gt;BIGAI, Peking University Beijing Institute of Big Data Research National Key Laboratory of General Artificial Intelligence, Peking University Research Institute of China Telecom School of Computer Science, Wangxuan Institute of Computer Technology&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03489v1</guid><pubDate>Wed, 04 Jun 2025 02:11:54 +0000</pubDate></item><item><title>macOSWorld: A Multilingual Interactive Benchmark for GUI Agents</title><link>http://arxiv.org/abs/2506.04135v1</link><description>グラフィカルユーザーインターフェース（GUI）エージェントは、コンピューター利用タスクの自動化とアクセシビリティの向上において有望な能力を示していますが、既存のインタラクティブなベンチマークはほとんどが英語のみで、Web利用、またはWindows、Linux、Android環境を対象としており、macOSは対象としていません。macOSは、独特のGUIパターンと独自のアプリケーションを持つ主要なOSです。このギャップを埋めるために、macOS上のGUIエージェントを評価するための初の包括的なベンチマークであるmacOSWorldを発表します。macOSWorldは、30のアプリケーション（28はmacOS専用）にわたる202の多言語インタラクティブタスクを特徴とし、タスクの指示とOSインターフェースは5つの言語（英語、中国語、アラビア語、日本語、ロシア語）で提供されます。GUIエージェントは欺瞞攻撃に対して脆弱であることが示されているため、macOSWorldには専用の安全性ベンチマークサブセットも含まれています。6つのGUIエージェントに対する評価では、劇的なギャップが明らかになりました。独自のコンピューター利用エージェントは30％以上の成功率でリードしているのに対し、オープンソースの軽量な研究モデルは2％未満にとどまっており、macOSドメインへの適応の必要性が浮き彫りになっています。多言語ベンチマークは、特にアラビア語において、一般的な弱点も露呈しており、英語と比較して平均27.5％の性能低下が見られます。安全性ベンチマークの結果は、欺瞞攻撃がより一般的であり、早急な対応が必要であることを強調しています。macOSWorldは、https://github.com/showlab/macosworld で入手できます。

&lt;img src="https://arxiv.org/html/2506.04135v1/x1.png"/&gt;&lt;p&gt;National University of Singapore, Pei Yang  Hai Ci Mike Zheng Shou Show Lab&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04135v1</guid><pubDate>Wed, 04 Jun 2025 16:26:56 +0000</pubDate></item><item><title>Reason from Future: Reverse Thought Chain Enhances LLM Reasoning</title><link>http://arxiv.org/abs/2506.03673v1</link><description>Chain-of-Thought (CoT)やTree-of-Thought (ToT)のような、注意深く設計された推論パラダイムは、詳細な思考と広範な思考探索によって、小規模言語モデルの推論能力を向上させることが示されています。しかし、探索空間における無制限の分岐因子は、過大な推論コストを生み出します。さらに、これらの手法は局所最適解に陥りやすく、問題を解決する際にモデルが全体的な視点を欠くことになります。そこで、我々はReason from Future (RFF)と呼ばれる新しい推論パラダイムを提案します。これは、トップダウン計画とボトムアップの推論蓄積を組み合わせた双方向推論によって推論パスを生成します。RFFの本質は、逆向き推論メカニズムにあり、主要な論理関係を優先し、中間ステップに目標指向の制約を課すことで、探索空間を削減し、逐次的な順方向推論に内在するエラーの蓄積を軽減します。多様な実験による実証評価の結果、RFFは、複雑なタスクを解決する際に、従来のパラダイムよりも高い精度とより少ない探索空間で優れた性能を発揮することが示されました。

&lt;img src="https://arxiv.org/html/2506.03673v1/x1.png"/&gt;&lt;p&gt;310000, 310009, 310058, Baohua Dong, China, China Alibaba Group, China Liangzhu Laboratory, China State Key Laboratory of Transvascular Implantation Devices, China Zhejiang Key Laboratory of Medical Imaging Artificial Intelligence, Gang Yu, Hangcheng Zhu, Hangzhou, Hongxia Xu, Jian Wu College of Computer Science, Ruohui Huang, Shuaihan Huang, Shuoshuo Sun, TIDRI, Technology, WeDoctor Cloud, Yanzhao Zheng, Yinlong Xu, Zhejiang University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03673v1</guid><pubDate>Wed, 04 Jun 2025 08:03:17 +0000</pubDate></item><item><title>Learning-at-Criticality in Large Language Models for Quantum Field Theory and Beyond</title><link>http://arxiv.org/abs/2506.03703v1</link><description>基礎物理学は、指針となる模範例や確立された原則がほとんどない、複雑な記号問題をしばしば抱えています。人工知能（AI）は有望ですが、学習のために膨大なデータセットを必要とするため、情報が乏しい最前線での利用が妨げられます。本稿では、この情報不足に対処するため、大規模言語モデル（LLM）を鋭い学習転移に調整する強化学習（RL）スキームである臨界学習（LaC）を紹介します。この転移点において、LLMは最小限のデータから最大の汎化能力を発揮し、非自明な算術推論のテストである7桁の7進数加算によって実証されます。このピークを明らかにするため、LLMがトークンをどのようにリンクするかという本質を捉えるように設計された最小限の概念ネットワークモデル（CoNet）を分析します。単一の模範例で学習されたこのモデルも、鋭い学習転移を受けます。この転移は、特にべき乗則に従う解の経路長など、二次相転移の特徴を示します。この臨界点において、システムは汎化に不可欠な「批判的思考パターン」を最大化し、その基盤となるスケールフリーな探索によって可能になります。これは、LLMが臨界点で動作することで最高のパフォーマンスを発揮し、そのような探索的ダイナミクスが根底にある操作規則の抽出を可能にすることを示唆しています。量子場理論においてLaCを実証します。記号的な松原和の少数の模範例を用いてLaCによって臨界点に調整された80億パラメータのLLMは、より大規模なモデルを大幅に上回り、未知のより高次の問題を解決します。したがって、LaCは物理原理である臨界現象を活用して、基礎物理学における複雑でデータが少ない課題に対応するためにAIを強化します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03703v1</guid><pubDate>Wed, 04 Jun 2025 08:35:05 +0000</pubDate></item><item><title>Critical transport behavior in quantum dot solids</title><link>http://arxiv.org/abs/2506.03676v1</link><description>最近の進歩により、シリコン太陽電池は急速にショックレー・クワイサー限界である効率33%に近づいています。量子ドット（QD）太陽電池は、この限界を超え、既存の太陽エネルギー方式の能力を超える次世代の太陽光発電技術を可能にする可能性を秘めています。太陽電池の実装に必要な広範な位相コヒーレンスと金属特性を示す、エピタキシャル融合された量子ドット固体が初めて作成された例はまだなく、これらの材料における金属-絶縁体転移を調査する必要があります。我々は、QD固体サンプルの3Dトモグラフィーに基づいて、一般的に研究されているアンダーソン・ハミルトニアンのオンサイト項とホッピング項の両方の無秩序を考慮した、QD固体中の電子輸送に関する新しいモデルを作成しました。伝達行列法と有限サイズスケーリングを用いて、動的な金属-絶縁体転移相図を作成しました。驚くほど広いパラメータ空間において、我々のモデルは、アンダーソン転移に期待される値とは異なる臨界指数を示しています。弱い運動（ホッピング）無秩序の追加により、アンダーソン転移（AI）の普遍性クラスからカイラル直交クラス（BDI）へのクロスオーバー領域の存在を示します。

&lt;img src="https://arxiv.org/html/2506.03676v1/extracted/6511139/Figures/TomographyNecking.png"/&gt;&lt;p&gt;Adam Goga, Gergely T. Zimanyi, Mikael A. Kovtun, Zachary Crawford&lt;/p&gt;&lt;p&gt;1 Physics Department, University of California, Davis, Davis CA 95616&lt;/p&gt;</description><guid isPermaLink="false">2506.03676v1</guid><pubDate>Wed, 04 Jun 2025 08:06:39 +0000</pubDate></item><item><title>chemtrain-deploy: A parallel and scalable framework for machine learning potentials in million-atom MD simulations</title><link>http://arxiv.org/abs/2506.04055v1</link><description>機械学習ポテンシャル（MLP）は急速に発展しており、分子動力学（MD）シミュレーションを変革する大きな可能性を示しています。しかし、既存のソフトウェアツールのほとんどは、特定のMLPアーキテクチャに縛られていたり、標準的なMDパッケージとの統合が不足していたり、GPU間で並列化できなかったりします。これらの課題に対処するため、我々はLAMMPSにおいてモデルに依存しないMLPの展開を可能にするフレームワークであるchemtrain-deployを発表します。chemtrain-deployは、JAXで定義された任意の半局所ポテンシャルをサポートし、ユーザーはLAMMPSの機能を活用して、複数のGPU上で大規模なMLPベースのMDシミュレーションを実行できます。最先端の効率を実現し、数百万個の原子を含む系までスケールします。液相-気相界面、結晶性材料、溶媒和されたペプチドなど、さまざまな系に適用したMACE、Allegro、PaiNNなどのグラフニューラルネットワークアーキテクチャを用いて、その性能とスケーラビリティを検証します。我々の結果は、実世界の高性能シミュレーションにおけるchemtrain-deployの実用的な有用性を強調し、MLPアーキテクチャの選択と将来の設計に関する指針を提供します。

&lt;img src="https://arxiv.org/html/2506.04055v1/x1.png"/&gt;&lt;p&gt;Paul Fuchs, Stephan Thaler, Weilong Chen&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2506.04055v1</guid><pubDate>Wed, 04 Jun 2025 15:19:26 +0000</pubDate></item><item><title>Limitations of Quantum Hardware for Molecular Energy Estimation Using VQE</title><link>http://arxiv.org/abs/2506.03995v1</link><description>変分量子固有値ソルバー（VQE）は、特にノイズの多い中間規模量子（NISQ）時代において、量子化学における電子構造問題を解決するための最も有望な量子アルゴリズムの1つです。本研究では、分子の基底状態エネルギーを決定するために、現在の量子ハードウェアに実装されたVQEアルゴリズムの能力と限界を調査し、特に適応的微分組み立て擬似トロッターアンザッツVQE（ADAPT-VQE）に焦点を当てます。分子ハミルトニアンによってもたらされる重大な計算上の課題に対処するために、ハミルトニアンを簡略化し、アンザッツを最適化し、COBYLAオプティマイザーの修正を通じて古典的なパラメータ最適化を改善するためのさまざまな戦略を検討します。これらの強化は、回路の深さと計算コストを最小限に抑えるように設計された、調整された量子コンピューティング実装に統合されています。ベンゼンをベンチマークシステムとして使用して、これらの最適化のIBM量子コンピュータへの適用を実証します。これらの改善にもかかわらず、私たちの結果は、現在の量子ハードウェアによって課せられる制限、特に量子ノイズが状態準備とエネルギー測定に与える影響を強調しています。今日のデバイスのノイズレベルは、信頼できる量子化学的洞察を生み出すのに十分な精度で分子ハミルトニアンを有意義に評価することを妨げています。最後に、VQEアルゴリズムを使用した実用的でスケーラブルな量子化学計算を可能にするための、将来の量子ハードウェアの要件を推定します。本研究は、分子モデリングにおける量子優位性を達成するために、量子アルゴリズムとハードウェアを進歩させるためのロードマップを提供します。

&lt;img src="https://arxiv.org/html/2506.03995v1/extracted/6512518/Figures/hardware/staircase_algorithm.png"/&gt;&lt;p&gt;David Casanova, Román Orús&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2506.03995v1</guid><pubDate>Wed, 04 Jun 2025 14:19:18 +0000</pubDate></item><item><title>Bridging Quantum Chemistry and MaxCut: Classical Performance Guarantees and Quantum Algorithms for the Hartree-Fock Method</title><link>http://arxiv.org/abs/2506.04223v1</link><description>量子化学において、自己無撞着場（SCF）アルゴリズムは、連続的および離散的な要素を持つ非線形最適化問題を定義します。本研究では、厳密に二次制約なしスピン/二値最適化問題（QUSO/QUBO）のシーケンスとして記述できる、ハートリー-フォックに触発されたSCFアルゴリズムを導出します。最適化問題を一連のMaxCutグラフ問題として再構成し、半正定値計画法を用いて効率的に解くことができます。この手順は、最適化ランドスケープの複雑さに関わらず、各SCFステップで性能保証を提供します。水酸化物アニオンOH-および分子窒素N2を研究することにより、QUBO-SCFおよびMaxCut-SCF法を数値的に実証します。本研究で扱った最大の問題は、220量子ビット（同等のスピン軌道）で構成される系を含みます。我々の結果は、QUBO-SCFおよびMaxCut-SCFが、従来のSCF計算と比較して、内部不安定性の影響をはるかに受けにくいことを示しています。さらに、新しいSCFアルゴリズムが、配置間相互作用などの単一参照法を強化できることを示します。最後に、ハートリー-フォック法から生じるQUSO問題に、最適化のための量子アルゴリズムをどのように適用できるかを探求します。GAS-SCF、QAOA-SCF、QA-SCF、DQI-SCFという4つの異なるハイブリッド量子古典アプローチを紹介します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.04223v1</guid><pubDate>Wed, 04 Jun 2025 17:59:02 +0000</pubDate></item><item><title>HTSC-2025: A Benchmark Dataset of Ambient-Pressure High-Temperature Superconductors for AI-Driven Critical Temperature Prediction</title><link>http://arxiv.org/abs/2506.03837v1</link><description>高温超伝導材料の発見は、人類の産業と日常生活にとって非常に重要な意味を持つ。近年、人工知能（AI）を用いて超伝導転移温度を予測する研究が盛んになり、これらのツールのほとんどが驚くべき精度を達成すると主張している。しかし、この分野で広く受け入れられているベンチマークデータセットの不足は、異なるAIアルゴリズム間の公平な比較を著しく妨げ、これらの手法のさらなる進歩を阻害している。本研究では、常圧高温超伝導ベンチマークデータセットであるHTSC-2025を発表する。この包括的なコンピレーションは、BCS超伝導理論に基づいて、理論物理学者が2023年から2025年にかけて発見した理論的に予測された超伝導材料を網羅しており、有名なX$_2$YH$_6$系、ペロブスカイトMXH$_3$系、M$_3$XH$_8$系、LaH$_{10}$構造進化に由来するカゴ状BCNドープ金属原子系、およびMgB$_2$から進化する二次元ハニカム構造系が含まれる。HTSC-2025ベンチマークは、https://github.com/xqh19970407/HTSC-2025 でオープンソース化されており、継続的に更新される予定である。このベンチマークは、AIベースの手法を用いた超伝導材料の発見を加速するために重要な意味を持つ。

&lt;img src="https://arxiv.org/html/2506.03837v1/x1.png"/&gt;&lt;p&gt;Peng-Jie Guo, Xiao-Qi Han, Xin-De Wang, Ze-Feng Gao, Zhenfeng Ouyang, Zhong-Yi Lu&lt;/p&gt;&lt;p&gt;1. School of Physics and Beijing Key Laboratory of Opto-electronic Functional Materials &amp; \&amp; &amp; Micro-nano Devices. Renmin University of China, Beijing 100872, China
2. Key Laboratory of Quantum State Construction and Manipulation (Ministry of Education), Renmin University of China, Beijing 100872, China
3. Hefei National Laboratory, Hefei 230088, China&lt;/p&gt;</description><guid isPermaLink="false">2506.03837v1</guid><pubDate>Wed, 04 Jun 2025 11:14:00 +0000</pubDate></item><item><title>Efficient and standardized interface energy calculations in hybrid heterostructures using fictitious atoms surface passivation</title><link>http://arxiv.org/abs/2506.03769v1</link><description>多様な物理化学的特性を組み合わせたヘテロ構造は、現代科学技術における幅広い応用においてますます需要が高まっています。しかし、材料科学におけるその重要性にもかかわらず、絶対界面エネルギーを正確に決定することは依然として大きな課題です。この困難さは、周期境界条件、平面波法の高い計算コスト、ヘテロ構造における多極相互作用、界面収束のための厚いスラブの必要性、およびスラブ両面の再構成された表面に起因します。本稿では、異種材料の組み合わせにおける絶対界面エネルギーを正確に決定するために設計された、表面終端のための標準化された計算効率の高い仮想H*電荷パッシベーション法を紹介します。このアプローチは、表面再構成に関連する問題を効果的に解決し、密度汎関数理論の枠組みの中で計算コストを大幅に削減します。その信頼性を示すために、H*パッシベーション技術を用いて、さまざまな準格子整合および格子不整合な急峻なIII-V/Si界面の絶対界面エネルギーを計算し、従来の再構成された表面法で得られた結果と比較してベンチマークします。さらに、歪んだエピタキシャルGaAs on Si(001)の初期段階を探求します。最後に、仮想H*パッシベーション法を評価し、電気双極子誤差の最小化、計算コストの削減、ひいては高性能コンピューティングからの温室効果ガス排出量の削減におけるその有効性を示します。最後に、幅広い材料にわたる界面エネルギーを計算するためのこのアプローチの可能性を強調します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03769v1</guid><pubDate>Wed, 04 Jun 2025 09:30:55 +0000</pubDate></item><item><title>Beyond Diamond: Interpretable Machine Learning Discovery of Coherent Quantum Defect Hosts in Semiconductors</title><link>http://arxiv.org/abs/2506.03844v1</link><description>広バンドギャップ半導体における量子点欠陥、例えばダイヤモンド中の窒素-空孔（NV）中心は、長いコヒーレンス時間と光で制御可能なスピン状態を持つため、固体スピン量子ビットの有力な候補である。しかし、このような深い準位の欠陥を支持できるホスト材料を特定することは、化学組成、結晶構造、電子環境の複雑な相互作用のために、依然として大きな課題である。本研究では、密度汎関数理論（DFT）に基づいた記述子と、構造に依存しないアンサンブルモデルを組み合わせた、スケーラブルで解釈可能な機械学習フレームワークを提示し、量子適合性のある欠陥ホスト材料を予測する。Materials ProjectとICSDからキュレーションされたデータセットで学習させたモデルは、高いマシューズ相関係数（MCC &gt; 0.95）を達成し、候補の優先順位付けを導くための信頼度スコアを割り当てる。静的誘電率や欠陥形成エネルギーなど、コヒーレンスに関連する特性の第一原理計算により、主要な予測が検証される。高い誘電応答はスピンコヒーレンスの必要条件ではあるが十分条件ではないが、本モデルはダイヤモンドやSiCなどの既知のホストをうまく再現し、WS2、MgO、CaS、TiO2などのこれまで見過ごされてきた候補を明らかにする。このアプローチは、データ駆動型スクリーニングと物理的に解釈可能な設計原理を結びつけ、次世代量子材料を発見するための堅牢な道筋を確立する。

&lt;img src="https://arxiv.org/html/2506.03844v1/x3.png"/&gt;&lt;p&gt;Mohammed Mahshook, Rudra Banerjee&lt;/p&gt;&lt;p&gt;Department of Physics and Nanotechnology, SRM Institute of Science and Technology, Kattankulathur, Tamil
Nadu, 603203, India&lt;/p&gt;</description><guid isPermaLink="false">2506.03844v1</guid><pubDate>Wed, 04 Jun 2025 11:21:17 +0000</pubDate></item><item><title>The isostructural alpha-gamma phase transition in cerium from the perspective of meta-generalized gradient approximations</title><link>http://arxiv.org/abs/2506.03578v1</link><description>電子構造において、汎関数階層の第3段階にあるメタ一般化勾配近似（メタGGA）の重要性が増しています。メタGGAは、軌道運動エネルギー密度を含む多数の要素から構築されており、広く使用されているPBE-GGAを含む一般化勾配近似（GGA）よりも柔軟性があります。しかし、ほとんどのメタGGAは、バンドギャップや電子の局在化が必要な場合、半局所密度汎関数に予想される制限に対処します。一方、メタGGAは軌道の陰関数です。この特徴は、厳密交換を含むハイブリッド密度汎関数に似ています。近年の研究により、一部のメタGGAはバンドギャップの計算において半局所近似の精度を超える可能性があることが示されています。セリウムは、最近のメタGGAに挑戦するのに理想的なテストベッドです。セリウムは、それぞれの相で非局在化および局在化されたf電子を持つ同構造のα-γ相転移を示します。正確な実験により、セリウムのα-γ相転移におけるフォノンエントロピー項は無視できることが判明しているため、転移におけるすべての変化は電子相関によって引き起こされます。f電子系の相関は半局所近似ではほとんど捉えられませんが、最近の超非局所性を持つLAKメタGGAは、従来の半局所密度汎関数の枠組みから抜け出し、セリウムの相転移に対して驚くべき精度を提供します。LAKおよびLAKの成功に触発されたさらなるメタGGAは、局在電子を持つ量子材料のためのメタGGAの最前線を開く可能性があります。

&lt;img src="https://arxiv.org/html/2506.03578v1/x1.png"/&gt;&lt;p&gt;Adrienn Ruzsinszky, Ashesh Giri, Chandra Shahi&lt;/p&gt;&lt;p&gt;Department of Physics and Engineering Physics, Tulane University, New Orleans, LA 70118&lt;/p&gt;</description><guid isPermaLink="false">2506.03578v1</guid><pubDate>Wed, 04 Jun 2025 04:53:32 +0000</pubDate></item></channel></rss>