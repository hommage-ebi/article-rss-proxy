<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Wed, 25 Jun 2025 03:23:14 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-25</title><link>https://arxiv.org/2025-06-25</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19543v1"&gt;Long-term atomistic finite-temperature substitutional diffusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19577v1"&gt;Tailoring Magnetic Properties of Zigzag Structured Thin Films via Interface Engineering and Columnar Nano-structuring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19690v1"&gt;Flexoelectric Polarization Enhancement in Paraelectric $\mathrm{BaHfO_3}$ via Strain Gradient Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19749v1"&gt;Atomic layer etching of InGaAs using sequential exposures of atomic hydrogen and oxygen gas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19659v1"&gt;Voltage-Induced Oxidation for Enhanced Purity and Reproducibility of Quantum Emission in Monolayer 2D Materials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19727v1"&gt;Moiré Collapse and Luttinger Liquids In Twisted Anisotropic Homobilayers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19546v1"&gt;Elastic heterogeneity governs anomalous scaling in a soft porous crystal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19682v1"&gt;The electronic structure of a doped Mott-Hubbard surface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19738v1"&gt;From Brownian dynamics to Poisson-Nernst-Planck equations: multi-resolution simulations of ions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19766v1"&gt;Efficient calculation of thermodynamic properties of baryon-rich QCD matter from heavy-ion transport models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19384v1"&gt;Deep Electromagnetic Structure Design Under Limited Evaluation Budgets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19538v1"&gt;Dynamics of discrete spacetimes with Quantum-enhanced Markov Chain Monte Carlo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19594v1"&gt;Numerical solution of quantum Landau-Lifshitz-Gilbert equation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19609v1"&gt;Beyond Static Models: Hypernetworks for Adaptive and Generalizable Forecasting in Complex Parametric Dynamical Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19778v1"&gt;Noncontextual Pauli Hamiltonians&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19325v1"&gt;FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19359v1"&gt;Evolutionary Level Repair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19385v1"&gt;Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19410v1"&gt;Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19420v1"&gt;Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19466v1"&gt;KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19530v1"&gt;NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19573v1"&gt;Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19635v1"&gt;On the efficacy of old features for the detection of new bots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19686v1"&gt;From memories to maps: Mechanisms of in context reinforcement learning in transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19702v1"&gt;LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19773v1"&gt;Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19783v1"&gt;SAGE: Strategy-Adaptive Generation Engine for Query Rewriting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19785v1"&gt;Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19843v1"&gt;Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19846v1"&gt;JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19250v1"&gt;Robust Behavior Cloning Via Global Lipschitz Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19256v1"&gt;Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19269v1"&gt;AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19279v1"&gt;EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19312v1"&gt;Capturing Fine-Grained Alignments Improves 3D Affordance Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19343v1"&gt;Discrepancy-Aware Graph Mask Auto-Encoder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19358v1"&gt;From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19399v1"&gt;Automated Detection of Pre-training Text in Black-box LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19406v1"&gt;A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19408v1"&gt;Is an object-centric representation beneficial for robotic manipulation ?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19459v1"&gt;Tagged for Direction: Pinning Down Causal Edge Directions with Precision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19467v1"&gt;Can Large Language Models Capture Human Annotator Disagreements?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19468v1"&gt;MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19469v1"&gt;Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19486v1"&gt;Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19525v1"&gt;Automatic Posology Structuration : What role for LLMs?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19531v1"&gt;ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19539v1"&gt;Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19561v1"&gt;MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19563v1"&gt;PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19567v1"&gt;FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19571v1"&gt;Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19578v1"&gt;Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19592v1"&gt;Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19599v1"&gt;ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19608v1"&gt;ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19621v1"&gt;VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19630v1"&gt;Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19633v1"&gt;Hierarchical Time Series Forecasting Via Latent Mean Encoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19642v1"&gt;The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19650v1"&gt;Identifying Macro Causal Effects in C-DMGs over DMGs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19652v1"&gt;Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19698v1"&gt;Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19732v1"&gt;Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19753v1"&gt;Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19769v1"&gt;A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19777v1"&gt;Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19823v1"&gt;Persona Features Control Emergent Misalignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19825v1"&gt;Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19839v1"&gt;Improving Progressive Generation with Decomposable Flow Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19280v1"&gt;Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19283v1"&gt;AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19315v1"&gt;JCAPT: A Joint Modeling Approach for CAPT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19342v1"&gt;Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19351v1"&gt;In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19352v1"&gt;Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19387v1"&gt;NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19433v1"&gt;Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19461v1"&gt;Iterative Quantum Feature Maps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19465v1"&gt;Stylized Structural Patterns for Improved Neural Network Pre-training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19484v1"&gt;Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19502v1"&gt;MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19549v1"&gt;RCStat: A Statistical Framework for using Relative Contextualization in Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19552v1"&gt;General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19591v1"&gt;Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19683v1"&gt;Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19689v1"&gt;When Can We Reuse a Calibration Set for Multiple Conformal Predictions?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19697v1"&gt;Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19708v1"&gt;Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19726v1"&gt;Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19742v1"&gt;NeRF-based CBCT Reconstruction needs Normalization and Initialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19767v1"&gt;SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19774v1"&gt;Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19847v1"&gt;Orthogonal Finetuning Made Scalable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19852v1"&gt;Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19491v1"&gt;Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19579v1"&gt;Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19755v1"&gt;Cross-regularization: Adaptive Model Complexity through Validation Gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19807v1"&gt;KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19597v1"&gt;Robotics Under Construction: Challenges on Job Sites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19246v1"&gt;Behavioral Anomaly Detection in Distributed Systems via Federated Contrastive Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19248v1"&gt;Inference-Time Reward Hacking in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19281v1"&gt;Robust OOD Graph Learning via Mean Constraints and Noise Reduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19289v1"&gt;Efficient Extreme Operating Condition Search for Online Relay Setting Calculation in Renewable Power Systems Based on Parallel Graph Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19296v1"&gt;The Effect of Depth on the Expressivity of Deep Linear State-Space Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19302v1"&gt;Adversarial Attacks on Deep Learning-Based False Data Injection Detection in Differential Relays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19329v1"&gt;Contrastive Cross-Modal Learning for Infusing Chest X-ray Knowledge into ECGs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19375v1"&gt;Path Learning with Trajectory Advantage Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19383v1"&gt;Explainable Artificial Intelligence Credit Risk Assessment using Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19396v1"&gt;Maximal Update Parametrization and Zero-Shot Hyperparameter Transfer for Fourier Neural Operators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19478v1"&gt;ADDQ: Adaptive Distributional Double Q-Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19496v1"&gt;COLUR: Confidence-Oriented Learning, Unlearning and Relearning with Noisy-Label Data for Model Restoration and Refinement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19537v1"&gt;Dimension Reduction for Symbolic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19550v1"&gt;Discovering Symmetries of ODEs by Symbolic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19583v1"&gt;ConStellaration: A dataset of QI-like stellarator plasma boundaries and optimization benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19626v1"&gt;Scaling Up Unbiased Search-based Symbolic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19643v1"&gt;Unsupervised Data Generation for Offline Reinforcement Learning: A Perspective from Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19645v1"&gt;Tensor-Parallelism with Partially Synchronized Activations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19680v1"&gt;Model Guidance via Robust Feature Attribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19692v1"&gt;Leveraging Lightweight Generators for Memory Efficient Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19693v1"&gt;ReBoot: Encrypted Training of Deep Neural Networks with CKKS Bootstrapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19703v1"&gt;Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19713v1"&gt;Guidance in the Frequency Domain Enables High-Fidelity Sampling at Low CFG Scales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19734v1"&gt;DRIFT: Data Reduction via Informative Feature Transformation- Generalization Begins Before Deep Learning starts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19752v1"&gt;On the necessity of adaptive regularisation:Optimal anytime online learning on $\boldsymbol{\ell_p}$-balls&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19780v1"&gt;Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19810v1"&gt;Ambiguous Online Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19813v1"&gt;Curating art exhibitions using machine learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19245v1"&gt;Universal kernels via harmonic analysis on Riemannian symmetric spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19258v1"&gt;Personality Prediction from Life Stories using Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19262v1"&gt;What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19270v1"&gt;Continuous-variable Quantum Diffusion Model for State Generation and Restoration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19275v1"&gt;A Qubit-Efficient Hybrid Quantum Encoding Mechanism for Quantum Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19282v1"&gt;A Batch-Insensitive Dynamic GNN Approach to Address Temporal Discontinuity in Graph Streams&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19340v1"&gt;CAM-NET: An AI Model for Whole Atmosphere with Thermosphere and Ionosphere Extension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19356v1"&gt;WebGuard++:Interpretable Malicious URL Detection via Bidirectional Fusion of HTML Subgraphs and Multi-Scale Convolutional BERT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19417v1"&gt;Center of Gravity-Guided Focusing Influence Mechanism for Multi-Agent Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19451v1"&gt;Low-Complexity Semantic Packet Aggregation for Token Communication via Lookahead Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19513v1"&gt;Visual hallucination detection in large vision-language models via evidential conflict&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19540v1"&gt;Overtuning in Hyperparameter Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19558v1"&gt;ConCM: Consistency-Driven Calibration and Matching for Few-Shot Class-Incremental Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19598v1"&gt;Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19789v1"&gt;A comparative analysis of machine learning algorithms for predicting probabilities of default&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19820v1"&gt;ProxelGen: Generating Proteins as 3D Densities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19830v1"&gt;Scaling Speculative Decoding with Lookahead Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19836v1"&gt;Machine Learning with Privacy for Protected Attributes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19837v1"&gt;Convergence of Mean Shift Algorithms for Large Bandwidths and Simultaneous Accurate Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19845v1"&gt;A Comparative Study of NAFNet Baselines for Image Restoration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19243v1"&gt;High precision PINNs in unbounded domains: application to singularity formulation in PDEs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19260v1"&gt;Network Structures as an Attack Surface: Topology-Based Privacy Leakage in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19268v1"&gt;HARPT: A Corpus for Analyzing Consumers' Trust and Privacy Concerns in Mobile Health Apps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19274v1"&gt;Stabilizing PDE--ML Coupled System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19533v1"&gt;Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19651v1"&gt;PEVLM: Parallel Encoding for Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19661v1"&gt;Higher-Order Graph Databases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19695v1"&gt;Near-optimal estimates for the $\ell^p$-Lipschitz constants of deep random ReLU neural networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19714v1"&gt;Conservative quantum offline model-based optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19741v1"&gt;Noise Consistency Training: A Native Approach for One-Step Generator in Learning Additional Controls&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19276v1"&gt;Rare dense solutions clusters in asymmetric binary perceptrons -- local entropy via fully lifted RDT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19759v1"&gt;The Shape of Consumer Behavior: A Symbolic and Topological Analysis of Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19382v1"&gt;Measuring and Guiding Monosemanticity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19418v1"&gt;Learning to Disentangle Latent Reasoning Rules with Language VAEs: A Systematic Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19483v1"&gt;Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19492v1"&gt;Is Long-to-Short a Free Lunch? Investigating Inconsistency and Reasoning Efficiency in LRMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19505v1"&gt;AnTKV: Anchor Token-Aware Sub-Bit Vector Quantization for KV Cache in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19512v1"&gt;heiDS at ArchEHR-QA 2025: From Fixed-k to Query-dependent-k for Retrieval Augmented Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19607v1"&gt;Correcting Hallucinations in News Summaries: Exploration of Self-Correcting LLM Methods with External Knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19733v1"&gt;Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19750v1"&gt;Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19761v1"&gt;Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19831v1"&gt;How Effectively Can BERT Models Interpret Context and Detect Bengali Communal Violent Text?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19835v1"&gt;MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19548v1"&gt;Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19603v1"&gt;Social Hatred: Efficient Multimodal Detection of Hatemongers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19665v1"&gt;Recurrent Visual Feature Extraction and Stereo Attentions for CT Report Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19743v1"&gt;NEAR$^2$: A Nested Embedding Approach to Efficient Product Retrieval and Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19848v1"&gt;ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality Debiasing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19441v1"&gt;TTSDS2: Resources and Benchmark for Evaluating Human-Quality Text to Speech Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.19806v1"&gt;LLM-Based Social Simulations Require a Boundary&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-25</guid><pubDate>Wed, 25 Jun 2025 12:22:33 +0900</pubDate></item><item><title>KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs</title><link>http://arxiv.org/abs/2506.19527v1</link><description>大規模言語モデル（LLM）は、オープンワールドのエージェントタスクにおいて大きな能力を発揮する一方で、静的な事前学習済みの知識に依存しているため、新しい特殊なタスクに迅速に適応するという課題も抱えています。ファインチューニングのような従来の方法は、しばしばコストがかかり、大量のデータを必要とし、「破滅的忘却」を引き起こす可能性があります。そこで、我々はKnowMapという、環境データと経験データから知識ベースを動的に構築する新しいアプローチを提案します。KnowMapは、小規模な知識埋め込みモデルをファインチューニングし、大規模なLLMに貴重なタスク固有の知識を付与します。ScienceWorldベンチマークでの実験では、gpt-4-turboモデルの性能が17.71%向上しました。KnowMapは、LLMのタスク適応のための効率的かつ効果的な手段を提供するだけでなく、環境知識と経験知識の統合がLLMの推論能力をどのように向上させるかを強調しています。

&lt;img src="https://arxiv.org/html/2506.19527v1/x1.png"/&gt;&lt;p&gt;Kaigui Bian, Kelin Fu&lt;/p&gt;&lt;p&gt;School of Computer Science Peking University China&lt;/p&gt;</description><guid isPermaLink="false">2506.19527v1</guid><pubDate>Tue, 24 Jun 2025 11:30:38 +0000</pubDate></item><item><title>Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective</title><link>http://arxiv.org/abs/2506.19805v1</link><description>物理情報ニューラルネットワーク（PINN）は、深層学習モデルの出力と勾配が支配方程式に従うようにすることで、偏微分方程式（PDE）を解くために広く用いられています。しかし、計算能力の制約から、PINNは通常、有限個の点を用いて最適化されるため、その収束性と精度を保証することが大きな課題となります。本研究では、孤立した点からその連続的な近傍領域へと損失関数の重みを適応的に変化させる新しい重み付けスキームを提案しました。実験結果から、提案する重み付けスキームが相対的な$L^2$誤差をより低い値に減少させることが示されました。

&lt;img src=""/&gt;&lt;p&gt;Chenhao Si School of Data Science The Chinese University of Hong Kong, China, China &amp;Ming Yan* School of Data Science The Chinese University of Hong Kong, Shenzhen Shenzhen&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19805v1</guid><pubDate>Tue, 24 Jun 2025 17:13:51 +0000</pubDate></item><item><title>Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study</title><link>http://arxiv.org/abs/2506.19794v1</link><description>大規模言語モデル（LLM）は、データ分析タスクの自動化に有望ですが、オープンソースモデルは、このような推論集約的なシナリオにおいて重大な制限に直面しています。本研究では、オープンソースLLMのデータ分析能力を向上させるための戦略を調査します。多様で現実的なシナリオのシードデータセットをキュレーションすることで、データ理解、コード生成、戦略的計画という3つの側面からモデルを評価します。私たちの分析から、3つの重要な発見が得られました。（1）戦略的計画の質がモデルのパフォーマンスの主要な決定要因であること、（2）インタラクション設計とタスクの複雑さが推論能力に大きな影響を与えること、（3）データ品質が、最適なパフォーマンスを達成する上で多様性よりも大きな影響を与えること。これらの洞察を活用して、データ合成手法を開発し、オープンソースLLMの分析的推論能力の大幅な向上を実証します。

&lt;img src=""/&gt;&lt;p&gt;Jintian Zhang, Yi Zhong, Yuqi Zhu, Zhejiang University Ant Group Independent Researcher Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19794v1</guid><pubDate>Tue, 24 Jun 2025 17:04:23 +0000</pubDate></item><item><title>A standard transformer and attention with linear biases for molecular conformer generation</title><link>http://arxiv.org/abs/2506.19834v1</link><description>低エネルギー分子配座、つまり分子内の原子の空間配置をサンプリングすることは、創薬および最適化プロセスで行われる多くの異なる計算にとって重要なタスクです。多数の特殊な同変ネットワークが、2D分子グラフから分子配座を生成するために設計されてきました。近年、非同変トランスフォーマーモデルは、汎化性能を向上させるためのスケーリング能力により、実行可能な代替手段として登場しています。しかし、非同変モデルは同変バイアスの欠如を補うために大きなモデルサイズを必要とするという懸念がありました。本論文では、適切に選択された位置エンコーディングが、これらのサイズ制限に効果的に対処できることを示します。分子グラフに対する相対位置エンコーディングを組み込んだ標準的なトランスフォーマーモデルは、2500万パラメータにスケールした場合、GEOM-DRUGSベンチマークにおいて、6400万パラメータを持つ現在の最先端の非同変ベースモデルを上回ります。相対位置エンコーディングは、NLPドメインで広く採用されている相対位置エンコーディング技術であるALiBiと同様に、グラフノード間の最短経路距離に応じて線形に増加する負の注意バイアスとして、異なる注意ヘッドに対して異なる傾きで実装しました。このアーキテクチャは、分子配座のための新しいクラスの生成モデルの基盤となる可能性があります。

&lt;img src="https://arxiv.org/html/2506.19834v1/x1.png"/&gt;&lt;p&gt;Viatcheslav Gurev IBM Research &amp;Timothy Rumbell IBM Research&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19834v1</guid><pubDate>Tue, 24 Jun 2025 17:50:49 +0000</pubDate></item><item><title>NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling</title><link>http://arxiv.org/abs/2506.19500v1</link><description>LLMが静的な知識に依存し、ツール呼び出しが脆弱であることは、特に大規模な複雑で異質なツールチェーンのオーケストレーションを著しく妨げる。既存の手法は通常、硬直的な単一パス実行を使用するため、エラー回復が不十分で、探索空間が指数関数的に拡大する。そこで、我々は、堅牢な関数呼び出しのためのグラフナビゲート型二段階計画アーキテクチャであるNaviAgentを導入する。これは、マルチパスデサイダーとグラフエンコードナビゲーターで構成される。LLM搭載エージェントとして、マルチパスデサイダーは4次元の決定空間を定義し、環境状態を継続的に認識し、すべてのツール呼び出しシナリオを完全にカバーするための最適なアクションを動的に選択する。グラフエンコードナビゲーターは、ツール依存性異種グラフ（TDHG）を構築し、ノード埋め込みはAPIスキーマ構造と過去の呼び出し動作を明示的に融合する。また、Deciderを効率的で成功率の高いツールチェーンに導くための新しいヒューリスティック探索戦略を統合する。実験の結果、NaviAgentは、すべての基盤モデルとタスクの複雑さにおいて、一貫して最高のタスク成功率（TSR）を達成し、Qwen2.5-14B、Qwen2.5-32B、Deepseek-V3において、平均的なベースライン（ReAct、ToolLLM、{\alpha}-UMI）をそれぞれ13.5%、16.4%、19.0%上回った。その実行ステップは通常、最も効率的なベースラインの1ステップ以内に収まり、品質と効率の強力なバランスを保証する。特に、ファインチューニングされたQwen2.5-14Bモデルは49.5%のTSRを達成し、我々のアーキテクチャ下ではるかに大きな32Bモデル（44.9%）を上回った。グラフエンコードナビゲーターを組み込むことで、TSRが平均2.4ポイント向上し、大規模モデル（Deepseek-V3およびGPT-4o）の複雑なタスクでは9ポイント以上向上し、ツールチェーンのオーケストレーションにおけるその重要な役割が強調される。

&lt;img src="https://arxiv.org/html/2506.19500v1/x1.png"/&gt;&lt;p&gt;Yan Jiang    
Hao Zhou LiZhong GU    
Ai Han    
TianLong Li JD.COM&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19500v1</guid><pubDate>Tue, 24 Jun 2025 10:39:07 +0000</pubDate></item><item><title>Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning</title><link>http://arxiv.org/abs/2506.19482v1</link><description>等変グラフニューラルネットワーク（GNN）は、多様な科学的応用において目覚ましい成功を収めています。しかし、既存の手法は、大規模な幾何グラフへのスケールアップ時に重大な効率性の課題に直面し、計算処理を容易にするために入力グラフを疎にした場合、パフォーマンスが著しく低下します。これらの制限に対処するため、大規模な幾何グラフ向けの等変GNNに対する2つの新しい拡張機能であるFastEGNNとDistEGNNを紹介します。FastEGNNは、実ノードの大規模な順序付けられていないグラフを効果的に近似する、仮想ノードの小さな順序付けられたセットという重要なイノベーションを採用しています。具体的には、相互の識別性を確保するために異なる仮想ノードに対して異なるメッセージパッシングおよび集約メカニズムを実装し、グローバルな分散性を実現するために仮想座標と実座標間の最大平均不一致（MMD）を最小化します。この設計により、FastEGNNは大規模な疎グラフを効率的に処理しながら、高い精度を維持できます。非常に大規模な幾何グラフの場合、仮想ノードが異なるデバイスのサブグラフ間のグローバルブリッジとして機能する分散拡張であるDistEGNNを提示し、一貫性を維持しながら、メモリと計算のオーバーヘッドを大幅に削減します。N体システム（100ノード）、タンパク質ダイナミクス（800ノード）、Water-3D（8,000ノード）、および新しいFluid113Kベンチマーク（113,000ノード）の4つの困難なドメインでモデルを包括的に評価します。結果は、優れた効率とパフォーマンスを示し、大規模な等変グラフ学習における新しい能力を確立します。コードはhttps://github.com/GLAD-RUC/DistEGNNで入手できます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19482v1</guid><pubDate>Tue, 24 Jun 2025 10:17:38 +0000</pubDate></item><item><title>Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs</title><link>http://arxiv.org/abs/2506.19290v1</link><description>ソフトウェアエンジニアリング（SWE）は近年、次世代LLMエージェントの重要なテストベッドとして台頭しており、持続的な反復問題解決（例：50回以上のインタラクションラウンド）と長文脈依存性解決（例：32kトークン以上）という2つの重要な側面において、固有の能力が求められています。しかし、SWEにおけるデータキュレーションプロセスは、コードファイルのフィルタリングやユニットテストの実行・検証のための専用ランタイム環境の構築に手動アノテーションが大きく依存しているため、非常に時間がかかります。その結果、既存のデータセットのほとんどは、数千件のGitHubソースのインスタンスに限定されています。そこで、SWEデータセットの量と多様性を体系的に拡大する、段階的で自動化されたデータキュレーションパイプラインを提案します。私たちのデータセットは、2,531の異なるGitHubリポジトリからの10,169件の実世界のPythonタスクインスタンスで構成されており、それぞれに自然言語で指定されたタスクと、自動化されたユニットテスト検証のための専用ランタイム環境イメージが付属しています。私たちは、提案するSWEデータセットから、8,000件以上のランタイム検証に成功したトレーニング軌跡を慎重にキュレーションしました。これらの軌跡でSkywork-SWEモデルをファインチューニングすると、驚くべきデータスケーリング現象が明らかになります。トレーニングされたモデルのLLMにおけるソフトウェアエンジニアリング能力のパフォーマンスは、データサイズが増加するにつれて向上し続け、飽和の兆候は見られません。特に、私たちのSkywork-SWEモデルは、検証ツールや複数回のロールアウトを使用せずに、SWE-bench Verifiedベンチマークで38.0%のpass@1精度を達成し、OpenHandsエージェントフレームワーク上に構築されたQwen2.5-Coder-32BベースのLLMの中で、新たな最先端（SOTA）を確立しました。さらに、テスト時のスケーリング技術を組み込むことで、パフォーマンスはさらに47.0%の精度に向上し、32Bパラメータ未満のモデルの以前のSOTA結果を上回りました。今後の研究を加速するために、Skywork-SWE-32Bモデルのチェックポイントを公開します。

&lt;img src="https://arxiv.org/html/2506.19290v1/x1.png"/&gt;&lt;p&gt;Changshi Li, Chris Yuhao Liu, Jujie He, Liang Zeng, Rui Yan, Tianwen Wei, Xuchen Song, Yang Liu, Yongcong Li, Yuzhen Xiao, and Yahui Zhou&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19290v1</guid><pubDate>Tue, 24 Jun 2025 03:53:36 +0000</pubDate></item><item><title>From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking</title><link>http://arxiv.org/abs/2506.19724v1</link><description>自律的なコード生成における最近の進歩は、実験を実行することで科学的発見を加速できるAIエージェントに対する期待を高めています。しかし、現在、そのようなエージェントが、コードの開始点として様々な量を与えられた場合に、科学的なアイデアを実装できるかどうかを評価するベンチマークは存在しません。これは、再現（コードの実行）とゼロからの再現（コードの完全な再実装と実行）の間を補間するものです。そこで、我々はAutoExperimentというベンチマークを導入します。これは、研究論文における自然言語記述に基づいて、AIエージェントが機械学習実験を実装し実行する能力を評価するものです。各タスクでは、エージェントに研究論文、主要な関数がマスクされたコードベース、および実験を実行するコマンドが与えられます。目標は、欠落しているコードを生成し、サンドボックス環境で実験を実行し、結果を再現することです。AutoExperimentは、欠落している関数の数$n$を変化させることで難易度を調整し、部分的な再現から完全な再現までを網羅します。最先端のエージェントを評価した結果、$n$が増加するにつれてパフォーマンスが急速に低下することがわかりました。環境と動的に対話できるエージェント（例えば、コードをデバッグするなど）は、固定された「エージェントレス」ハーネスのエージェントよりも優れたパフォーマンスを発揮でき、シングルショットとマルチトライの成功率（Pass@1対Pass@5）の間には大きな隔たりがあり、我々のベンチマークに対する検証アプローチの必要性を示唆しています。我々の発見は、長期的なコード生成、コンテキスト検索、および自律的な実験実行における重要な課題を浮き彫りにし、AutoExperimentをAI主導の科学実験における進歩を評価するための新しいベンチマークとして確立します。我々のデータとコードは、https://github.com/j1mk1m/AutoExperiment でオープンソースとして公開されています。

&lt;img src="https://arxiv.org/html/2506.19724v1/x1.png"/&gt;&lt;p&gt;Alex Wilf, Daniel Fried Carnegie Mellon University, Gyeongwon James Kim, Louis-Philippe Morency&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19724v1</guid><pubDate>Tue, 24 Jun 2025 15:39:20 +0000</pubDate></item><item><title>Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI</title><link>http://arxiv.org/abs/2506.19613v1</link><description>科学的発見は長らく、専門知識、身体能力、睡眠サイクルといった人間の限界によって制約されてきた。近年、AI科学者や自動化された実験室の台頭により、研究の認知的側面と運用的側面の両方が加速している。しかし、重要な制約は依然として残っている。AIシステムは仮想環境に閉じ込められることが多く、自動化された実験室は物理世界で新しい仮説を適応的に検証するための柔軟性と自律性を欠いている。汎用ロボット基盤モデル、拡散ベースの行動ポリシー、微細な操作学習、シミュレーションから実世界への転移など、具現化されたAIの最近の進歩は、認知的知能と具現化された知能の統合の可能性を示している。この融合は、反復的で自律的な実験をサポートし、偶然の発見の可能性をもたらす閉ループシステムへの扉を開く。本ポジションペーパーでは、認知的知能と具現化された知能を深く統合する多層的な閉ループフレームワークであるインテリジェント科学実験室（ISL）というパラダイムを提案する。ISLは、科学的推論のための基盤モデル、エージェントベースのワークフローオーケストレーション、および堅牢な物理実験のための具現化されたエージェントを統合する。このようなシステムは、科学的発見の現在の限界を克服し、AI主導の科学の完全な変革の可能性を実現するために不可欠であると主張する。

&lt;img src="https://arxiv.org/html/2506.19613v1/x1.png"/&gt;&lt;p&gt;Chinese Academy of Sciences Bram Hoex University of New South Wales Wangmeng Zuo Harbin Institute of Technology Philippe Schwaller Swiss Federal Institute of Technology Lausanne Wanli Ouyang Shanghai AI Laboratory LEI BAI Shanghai AI Laboratory Yanyong Zhang University of Science, Oxford Tianfan Fu Nanjing University Di Hu Renmin University of China Andres M Bran Swiss Federal Institute of Technology Lausanne Nian Ran Shanghai Institute of Ceramics, Sha Zhang University of Science, Technology of China Lingyu Duan Peking University Shixiang Tang Shanghai AI Laboratory &amp; The Chinese University of Hong Kong Dongzhan Zhou Shanghai AI Laboratory, Technology of China Suorong Yang Nanjing University Tong Xie University of New South Wales Xiangyuan Xue Shanghai Jiao Tong University Zixuan Hu Peking University Rui Li Harbin Institute of Technology Wenxi Qu Tongji University Zhenfei Yin The University of Sydney&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19613v1</guid><pubDate>Tue, 24 Jun 2025 13:31:44 +0000</pubDate></item><item><title>Operator Forces For Coarse-Grained Molecular Dynamics</title><link>http://arxiv.org/abs/2506.19628v1</link><description>粗視化分子動力学シミュレーションは、相関のある原子のグループを粗視化ビーズで置き換えることで、原子レベルのシミュレーションの長さと時間スケールを拡張します。機械学習による粗視化（MLCG）は、CG分子動力学のための高精度な力場を構築する有望なアプローチとして近年登場しました。しかし、MLCG力場の調整は通常、力マッチングに依存しており、対応する力のラベルを持つ広範な参照原子軌道を必要とします。実際には、原子レベルの力は記録されないことが多く、既存のデータセットでは従来の力マッチングは実行不可能です。最近、ノイズベースのカーネルが導入され、参照原子レベルの力が存在しない状況など、データが少ない状況に合わせて力マッチングを適応させています。このアプローチは、遅い集団運動を再現する力場を生成しますが、ノイズベースのカーネルの破壊的な影響により、重大な局所的な歪みを引き起こします。本研究では、グローバルな配座精度を維持しながら、これらの局所的な歪みを大幅に低減する、正規化フローに基づくより一般的なカーネルを導入します。小タンパク質で我々の方法を実証し、フローベースのカーネルが配座サンプルのみから高品質のCG力を生成できることを示します。

&lt;img src="https://arxiv.org/html/2506.19628v1/x1.png"/&gt;&lt;p&gt;Aleksander Durumeric, Atharva Kelkar, Frank Noé, Leon Klein, Yaoyi Chen&lt;/p&gt;&lt;p&gt;Department of Mathematics and Computer Science, Freie Universität, Berlin,
Germany
Department of Physics, Rice University, Houston, Texas 77005, USA
Microsoft Research AI for Science, Berlin, Germany&lt;/p&gt;</description><guid isPermaLink="false">2506.19628v1</guid><pubDate>Tue, 24 Jun 2025 13:51:20 +0000</pubDate></item><item><title>Block Tensor Decomposition: A dual grid scheme with formal O(N3) for THC decomposition of molecular systems</title><link>http://arxiv.org/abs/2506.19392v1</link><description>電子間相互作用の正確かつ高速な取り扱いは、電子構造理論における中心的な課題であり続けています。なぜなら、ポスト Hartree-Fock 法はしばしば、4 指標電子反発積分 (ERI) の計算コストに悩まされてきたからです。テンソル超収縮 (THC) や補間分離密度フィッティング (ISDF) などの低ランク手法が、Hartree-Fock 交換相関計算のために提案されてきました。しかし、THC カーネルの構築時間が基底関数の数の 4 乗で増加するため、分子系への適用は依然として非効率です。本研究では、ヒルベルトソートとピボット付きコレスキー分解を組み合わせたデュアルグリッドスキームに基づくブロックテンソル分解 (BTD) と呼ばれるアルゴリズムを提案します。これにより、コンパクトな補間グリッドを生成し、THC/ISDF カーネル構築において厳密な $O(N^3)$ スケーリングを可能にします。BTD の主要なパラメータは、効率と精度を両立させるために差分進化によって最適化されます。さらに、BTD をスケールされた反対スピン MP2 (SOS-MP2) に適用し、実空間における疎なマッピングを活用して、電子相関計算で 2 次スケーリング、交換計算で線形スケーリングを実現します。本研究は、分子系向けの低スケーリング THC/ISDF 手法を進歩させ、効率的かつ正確な電子構造計算のための堅牢なフレームワークを提供します。

&lt;img src="https://arxiv.org/html/2506.19392v1/extracted/6554204/btd.png"/&gt;&lt;p&gt;Peifeng Su, Wei Wu, Xuewei Xiong, Yueyang Zhang&lt;/p&gt;&lt;p&gt;The State Key Laboratory of Physical Chemistry of Solid Surfaces, Fujian Provincial Key Laboratory of Theoretical and Computational Chemistry, and College of Chemistry and Chemical Engineering, Xiamen University, Xiamen, Fujian 361005, China&lt;/p&gt;</description><guid isPermaLink="false">2506.19392v1</guid><pubDate>Tue, 24 Jun 2025 07:42:15 +0000</pubDate></item><item><title>AI-assisted prediction of catalytically reactive hotspots in nanoalloys</title><link>http://arxiv.org/abs/2506.19386v1</link><description>ナノ合金は、組成、形状、サイズの変化を通じて化学的特性を調整するユニークな機会を提供します。しかし、この柔軟性は複雑さをもたらし、実験的および従来の理論的手法の両方に課題を突きつけます。本研究では、ナノ合金における反応性ホットスポットを予測するためのAI支援フレームワークを提示します。まず、2NN-MEAMデータで学習させた格子ベースの機械学習ポテンシャルを用いたメトロポリス・モンテカルロ法を用いて、熱力学的に安定なナノ粒子構造を迅速に特定します。これはPt-Niホモトープで実証されています。このアプローチにより、NiリッチなコアとPt濃縮された表面を持つコアシェル構造が得られます。触媒活性を予測するために、反応性とdバンド中心との相関関係を利用します。高コストなDFT計算に頼るのではなく、SCC-DFTBと機械学習を用いたマルチスケール法を用いて、広範囲のナノ合金のサイズと組成にわたってdバンド中心を効率的かつ正確にマッピングします。このフレームワークは、実験的に関連性の高いPt-Niナノ粒子で検証されており、他のナノ合金系にも容易に拡張可能です。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.19386v1</guid><pubDate>Tue, 24 Jun 2025 07:22:16 +0000</pubDate></item><item><title>Exchange-correlation torques from gauge symmetries</title><link>http://arxiv.org/abs/2506.19458v1</link><description>非共線磁性系における正確な交換相関（xc）スピン・トルクの予測問題は、過去20年間、スピン密度汎関数理論（SDFT）の主要な課題であった。スピン・トルクがスピン流の発散、すなわちSDFTにとって本質的でない量に直接結びついているという事実が、進歩を妨げてきた。さらに、SDFTはベクトルポテンシャルやスピン軌道相互作用が存在する場合には適用できない。本論文では、SpinCurrent-DFTにおけるxcエネルギーのU(1)xSU(2)ゲージ不変性の物理的意味を利用した解決策を提案する。一般化されたKohn-Sham（GKS）形式の枠組みにおいて、メタ一般化勾配近似に基づく明示的なxcトルクの式を導出する。重要な項の一つは、GKSスピン運動エネルギー密度を含むxcトルクを表し、もう一つの項は、ランダウ・リフシッツ方程式の現象論的なスピン流に似ている。これらはどちらも第一原理から導出される。また、この関数形式により、GKSの粒子電流とスピン電流が、形式的に相互作用する対応物と同一になることを示す。したがって、長年の問題を解決する非共線平衡条件と断熱力学が導出される。

&lt;img src="https://arxiv.org/html/2506.19458v1/extracted/6566617/Cr_monolayer_torque.png"/&gt;&lt;p&gt;Giovanni Vignale, Jacques K. Desmarais, Kamel Bencheikh, Stefano Pittalis&lt;/p&gt;&lt;p&gt;Dipartimento di Chimica, Università di Torino, via Giuria 5, 10125 Torino, Italy
Institute for Functional Intelligent Materials, National University of Singapore, 4 Science Drive 2, Singapore 117544
Istituto Nanoscienze, Consiglio Nazionale delle Ricerche, Via Campi 213A, I-41125 Modena, Italy
Setif 1 University-Ferhat Abbas, Faculty of Sciences, Department of Physics and Laboratory of Quantum Physics and Dynamical Systems, Setif, Algeria&lt;/p&gt;</description><guid isPermaLink="false">2506.19458v1</guid><pubDate>Tue, 24 Jun 2025 09:39:12 +0000</pubDate></item><item><title>Massive Atomic Diversity: a compact universal dataset for atomistic machine learning</title><link>http://arxiv.org/abs/2506.19674v1</link><description>原子スケールシミュレーションのための機械学習モデルの開発は、過去20年間に電子構造計算を用いて計算された材料および分子特性の大規模データベースから多大な恩恵を受けてきました。近年、これらのデータベースは、任意の原子構造と組成に対して正確な予測を行うことを目的とした汎用モデルの訓練を可能にしました。しかし、これらのデータベースの多くは、それ自体が材料発見を目的として構築されており、したがって、主に安定な、または少なくとも妥当な構造をサンプリングし、各化合物に対して最も正確な予測を行うこと（例えば、計算の詳細を手元の材料に合わせて調整すること）を目標としていました。本稿では、任意の構造に対して妥当な予測を提供できる機械学習モデルを訓練するために特別に設計されたデータセットを紹介します。したがって、これは異なる哲学に従っています。比較的少数の安定構造のセットから始めて、このデータセットは、結果として得られる構造の安定性をほぼ完全に無視して、これらの構造を積極的に歪ませることにより、大規模な原子多様性（MAD）を含むように構築されています。一方、電子構造の詳細は、特定の構造に対して最も正確な予測を得たり、計算量を最小限に抑えたりするのではなく、一貫性を最大化するように選択されています。ここで紹介するMADデータセットは、10万未満の構造しか含んでいませんが、すでに、2〜3桁多い構造を持つ従来のデータセットで訓練されたモデルと競合できる汎用原子間ポテンシャルの訓練を可能にすることが示されています。MADデータセットの構築の哲学と詳細について詳しく説明します。また、他の一般的なデータセットと比較し、汎用的な材料地図作成ツールとして使用できる低次元構造潜在空間も紹介します。

&lt;img src="https://arxiv.org/html/2506.19674v1/x1.png"/&gt;&lt;p&gt;Arslan Mazitov, Giovanni Pizzi, Guillaume Fraux, Marnik Bercx, Michele Ceriotti, Sandip De, Sofiia Chorna&lt;/p&gt;&lt;p&gt;BASF SE, Carl-Bosch-Straße 38, 67056 Ludwigshafen, Germany
Laboratory of Computational Science and Modeling, Institut des Matériaux, École Polytechnique Fédérale de Lausanne, 1015 Lausanne, Switzerland
National Centre for Computational Design and Discovery of Novel Materials (MARVEL), 5232 Villigen PSI, Switzerland
PSI Center for Scientific Computing, Theory and Data, 5232 Villigen PSI, Switzerland&lt;/p&gt;</description><guid isPermaLink="false">2506.19674v1</guid><pubDate>Tue, 24 Jun 2025 14:40:59 +0000</pubDate></item><item><title>Machine Learning Accelerates Raman Computations from Molecular Dynamics for Materials Science</title><link>http://arxiv.org/abs/2506.19595v1</link><description>ラマン分光法は、多くの研究室で使用されている分子や材料の特性評価のための強力な実験技術です。ラマン・スペクトルの第一原理理論計算は、これらの系におけるラマン活性の根底にある微視的な効果を解明するため重要です。これらの計算は、多くの場合、正準調和近似を用いて行われますが、これはラマン応答における特定の熱変化を捉えることができません。非調和振動効果は、最近、いくつかの材料において重要な役割を果たすことが判明しており、調和フォノンを超えたラマン効果の理論的扱いを促しています。分子動力学（MD-ラマン）によるラマン分光法は、非調和振動やその他の関連する熱効果を含む確立されたアプローチですが、MD-ラマン計算は、実用的な材料計算には計算コストが高すぎると長らく考えられてきました。本展望記事では、機械学習の分野における最近の進歩が、精度や予測能力を犠牲にすることなく、関連する計算タスクを劇的に加速させていることを強調します。これらの最近の進展は、MD-ラマンおよび関連手法が、分子や材料の理論的予測および特性評価のための汎用性の高いツールとして、ますます重要になっていることを示しています。

&lt;img src="https://arxiv.org/html/2506.19595v1/x1.png"/&gt;&lt;p&gt;David A. Egger, Manuel Grumet, Tomáš Bučko&lt;/p&gt;&lt;p&gt;Atomistic Modeling Center, Munich Data Science Institute, Technical University of Munich, 85748 Garching, Germany
Department of Physical and Theoretical Chemistry, Faculty of Natural Sciences, Comenius University
in Bratislava, SK-84215 Bratislava, Slovakia
Institute of Inorganic Chemistry, Slovak Academy of Sciences, SK-84236 Bratislava, Slovakia
Physics Department, TUM School of Natural Sciences, Technical University of Munich, 85748 Garching, Germany&lt;/p&gt;</description><guid isPermaLink="false">2506.19595v1</guid><pubDate>Tue, 24 Jun 2025 13:04:37 +0000</pubDate></item></channel></rss>