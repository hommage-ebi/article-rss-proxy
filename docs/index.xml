<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Fri, 11 Jul 2025 03:40:57 +0000</lastBuildDate><item><title>other arxiv papers 2025-07-11</title><link>https://arxiv.org/2025-07-11</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07386v1"&gt;High thermal conductivity dominated by thermal phonons with mean free paths exceeding hundred nanometer in three-dimensional covalent organic framework derivatives: a molecular dynamics study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07403v1"&gt;Promising ferroelectric metal EuAuBi with switchable giant shift current&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07466v1"&gt;In-situ SHG microscopy investigation of the domain-wall-conductivity enhancement procedure in lithium niobate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07553v1"&gt;Altermagnetic Multiferroics: Symmetry-Locked Magnetoelectric Coupling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07575v1"&gt;Strain-Stabilized Interfacial Polarization Tunes Work Function Over 1 eV in RuO2/TiO2 Heterostructures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07614v1"&gt;First-principles analysis of the effect of magnetic states on the oxygen vacancy formation energy in doped La$_{0.5}$Sr$_{0.5}$CoO$_3$ perovskite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07618v1"&gt;Strain-tunable type-II to type-III &amp; Gimbal nodal line transition in Imm2-phase of Cu$_2$SnS$_3$: An ab-initio study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07720v1"&gt;In situ impedance spectroscopy tests of Li$_{4-x}$Ge$_{1-x}$P$_x$O$_4$ as potential solid state electrolyte for Micro Li ion Batteries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07726v1"&gt;Muonium as a probe of point defects in type-Ib diamond&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07791v1"&gt;Fundamental of CO2 Adsorption and Diffusion in Sub-nanoporous Materials: Application to CALF-20&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07849v1"&gt;Modulation of PEDOT properties via cobalt ferrite nanoparticles: morphology, conjugation length, doping level, structure, and electrical conductivity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07458v1"&gt;Common topological origin of longitudinal and transverse magnetoresistance in Fe3GeTe2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07624v1"&gt;Resilient cluster Mott states in layered Nb$_3$Cl$_8$ against pressure-induced symmetry breaking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07639v1"&gt;Geometry-Dependent Adhesion in Transparent, Monodomain Liquid Crystal Elastomers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07650v1"&gt;Pressure induced ferromagnetic to antiferromagnetic phase transition in transition metal chalcogenide Cr$_{3}$Te$_4$&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07716v1"&gt;Superlubricity of Borophene: Tribological Properties in Comparison to hBN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07784v1"&gt;Reversible local strain engineering of $\mathrm{WS}_2$ using a micro-mechanical spring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07950v1"&gt;Sum Rules in Quantum Liquids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07409v1"&gt;Observation of superconductivity-induced leading-edge gap in Sr-doped $\mathrm{La}_{3}\mathrm{Ni}_{2}\mathrm{O}_{7}$ thin films&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07434v1"&gt;Large unconventional anomalous Hall effect far above room temperature in epitaxial Fe$_3$Ga$_4$ films&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07680v1"&gt;Temporal modulation of second harmonic generation in ferroelectrics by a pulsed electric field&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07819v1"&gt;Growth of Structural Lengthscale in Kob Andersen Binary Mixtures: Role of medium range order&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07948v1"&gt;Physics-Informed Gaussian Process Inference of Liquid Structure from Scattering Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07577v1"&gt;Phase space geometry of a Four-wings chaotic attractor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07912v1"&gt;Robust Lindbladian Estimation for Quantum Dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07445v1"&gt;StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07595v1"&gt;Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07599v1"&gt;Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07644v1"&gt;PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07723v1"&gt;Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07743v1"&gt;Identification of Violin Reduction via Contour Lines Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07787v1"&gt;Measuring AI Alignment with Human Flourishing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07818v1"&gt;MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07820v1"&gt;AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07857v1"&gt;Searching for actual causes: Approximate algorithms with adjustable precision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07893v1"&gt;An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07376v1"&gt;PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07393v1"&gt;KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07394v1"&gt;Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07399v1"&gt;Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07405v1"&gt;HGMP:Heterogeneous Graph Multi-Task Prompt Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07414v1"&gt;GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07418v1"&gt;Optimal Auction Design in the Joint Advertising&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07419v1"&gt;MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07421v1"&gt;SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07439v1"&gt;Towards Interpretable Time Series Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07453v1"&gt;Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07460v1"&gt;Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07495v1"&gt;PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07505v1"&gt;Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07532v1"&gt;Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07539v1"&gt;CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07544v1"&gt;Position: We Need An Algorithmic Understanding of Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07579v1"&gt;NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07619v1"&gt;Towards conservative inference in credal networks using belief functions: the case of credal chains&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07622v1"&gt;TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07725v1"&gt;Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07748v1"&gt;When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07754v1"&gt;OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07780v1"&gt;Where are we with calibration under dataset shift in image classification?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07796v1"&gt;Visual Instance-aware Prompt Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07808v1"&gt;Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07828v1"&gt;Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07853v1"&gt;Optimization Guarantees for Square-Root Natural-Gradient Variational Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07868v1"&gt;Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07885v1"&gt;UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07906v1"&gt;Agentic Retrieval of Topics and Insights from Earnings Calls&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07930v1"&gt;Probing Experts' Perspectives on AI-Assisted Public Speaking Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07931v1"&gt;Meek Models Shall Inherit the Earth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07947v1"&gt;Low Resource Reconstruction Attacks Through Benign Prompts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07957v1"&gt;MIRIX: Multi-Agent Memory System for LLM-Based Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07982v1"&gt;Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07983v1"&gt;Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07986v1"&gt;EXPO: Stable Reinforcement Learning with Expressive Policies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07990v1"&gt;Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07406v1"&gt;Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07413v1"&gt;Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07416v1"&gt;Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07417v1"&gt;May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07484v1"&gt;Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07485v1"&gt;Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07509v1"&gt;Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07543v1"&gt;The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07551v1"&gt;ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07572v1"&gt;Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07576v1"&gt;On Trustworthy Rule-Based Models and Explanations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07586v1"&gt;Bayesian Discrete Diffusion Beats Autoregressive Perplexity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07668v1"&gt;Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07685v1"&gt;Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07714v1"&gt;Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07778v1"&gt;Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07817v1"&gt;On the Effect of Instruction Tuning Loss on Generalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07871v1"&gt;Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07929v1"&gt;Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07935v1"&gt;Working with AI: Measuring the Occupational Implications of Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07966v1"&gt;Scaling RL to Long Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07969v1"&gt;Reinforcement Learning with Action Chunking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07993v1"&gt;Multigranular Evaluation for Brain Visual Decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07995v1"&gt;Single-pass Adaptive Image Tokenization for Minimum Program Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07999v1"&gt;Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07388v1"&gt;GRIT: Graph Transformer For Internal Ice Layer Thickness Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07511v1"&gt;Uncertainty Quantification for Motor Imagery BCI -- Machine Learning vs. Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07613v1"&gt;Sparse Self-Federated Learning for Energy Efficient Cooperative Intelligence in Society 5.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07621v1"&gt;Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07637v1"&gt;HLF-FSL. A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07675v1"&gt;Some Theoretical Results on Layerwise Effective Dimension Oscillations in Finite Width ReLU Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07804v1"&gt;Deep Survival Analysis in Multimodal Medical Data: A Parametric and Probabilistic Approach with Competing Risks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07829v1"&gt;Towards Benchmarking Foundation Models for Tabular Data With Text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07848v1"&gt;"So, Tell Me About Your Policy...": Distillation of interpretable policies from Deep Reinforcement Learning agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07854v1"&gt;Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply Chain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07855v1"&gt;Principled Foundations for Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07883v1"&gt;SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07955v1"&gt;Dynamic Chunking for End-to-End Hierarchical Sequence Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07996v1"&gt;Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07389v1"&gt;ST-GRIT: Spatio-Temporal Graph Transformer For Internal Ice Layer Thickness Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07432v1"&gt;Neural networks leverage nominally quantum and post-quantum representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07496v1"&gt;Semi-supervised learning and integration of multi-sequence MR-images for carotid vessel wall and plaque segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07498v1"&gt;Teaching LLM to Reason: Reinforcement Learning from Algorithmic Problems without Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07510v1"&gt;Divergence Minimization Preference Optimization for Diffusion Model Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07581v1"&gt;CHOMET: Conditional Handovers via Meta-Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07589v1"&gt;Stress Monitoring in Healthcare: An Ensemble Machine Learning Framework Using Wearable Sensor Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07625v1"&gt;Concentration of measure for non-linear random matrices with applications to neural networks and non-commutative polynomials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07630v1"&gt;Exploring the Limits of Model Compression in LLMs: A Knowledge Distillation Study on QA Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07712v1"&gt;Balancing the Past and Present: A Coordinated Replay Framework for Federated Class-Incremental Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07738v1"&gt;Efficient and Scalable Estimation of Distributional Treatment Effects with Multi-Task Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07765v1"&gt;Distributed and Decentralised Training: Technical Governance Challenges in a Shifting AI Landscape&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07768v1"&gt;TRIX- Trading Adversarial Fairness via Mixed Adversarial Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07771v1"&gt;A Unified Empirical Risk Minimization Framework for Flexible N-Tuples Weak Supervision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07826v1"&gt;An Empirical Bernstein Inequality for Dependent Data in Hilbert Spaces and Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07852v1"&gt;Pre-Trained AI Model Assisted Online Decision-Making under Missing Covariates: A Theoretical Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07872v1"&gt;Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07898v1"&gt;Efficient Causal Discovery for Autoregressive Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07919v1"&gt;Plausible Counterfactual Explanations of Recommendations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07949v1"&gt;TinierHAR: Towards Ultra-Lightweight Deep Learning Models for Efficient Human Activity Recognition on Edge Devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07965v1"&gt;Prospective Learning in Retrospect&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.08000v1"&gt;Impact of Pretraining Word Co-occurrence on Compositional Generalization in Multimodal Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07396v1"&gt;IML-Spikeformer: Input-aware Multi-Level Spiking Transformer for Speech Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07469v1"&gt;Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07559v1"&gt;Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07580v1"&gt;COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07582v1"&gt;Improving Clustering on Occupational Text Data through Dimensionality Reduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07604v1"&gt;Synthetic MC via Biological Transmitters: Therapeutic Modulation of the Gut-Brain Axis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07683v1"&gt;Accelerating Transposed Convolutions on FPGA-based Edge Devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07769v1"&gt;BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07779v1"&gt;Approximation Depth of Convex Polytopes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07792v1"&gt;Space-Filling Regularization for Robust and Interpretable Nonlinear State Space Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07814v1"&gt;Pay Attention to Attention Distribution: A New Local Lipschitz Bound for Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07867v1"&gt;Re-Bottleneck: Latent Re-Structuring for Neural Audio Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07877v1"&gt;Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07907v1"&gt;A statistical physics framework for optimal learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07518v1"&gt;Triadic Multi-party Voice Activity Projection for Turn-taking in Spoken Dialogue Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07562v1"&gt;The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07640v1"&gt;Lost in Pronunciation: Detecting Chinese Offensive Language Disguised by Phonetic Cloaking Replacement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07694v1"&gt;SAS: Simulated Attention Score&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07741v1"&gt;Code-Switching in End-to-End Automatic Speech Recognition: A Systematic Literature Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07803v1"&gt;StreamUni: Achieving Streaming Speech Translation with a Unified Large Speech-Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07810v1"&gt;Understanding and Controlling Repetition Neurons and Induction Heads in In-Context Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07824v1"&gt;Conditional Unigram Tokenization with Parallel Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07870v1"&gt;DocCHA: Towards LLM-Augmented Interactive Online diagnosis System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07939v1"&gt;SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07988v1"&gt;Automating Expert-Level Medical Reasoning Evaluation of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07499v1"&gt;Extracting ORR Catalyst Information for Fuel Cell from Scientific Literature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07700v1"&gt;Rethinking the Privacy of Text Embeddings: A Reproducibility Study of "Text Embeddings Reveal (Almost) As Much As Text"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2507.07610v1"&gt;SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-07-11</guid><pubDate>Fri, 11 Jul 2025 12:39:24 +0900</pubDate></item><item><title>Automating MD simulations for Proteins using Large language Models: NAMD-Agent</title><link>http://arxiv.org/abs/2507.07887v1</link><description>分子動力学シミュレーションは、タンパク質の構造、ダイナミクス、機能を原子レベルで理解するための不可欠なツールです。しかし、MDシミュレーション用の高品質な入力ファイルを作成するには、時間がかかり、エラーが発生しやすいプロセスとなる可能性があります。本研究では、大規模言語モデル（LLM）、特にGemini 2.0 Flashを、PythonスクリプトとSeleniumベースのWeb自動化と組み合わせて活用し、MD入力ファイルの生成を効率化する自動化パイプラインを紹介します。このパイプラインは、NAMDのシミュレーション対応入力を準備するためのCHARMM GUIの包括的なWebベースのインターフェースを利用します。Geminiのコード生成および反復的な改良機能を統合することで、シミュレーションスクリプトが自動的に記述、実行、修正され、CHARMM GUIを操作し、適切なパラメータを抽出し、必要なNAMD入力ファイルを生成します。後処理は、シミュレーション出力をさらに洗練するために追加のソフトウェアを使用して実行され、完全でほぼハンズフリーのワークフローを可能にします。私たちの結果は、このアプローチがセットアップ時間を短縮し、手動エラーを最小限に抑え、複数のタンパク質システムを並行して処理するためのスケーラブルなソリューションを提供することを示しています。この自動化されたフレームワークは、計算構造生物学におけるLLMのより広範な応用への道を開き、シミュレーション自動化における将来の開発のための堅牢で適応可能なプラットフォームを提供します。

&lt;img src="https://arxiv.org/html/2507.07887v1/extracted/6612909/Figures/ReAct.png"/&gt;&lt;p&gt;Achuth Chandrasekhar, Amir Barati Farimani&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07887v1</guid><pubDate>Thu, 10 Jul 2025 16:17:40 +0000</pubDate></item><item><title>An Automated Length-Aware Quality Metric for Summarization</title><link>http://arxiv.org/abs/2507.07653v1</link><description>本論文では、任意のテキストの要約品質を評価するための定量的かつ客観的な指標であるNOrmed Index of Retention（NOIR）を提案します。NOIRは、意味内容の保持と要約の長さの圧縮の両方に依存します。これにより、要約において最も重要なスキルであるリコールと圧縮のトレードオフがどれだけうまく管理されているかを測定できます。実験により、NOIRは要約器のトークン長と意味保持のトレードオフを効果的に捉え、要約品質に対する人間の認識と相関することが示されています。言語モデル埋め込みを使用して意味的類似性を測定することで、時間のかかる人間が作成した参照要約に頼ることなく、要約品質を評価するための自動化された代替手段を提供します。提案された指標は、さまざまな要約タスクに適用でき、要約アルゴリズム、要約プロンプト、および合成的に生成された要約を評価および改善するための自動化されたツールを提供します。

&lt;img src="https://arxiv.org/html/2507.07653v1/extracted/6612039/Summary_Similarity_versus_Length_Compression.png"/&gt;&lt;p&gt;Sonnetiq&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07653v1</guid><pubDate>Thu, 10 Jul 2025 11:25:16 +0000</pubDate></item><item><title>FrugalRAG: Learning to retrieve and reason for multi-hop QA</title><link>http://arxiv.org/abs/2507.07634v1</link><description>大規模な非構造化ドキュメントコーパスへのアクセスを前提として、複雑な質問に答える問題を検討します。この問題を解決するための事実上のアプローチは、モデルが回答を生成するのに十分な情報を持つまで、（反復的に）ドキュメントを検索し、検索されたドキュメントを通して推論する言語モデルを活用することです。このアプローチを改善する試みは、精度や再現率などの検索拡張生成（RAG）のメトリクスに焦点を当てており、次の2つのタイプに分類できます。（a）思考の連鎖の痕跡で拡張された大規模な質問応答（QA）データセットでのファインチューニング、および（b）質問とドキュメントの関連性シグナルに依存するRLベースのファインチューニング技術の活用。ただし、検索回数の効率も同様に重要なメトリクスですが、あまり注目されていません。本研究では、以下を示します。（1）最近の文献で広く主張されていることとは異なり、RAGメトリクスを改善するために大規模なファインチューニングは必要ありません。具体的には、改善されたプロンプトを備えた標準的なReActパイプラインは、HotPotQAなどのベンチマークで最先端の方法を上回ることができます。（2）教師ありおよびRLベースのファインチューニングは、倹約の観点からRAGを支援できます。つまり、推論時の検索回数による遅延を削減できます。たとえば、同じベースモデルを使用し、わずかなトレーニングコスト（1000例）で、一般的なRAGベンチマークで、ほぼ半分のコスト（検索回数）で競争力のあるRAGメトリクスを達成できることを示します。

&lt;img src="https://arxiv.org/html/2507.07634v1/extracted/6611961/figures/fig.png"/&gt;&lt;p&gt;Abhinav Java Microsoft Research India &amp;Srivathsan Koundinyan Microsoft Research India skoundinyan@microsoft.com &amp;Nagarajan Natarajan Microsoft Research India nagarajn@microsoft.com &amp;Amit Sharma Microsoft Research India amshar@microsoft.com&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07634v1</guid><pubDate>Thu, 10 Jul 2025 11:02:13 +0000</pubDate></item><item><title>RLEP: Reinforcement Learning with Experience Replay for LLM Reasoning</title><link>http://arxiv.org/abs/2507.07451v1</link><description>大規模言語モデルのための強化学習（RL）は、エネルギー集約的な取り組みです。学習は不安定になる可能性があり、ポリシーは事前学習済みの重みから徐々に逸脱する可能性があります。そこで、私たちは\emph{RLEP} -- \,経験再生を用いた強化学習\, -- \,という二段階のフレームワークを提案します。これは、まず検証済みの軌跡を収集し、その後の学習中にそれらを再生します。更新ステップごとに、ポリシーは、新たに生成されたロールアウトと、これらの再生された成功例をブレンドしたミニバッチで最適化されます。高品質な例を再生することで、RLEPはモデルを実りのない探索から遠ざけ、有望な推論パスに学習を集中させ、より速い収束とより強力な最終的なパフォーマンスの両方を提供します。Qwen2.5-Math-7Bベースモデルでは、RLEPは大幅に少ない更新回数でベースラインのピーク精度に到達し、最終的にはそれを上回り、AIME-2024での精度を38.2%から39.9%に、AIME-2025での精度を19.8%から22.3%に、AMC-2023での精度を77.0%から82.2%に向上させます。再現性とさらなる研究を促進するために、私たちのコード、データセット、チェックポイントは、https://github.com/Kwai-Klear/RLEP で公開されています。

&lt;img src="https://arxiv.org/html/2507.07451v1/extracted/6611043/figures/trip_demo_carton.png"/&gt;&lt;p&gt;Fuzheng Zhang, Guorui Zhou Klear Team, Hongzhi Zhang, Jia Fu, Jingyuan Zhang, Kai Fu, Kuaishou Technology, Qi Wang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07451v1</guid><pubDate>Thu, 10 Jul 2025 05:58:55 +0000</pubDate></item><item><title>SAND: Boosting LLM Agents with Self-Taught Action Deliberation</title><link>http://arxiv.org/abs/2507.07441v1</link><description>大規模言語モデル（LLM）エージェントは通常、ReActスタイルの専門家軌跡に対する教師ありファインチューニング、またはペアワイズロールアウトに対する選好最適化によって調整されます。これらの手法のほとんどは、特定の専門家の行動を模倣したり、選択された推論思考や行動を拒否されたものよりも促進することに焦点を当てています。しかし、代替行動について推論し比較することなく、これらの手法でファインチューニングされたLLMエージェントは、限られた行動空間の探索のために、一見もっともらしいが最適ではない行動に過度にコミットする可能性があります。これに対処するため、本論文では、LLMエージェントが1つの行動にコミットする前に、候補行動について明示的に熟考できるようにする、Self-taught ActioN Deliberation（SAND）フレームワークを提案します。大規模な行動空間とステップレベルの行動評価を考慮して、いつ、何を熟考するかという課題に取り組むために、自己整合性行動サンプリングと実行ガイド付き行動批判を組み込み、LLMエージェントのベースモデルを使用してステップごとの行動熟考思考を合成するのに役立てます。反復的な方法で、熟考軌跡はLLMエージェント自体のファインチューニングに使用されます。2つの代表的なインタラクティブエージェントタスクで評価した結果、SANDは初期の教師ありファインチューニングと比較して平均20％の改善を達成し、最先端のエージェント調整アプローチも上回りました。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07441v1</guid><pubDate>Thu, 10 Jul 2025 05:38:15 +0000</pubDate></item><item><title>GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing</title><link>http://arxiv.org/abs/2507.07735v1</link><description>ジェイルブレイク攻撃は、大規模言語モデル（LLM）に有害または非倫理的なコンテンツを生成させることで、その重大な脆弱性を明らかにします。これらの脅威の評価は、LLMの進化する性質と、その脆弱性を効果的に探るために必要な高度な技術のために、特に困難です。現在のベンチマークと評価方法では、これらの課題に完全に対応することが難しく、LLMの脆弱性評価にギャップが生じています。本稿では、既存のジェイルブレイク評価の実践をレビューし、効果的なジェイルブレイク評価プロトコルのために想定される3つの望ましい要件を特定します。これらの課題に対処するために、我々はGuardValという新しい評価プロトコルを導入します。これは、防御側LLMの状態に基づいてジェイルブレイクプロンプトを動的に生成および改良し、安全性が重要な状況に対処する防御側LLMの能力をより正確に評価します。さらに、プロンプトの改良中の停滞を防ぎ、防御側LLMのより深い弱点を露呈する、ますます効果的なジェイルブレイクプロンプトの生成を保証する新しい最適化手法を提案します。このプロトコルを、Mistral-7bからGPT-4まで、10の安全ドメインにわたる多様なモデルセットに適用します。我々の調査結果は、モデル間の明確な行動パターンを強調し、それらの堅牢性の包括的なビューを提供します。さらに、我々の評価プロセスは、LLMの挙動の理解を深め、将来の研究に役立ち、より安全なモデルの開発を推進する洞察につながります。

&lt;img src="https://arxiv.org/html/2507.07735v1/extracted/6612343/figures/attack_example.jpg"/&gt;&lt;p&gt;Haibo Jin, Haohan Wang, Liying Kang, Peiyan Zhang&lt;/p&gt;&lt;p&gt;
Hong Kong Polytechnic University
University of Illinois at Urbana-Champaign&lt;/p&gt;</description><guid isPermaLink="false">2507.07735v1</guid><pubDate>Thu, 10 Jul 2025 13:15:20 +0000</pubDate></item><item><title>Probabilistic Approximate Optimization: A New Variational Monte Carlo Algorithm</title><link>http://arxiv.org/abs/2507.07420v1</link><description>我々は、一般化された\textit{確率的近似最適化アルゴリズム (PAOA)} を導入する。これは、Weitzら~\cite{Combes_2023}による先行研究を拡張し形式化した古典的な変分モンテカルロフレームワークであり、今日のイジングマシンや確率的コンピュータ上でパラメータ化された高速サンプリングを可能にする。PAOAは、独立なサンプルからのコスト評価に基づいて、二値確率ユニットのネットワークの結合を反復的に修正することによって動作する。我々は、微分不要な更新と完全な $2^N \times 2^N$ マルコフフローの勾配との間に直接的な対応関係を確立し、PAOAが原理に基づいた変分定式化を許容することを示す。シミュレーテッドアニーリングは、制約されたパラメータ化の下での極限的な場合として現れ、大規模な3Dスピングラス問題を解くために、オンチップアニーリングを備えたFPGAベースの確率的コンピュータ上でこのレジームを実装する。標準的な26スピンのSherrington-Kirkpatrickモデル上で、一致するパラメータを用いてPAOAをQAOAと比較ベンチマークした結果、PAOAの方が優れた性能を示すことが明らかになった。PAOAは複数の温度プロファイルを最適化することでシミュレーテッドアニーリングを自然に拡張し、SK-L\'evyのようなヘビーテールの問題においてSAよりも優れた性能を発揮することを示す。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07420v1</guid><pubDate>Thu, 10 Jul 2025 04:26:13 +0000</pubDate></item><item><title>Predicting and generating antibiotics against future pathogens with ApexOracle</title><link>http://arxiv.org/abs/2507.07862v1</link><description>抗菌剤耐性（AMR）はエスカレートしており、現在の抗生物質開発を上回るペースで進行している。そのため、新たな病原体に対して有効な抗生物質を発見することがますます重要になっている。しかし、既存のアプローチでは、新規病原体や出現する薬剤耐性菌株に対して有効な分子を迅速に特定することはできない。本稿では、既存化合物の抗菌力を予測し、かつ、これまで遭遇したことのない菌株に対して活性のあるデノボ分子を設計する人工知能（AI）モデルであるApexOracleを紹介する。分子の特徴のみに依存するモデルとは異なり、ApexOracleは、基盤となる離散拡散言語モデルを介して取得された分子の特徴と、ゲノム由来および文献由来の菌株表現を組み合わせた二重埋め込みフレームワークの統合を通じて、病原体固有のコンテキストを組み込んでいる。多様な細菌種および化学的モダリティにおいて、ApexOracleは活性予測において最先端のアプローチを一貫して上回り、抗菌剤データがほとんどまたは全くない新規病原体への信頼性の高い転移可能性を示した。その統一された表現生成アーキテクチャは、優先度の高い脅威に対して高い予測効果を持つ「自然界に存在しない」分子のインシリコ作成をさらに可能にする。迅速な活性予測と標的分子生成を組み合わせることで、ApexOracleはAMRに対抗し、将来の感染症の発生に備えるためのスケーラブルな戦略を提供する。

&lt;img src="https://arxiv.org/html/2507.07862v1/x1.png"/&gt;&lt;p&gt;Fangping Wan, Marcelo Der Torossian Torres, Tianang Leng&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2507.07862v1</guid><pubDate>Thu, 10 Jul 2025 15:42:31 +0000</pubDate></item><item><title>Hess-MC2: Sequential Monte Carlo Squared using Hessian Information and Second Order Proposals</title><link>http://arxiv.org/abs/2507.07461v1</link><description>Sequential Monte Carlo (SMC) 法を用いてベイズ推論を行う際、事後分布の近似精度と計算効率という2つの考慮事項が生じます。計算需要に対応するため、Sequential Monte Carlo Squared (SMC$^2$) は高性能計算 (HPC) 環境に適しています。SMC$^2$ における提案分布の設計は、精度を向上させ、事後分布の探索を改善することができます。なぜなら、不適切な提案は重要度重みの高い分散や粒子の縮退につながる可能性があるからです。Metropolis-Adjusted Langevin Algorithm (MALA) は勾配情報を使用するため、粒子はより高い確率の領域を優先的に探索します。本論文では、このアイデアを拡張し、2次情報、具体的には対数目標のヘッセ行列を組み込みます。2次提案は以前に particle Markov Chain Monte Carlo (p-MCMC) 法で検討されてきましたが、SMC$^2$ フレームワークに導入したのは我々が初めてです。2次提案は、勾配（1次導関数）だけでなく、目標分布の曲率（2次導関数）も使用します。合成モデルに関する実験結果は、他の提案と比較して、ステップサイズ選択と事後分布近似精度において、我々のアプローチの利点を強調しています。

&lt;img src=""/&gt;&lt;p&gt;Andrew Millard1, Conor Rosato2, Joshua Murphy1, Lee Devlin1, Paul Horridge1
and Simon Maskell1 Email: {joshua.murphy, andrew.millard, cmrosa, ljdevlin, p.horridge, smaskell}@liverpool.ac.uk&lt;/p&gt;&lt;p&gt;1 Department of Electrical Engineering and Electronics, University of Liverpool, United Kingdom 2 Department of Pharmacology and Therapeutics, University of Liverpool, United Kingdom&lt;/p&gt;</description><guid isPermaLink="false">2507.07461v1</guid><pubDate>Thu, 10 Jul 2025 06:26:54 +0000</pubDate></item><item><title>Can AI-predicted complexes teach machine learning to compute drug binding affinity?</title><link>http://arxiv.org/abs/2507.07882v1</link><description>結合親和性予測のための機械学習ベースのスコアリング関数（MLSF）の訓練において、合成データ拡張に共フォールディングモデルを使用することの実現可能性を評価します。我々の結果は、性能向上が拡張データの構造的品質に大きく依存することを示しています。この点を考慮し、参照構造なしで高品質な共フォールディング予測を識別するための簡単なヒューリスティクスを確立し、MLSF訓練において実験構造の代替として利用できるようにしました。我々の研究は、共フォールディングモデルに基づく将来のデータ拡張戦略に情報を提供します。

&lt;img src="https://arxiv.org/html/2507.07882v1/extracted/6612811/Figures/Figure_1.png"/&gt;&lt;p&gt;Aniket Magarkar, Philip C. Biggin, Savva Grevtsev, Thomas Douglas, Wei-Tse Hsu&lt;/p&gt;&lt;p&gt;Boehringer Ingelheim Pharma GmbH &amp; Co. KG, Birkendorfer Str. 65, 88397 Biberach an der Riß, Germany
Department of Biochemistry, University of Oxford, South Parks Road, Oxford, OX1 3QU, UK
Department of Chemistry, University of Oxford, Mansfield Road, Oxford, OX1 3TA, UK&lt;/p&gt;</description><guid isPermaLink="false">2507.07882v1</guid><pubDate>Thu, 10 Jul 2025 16:05:16 +0000</pubDate></item><item><title>Learning Collective Variables from Time-lagged Generation</title><link>http://arxiv.org/abs/2507.07390v1</link><description>状態遷移のような稀な現象は、タイムスケールが長いため、分子動力学シミュレーションで直接観測することが困難です。拡張サンプリング法は、注意深く選択された低次元の特徴量である集団変数（CV）にバイアスを導入することで、これを克服します。集団変数は、遅い自由度を捉えます。機械学習アプローチ（MLCV）は、CVの発見を自動化しましたが、既存の方法は通常、正確なサンプリングに不可欠な詳細なダイナミクスを完全にエンコードすることなく、準安定状態を識別することに焦点を当てています。我々は、生成モデルの時間遅延条件から直接CVを学習するフレームワークであるTLCを提案します。TLCは、静的なボルツマン分布をモデル化する代わりに、時間遅延条件付き分布をモデル化し、遅い動的挙動を捉えるCVを生成します。我々は、アラニンジペプチド系において、2つのCVベースの拡張サンプリングタスク（(i)ステアリング分子動力学（SMD）および(ii)オンザフライ確率拡張サンプリング（OPES））を用いてTLCを検証し、遷移経路サンプリングと状態識別の両方において、既存のMLCV法と同等またはそれ以上の性能を示すことを実証しました。

&lt;img src="https://arxiv.org/html/2507.07390v1/x1.png"/&gt;&lt;p&gt;Kiyoung Seong, Rafael Gomez-Bombarelli, Seonghyun Park, Soojung Yang, Sungsoo Ahn&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07390v1</guid><pubDate>Thu, 10 Jul 2025 03:06:21 +0000</pubDate></item><item><title>PyVision: Agentic Vision with Dynamic Tooling</title><link>http://arxiv.org/abs/2507.07998v1</link><description>LLMは、計画、推論、外部ツールを動的に呼び出すことができるシステムであるエージェントとして、ますます展開されています。しかし、視覚的推論においては、従来のアプローチは主に、事前定義されたワークフローと静的なツールセットによって制限されたままです。本報告書では、MLLMがタスクに合わせてPythonベースのツールを自律的に生成、実行、改良することを可能にし、柔軟で解釈可能な問題解決を可能にする、インタラクティブなマルチターンのフレームワークであるPyVisionを紹介します。PyVisionによって作成されたツールの分類法を開発し、多様なベンチマークにおけるそれらの使用状況を分析します。定量的に、PyVisionは一貫したパフォーマンス向上を達成し、V*でGPT-4.1を+7.8%、VLMsAreBlind-miniでClaude-4.0-Sonnetを+31.1%向上させます。これらの結果は、より広範な変化を示唆しています。動的なツール作成は、モデルがツールを使用するだけでなく、ツールを発明することを可能にし、よりエージェント的な視覚的推論へと進歩します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07998v1</guid><pubDate>Thu, 10 Jul 2025 17:59:55 +0000</pubDate></item><item><title>Why is Your Language Model a Poor Implicit Reward Model?</title><link>http://arxiv.org/abs/2507.07981v1</link><description>報酬モデルは、言語モデルの事後学習および推論パイプラインにおいて重要です。都合の良いことに、最近の研究では、すべての言語モデルが、アーキテクチャの変更を必要とせずに、暗黙的な報酬モデル（IM-RM）を定義することが示されました。しかし、そのようなIM-RMは、特に分布外において、言語モデルの隠れ表現に専用の線形ヘッドを適用する明示的な報酬モデル（EX-RM）と比較して、汎化性能が低い傾向があります。EX-RMとIM-RMはほぼ同一であるため、汎化性能のギャップの存在は不可解です。これらは、同じデータ、損失関数、および言語モデルを使用してトレーニングでき、報酬の計算方法のみが異なります。異なる報酬モデルタイプの根底にある暗黙的なバイアスを根本的に理解するために、このギャップの根本原因を調査します。理論と実験に裏打ちされた私たちの主な発見は、IM-RMが表面的なトークンレベルの手がかりに大きく依存しているということです。その結果、トークンレベルの分布シフト下、および分布内においても、EX-RMよりも汎化性能が低いことがよくあります。さらに、汎化性能のギャップに関する代替仮説に対する証拠を提供します。最も注目すべきは、IM-RMが検証よりも生成が難しいタスクで苦労するという直感的な主張に異議を唱えます。なぜなら、IM-RMは検証者としても生成者としても機能できるからです。総合すると、私たちの結果は、一見些細な設計上の選択が、報酬モデルの汎化性能に大きな影響を与える可能性があることを強調しています。

&lt;img src="https://arxiv.org/html/2507.07981v1/x1.png"/&gt;&lt;p&gt;Intelligence, Jiarui Yao, Noam Razin, Princeton University University of Illinois Urbana-Champaign, Sanjeev Arora Princeton Language, Yong Lin&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07981v1</guid><pubDate>Thu, 10 Jul 2025 17:55:05 +0000</pubDate></item><item><title>DTECT: Dynamic Topic Explorer &amp; Context Tracker</title><link>http://arxiv.org/abs/2507.07910v1</link><description>テキストデータの爆発的な増加は、進化するテーマやトレンドを発見する上で大きな課題となっています。既存の動的トピックモデリング技術は強力であるものの、解釈やユーザーフレンドリーな探索を強力にサポートするものがなく、断片的なパイプラインとして存在することがよくあります。そこで、生のテキストデータと意味のある時間的洞察との間のギャップを埋めるエンドツーエンドのシステム、DTECT（Dynamic Topic Explorer &amp; Context Tracker）を紹介します。DTECTは、データの前処理、複数のモデルアーキテクチャ、および時間的トピックモデルのトピック品質を分析するための専用の評価指標をサポートする統合されたワークフローを提供します。LLM駆動の自動トピックラベリング、時間的に顕著な単語によるトレンド分析、ドキュメントレベルの要約によるインタラクティブな可視化、直感的なデータクエリのための自然言語チャットインターフェースを導入することで、解釈可能性を大幅に向上させます。これらの機能を単一のまとまりのあるプラットフォームに統合することで、DTECTはユーザーがテーマのダイナミクスをより効果的に追跡および理解できるようにします。DTECTはオープンソースであり、https://github.com/AdhyaSuman/DTECT で入手できます。

&lt;img src="https://arxiv.org/html/2507.07910v1/x1.png"/&gt;&lt;p&gt;Debarshi Kumar Sanyal Indian Association for the Cultivation of Science adhyasuman30@gmail.com, Suman Adhya&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07910v1</guid><pubDate>Thu, 10 Jul 2025 16:44:33 +0000</pubDate></item><item><title>From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems</title><link>http://arxiv.org/abs/2507.07847v1</link><description>検索拡張生成 (RAG) は、自然言語処理 (NLP) において重要なフレームワークとして登場し、外部ドキュメント検索と大規模言語モデル (LLM) を統合することで、事実の一貫性を向上させ、ハルシネーションを低減しています。しかし、RAG の有効性は、検索されたドキュメントにおける共参照の複雑さによって阻害されることが多く、文脈学習を妨げる曖昧さを生み出します。本研究では、エンティティの共参照が RAG ベースのシステムにおけるドキュメント検索と生成パフォーマンスの両方にどのように影響するかを体系的に調査し、検索の関連性、文脈理解、および全体的な応答品質に焦点を当てます。共参照解決が検索の有効性を高め、質問応答 (QA) のパフォーマンスを向上させることを示します。検索タスクにおけるさまざまなプーリング戦略の比較分析を通じて、平均プーリングが共参照解決の適用後に優れた文脈捕捉能力を発揮することを発見しました。QA タスクでは、より小さなモデルが曖昧さ解消プロセスからより多くの恩恵を受けることを発見しました。これは、参照の曖昧さを処理するための固有の能力が限られているためと考えられます。これらの発見に基づき、本研究は RAG における共参照の複雑さによってもたらされる課題についてより深い理解を提供し、知識集約型 AI アプリケーションにおける検索と生成の改善のための指針を提供することを目的としています。

&lt;img src="https://arxiv.org/html/2507.07847v1/x1.png"/&gt;&lt;p&gt;Junyoung Son, Korea University Naver Corp, Seongtae Hong, Youngjoon Jang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07847v1</guid><pubDate>Thu, 10 Jul 2025 15:26:59 +0000</pubDate></item><item><title>KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities</title><link>http://arxiv.org/abs/2507.07695v1</link><description>大規模言語モデル(LLM)を再学習してより多くの知識を取り込む場合、ファインチューニングは非常にリソースを消費するプロセスです。時間と計算コストを削減するために多くのファインチューニング技術が開発されてきましたが、LLMのサイズと複雑さが増大し続けるにつれて、課題は依然として残っています。これに対処するため、LLMにおける知識拡張への新しいアプローチが必要です。検索拡張生成(RAG)は、外部知識をデータベースに保存し、質問応答をサポートするために関連するチャンクを検索するという代替手段を提供します。しかし、RAGの単純な実装は、スケーラビリティと回答精度において重大な制限に直面します。本論文では、これらの制限を克服するために設計された新しいフレームワークであるKeyKnowledgeRAG (K2RAG)を紹介します。分割統治パラダイムに触発されたK2RAGは、密ベクトル検索と疎ベクトル検索、知識グラフ、テキスト要約を統合して、検索品質とシステム効率を向上させます。このフレームワークには、トレーニングデータを要約する前処理ステップも含まれており、トレーニング時間を大幅に短縮します。K2RAGはMultiHopRAGデータセットを使用して評価され、提案されたパイプラインはドキュメントコーパスでトレーニングされ、別の評価セットでテストされました。結果は、一般的な単純なRAG実装と比較して顕著な改善を示しました。K2RAGは、平均回答類似度スコアが0.57と最も高く、第3四分位数(Q3)の類似度が0.82と最も高く、正解との整合性が向上していることを示しています。精度向上に加えて、このフレームワークは非常に効率的であることが証明されました。要約ステップにより、個々のコンポーネントの平均トレーニング時間が93%削減され、実行速度は従来の知識グラフベースのRAGシステムよりも最大40%高速になりました。K2RAGは優れたスケーラビリティも示し、本研究でテストされたいくつかの単純なRAG実装よりも3分の1のVRAMしか必要としませんでした。

&lt;img src="https://arxiv.org/html/2507.07695v1/extracted/6612194/images/rag_tree_over_time.png"/&gt;&lt;p&gt;Hruday Markondapatnaikuni University of Sydney Basem Suleiman University of New South Wales Abdelkarim Erradi Qatar University Shijing Chen University of New South Wales&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07695v1</guid><pubDate>Thu, 10 Jul 2025 12:19:03 +0000</pubDate></item><item><title>DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search</title><link>http://arxiv.org/abs/2507.07426v1</link><description>大規模言語モデルの最近の進歩は、創薬などの科学分野で大きな可能性を示しています。しかし、その有効性は、事前学習で獲得した知識を超える推論を行う場合に制約を受けます。ファインチューニングや検索拡張生成などの従来のアプローチは、高い計算コストを強いるか、構造化された科学データを十分に活用できないかのいずれかの限界に直面しています。これらの課題を克服するために、我々は、RAG、マルチエージェントコラボレーション、モンテカルロ木探索を相乗的に統合した、創薬リポジショニングのための新しいフレームワークであるDrugMCTSを提案します。このフレームワークは、分子およびタンパク質の情報を検索および分析する5つの専門エージェントを採用し、構造化された反復的な推論を可能にします。ドメイン固有のファインチューニングを必要とせずに、DrugMCTSはQwen2.5-7B-InstructがDeepseek-R1を20%以上上回ることを可能にします。DrugBankおよびKIBAデータセットでの広範な実験により、DrugMCTSは、汎用LLMおよび深層学習ベースラインの両方と比較して、大幅に高いリコールとロバスト性を達成することが示されています。我々の結果は、創薬のためのLLMアプリケーションを進歩させる上で、構造化された推論、エージェントベースのコラボレーション、およびフィードバック駆動型の検索メカニズムの重要性を強調しています。

&lt;img src="https://arxiv.org/html/2507.07426v1/extracted/6609471/workflow.png"/&gt;&lt;p&gt;Linqi Song, Tong Xie, Yinqiao Li, Yudai Matsuda, Yuwei Wan, Zerui Yang&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07426v1</guid><pubDate>Thu, 10 Jul 2025 04:39:55 +0000</pubDate></item><item><title>Effects of One-particle Reduced Density Matrix Optimization in Variational Quantum Eigensolvers</title><link>http://arxiv.org/abs/2507.07667v1</link><description>変分量子固有値ソルバー（VQE）は、近期的量子コンピュータ上で分子系をシミュレーションするための有望な手法です。このアプローチはエネルギー推定を利用しますが、VQEによって生成される1粒子還元密度行列（1-RDM）から、他の関連する分子特性を抽出できます。これらの特性の精度は、1-RDMの信頼性と収束に強く依存しますが、エネルギーのみの最適化では保証されません。そこで、エネルギーと分子特性の両方の精度を向上させるために、VQE内で1-RDMを最適化することの効果を調査します。1-RDMの収束を強制するために、コスト関数にペナルティ項を組み込むことで、エネルギーと1-RDMを最適化する2段階アルゴリズムを実装しました。最初のステップはエネルギー最小化に焦点を当て、2番目のステップでは、エネルギーと1-RDMの同時改善を促進するために、重み付けされたペナルティがコスト関数に追加されます。このアプローチは、それぞれ活性空間（4,4）および（2,2）を持つk-UpCCGSDおよびGateFabric ansatzesでテストおよび検証されました。k-UpCCGSDはCISDに近いエネルギーを生成するため、1-RDMを最適化してもエネルギーにはほとんど影響しませんが、電子密度、双極子モーメント、原子電荷などの電子特性を大幅に改善します。GateFabricは当初、CISDからのエネルギー偏差が大きいことを示していますが、1-RDMを最適化することで、エネルギー精度と1-RDMの品質が大幅に向上します。これらの結果は、エネルギーと1-RDMの同時最適化が、変分量子アルゴリズムにおけるエネルギーと分子特性の精度を向上させるための効果的な戦略であることを示しています。

&lt;img src="https://arxiv.org/html/2507.07667v1/x1.png"/&gt;&lt;p&gt;Amanda Marques de Lima Departamento de Química Fundamental Universidade Federal de Pernambuco Recife-PE, Brazil, Brazil &amp;Eivson Darlivam Rodrigues de Aguiar Silva Departamento de Química Fundamental Universidade Federal de Pernambuco Recife-PE, Brazil &amp;Erico Souza Teixeira Centro de Exelência em Computação Quântica, Brazil &amp;Ricardo Luiz Longo Departamento de Química Fundamental Universidade Federal de Pernambuco Recife-PE, Campinas-SP, Venturus&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07667v1</guid><pubDate>Thu, 10 Jul 2025 11:48:34 +0000</pubDate></item><item><title>Machine Learning-Assisted Surrogate Modeling with Multi-Objective Optimization and Decision-Making of a Steam Methane Reforming Reactor</title><link>http://arxiv.org/abs/2507.07641v1</link><description>本研究では、蒸気メタン改質（SMR）反応器のための統合モデリングおよび最適化フレームワークを提示する。これは、数理モデル、人工ニューラルネットワーク（ANN）に基づくハイブリッドモデリング、高度な多目的最適化（MOO）、および多基準意思決定（MCDM）技術を組み合わせたものである。内部物質移動抵抗を考慮した一次元固定床反応器モデルを用いて、反応器の性能をシミュレーションした。数理モデルの高い計算コストを削減するために、ハイブリッドANNサロゲートを構築し、高い予測精度を維持しながら、平均シミュレーション時間を93.8％削減した。次に、このハイブリッドモデルを、非劣ソート遺伝的アルゴリズムII（NSGA-II）ソルバーを用いた3つのMOOシナリオに組み込んだ。1）メタン転換率と水素出力を最大化する。2）水素出力を最大化しながら二酸化炭素排出量を最小化する。3）3つの目的を組み合わせたケース。最適なトレードオフ解は、理想解との類似性による順位付け手法（TOPSIS）と、理想平均距離に基づく簡略化された選好順位付け（sPROBID）という2つのMCDM法を用いてさらに順位付けおよび選択された。最適な結果には、最初のケースでは0.863のメタン転換率と4.556 mol/sの水素出力、3番目のケースでは0.988のメタン転換率と3.335 mol/sの水素および0.781 mol/sの二酸化炭素が含まれる。この包括的な方法論は、複数の、しばしば相反する目的を持つ複雑な触媒反応器システムを最適化するための、スケーラブルで効果的な戦略を提供する。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07641v1</guid><pubDate>Thu, 10 Jul 2025 11:10:16 +0000</pubDate></item><item><title>NNQS-AFQMC: Neural network quantum states enhanced fermionic quantum Monte Carlo</title><link>http://arxiv.org/abs/2507.07540v1</link><description>我々は、補助場量子モンテカルロ（AFQMC）において、ニューラルネットワーク量子状態（NNQS）を試行波動関数として実装するための効率的な手法を紹介する。NNQSは、多体波動関数を柔軟に表現できる最近開発された変分アンザッツの一種であるが、最適化の際に高い計算コストを伴うことが多い。一方、AFQMCは、基底状態計算のための強力な確率的射影法であるが、通常、試行波動関数または試行密度行列による近似的な制約を必要とし、その品質が精度に影響を与える。最近の進歩により、広範な高度に相関した波動関数を確率的サンプリング技術を通じてAFQMCに統合できることが示されている。本研究では、NNQSとAFQMCの直接的な統合を提示し、NNQSが管理可能な計算コストでAFQMCのための高品質な試行波動関数として機能することを可能にする。我々は、NNQS-AFQMC法を、引き伸ばされた構造における困難な窒素分子（N$_2$）に適用してテストする。我々の結果は、NNQS試行波動関数を用いたAFQMCがほぼ正確な全エネルギーを達成できることを示し、NNQSを用いたAFQMCが強相関電子構造計算における長年の課題を克服する可能性を強調する。また、この有望な方法論を改善するための今後の研究の方向性についても概説する。

&lt;img src="https://arxiv.org/html/2507.07540v1/x1.png"/&gt;&lt;p&gt;Bowen Kan, Bowen Zhao, Honghui Shang, Huan Ma, Zhi-Yu Xiao&lt;/p&gt;&lt;p&gt;Institute of Physics, Chinese Academy of Sciences, P.O. Box 603, Beijing 100190, China
[&lt;/p&gt;</description><guid isPermaLink="false">2507.07540v1</guid><pubDate>Thu, 10 Jul 2025 08:36:35 +0000</pubDate></item><item><title>General purpose models for the chemical sciences</title><link>http://arxiv.org/abs/2507.07456v1</link><description>データ駆動型技術は、化学科学を変革し加速する大きな可能性を秘めている。しかし、化学科学はまた、非常に多様で、小さく、曖昧なデータセットという特有の課題を抱えており、従来の機械学習アプローチでは完全に活用することが難しい。大規模言語モデルのような汎用モデル（GPM）という新しいクラスのモデルは、直接訓練されていないタスクを解決し、異なる形式の少量のデータを柔軟に扱う能力を示している。本レビューでは、GPMの基本的な構築原理について議論し、科学プロセス全体にわたる化学科学におけるこれらのモデルの最近の応用例を概説する。これらの応用の多くはまだプロトタイプ段階にあるが、GPMへの関心の高まりにより、今後数年間でその多くが成熟すると予想される。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2507.07456v1</guid><pubDate>Thu, 10 Jul 2025 06:18:46 +0000</pubDate></item><item><title>Phase Stability and Transformations in Lead Mixed Halide Perovskites from Machine Learning Force Fields</title><link>http://arxiv.org/abs/2507.07926v1</link><description>ハロゲン化鉛ペロブスカイト(APbX$_3$)は調整可能な光電子特性を提供するが、複雑な相安定性の状況を特徴とする。本研究では、オンザフライデータ収集と等変メッセージパッシングニューラルネットワークポテンシャルを用いて、CsPbX$_3$, MAPbX$_3$, FAPbX$_3$という3つの代表的なペロブスカイト系の大規模分子動力学シミュレーションを行う。これらのシミュレーションをPDynA解析ツールキットと統合することで、平衡状態図と、温度およびハロゲン混合条件の変化下での動的な構造進化の両方を明らかにする。我々の発見は、Aサイトカチオンが八面体傾斜モードと相経路を強く調節することを示している。MA$^+$は、広範な分子再配置と結晶回転を必要とすることにより、MAPbX$_3$におけるベータ相からガンマ相への転移を効果的に「禁止」する。一方、議論の余地のあるFAPbX$_3$の低温相は、$a^+a^+a^+$傾斜を持つIm$\bar{3}$立方晶相として最もよく表現される。さらに、ハロゲン組成と配置のわずかな変化（均一な混合から部分的な分離まで）は、傾斜相関を変化させる。分離されたドメインは、均一な相転移を妨げる異常な傾斜モードを促進することさえある。これらの結果は、カチオン環境とハロゲン分布の間のマルチスケールな相互作用を強調し、相安定性を向上させるためのペロブスカイト構造の調整に対する合理的な根拠を提供する。

&lt;img src="https://arxiv.org/html/2507.07926v1/x1.png"/&gt;&lt;p&gt;Aron Walsh, Johan Klarbring, Xia Liang&lt;/p&gt;&lt;p&gt;Department of Materials, Imperial College London, South Kensington Campus, London SW7 2AZ, UK
Department of Physics, Chemistry and Biology (IFM), Linköping University, SE-581 83, Linköping, Sweden&lt;/p&gt;</description><guid isPermaLink="false">2507.07926v1</guid><pubDate>Thu, 10 Jul 2025 17:07:31 +0000</pubDate></item><item><title>A Semi-Empirical Descriptor for Open Circuit Voltage</title><link>http://arxiv.org/abs/2507.07760v1</link><description>層状遷移金属酸化物（TMO）は、Na/Li電池の正極材料として広く使用されています。開放回路電圧（OCV）は、容量とともにエネルギー密度を決定する重要な物理的および化学的要因の一つであり、正極の性能に影響を与えます。電圧プロファイルの形状は、サイクル中の生成相の形成エネルギーにも影響されます。理論的な観点から見ると、形成エネルギー（および電圧）は、相間の内部エネルギーの差として定義されます。したがって、OCVの計算には、内部エネルギーの正確な予測が不可欠です。本研究では、与えられたTMOの内部エネルギーを、明確な物理的意味を持つ個別の寄与に分解する理論的枠組みを提示します。具体的には、エネルギーを、DFTよりも計算が容易で、実験データベースから取得できるパラメータに分解します。これらのパラメータから、異なる組成に対して計算可能なポテンシャル項を定義し、電圧プロファイルの計算に使用できます。

&lt;img src="https://arxiv.org/html/2507.07760v1/extracted/6611903/figure6.png"/&gt;&lt;p&gt;Mark Huijben, Payam Kaghazhi, Sourav Baiju&lt;/p&gt;&lt;p&gt;Materials Syntesis and Processing (IMD-2), Institute of Energy Materials and Devices Forschungszentrum Juelich GmbH, Germany MESA+ Institute for Nanotechnology University of Twente 7500 AE Enschede, the Netherlands&lt;/p&gt;</description><guid isPermaLink="false">2507.07760v1</guid><pubDate>Thu, 10 Jul 2025 13:36:21 +0000</pubDate></item></channel></rss>