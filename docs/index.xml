<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Wed, 04 Jun 2025 03:21:51 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-04</title><link>https://arxiv.org/2025-06-04</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02371v1"&gt;SFBD Flow: A Continuous-Optimization Framework for Training Diffusion Models with Noisy Samples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02390v1"&gt;GAdaBoost: An Efficient and Robust AdaBoost Algorithm Based on Granular-Ball Structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02392v1"&gt;Improving Generalization of Neural Combinatorial Optimization for Vehicle Routing Problems via Test-Time Projection Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02451v1"&gt;Weak Supervision for Real World Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02504v1"&gt;Stochastic Momentum Methods for Non-smooth Non-Convex Finite-Sum Coupled Compositional Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02539v1"&gt;VerificAgent: Integrating Expert Knowledge and Fact-Checked Memory for Robust Domain-Specific Task Planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02563v1"&gt;Privacy-Preserving Federated Convex Optimization: Balancing Partial-Participation and Efficiency via Noise Cancellation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02577v1"&gt;Reachability Weighted Offline Goal-conditioned Resampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02599v1"&gt;Assessing the Completeness of Traffic Scenario Categories for Automated Highway Driving Functions via Cluster-based Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02616v1"&gt;Compositional Learning for Modular Multi-Agent Self-Organizing Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02630v1"&gt;HAM: A Hyperbolic Step to Regulate Implicit Bias&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02665v1"&gt;Beyond Invisibility: Learning Robust Visible Watermarks for Stronger Copyright Protection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02811v1"&gt;CART-based Synthetic Tabular Data Generation for Imbalanced Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02883v1"&gt;A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02897v1"&gt;Sociodynamics-inspired Adaptive Coalition and Client Selection in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02935v1"&gt;MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02939v1"&gt;QKV Projections Require a Fraction of Their Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02946v1"&gt;Abstract Counterfactuals for Language Model Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02965v1"&gt;Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02978v1"&gt;On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02986v1"&gt;Implicit Regularization of the Deep Inverse Prior Trained with Inertia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03085v1"&gt;Non-Asymptotic Length Generalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03093v1"&gt;From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03109v1"&gt;On Weak-to-Strong Generalization and f-Divergence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03111v1"&gt;Rectified Flows for Fast Multiscale Fluid Flow Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03128v1"&gt;Zero-Shot Time Series Forecasting with Covariates via In-Context Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03142v1"&gt;Not All Tokens Are Meant to Be Forgotten&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02366v1"&gt;Approximate Borderline Sampling using Granular-Ball for Classification Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02370v1"&gt;Reconciling Hessian-Informed Acceleration and Scalar-Only Communication for Efficient Federated Zeroth-Order Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02382v1"&gt;Multi-level and Multi-modal Action Anticipation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02385v1"&gt;Multi-agent Markov Entanglement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02389v1"&gt;Univariate to Multivariate: LLMs as Zero-Shot Predictors for Time-Series Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02394v1"&gt;Joint Modeling for Learning Decision-Making Dynamics in Behavioral Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02413v1"&gt;Tensor State Space-based Dynamic Multilayer Network Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02415v1"&gt;AERO: A Redirection-Based Optimization Framework Inspired by Judo for Robust Probabilistic Forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02422v1"&gt;Enhancing Convergence, Privacy and Fairness for Wireless Personalized Federated Learning: Quantization-Assisted Min-Max Fair Scheduling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02475v1"&gt;Comba: Improving Nonlinear RNNs with Closed-loop Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02572v1"&gt;HATA: Trainable and Hardware-Efficient Hash-Aware Top-k Attention for Scalable Large Model Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02619v1"&gt;HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02651v1"&gt;Asymptotics of SGD in Sequence-Single Index Models and Single-Layer Attention Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02654v1"&gt;A Pretrained Probabilistic Transformer for City-Scale Traffic Volume Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02668v1"&gt;FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02694v1"&gt;XicorAttention: Time Series Transformer Using Attention with Nonlinear Correlation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02712v1"&gt;Theoretical Performance Guarantees for Partial Domain Adaptation via Partial Optimal Transport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02724v1"&gt;WeightLoRA: Keep Only Necessary Adapters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02749v1"&gt;Knowledge Graph Completion by Intermediate Variables Regularization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02754v1"&gt;Safely Learning Controlled Stochastic Dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02757v1"&gt;Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02767v1"&gt;Accelerating Model-Based Reinforcement Learning using Non-Linear Trajectory Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02793v1"&gt;Doubly-Robust Estimation of Counterfactual Policy Mean Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02802v1"&gt;A Learned Cost Model-based Cross-engine Optimizer for SQL Workloads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02818v1"&gt;ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02825v1"&gt;Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02842v1"&gt;Sheaves Reloaded: A Directional Awakening&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02849v1"&gt;Learned Controllers for Agile Quadrotors in Pursuit-Evasion Games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02887v1"&gt;Overcoming Challenges of Partial Client Participation in Federated Learning : A Comprehensive Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02908v1"&gt;Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02933v1"&gt;From Theory to Practice with RAVEN-UCB: Addressing Non-Stationarity in Multi-Armed Bandits through Variance Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02964v1"&gt;FORLA:Federated Object-centric Representation Learning with Slot Attention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02980v1"&gt;Non-stationary Bandit Convex Optimization: A Comprehensive Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03049v1"&gt;Torsion in Persistent Homology and Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03062v1"&gt;Multi-Metric Adaptive Experimental Design under Fixed Budget with Validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03074v1"&gt;GL-LowPopArt: A Nearly Instance-Wise Minimax Estimator for Generalized Low-Rank Trace Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03075v1"&gt;Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of Randomness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03087v1"&gt;How Explanations Leak the Decision Logic: Stealing Graph Neural Networks via Explanation Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03096v1"&gt;FuseLIP: Multimodal Embeddings via Early Fusion of Discrete Tokens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03120v1"&gt;Validating remotely sensed biomass estimates with forest inventory data in the western US&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03131v1"&gt;Native-Resolution Image Synthesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02378v1"&gt;Exploring Explanations Improves the Robustness of In-Context Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02386v1"&gt;Asymptotically Optimal Linear Best Feasible Arm Identification with Fixed Budget&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02406v1"&gt;Random at First, Fast at Last: NTK-Guided Fourier Pre-Processing for Tabular DL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02438v1"&gt;A Review of Various Datasets for Machine Learning Algorithm-Based Intrusion Detection System: Advances and Challenges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02458v1"&gt;A Novel Deep Reinforcement Learning Method for Computation Offloading in Multi-User Mobile Edge Computing with Decentralization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02489v1"&gt;Grasp2Grasp: Vision-Based Dexterous Grasp Translation via Schrödinger Bridges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02515v1"&gt;FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02541v1"&gt;Rethinking Post-Unlearning Behavior of Large Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02542v1"&gt;HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02548v1"&gt;CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02553v1"&gt;Response-Level Rewards Are All You Need for Online Reinforcement Learning in LLMs: A Mathematical Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02554v1"&gt;HiLO: High-Level Object Fusion for Autonomous Driving using Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02612v1"&gt;Simple, Good, Fast: Self-Supervised World Models Free of Baggage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02623v1"&gt;SiamNAS: Siamese Surrogate Model for Dominance Relation Prediction in Multi-objective Neural Architecture Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02657v1"&gt;Maximizing the Promptness of Metaverse Systems using Edge Computing by Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02664v1"&gt;Computational Thresholds in Multi-Modal Learning via the Spiked Matrix-Tensor Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02677v1"&gt;Self-Disentanglement and Re-Composition for Cross-Domain Few-Shot Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02703v1"&gt;Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02710v1"&gt;Online Bayesian system identification in multivariate autoregressive models via message passing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02726v1"&gt;RACE-Align: Retrieval-Augmented and Chain-of-Thought Enhanced Preference Alignment for Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02841v1"&gt;Ensemble-MIX: Enhancing Sample Efficiency in Multi-Agent RL Using Ensemble Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02881v1"&gt;Simulation-Based Inference for Adaptive Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02890v1"&gt;Scaling Fine-Grained MoE Beyond 50B Parameters: Empirical Evaluation and Practical Insights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02896v1"&gt;FlySearch: Exploring how vision-language models explore&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02924v1"&gt;INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02950v1"&gt;Interaction Field Matching: Overcoming Limitations of Electrostatic Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02955v1"&gt;UniConFlow: A Unified Constrained Generalization Framework for Certified Motion Planning with Flow Matching Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02972v1"&gt;Computation- and Communication-Efficient Online FL for Resource-Constrained Aerial Vehicles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02992v1"&gt;Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03032v1"&gt;TestAgent: An Adaptive and Intelligent Expert for Human Assessment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03044v1"&gt;On the Benefits of Accelerated Optimization in Robust and Private Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03056v1"&gt;Corrigibility as a Singular Target: A Vision for Inherently Reliable Foundation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03065v1"&gt;Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03068v1"&gt;Causal Explainability of Machine Learning in Heart Failure Prediction from Electronic Health Records&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03088v1"&gt;Modelling the Effects of Hearing Loss on Neural Coding in the Auditory Midbrain with Variational Conditioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03133v1"&gt;PoLAR: Polar-Decomposed Low-Rank Adapter Representation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03149v1"&gt;Causal Estimation of Tokenisation Bias&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03150v1"&gt;IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02373v1"&gt;Olfactory Inertial Odometry: Methodology for Effective Robot Navigation by Scent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02911v1"&gt;Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03053v1"&gt;MAEBE: Multi-Agent Emergent Behavior Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03100v1"&gt;Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02372v1"&gt;AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM Output&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02431v1"&gt;From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02442v1"&gt;Should LLM Safety Be More Than Refusing Harmful Instructions?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02460v1"&gt;MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02461v1"&gt;XToM: Exploring the Multilingual Theory of Mind for Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02478v1"&gt;FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02480v1"&gt;ORPP: Self-Optimizing Role-playing Prompts to Enhance Language Model Capabilities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02483v1"&gt;Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02519v1"&gt;Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02532v1"&gt;ReasoningFlow: Semantic Structure of Complex Reasoning Traces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02536v1"&gt;Answer Convergence as a Signal for Early Stopping in Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02573v1"&gt;IndoSafety: Culturally Grounded Safety for LLMs in Indonesian Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02591v1"&gt;On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02592v1"&gt;Beyond the Surface: Measuring Self-Preference in LLM Judgments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02659v1"&gt;Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02689v1"&gt;MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02701v1"&gt;On Entity Identification in Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02740v1"&gt;Stereotypical gender actions can be extracted from Web text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02753v1"&gt;Multi-task Learning with Active Learning for Arabic Offensive Speech Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02827v1"&gt;TO-GATE: Clarifying Questions and Summarizing Responses with Trajectory Optimization for Eliciting Human Preference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02921v1"&gt;A Controllable Examination for Long-Context Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02961v1"&gt;FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02973v1"&gt;Expanding before Inferring: Enhancing Factuality in Large Language Models through Premature Layers Interpolation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02995v1"&gt;It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02998v1"&gt;A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03038v1"&gt;Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03090v1"&gt;Literary Evidence Retrieval via Long-Context Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03101v1"&gt;Beyond Text Compression: Evaluating Tokenizers Across Scales&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03122v1"&gt;AUTOCIRCUIT-RL: Reinforcement Learning-Driven LLM for Automated Circuit Topology Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02391v1"&gt;Consultant Decoding: Yet Another Synergistic Mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02404v1"&gt;GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02412v1"&gt;SingaKids: A Multilingual Multimodal Dialogic Tutor for Language Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02425v1"&gt;Gender Inequality in English Textbooks Around the World: an NLP Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02449v1"&gt;IP-Dialog: Evaluating Implicit Personalization in Dialogue Systems with Synthetic Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02479v1"&gt;BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02481v1"&gt;Do Language Models Think Consistently? A Study of Value Preferences Across Varying Response Lengths&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02510v1"&gt;M$^3$FinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02533v1"&gt;Natural Language Processing to Enhance Deliberation in Political Online Discussions: A Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02544v1"&gt;CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02561v1"&gt;Pruning General Large Language Models into Customized Expert Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02590v1"&gt;Synthetic Speech Source Tracing using Metric Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02596v1"&gt;EssayBench: Evaluating Large Language Models in Multi-Genre Chinese Essay Writing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02672v1"&gt;EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02708v1"&gt;Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02720v1"&gt;Benchmarking and Advancing Large Language Models for Local Life Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02730v1"&gt;An Exploratory Framework for Future SETI Applications: Detecting Generative Reactivity via Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02758v1"&gt;Exploiting the English Vocabulary Profile for L2 word-level vocabulary assessment with LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02803v1"&gt;SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02867v1"&gt;Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02872v1"&gt;Token and Span Classification for Entity Recognition in French Historical Encyclopedias&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02878v1"&gt;CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02894v1"&gt;A Multi-Dialectal Dataset for German Dialect ASR and Dialect-to-Standard Speech Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02899v1"&gt;IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02959v1"&gt;HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02979v1"&gt;Towards a Japanese Full-duplex Spoken Dialogue System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03009v1"&gt;Conditioning Large Language Models on Legal Systems? Detecting Punishable Hate Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03051v1"&gt;Facts Do Care About Your Language: Assessing Answer Quality of Multilingual LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03106v1"&gt;Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02414v1"&gt;StarVC: A Unified Auto-Regressive Framework for Joint Text and Speech Generation in Voice Conversion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02494v1"&gt;Minos: A Multimodal Evaluation Model for Bidirectional Generation Between Image and Text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02527v1"&gt;Multilingual Information Retrieval with a Monolingual Knowledge Base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02584v1"&gt;Prosodic Structure Beyond Lexical Content: A Study of Self-Supervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02589v1"&gt;Evaluating Named Entity Recognition Models for Russian Cultural News Texts: From BERT to LLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02627v1"&gt;Overcoming Data Scarcity in Multi-Dialectal Arabic ASR via Whisper Fine-Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02678v1"&gt;TL;DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02761v1"&gt;Rethinking Machine Unlearning in Image Generation Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.02987v1"&gt;Performance of leading large language models in May 2025 in Membership of the Royal College of General Practitioners-style examination questions: a cross-sectional analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03035v1"&gt;Leveraging Information Retrieval to Enhance Spoken Language Understanding Prompts in Few-Shot Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03135v1"&gt;OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.03147v1"&gt;UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-04</guid><pubDate>Wed, 04 Jun 2025 12:19:07 +0900</pubDate></item><item><title>MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query</title><link>http://arxiv.org/abs/2506.03144v1</link><description>セマンティック検索は現代のアプリケーションにとって不可欠ですが、現在の研究では十分に探求されていません。既存のデータセットは、単一言語、単一画像、または単一の検索条件に限定されており、画像がキャプションに置き換えられた場合でもパフォーマンスが維持されることから明らかなように、視覚情報の表現力を十分に活用できていないことがよくあります。しかし、実際の検索シナリオでは、複数の画像を含む、インターリーブされた多条件クエリが頻繁に発生します。そこで本論文では、インターリーブされた多条件セマンティック検索のための初の多言語データセットであるMERITを紹介します。MERITは、5言語で135,000個の製品を含む320,000件のクエリで構成され、7つの異なる製品カテゴリを網羅しています。MERITに関する広範な実験により、既存のモデルの限界が明らかになりました。既存のモデルは、クエリ内の特定の条件要素を無視し、グローバルなセマンティック情報のみに焦点を当てています。その結果、事前学習済みのMLLMを適応させる新しいファインチューニングフレームワークであるCoralを提案します。Coralは、埋め込み再構築を統合してきめ細かい条件要素を保持し、コントラスト学習によって包括的なグローバルセマンティクスを抽出します。実験の結果、CoralはMERITにおいて従来のアプローチよりも45.9%のパフォーマンス向上を達成し、8つの確立された検索ベンチマーク全体で強力な汎化能力が検証されました。総じて、新しいデータセット、既存のアプローチにおける重要な限界の特定、革新的なファインチューニングフレームワークという私たちの貢献は、インターリーブされた多条件セマンティック検索における将来の研究の基礎を確立します。

&lt;img src="https://arxiv.org/html/2506.03144v1/x1.png"/&gt;&lt;p&gt;ByteDance Inc. Zhejiang University Equal Contributions MERIT-2025.github.io, Hang Song, Linfeng Li, Qi Xu, Wei Chow, Xian Wang, Yuan Gao&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03144v1</guid><pubDate>Tue, 03 Jun 2025 17:59:14 +0000</pubDate></item><item><title>GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents</title><link>http://arxiv.org/abs/2506.03143v1</link><description>VLM（Vision Language Model）を活用したGUIエージェント構築における主要な課題の一つは、視覚的グラウンディング、つまり、視覚的なコンテンツとテキストによる計画に基づいて、アクション実行に適した画面領域を特定することです。既存の研究の多くは、これをテキストベースの座標生成タスクとして定式化しています。しかし、これらのアプローチは、空間的・意味的なアライメントの弱さ、曖昧な教師信号への対応の難しさ、画面座標の密な性質と、Vision Transformerのようなモデルによって抽出される視覚的特徴の粗いパッチレベルの粒度とのミスマッチなど、いくつかの制限があります。本論文では、座標フリーのGUIグラウンディングのためのVLMベースの手法であるGUI-Actorを提案します。GUI-Actorの中核は、専用の&lt;ACTOR&gt;トークンをすべての関連する視覚パッチトークンと整列させることを学習する、注意機構に基づくアクションヘッドを導入し、モデルが単一のフォワードパスで1つまたは複数のアクション領域を提案できるようにします。これに合わせて、アクション実行のために提案された候補の中から最も妥当なアクション領域を評価し選択するためのグラウンディング検証器を設計します。広範な実験により、GUI-Actorは複数のGUIアクショングラウンディングベンチマークにおいて、既存の最先端の手法を上回り、未知の画面解像度やレイアウトへの汎化性能が向上することが示されています。特に、GUI-Actor-7BはScreenSpot-ProにおいてUI-TARS-72B（38.1）を上回り、バックボーンとしてQwen2-VLで40.7、Qwen2.5-VLで44.6のスコアを達成しています。さらに、検証器を組み込むことで、VLMバックボーンを固定したまま、新しく導入されたアクションヘッド（7Bモデルの場合、約1億パラメータ）のみをファインチューニングするだけで、既存の最先端モデルに匹敵する性能を達成できることがわかりました。これは、GUI-Actorが基盤となるVLMの汎用的な強みを損なうことなく、効果的なグラウンディング能力を付与できることを示しています。

&lt;img src="https://arxiv.org/html/2506.03143v1/x1.png"/&gt;&lt;p&gt;Baolin Peng, Bo Qiao, Chaoyun Zhang, Dongmei Zhang, Huan Zhang, Huiqiang Jiang, Jianbing Zhang, Jianfeng Gao, Jianwei Yang, Jian Mu, Kanzhi Cheng, Lars Liden, Qianhui Wu, Qingwei Lin, Reuben Tan, Rui Yang, Si Qin, Tong Zhang&lt;/p&gt;&lt;p&gt;Microsoft
Nanjing University
University of Illinois Urbana-Champaign&lt;/p&gt;</description><guid isPermaLink="false">2506.03143v1</guid><pubDate>Tue, 03 Jun 2025 17:59:08 +0000</pubDate></item><item><title>Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs</title><link>http://arxiv.org/abs/2506.02529v1</link><description>Webアプリケーションは現代のソフトウェアエコシステムにとって不可欠ですが、その信頼性を確保することは、Webインターフェースの複雑さと動的な性質のために依然として困難です。大規模言語モデル（LLM）の最近の進歩は、複雑なタスクの自動化に有望性を示していますが、動的なナビゲーションフローや複雑なフォーム操作の処理には限界が残っています。本論文では、Webアプリケーションテストの2つの重要な側面、すなわちサイトナビゲーションとフォーム入力のためのテストケースを生成する自動化システムを提案します。サイトナビゲーションについては、画面遷移グラフとLLMを使用してナビゲーションフローをモデル化し、テストシナリオを生成します。フォーム入力については、状態グラフを使用して条件付きフォームを処理し、Seleniumスクリプトの生成を自動化します。主な貢献は、（1）サイトナビゲーションテストのためのグラフ構造とLLMの斬新な統合、（2）フォーム入力テストケースを自動化するための状態グラフベースのアプローチ、（3）フォーム操作テストを評価するための包括的なデータセットです。実験結果は、テストカバレッジと堅牢性の向上におけるシステムの有効性を示し、Webアプリケーションテストの現状を前進させるものです。

&lt;img src="https://arxiv.org/html/2506.02529v1/x1.png"/&gt;&lt;p&gt;Hiep Nguyen, Minh Le Nguyen, Minh Ngoc Nguyen, Nguyen-Khang Le, Quan Minh Bui, Shoshin Nomura, Son T. Luu, Trung Vo&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02529v1</guid><pubDate>Tue, 03 Jun 2025 07:08:21 +0000</pubDate></item><item><title>Entity-Augmented Neuroscience Knowledge Retrieval Using Ontology and Semantic Understanding Capability of LLM</title><link>http://arxiv.org/abs/2506.03145v1</link><description>神経科学の研究論文は、膨大な知識の宝庫である。この広範な文献から既存の情報を正確に検索し、新たな洞察を発見することは、この分野の発展に不可欠である。しかし、知識が複数のソースに分散している場合、現在の最先端の検索手法では、必要な情報を抽出するのが困難なことが多い。知識グラフ（KG）は、複数のソースからの知識を統合し、リンクすることができるが、神経科学におけるKG構築の既存の手法は、ラベル付きデータに依存し、専門知識を必要とする場合が多い。神経科学のような専門分野で大規模なラベル付きデータを取得することは、大きな課題となる。本研究では、大規模言語モデル（LLM）、神経科学オントロジー、テキスト埋め込みを利用して、ラベルなしの大規模な神経科学研究コーパスからKGを構築するための新しい手法を提案する。知識グラフ構築のためにLLMによって識別された神経科学テキストセグメントのセマンティックな関連性を分析する。また、KGから知識を抽出するためのエンティティ拡張情報検索アルゴリズムを導入する。提案手法を評価するためにいくつかの実験を行い、その結果、本手法はラベルなしの神経科学研究コーパスからの知識発見を大幅に向上させることが示された。エンティティ抽出において0.84のF1スコアを達成し、KGから得られた知識は54%以上の質問に対する回答を改善する。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03145v1</guid><pubDate>Tue, 03 Jun 2025 17:59:18 +0000</pubDate></item><item><title>Adaptive Graph Pruning for Multi-Agent Communication</title><link>http://arxiv.org/abs/2506.02951v1</link><description>大規模言語モデル（LLM）に基づくマルチエージェントシステムは、特に協調的なコミュニケーションによって強化された場合に、様々なタスクで目覚ましい性能を示しています。しかし、現在の手法は固定されたエージェント数と静的なコミュニケーション構造に依存していることが多く、タスクの複雑さの変化に適応する能力が制限されています。本論文では、エージェントの数（ハードプルーニング）とコミュニケーションのトポロジー（ソフトプルーニング）を共同で最適化する、新しいタスク適応型マルチエージェント協調フレームワークであるAdaptive Graph Pruning（AGP）を提案します。具体的には、我々の手法は2段階のトレーニング戦略を採用しています。まず、異なるエージェント数に対してソフトプルーニングネットワークを個別にトレーニングし、特定のタスクにおける最適なエージェント数固有の完全グラフと位置マスクを決定します。次に、最大完全グラフ内でハードプルーニングとソフトプルーニングを共同で最適化し、タスクごとにエージェントの数とそのコミュニケーションのトポロジーを動的に構成します。広範な実験により、我々のアプローチは以下のことが示されています。（1）高性能であり、6つのベンチマークで最先端の結果を達成し、複数の主流LLMアーキテクチャにわたって一貫して汎化され、性能が$2.58\%\sim 9.84\%$向上しています。（2）タスク適応型であり、特定のタスクに合わせて最適化されたコミュニケーションのトポロジーを動的に構築し、3つのタスクカテゴリ（一般的推論、数学的推論、コード生成）すべてにおいて非常に高い性能を発揮します。（3）トークンエコノミーであり、トレーニングステップ数とトークン消費量を同時に削減し、トークン消費量が90％以上減少します。（4）トレーニング効率が高く、他の手法と比較して非常に少ないトレーニングステップで高い性能を達成します。6つのベンチマークにおいて、約10ステップのトレーニング後には既存のベースラインを上回る性能を発揮します。

&lt;img src="https://arxiv.org/html/2506.02951v1/x1.png"/&gt;&lt;p&gt;Boyi Li, Der-Horng Lee, Gaoang Wang, Zhonghan Zhao&lt;/p&gt;&lt;p&gt;Zhejiang University - University of Illinois Urbana-Champaign Institute
Zhejiang University, College of Computer Science and Technology&lt;/p&gt;</description><guid isPermaLink="false">2506.02951v1</guid><pubDate>Tue, 03 Jun 2025 14:46:00 +0000</pubDate></item><item><title>Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework</title><link>http://arxiv.org/abs/2506.02454v1</link><description>視覚化は、概念や情報を効果的に伝える上で重要な役割を果たします。推論と検索拡張生成における最近の進歩により、大規模言語モデル（LLM）は深い調査を行い、包括的なレポートを作成できるようになりました。しかし、その進歩にもかかわらず、既存の深層調査フレームワークは主にテキストのみのコンテンツ生成に焦点を当てており、テキストと視覚化が混在したコンテンツの自動生成は十分に探求されていません。この新しいタスクは、有益な視覚化を設計し、それらをテキストレポートと効果的に統合するという重要な課題を提起します。これらの課題に対処するために、視覚化の形式的記述（FDV）を提案します。これは、LLMが多様で高品質な視覚化を学習し生成できるようにする、チャートの構造化されたテキスト表現です。この表現に基づいて、タスクを4つの段階に分解するエージェントフレームワークであるMultimodal DeepResearcherを導入します。（1）調査、（2）模範レポートのテキスト化、（3）計画、（4）マルチモーダルレポートの生成。生成されたマルチモーダルレポートの評価のために、MultimodalReportBenchを開発しました。これには、入力として提供される100の多様なトピックと、5つの専用メトリックが含まれています。モデルと評価方法にわたる広範な実験により、Multimodal DeepResearcherの有効性が実証されています。特に、同じClaude 3.7 Sonnetモデルを使用した場合、Multimodal DeepResearcherはベースラインメソッドに対して82％の全体的な勝率を達成しています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02454v1</guid><pubDate>Tue, 03 Jun 2025 05:18:19 +0000</pubDate></item><item><title>Comparative Analysis of AI Agent Architectures for Entity Relationship Classification</title><link>http://arxiv.org/abs/2506.02426v1</link><description>エンティティ関係分類は、情報抽出において依然として困難な課題であり、特にラベル付きデータが限られ、関係構造が複雑なシナリオではその傾向が顕著です。本研究では、大規模言語モデル（LLM）を用いて関係分類を実行するために設計された、3つの異なるAIエージェントアーキテクチャの比較分析を行います。検討するエージェントアーキテクチャには、（1）反省的な自己評価、（2）階層的なタスク分解、（3）新規なマルチエージェント動的サンプル生成メカニズムが含まれ、それぞれ異なる推論モードとプロンプト適応を活用しています。特に、当社の動的サンプル生成アプローチは、リアルタイムの協調的および敵対的なプロンプトを導入します。複数のドメインとモデルバックエンドにわたって、これらのアーキテクチャのパフォーマンスを体系的に比較します。実験の結果、マルチエージェント連携が一貫して標準的なフューショットプロンプトを上回り、ファインチューニングされたモデルのパフォーマンスに近づくことが示されました。これらの発見は、構造化された関係抽出のためのモジュール式で汎用的なLLMベースのシステムの設計に関する実践的なガイダンスを提供します。ソースコードとデータセットは、\href{https://github.com/maryambrj/ALIEN.git}{https://github.com/maryambrj/ALIEN.git}で入手できます。

&lt;img src="https://arxiv.org/html/2506.02426v1/extracted/6506729/images/reflection.png"/&gt;&lt;p&gt;Maryam Berijanian Michigan State University Kuldeep Singh Michigan State University Amin Sehati&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02426v1</guid><pubDate>Tue, 03 Jun 2025 04:19:47 +0000</pubDate></item><item><title>Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning</title><link>http://arxiv.org/abs/2506.03136v1</link><description>我々は、教師データとなる正解コードを一切使用せず、コーディング能力とユニットテスト生成能力を、それらの相互作用の結果に基づいて共進化させる、専用の報酬設計を備えた新しい強化学習フレームワークCUREを提案します。このアプローチにより、柔軟でスケーラブルなトレーニングが可能になり、ユニットテスターはコーダーのミスから直接学習できます。我々が導出したReasonFlux-Coder-7Bおよび14Bモデルは、Qwen2.5-Instructモデルを最適化した後、コード生成精度を5.3%、Best-of-N精度を9.0%向上させ、同様のサイズのQwen-Coder、DeepSeek-Coder、Seed-Coderを上回っています。これらのモデルは、テスト時のスケーリングやエージェントコーディングなどのダウンストリームタスクに自然に拡張され、ベースモデルと比較して8.1%の改善を達成しています。長文CoTモデルに関しては、ReasonFlux-Coder-4Bは一貫してQwen3-4Bを上回り、ユニットテスト生成において64.8%の推論効率を達成しています。特筆すべきは、我々のモデルがベースモデルに対する強化学習のための効果的な報酬モデルとしても機能することを発見したことです。プロジェクト: https://github.com/Gen-Verse/CURE

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03136v1</guid><pubDate>Tue, 03 Jun 2025 17:58:42 +0000</pubDate></item><item><title>Coding Agents with Multimodal Browsing are Generalist Problem Solvers</title><link>http://arxiv.org/abs/2506.03011v1</link><description>現代の人間の労働は専門化によって特徴づけられる。私たちは何年も訓練を受け、様々なタスクで優れたパフォーマンスを発揮できる特定のツールを開発する。同様に、AIエージェントもソフトウェアエンジニアリング、ウェブナビゲーション、ワークフロー自動化などの分野に特化してきた。しかし、その結果、あることには優れているが、意図された範囲を超えて汎用化できないエージェントが生まれる。その理由の一つは、エージェント開発者が高度に専門化されたツールセットを提供したり、特定のユースケースやベンチマークに最適化されたアーキテクチャ上の決定を下したりするためである。本研究では、「多様なタスクで高いパフォーマンスを達成するために使用できる、最小限の汎用ツールセットとは何か？」という問いを提起する。私たちの答えは、OpenHands-Versaという汎用エージェントであり、コード編集と実行、ウェブ検索、そしてマルチモーダルなウェブブラウジングとファイルアクセスという、控えめな数の汎用ツールで構築されている。重要なことに、OpenHands-Versaは、SWE-Bench Multimodal、GAIA、The Agent Companyという3つの多様で困難なベンチマークにおいて、主要な専門エージェントを上回る、または匹敵するパフォーマンスを示し、以前に発表された最高の結果を成功率でそれぞれ9.1、1.3、9.1ポイント絶対的に上回っている。さらに、既存の最先端のマルチエージェントシステムが、そのターゲットドメインを超えて汎用化できないことを示す。これらの結果は、多様なタスクを解決するための汎用エージェントの開発の実現可能性を示し、OpenHands-Versaを今後の研究のための強力なベースラインとして確立する。

&lt;img src="https://arxiv.org/html/2506.03011v1/extracted/6507313/Figures/tool_usage_comparison_final.png"/&gt;&lt;p&gt;Carnegie Mellon University Independent All Hands AI&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03011v1</guid><pubDate>Tue, 03 Jun 2025 15:50:55 +0000</pubDate></item><item><title>Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints</title><link>http://arxiv.org/abs/2506.02683v1</link><description>大規模言語モデル（LLM）の著しい進歩にもかかわらず、計画タスクは依然としてLLMベースのエージェントにとって課題となっています。既存の計画手法は、厳しい制約と連鎖的なエラーという2つの主要な制限に直面しています。これらの制限に対処するため、私たちは新しい並列計画パラダイムを提案します。これは、タスクを分解し、サブタスクの計画を並行して行い、サブプランを最終的な計画に統合する（DPPM）というものです。具体的には、DPPMは制約に基づいて複雑なタスクをサブタスクに分解し、各サブタスクのサブプランを並行して生成し、それらをグローバルな計画に統合します。さらに、私たちのアプローチは検証および改善モジュールを組み込んでおり、エラー修正と競合解決を可能にします。実験結果は、DPPMが旅行計画タスクにおいて既存の手法を大幅に上回ることを示しています。

&lt;img src="https://arxiv.org/html/2506.02683v1/extracted/6507199/Figures/decompose.png"/&gt;&lt;p&gt;Beihang University zqzeng@scut.edu.cn, South China University of Technology&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02683v1</guid><pubDate>Tue, 03 Jun 2025 09:33:13 +0000</pubDate></item><item><title>KARE-RAG: Knowledge-Aware Refinement and Enhancement for RAG</title><link>http://arxiv.org/abs/2506.02503v1</link><description>検索拡張生成 (RAG) は、大規模言語モデル (LLM) がより広範な知識源にアクセスできるようにしますが、高度な検索手法を用いても、検索されたドキュメントのノイズが原因で事実の不整合が依然として残ります。本稿では、ロバストなパフォーマンスのためには、ノイズの多いコンテンツを処理する生成モデルの能力を高めることが同様に重要であることを示します。本論文では、KARE-RAG (Knowledge-Aware Refinement and Enhancement for RAG) を提案します。これは、(1) トレーニング中のエラー検出を容易にする構造化された知識表現、(2) 重要なエラーの修正を優先する洗練されたトレーニング目標である Dense Direct Preference Optimization (DDPO)、(3) 事実の不正確さを修正しながらセマンティックな一貫性を維持するコントラストデータ生成パイプラインという、3つの主要なイノベーションを通じて知識の利用を改善します。実験の結果、我々の手法はモデルスケール全体で標準的な RAG パイプラインを大幅に強化し、一般的な能力を損なうことなく、ドメイン内およびドメイン外のタスクパフォーマンスを向上させることが示されました。特に、これらの改善はわずかなトレーニングデータで達成されており、ターゲットを絞った学習戦略を通じてデータ効率の高い最適化が可能であることを示唆しています。我々の発見は、RAG の改善のための新しい方向性を示しています。モデルが検索されたコンテンツを処理する方法を改善することで、多様な推論パラダイムにわたってパフォーマンスを向上させることができます。すべてのデータとコードは Github で公開される予定です。

&lt;img src="https://arxiv.org/html/2506.02503v1/extracted/6506396/figures/KARE-RAG.drawio.png"/&gt;&lt;p&gt;Beijing, China, Chinese Academy of Sciences, Department of Computer Science, Dept. of Computer Science, Institute for AI, Institute of Information Engineering, Northeastern University, School of Biomedical Engineering, School of Informatics, Shenyang, Technology, Tsinghua, Tsinghua University, Xiamen University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02503v1</guid><pubDate>Tue, 03 Jun 2025 06:31:17 +0000</pubDate></item><item><title>Sample complexity of Schrödinger potential estimation</title><link>http://arxiv.org/abs/2506.03043v1</link><description>本稿では、シュレーディンガーポテンシャル推定の問題を取り扱う。これは、シュレーディンガーブリッジやSDEに対する確率的最適制御に基づく現代的な生成モデリング手法において重要な役割を果たす。単純な事前拡散過程が与えられたとき、これらの手法は、与えられた二つの分布$\rho_0$と$\rho_T^*$の間の、最小限の労力で済む経路を探す。この場合の最適なドリフトは、シュレーディンガーポテンシャルを通して表現できる。本稿では、時刻Tにおける周辺分布への適合を目的とした、許容可能な対数ポテンシャルのクラスにおける経験的Kullback-Leibler（KL）リスク最小化器の汎化能力を研究する。目標分布$\rho_T^*$と事前過程に関して妥当な仮定の下で、$\rho_T^*$と推定された対数ポテンシャルに対応する終端密度との間のKLダイバージェンスに対する非漸近的な高確率上限を導出する。特に、$\rho_0$と$\rho_T^*$の両方が非有界なサポートを持つ場合でも、サンプルサイズnが無限大に近づくにつれて、過剰なKLリスクが$O(\log^2 n / n)$の速さで減少することを示す。

&lt;img src=""/&gt;&lt;p&gt;Iurii Pustovalov Alexey Naumov, Nikita Puchkin Denis Suchkov, Yuri Sapronov Denis Belomestny&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03043v1</guid><pubDate>Tue, 03 Jun 2025 16:26:03 +0000</pubDate></item><item><title>On the Need to Align Intent and Implementation in Uncertainty Quantification for Machine Learning</title><link>http://arxiv.org/abs/2506.03037v1</link><description>機械学習（ML）モデルの不確実性を定量化することは、現代のデータ分析における基本的な課題です。この課題は、少なくともこの分野の2つの重要な側面によって複雑化しています。（a）不確実性と推定に関する分野を超えた一貫性のない用語、（b）多様な問題の文脈で信頼できる不確実性を確立するためのさまざまな技術的要件です。本ポジションペーパーでは、これらの矛盾を特定し、異なる文脈がどのように異なる認識論的要求を課すかを明確にすることで、これらの課題の深さを明らかにすることを目指します。推定対象（例：予測、推論、シミュレーションベースの推論）、不確実性構造（例：頻度主義、ベイズ、フィデューシャル）、およびそれらの間のマッピングに使用されるアプローチの現在の状況を検証します。文献に基づいて、問題のあるマッピングの例を強調し、説明します。これらの問題に対処するために、不確実性定量化（UQ）アプローチの\textit{意図}と\textit{実装}の間の整合性を促進する標準を提唱します。MLモデルにおける信頼できるUQに必要な（十分ではないにしても）信頼性のいくつかの軸について議論し、これらの軸が不確実性を考慮したMLシステムの設計と評価にどのように役立つかを示します。私たちの実践的な推奨事項は科学的MLに焦点を当て、特にシミュレーションベースの推論（SBI）の文脈で、説明的な事例と使用シナリオを提供します。

&lt;img src=""/&gt;&lt;p&gt;Shubhendu Trivedi &amp;Brian D. Nord&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03037v1</guid><pubDate>Tue, 03 Jun 2025 16:19:59 +0000</pubDate></item><item><title>ThinkTank: A Framework for Generalizing Domain-Specific AI Agent Systems into Universal Collaborative Intelligence Platforms</title><link>http://arxiv.org/abs/2506.02931v1</link><description>本稿では、専門的なAIエージェントシステムを、多様な分野にわたる複雑な問題解決を支援できる汎用的な協調型インテリジェンスプラットフォームへと変革するために設計された、包括的でスケーラブルなフレームワークであるThinkTankを紹介します。ThinkTankは、実績のある科学的コラボレーション手法を適用することで、エージェントの役割、会議の構造、知識統合メカニズムを体系的に一般化します。役割の抽象化、反復的なコラボレーションのための会議タイプの一般化、および高度な知識ストレージを備えた検索拡張生成の統合を通じて、このフレームワークは専門知識の創出と堅牢な知識共有を促進します。ThinkTankにより、組織はコラボレーティブAIを知識集約型タスクに活用できるようになり、OllamaとLlama3.1などのモデルを使用したローカル展開を通じて、データのプライバシーとセキュリティを確保します。ThinkTankフレームワークは、クラウドベースの代替手段と比較して、費用対効果、データセキュリティ、スケーラビリティ、および競争上の地位において大きな優位性をもたらすように設計されており、AI主導の協調的な問題解決のための普遍的なプラットフォームとしての地位を確立します。ThinkTankのコードは、https://github.com/taugroup/ThinkTank で入手できます。

&lt;img src="https://arxiv.org/html/2506.02931v1/extracted/6505990/arch.png"/&gt;&lt;p&gt;Praneet Sai Madhu Surabhi1               Dheeraj Reddy Mudireddy2 Jian Tao&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02931v1</guid><pubDate>Tue, 03 Jun 2025 14:32:48 +0000</pubDate></item><item><title>StreamBP: Memory-Efficient Exact Backpropagation for Long Sequence Training of LLMs</title><link>http://arxiv.org/abs/2506.03077v1</link><description>長鎖推論のような複雑なタスクにおけるモデルの能力を向上させるためには、長いシーケンスデータで言語モデルを訓練することが不可欠な要件です。しかし、シーケンス長が長くなるにつれて、勾配チェックポイント法を適用しても、逆伝播（BP）プロセス中に活性化値を保存するためのメモリコストが非常に大きくなります。この課題に対処するため、我々はStreamBPと呼ばれるメモリ効率の良い正確なBP法を提案します。これは、層ごとにシーケンス次元に沿って連鎖律を線形分解し、活性化値とロジットのメモリコストを大幅に削減します。提案手法は、SFT、GRPO、DPOなどの一般的な目的に適用可能です。実装の観点から見ると、StreamBPは言語モデルの因果構造を活用することで、計算FLOPsを削減し、BP速度を向上させます。勾配チェックポイント法と比較して、StreamBPはBPの最大シーケンス長を2.8〜5.5倍に拡大し、BP時間は同程度かそれ以下です。StreamBPのシーケンス長スケーリング能力は、トレーニングを加速するためにバッチサイズのスケーリングに直接転用できることに注意してください。さらに、通信効率の良い分散StreamBPを開発し、マルチGPUトレーニングを効果的にサポートし、その適用範囲を広げます。我々のコードは、あらゆるTransformerモデルのトレーニングパイプラインに簡単に統合でき、https://github.com/Ledzy/StreamBP で入手可能です。

&lt;img src="https://arxiv.org/html/2506.03077v1/x1.png"/&gt;&lt;p&gt;Qijun Luo Mengqi Li Lei Zhao Xiao Li The Chinese University of Hong Kong, Shenzhen Shanghai Jiao Tong University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03077v1</guid><pubDate>Tue, 03 Jun 2025 16:54:15 +0000</pubDate></item><item><title>Provable Reinforcement Learning from Human Feedback with an Unknown Link Function</title><link>http://arxiv.org/abs/2506.03066v1</link><description>リンク関数は、RL問題の価値関数から人間の好みがどのように生成されるかを特徴づけるものであり、RLHFアルゴリズムを設計する上で重要な要素です。DPOやPPOなど、実証研究における最先端のものを含むほぼすべてのRLHFアルゴリズムは、リンク関数がエージェントに既知である（例えば、ブラッドリー・テリーモデルに従ったロジスティック関数）と仮定していますが、人間の好みの複雑さを考えると、これは現実的とは言えません。リンク関数の誤った特定を避けるため、本論文では未知のリンク関数を持つ一般的なRLHF問題を研究します。我々は、新しいゼロ次ポリシー最適化法に基づいたZSPOと呼ばれる新しいポリシー最適化アルゴリズムを提案します。その鍵は、人間の好みを利用して、真のポリシー勾配方向と正の相関を持つパラメータ更新方向を構築することです。ZSPOは、価値関数の差から勾配を推定する代わりに、価値関数の差の符号を推定することでこれを実現するため、リンク関数を知る必要はありません。緩やかな条件下で、ZSPOはポリシーの反復回数と反復ごとの軌跡数に依存する多項式収束率で定常ポリシーに収束します。数値結果は、リンク関数のミスマッチ下でのZSPOの優位性も示しています。

&lt;img src="https://arxiv.org/html/2506.03066v1/x1.png"/&gt;&lt;p&gt;Ann Arbor, Lei Ying University of Michigan, Qining Zhang University of Michigan&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03066v1</guid><pubDate>Tue, 03 Jun 2025 16:42:39 +0000</pubDate></item><item><title>How do Pre-Trained Models Support Software Engineering? An Empirical Study in Hugging Face</title><link>http://arxiv.org/abs/2506.03013v1</link><description>オープンソースの事前学習済みモデル（PTM）は、様々な機械学習（ML）タスクに豊富なリソースを提供するが、これらのリソースはソフトウェアエンジニアリング（SE）のニーズに合わせた分類が不足している。このギャップを埋めるため、我々は147のSEタスクを網羅する分類体系を導き出し、一般的なオープンソースMLリポジトリであるHugging Face（HF）のPTMにSE指向の分類を適用する。我々のリポジトリマイニング研究は、HF APIからPTMのデータベースを体系的に収集することから始まり、モデルカードの説明とメタデータ、および関連するarXiv論文の要約を考慮した。複数のフィルタリングステップ（外れ値の検出、ほぼ同一のPTMの特定、Gemini 2.0 Flashの使用）を通じてSEとの関連性を確認し、これは3人の人間アノテーターによる5つのパイロット研究で検証された。このアプローチにより、2,205のSE PTMが発見された。我々は、コード生成がPTMの中で最も一般的なSEタスクであり、主にソフトウェアの実装に焦点を当てている一方で、要求工学やソフトウェア設計活動への注目は限られていることを発見した。MLタスクの観点からは、テキスト生成がSE PTMの中で支配的である。特に、SE PTMの数は2023年第2四半期以降、著しく増加している。我々の分類は、適切なPTMのサンプリングや選択など、将来の自動化されたSEシナリオのための強固な基盤を提供する。

&lt;img src="https://arxiv.org/html/2506.03013v1/x1.png"/&gt;&lt;p&gt;Alexandra González, David Lo, Silverio Martínez-Fernández, Xavier Franch&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03013v1</guid><pubDate>Tue, 03 Jun 2025 15:51:17 +0000</pubDate></item><item><title>Quantitative LLM Judges</title><link>http://arxiv.org/abs/2506.02945v1</link><description>LLM-as-a-judge（LLMを審査員とする）は、大規模言語モデル（LLM）が別のLLMの出力を自動的に評価するフレームワークです。本稿では、既存のLLM審査員の評価スコアを、回帰モデルを用いて特定のドメインにおける人間のスコアに整合させる、定量的なLLM審査員を提案します。これらのモデルは、審査員のテキストによる評価とスコアを用いて、元の審査員のスコアを改善するように訓練されます。絶対評価および相対評価の異なるタイプに対して、4つの定量的な審査員を提示し、本フレームワークの汎用性と多様性を示します。本フレームワークは、教師ありファインチューニングよりも計算効率が高く、人間のフィードバックが限られている場合に統計的に効率的である可能性があり、これは本研究のほとんどの応用において予想されます。これらの主張を、2つのベース審査員を用いて4つのデータセットで実証的に検証します。実験結果から、定量的な審査員は、事後モデリングを通じて既存の審査員の予測能力を効果的に向上させることができることが示されました。

&lt;img src="https://arxiv.org/html/2506.02945v1/x1.png"/&gt;&lt;p&gt;Aishwarya Sahoo, Branislav Kveton Adobe Research, Franck Dernoncourt, Jeevana Kruthi Karnuthala, Jennifer Healey, Nedim Lipka, Ryan Rossi Adobe Research
Uttaran Bhattacharya, Sankaran Vaidyanathan University of Massachusetts Amherst
Alexa Siu, Tushar Parmanand Budhwani University of Massachusetts Amherst
Pranchal Agarwal&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02945v1</guid><pubDate>Tue, 03 Jun 2025 14:44:23 +0000</pubDate></item><item><title>Sample, Predict, then Proceed: Self-Verification Sampling for Tool Use of LLMs</title><link>http://arxiv.org/abs/2506.02918v1</link><description>状態を持つ環境におけるツール利用は、大規模言語モデル（LLM）にとって特有の課題を提示します。既存のテスト時の計算戦略は、環境内での反復試行に依存しており、現実的ではありません。そこで、我々はダイナミクスモデリング（DyMo）を提案します。これは、ポストトレーニング中にLLMに関数呼び出しに加えて状態予測能力を付与する手法です。これにより、LLMは内部環境モデルを通じて、自身のアクションの将来の状態を予測できます。Berkeley Function Calling Leaderboard V2において、DyMoは成功率を向上させ、幻覚を大幅に削減します。さらに、内部環境モデルを自己検証サンプリング（SVS）に統合し、試行回数kに対するpass^kを大幅に改善し、モデルが信頼性の低い出力を拒否できるようにすることを示します。DyMoとSVSを組み合わせることで、LLMのツール利用における有効性と信頼性が大幅に向上します。我々は、この研究が、オラクル環境に繰り返し問い合わせることなく、LLM推論のためのスケーラブルな計画RL手法への道筋を示すと信じています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02918v1</guid><pubDate>Tue, 03 Jun 2025 14:20:59 +0000</pubDate></item><item><title>BNPO: Beta Normalization Policy Optimization</title><link>http://arxiv.org/abs/2506.02864v1</link><description>DeepSeek-R1やKimi-k1.5を含む最近の研究は、ルールベースの二値報酬関数を用いた強化学習が、大規模言語モデルの推論能力を大幅に向上させることを示しています。これらのモデルは主に、ベースライン付きREINFORCEやグループ相対ポリシー最適化（GRPO）などのREINFORCEベースのポリシー最適化技術を利用しています。しかし、重要な制限が残っています。現在のポリシー最適化手法は、報酬の正規化を無視するか、静的な正規化戦略を採用しており、トレーニング中のポリシー更新の動的な性質に適応できません。これにより、不安定な勾配推定が生じ、トレーニングの安定性が損なわれる可能性があります。この問題に対処するために、動的に更新されるパラメータを持つベータ分布を使用して報酬を適応的に正規化する、新しいポリシー最適化手法であるベータ正規化ポリシー最適化（BNPO）を提案します。BNPOは、正規化を変化するポリシー分布に合わせることで、より正確で分散の少ない勾配推定を可能にし、安定したトレーニングダイナミクスを促進します。BNPOの分散低減特性を示す理論的分析を提供し、二値報酬設定下でREINFORCEとGRPOの両方を一般化することを示します。さらに、BNPOの適用範囲をより複雑な報酬システムに拡張するために、アドバンテージ分解メカニズムを導入します。実験結果は、BNPOが推論タスクにおいてポリシー最適化手法の中で最先端の性能を達成することを確認しています。コードはhttps://github.com/changyi7231/BNPOで入手できます。

&lt;img src=""/&gt;&lt;p&gt;Changyi Xiao, Fudan University Meituan Group, Mengdi Zhang, Yixin Cao School of Computer Science&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02864v1</guid><pubDate>Tue, 03 Jun 2025 13:28:57 +0000</pubDate></item><item><title>Heterogeneous Group-Based Reinforcement Learning for LLM-based Multi-Agent Systems</title><link>http://arxiv.org/abs/2506.02718v1</link><description>大規模言語モデル（LLM）は、多様な自然言語処理タスクにおいて目覚ましい成功を収めていますが、現実世界のアプリケーションへの展開は、固定された知識の限界と、単一の推論で制御可能で正確な出力を生成することの難しさによって妨げられています。特化したLLMエージェントから構築されたマルチエージェントシステム（MAS）は、動的な連携と反復的な推論を可能にする有望な解決策を提供します。しかし、これらのシステムの最適化は依然として課題であり、プロンプトエンジニアリングや教師ありファインチューニングなどの従来の方法は、高いエンジニアリングコストと限られた適応性を伴います。強化学習（RL）、特にマルチエージェント強化学習（MARL）は、システムレベルのフィードバックに基づいてエージェントポリシーを洗練することにより、スケーラブルなフレームワークを提供します。それにもかかわらず、マルチエージェント近接方策最適化（MAPPO）などの既存のMARLアルゴリズムは、Criticネットワークに依存しており、トレーニングの不安定性を引き起こし、計算負荷を増大させる可能性があります。これらの制限に対処し、典型的なマルチエージェント検索システム（MASS）を対象とするために、我々は、ロールアウトの異種グループ間の相対的な報酬の優位性を推定することにより、ポリシーの更新をガイドする、新しいCriticフリーのアルゴリズムであるマルチエージェント異種グループ方策最適化（MHGPO）を提案します。MHGPOは、Criticネットワークの必要性を排除し、安定性を高め、計算コストを削減します。さらに、効率と有効性の間でトレードオフを行う3つのグループロールアウトサンプリング戦略を導入します。マルチエージェントLLMベースの検索システムでの実験は、MHGPOがウォームアップを必要とせずに、タスクのパフォーマンスと計算効率の両方でMAPPOを一貫して上回ることを示しており、複雑なLLMベースのMASの安定したスケーラブルな最適化の可能性を強調しています。

&lt;img src="https://arxiv.org/html/2506.02718v1/x1.png"/&gt;&lt;p&gt;Guanzhong Chen Shaoxiong Yang Chao Li Wei Liu Jian Luan Zenglin Xu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02718v1</guid><pubDate>Tue, 03 Jun 2025 10:17:19 +0000</pubDate></item><item><title>Symmetry-Aware GFlowNets</title><link>http://arxiv.org/abs/2506.02685v1</link><description>生成フローネットワーク（GFlowNets）は、報酬に比例してグラフをサンプリングするための強力なフレームワークを提供します。しかし、既存のアプローチは、状態遷移確率の計算における不正確さによる系統的なバイアスに悩まされています。これらのバイアスは、グラフに内在する対称性に根ざしており、原子ベースとフラグメントベースの両方の生成スキームに影響を与えます。この課題に対処するため、対称性認識GFlowNets（SA-GFN）を導入します。これは、報酬のスケーリングを通じて、対称性補正を学習プロセスに組み込む手法です。SA-GFNは、バイアス補正を報酬構造に直接統合することで、明示的な状態遷移計算の必要性を排除します。実験結果は、SA-GFNが偏りのないサンプリングを可能にし、多様性を高め、ターゲット分布に非常に近い高報酬グラフを一貫して生成することを示しています。

&lt;img src="https://arxiv.org/html/2506.02685v1/x1.png"/&gt;&lt;p&gt;Hohyun Kim, Min-hwan Oh, Seunggeun Lee&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.02685v1</guid><pubDate>Tue, 03 Jun 2025 09:38:15 +0000</pubDate></item><item><title>Protein Inverse Folding From Structure Feedback</title><link>http://arxiv.org/abs/2506.03028v1</link><description>逆フォールディング問題は、所望の三次元構造に折り畳まれるアミノ酸配列を設計することを目的としており、様々なバイオテクノロジー応用において極めて重要である。本研究では、タンパク質フォールディングモデルからのフィードバックを用いて、逆フォールディングモデルをファインチューニングするために、Direct Preference Optimization（DPO）を活用した新しいアプローチを紹介する。ターゲットとなるタンパク質構造が与えられたとき、まず逆フォールディングモデルから候補配列をサンプリングし、次に各配列の三次元構造をフォールディングモデルで予測し、ペアワイズな構造的選好ラベルを生成する。これらのラベルを用いて、DPOの目的関数下で逆フォールディングモデルをファインチューニングする。CATH 4.2テストセットでの結果は、DPOファインチューニングがベースラインモデルの配列回復率を向上させるだけでなく、平均TMスコアを0.77から0.81に大幅に向上させ、構造的類似性が向上していることを示している。さらに、DPOベースの手法を困難なタンパク質構造に反復適用することで、ベースラインモデルと比較して平均TMスコアが79.5％増加するなど、大幅な改善が得られた。本研究は、選好最適化を効果的に利用することで、構造フィードバックからのタンパク質配列設計能力を向上させるための有望な方向性を示すものである。

&lt;img src="https://arxiv.org/html/2506.03028v1/x1.png"/&gt;&lt;p&gt;CAS Zhejiang Lab MBZUAI jiezhongqiu@outlook.com, Junde XU Zijun Gao Xinyi Zhou Jie Hu Xingyi Cheng CUHK Hangzhou Institute of Medicine&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.03028v1</guid><pubDate>Tue, 03 Jun 2025 16:02:12 +0000</pubDate></item></channel></rss>