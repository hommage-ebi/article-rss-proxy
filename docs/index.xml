<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Tue, 10 Jun 2025 03:23:11 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-10</title><link>https://arxiv.org/2025-06-10</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07353v1"&gt;High heating rate effects in sintering: A phase-field study of La-doped alumina&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07545v1"&gt;Si Intercalation Beneath Epitaxial Graphene: Modulating Mott States at the SiC(0001) Interface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07608v1"&gt;Orbital Hall Effect Enables Field-Free Magnetization Reversal in Ferrimagnets without Additional Conversion Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07650v1"&gt;Interacting Dirac magnons in honeycomb ferromagnets CrBr$_3$&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07908v1"&gt;Common origin of the photoplastic and electroplastic effect in ZnS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07518v1"&gt;Structure-Informed Learning of Flat Band 2D Materials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07573v1"&gt;Roles of Non-switchable Domains and Internal Bias in Electrocaloric and Pyroelectric effects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07682v1"&gt;The role of spin-orbit coupling and state-crossing topography in the non-radiative decay of Ir(III) complexes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07717v1"&gt;Unconventional S-orbital state of Tb and cooperative Ru(4d)-Tb(4f) spin-ordering in strongly correlated 4d-4f system, Ba3TbRu2O9&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07762v1"&gt;Excitonic Properties and Optical Signatures in Quasi-1D Metal-Halide Perovskites with Tunable Octahedral Connectivity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07782v1"&gt;Enhanced Strain Transfer and Optoelectronic Performance in MoS2 Devices via Formvar Encapsulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07839v1"&gt;Predicting aqueous and electrochemical stability of 2D materials from extended Pourbaix analyses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07733v1"&gt;Schrödinger equation with Pauli-Fierz Hamiltonian and double well potential as model of vibrationally enhanced tunneling for proton transfer in hydrogen bond&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07648v1"&gt;Continuous-time multifarious systems -- Part I: equilibrium multifarious self-assembly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07649v1"&gt;Continuous-time multifarious systems -- Part II: non-reciprocal multifarious self-organization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07792v1"&gt;A unified fluid model for nonthermal plasmas and reacting flows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07843v1"&gt;Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07849v1"&gt;Dense Associative Memory in a Nonlinear Optical Hopfield Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07359v1"&gt;2N-storage Runge-Kutta methods: Order conditions, general properties and some analytic solutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07919v1"&gt;Uncovering the Functional Roles of Nonlinearity in Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07411v1"&gt;An Intelligent Fault Self-Healing Mechanism for Cloud AI Systems via Integration of Large Language Models and Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07418v1"&gt;Evaluating Visual Mathematics in Multimodal LLMs: A Multilingual Benchmark Based on the Kangaroo Tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07443v1"&gt;LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07446v1"&gt;Fact in Fragments: Deconstructing Complex Claims via LLM-based Atomic Fact Extraction and Verification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07450v1"&gt;Efficient Generation of Diverse Cooperative Agents with World Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07528v1"&gt;Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07731v1"&gt;NeurIPS 2025 E2LM Competition : Early Training Evaluation of Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07736v1"&gt;RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07807v1"&gt;A Proposal to Extend the Common Model of Cognition with Metacognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07824v1"&gt;Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07837v1"&gt;HAIBU-ReMUD: Reasoning Multimodal Ultrasound Dataset and Model Bridging to General Specific Domains&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07368v1"&gt;C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07373v1"&gt;HyColor: An Efficient Heuristic Algorithm for Graph Coloring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07388v1"&gt;Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07390v1"&gt;Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07399v1"&gt;MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07406v1"&gt;InverseScope: Scalable Activation Inversion for Interpreting Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07407v1"&gt;Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07408v1"&gt;Fractional-order Jacobian Matrix Differentiation and Its Application in Artificial Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07416v1"&gt;LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07417v1"&gt;Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07424v1"&gt;Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07428v1"&gt;HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07431v1"&gt;FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07434v1"&gt;Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07448v1"&gt;Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07454v1"&gt;Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07463v1"&gt;CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07464v1"&gt;DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07471v1"&gt;Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07505v1"&gt;Reinforcement Learning via Implicit Imitation Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07527v1"&gt;Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07539v1"&gt;Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07542v1"&gt;APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07548v1"&gt;Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07555v1"&gt;Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07557v1"&gt;SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07563v1"&gt;MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07564v1"&gt;SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07570v1"&gt;LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07578v1"&gt;Denoising the Future: Top-p Distributions for Moving Through Time&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07583v1"&gt;Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07587v1"&gt;PrunePEFT: Iterative Hybrid Pruning for Parameter-Efficient Fine-tuning of LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07600v1"&gt;SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07603v1"&gt;SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07652v1"&gt;FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07664v1"&gt;Synthesis by Design: Controlled Data Generation via Structural Guidance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07671v1"&gt;GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07698v1"&gt;NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07713v1"&gt;Consistent Video Editing as Flow-Driven Image-to-Video Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07725v1"&gt;ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07739v1"&gt;ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07754v1"&gt;Comparing Credit Risk Estimates in the Gen-AI Era&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07759v1"&gt;REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07813v1"&gt;Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07822v1"&gt;Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07829v1"&gt;Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07841v1"&gt;Diffusion models under low-noise regime&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07848v1"&gt;PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07853v1"&gt;A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07864v1"&gt;Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07896v1"&gt;Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07900v1"&gt;MiniCPM4: Ultra-Efficient LLMs on End Devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07940v1"&gt;Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07943v1"&gt;Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07961v1"&gt;BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07964v1"&gt;SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07976v1"&gt;Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07982v1"&gt;$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08003v1"&gt;Audio-Sync Video Generation with Multi-Stream Temporal Control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08004v1"&gt;Dynamic View Synthesis as an Inverse Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08010v1"&gt;Vision Transformers Don't Need Trained Registers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08012v1"&gt;GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07355v1"&gt;SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07358v1"&gt;Lightweight Joint Audio-Visual Deepfake Detection via Single-Stream Multi-Modal Learning Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07364v1"&gt;Multiple Object Stitching for Unsupervised Representation Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07376v1"&gt;Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07392v1"&gt;From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07400v1"&gt;MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07435v1"&gt;Fast Geometric Embedding for Node Influence Maximization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07436v1"&gt;Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07449v1"&gt;LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07452v1"&gt;When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07458v1"&gt;KScope: A Framework for Characterizing the Knowledge Status of Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07477v1"&gt;Premise Selection for a Lean Hammer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07484v1"&gt;CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07501v1"&gt;Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07520v1"&gt;LeVo: High-Quality Song Generation with Multi-Preference Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07524v1"&gt;IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07581v1"&gt;FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07606v1"&gt;PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07621v1"&gt;LoRMA: Low-Rank Multiplicative Adaptation for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07744v1"&gt;Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07751v1"&gt;Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07756v1"&gt;Agent Semantics, Semantic Spacetime, and Graphical Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07785v1"&gt;Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07801v1"&gt;MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07804v1"&gt;Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07836v1"&gt;Are Trees Really Green? A Detection Approach of IoT Malware Attacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07854v1"&gt;Residual Reweighted Conformal Prediction for Graph Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07857v1"&gt;LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07861v1"&gt;Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07883v1"&gt;Diffusion Counterfactual Generation with Semantic Abduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07897v1"&gt;GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07903v1"&gt;Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07915v1"&gt;LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07927v1"&gt;Solving Inequality Proofs with Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07935v1"&gt;Diffusion of Responsibility in Collective Decision Making&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07936v1"&gt;Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07945v1"&gt;ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07962v1"&gt;Correlated Errors in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07963v1"&gt;Reinforcing Multimodal Understanding and Generation with Dual Self-rewards&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07972v1"&gt;HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08001v1"&gt;Reparameterized LLM Training via Orthogonal Equivalence Transformation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08008v1"&gt;Hidden in plain sight: VLMs overlook their visual representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08009v1"&gt;Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08013v1"&gt;StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07865v1"&gt;FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07405v1"&gt;RiemannFormer: A Framework for Attention in Curved Spaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07440v1"&gt;Federated In-Context Learning: Iterative Refinement for Improved Answer Quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07467v1"&gt;Circumventing Backdoor Space via Weight Symmetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07549v1"&gt;Improving Memory Efficiency for Training KANs via Meta Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07584v1"&gt;MIRA: Medical Time Series Foundation Model for Real-World Health Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07585v1"&gt;Aircraft Trajectory Dataset Augmentation in Latent Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07596v1"&gt;TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07616v1"&gt;FuXi-Air: Urban Air Quality Forecasting Based on Emission-Meteorology-Pollutant multimodal Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07624v1"&gt;Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07666v1"&gt;ProARD: progressive adversarial robustness distillation: provide wide range of robust students&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07673v1"&gt;How Benchmark Prediction from Fewer Data Misses the Mark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07706v1"&gt;Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07769v1"&gt;Clustered Federated Learning via Embedding Distributions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07949v1"&gt;Cost-Optimal Active AI Model Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07975v1"&gt;Hyperpruning: Efficient Search through Pruned Variants of Recurrent Neural Networks Leveraging Lyapunov Spectrum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07980v1"&gt;Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07357v1"&gt;CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07366v1"&gt;MoE-GPS: Guidlines for Prediction Strategy for Dynamic Expert Duplication in MoE Load Balancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07378v1"&gt;Moment Alignment: Unifying Gradient and Hessian Matching for Domain Generalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07413v1"&gt;Variational Supervised Contrastive Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07492v1"&gt;Explicit Preference Optimization: No Need for an Implicit Reward Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07500v1"&gt;Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07517v1"&gt;Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07575v1"&gt;Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07590v1"&gt;Explore the vulnerability of black-box models via diffusion models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07595v1"&gt;Exploiting Curvature in Online Convex Optimization with Delayed Feedback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07637v1"&gt;HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07687v1"&gt;Rao-Blackwellised Reparameterisation Gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07691v1"&gt;Training Superior Sparse Autoencoders for Instruct Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07695v1"&gt;Towards a Small Language Model Lifecycle Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07735v1"&gt;Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07760v1"&gt;Quickest Causal Change Point Detection by Adaptive Intervention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07770v1"&gt;Diffusion Models-Aided Uplink Channel Estimation for RIS-Assisted Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07773v1"&gt;Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07806v1"&gt;Identifiable Object Representations under Spatial Ambiguities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07844v1"&gt;Conditional Local Independence Testing with Application to Dynamic Causal Discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07859v1"&gt;Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07871v1"&gt;Can Hessian-Based Insights Support Fault Diagnosis in Attention-based Models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07884v1"&gt;Schauder Bases for $C[0, 1]$ Using ReLU, Softplus and Two Sigmoidal Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07888v1"&gt;SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07899v1"&gt;MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07918v1"&gt;CausalPFN: Amortized Causal Effect Estimation via In-Context Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07933v1"&gt;Ensemble-Based Survival Models with the Self-Attended Beran Estimator Predictions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07948v1"&gt;TokenBreak: Bypassing Text Classification Models Through Token Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07969v1"&gt;A Two-Phase Deep Learning Framework for Adaptive Time-Stepping in High-Speed Flow Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07981v1"&gt;Real-time Localization of a Soccer Ball from a Single Camera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07984v1"&gt;CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07985v1"&gt;Rethinking Crowd-Sourced Evaluation of Neuron Explanations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07998v1"&gt;Generative Modeling of Weights: Generalization or Memorization?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07999v1"&gt;MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07468v1"&gt;Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07534v1"&gt;Flowing Datasets with Wasserstein over Wasserstein Gradient Flows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07605v1"&gt;TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07661v1"&gt;The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07667v1"&gt;Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07714v1"&gt;Profiling Electric Vehicles via Early Charging Voltage Patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07795v1"&gt;LLM Unlearning Should Be Form-Independent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07810v1"&gt;A weighted quantum ensemble of homogeneous quantum classifiers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07826v1"&gt;R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07863v1"&gt;VIVAT: Virtuous Improving VAE Training through Artifact Mitigation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07920v1"&gt;W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07925v1"&gt;A Comparative Study of U-Net Architectures for Change Detection in Satellite Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07929v1"&gt;A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07932v1"&gt;Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07952v1"&gt;Discrete and Continuous Difference of Submodular Minimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07956v1"&gt;Language Models over Canonical Byte-Pair Encodings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07356v1"&gt;Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07423v1"&gt;SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07429v1"&gt;Conjoined Predication and Scalar Implicature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07438v1"&gt;LG-ANNA-Embedding technical report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07453v1"&gt;Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07461v1"&gt;From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07479v1"&gt;Improving Fairness of Large Language Models in Multi-document Summarization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07502v1"&gt;DEBATE: A Dataset for Disentangling Textual Ambiguity in Mandarin Through Speech&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07506v1"&gt;What Do Indonesians Really Need from Language Technology? A Nationwide Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07510v1"&gt;DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07523v1"&gt;Towards Large Language Models with Self-Consistent Natural Language Explanations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07541v1"&gt;Bit-level BPE: Below the byte boundary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07597v1"&gt;Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07617v1"&gt;Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07626v1"&gt;Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07645v1"&gt;Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07658v1"&gt;Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07712v1"&gt;Through the Valley: Path to Effective Long CoT Training for Small Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07719v1"&gt;Multilingual Grammatical Error Annotation: Combining Language-Agnostic Framework with Language-Specific Flexibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07726v1"&gt;Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07851v1"&gt;Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07947v1"&gt;Statistical Hypothesis Testing for Auditing Robustness in Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08007v1"&gt;Reinforcement Pre-Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07402v1"&gt;Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07460v1"&gt;GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07572v1"&gt;Learning Speaker-Invariant Visual Features for Lipreading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07631v1"&gt;Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07937v1"&gt;Quantum Graph Transformer for NLP Sentiment Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.08011v1"&gt;Play to Generalize: Learning to Reason Through Game Play&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07515v1"&gt;Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.07646v1"&gt;Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-10</guid><pubDate>Tue, 10 Jun 2025 12:21:12 +0900</pubDate></item><item><title>WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code</title><link>http://arxiv.org/abs/2506.07818v1</link><description>生成AI技術の急速な進歩に伴い、マルチモーダル大規模言語モデル（MLLM）は、複雑なWebアプリケーション開発を実行できるAIソフトウェアエンジニアとして機能する可能性を秘めています。モデルが様々な開発段階の課題に対処するために多次元的なサブ能力の融合を必要とすることを考慮すると、開発効率の向上を正確に導くためには、マルチビュー評価フレームワークの構築が不可欠です。しかし、既存のベンチマークは通常、サブ能力の評価を提供することに失敗し、Webページの生成結果のみに焦点を当てています。本研究では、ソフトウェアエンジニアリングの原則から着想を得て、MLLMをWebUI認識、HTMLプログラミング、WebUI-HTML理解、WebUI-to-Codeという4つの主要分野で体系的に評価するために設計されたベンチマークであるWebUIBenchを提案します。WebUIBenchは、0.7Kを超える実際のWebサイトから派生した21Kの高品質な質問応答ペアで構成されています。29の主流MLLMの広範な評価により、開発プロセス中にモデルが遭遇したスキル特性と様々な弱点が明らかになります。

&lt;img src="https://arxiv.org/html/2506.07818v1/x1.png"/&gt;&lt;p&gt;Beijing Jiaotong University, China Telecom, Institute of Artificial Intelligence (TeleAI), Nanjing University zyllin@bjtu.edu.cn; zhengdazhou@smail.nju.edu.cn; tuzixini@gmail.com tianrui@mail.nwpu.edu.cn; mayilun@mail.nwpu.edu.cn; gjy3035@gmail.com; xuelong_li@ieee.org : https://github.com/MAIL-Tele-AI/WebUIBench, Northwestern Polytechnical University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07818v1</guid><pubDate>Mon, 09 Jun 2025 14:46:02 +0000</pubDate></item><item><title>TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review</title><link>http://arxiv.org/abs/2506.07642v1</link><description>大規模言語モデル（LLM）は査読支援において大きな可能性を示していますが、現在の手法では、効率を維持しながら徹底的で洞察力に富んだレビューを生成することが難しい場合があります。本論文では、論文レビューを階層的かつ双方向の質問応答プロセスとしてモデル化する新しいフレームワークであるTreeReviewを提案します。TreeReviewはまず、高レベルの質問を細分化されたサブ質問に再帰的に分解することで、レビュー質問のツリーを構築し、次に、葉から根へと回答を反復的に集約して質問ツリーを解決し、最終的なレビューを得ます。重要なのは、必要に応じてフォローアップ質問を生成することで、より深い調査を可能にする動的な質問拡張メカニズムを組み込んでいることです。ICLRおよびNeurIPSの会場から派生したベンチマークを構築し、完全なレビュー生成および実行可能なフィードバックコメント生成タスクで当社の方法を評価します。LLMベースおよび人間による評価の両方の実験結果は、TreeReviewが、包括的で、詳細で、専門家と連携したレビューフィードバックを提供する上で、強力なベースラインを上回り、計算集約的なアプローチと比較してLLMトークンの使用量を最大80％削減することを示しています。当社のコードとベンチマークデータセットは、https://github.com/YuanChang98/tree-review で入手できます。

&lt;img src="https://arxiv.org/html/2506.07642v1/extracted/6524794/limitation.png"/&gt;&lt;p&gt;Chinese Academy of Sciences Department of Information Resources Management, Management, National Science Library, School of Economics, Technology (Guangzhou) The University of Hong Kong, University of Chinese Academy of Sciences Tsinghua University Hong Kong University of Science&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07642v1</guid><pubDate>Mon, 09 Jun 2025 11:07:55 +0000</pubDate></item><item><title>A Hybrid GA LLM Framework for Structured Task Optimization</title><link>http://arxiv.org/abs/2506.07483v1</link><description>GA LLMは、遺伝的アルゴリズムと大規模言語モデルを組み合わせたハイブリッドフレームワークであり、厳格な制約下での構造化された生成タスクを処理します。計画やレポートなどの各出力は遺伝子として扱われ、選択、交叉、突然変異などの進化演算は、言語モデルによって誘導され、反復的にソリューションを改善します。言語モデルは、ドメイン知識と創造的なバリエーションを提供し、遺伝的アルゴリズムは、構造的な整合性とグローバルな最適化を保証します。GA LLMは、旅程計画、学術的なアウトライン作成、ビジネスレポートなどのタスクで効果的であることが証明されており、一貫して構造が整っており、要件を満たす結果を生み出しています。そのモジュール設計により、新しいタスクへの適応も容易です。言語モデルのみを使用する場合と比較して、GA LLMは両方のコンポーネントの強みを組み合わせることで、より優れた制約充足とより高品質なソリューションを実現します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07483v1</guid><pubDate>Mon, 09 Jun 2025 07:00:04 +0000</pubDate></item><item><title>Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs</title><link>http://arxiv.org/abs/2506.07958v1</link><description>物理情報付きコルモゴロフ-アーノルドネットワーク（PIKAN）、特にそのチェビシェフ基底の変種（cPIKAN）は、偏微分方程式（PDE）を解くための有望なモデルとして最近登場しました。しかし、それらの学習ダイナミクスと収束挙動は、理論的にも数値的にもほとんど解明されていません。本研究では、ニューラルタンジェントカーネル（NTK）理論を用いてcPIKANを分析することにより、その理論的理解を深めることを目的としています。私たちの目的は、勾配ベースの学習におけるカーネル構造の進化と、その後の学習効率への影響を識別することです。まず、教師あり設定における標準的なcKANのNTKを導出し、次に、物理情報付きのコンテキストに分析を拡張します。定常状態のヘルムホルツ方程式、過渡拡散方程式、アレン-カーン方程式、およびオイラー-ベルヌーイ梁方程式によって支配される強制振動という、4つの代表的なPDEについて、NTK行列のスペクトル特性、特に固有値分布とスペクトルバイアスを分析します。また、一次、二次、ハイブリッドアプローチなど、さまざまな最適化戦略がNTKの進化と結果として生じる学習ダイナミクスに与える影響についても調査します。結果は、cPIKANのコンテキストにおけるNTKの扱いやすい挙動を示しており、標準的な物理情報付きニューラルネットワーク（PINN）では捉えられない学習ダイナミクスを明らかにしています。スペクトルの傾向は、領域分割がいつ学習を改善するかを明らかにし、カーネルの挙動とさまざまな設定での収束率を直接結び付けます。私たちの知る限り、これはcPIKANの最初の体系的なNTK研究であり、その経験的パフォーマンスを明確化し予測する理論的洞察を提供します。

&lt;img src="https://arxiv.org/html/2506.07958v1/x1.png"/&gt;&lt;p&gt;Farinaz Mostajeran, Salah A. Faroughi&lt;/p&gt;&lt;p&gt;Energy &amp; Intelligence Lab, Department of Chemical Engineering, University of Utah, Salt Lake City, Utah 84112, USA&lt;/p&gt;</description><guid isPermaLink="false">2506.07958v1</guid><pubDate>Mon, 09 Jun 2025 17:30:13 +0000</pubDate></item><item><title>Accelerating Constrained Sampling: A Large Deviations Approach</title><link>http://arxiv.org/abs/2506.07816v1</link><description>制約された領域における目標確率分布のサンプリング問題は、機械学習を含む多くの応用分野で発生します。制約付きサンプリングのために、反射ランジュバン力学（RLD）の離散化に基づく射影ランジュバンモンテカルロ（PLMC）や、より一般的には、歪反射非可逆ランジュバン力学（SRNLD）の離散化に基づく歪反射非可逆ランジュバンモンテカルロ（SRNLMC）など、様々なランジュバンアルゴリズムが提案され、研究されてきました。本研究では、RLDに歪対称行列を加えたSRNLDの長時間挙動に焦点を当てます。SRNLD（およびSRNLMC）の非漸近的収束解析や、RLD（およびPMLC）と比較した加速化については研究されていますが、実際には良好な性能を達成するために、力学系における歪対称行列をどのように設計すべきかは明らかではありません。本研究では、歪対称行列と境界上の内向き単位法線ベクトル場の積がゼロになるように歪対称行列を選択した場合の、SRNLDの経験測度に対する大規模偏差原理（LDP）を確立します。レート関数を明示的に特徴づけることで、この歪対称行列の選択により、SRNLDがRLDと比較して目標分布への収束を加速できることを示します。提案された歪対称行列に基づくSRNLMCの数値実験は、優れた性能を示し、大規模偏差理論からの理論的知見を検証します。

&lt;img src="https://arxiv.org/html/2506.07816v1/extracted/6526048/figures/Target.png"/&gt;&lt;p&gt;Yingli Wang Changwei Tu Xiaoyu Wang Lingjiong Zhu&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07816v1</guid><pubDate>Mon, 09 Jun 2025 14:44:39 +0000</pubDate></item><item><title>Poisson Midpoint Method for Log Concave Sampling: Beyond the Strong Error Lower Bounds</title><link>http://arxiv.org/abs/2506.07614v1</link><description>本稿では、過減衰/過小減衰ランジュバン力学に対するポアソン中点離散化（ランダム化中点法の変形）を用いて、$\mathbb{R}^d$上の強対数凹分布からサンプリングする問題を研究する。2-Wasserstein距離（$W_2$）における収束を証明し、目標精度（$\epsilon$）に対する依存性において、オイラー・丸山離散化よりも3次的に高速化を達成し、ランダム化中点法に対する既存の限界を上回る。特に、過小減衰ランジュバン力学の場合、本稿では、$W_2$収束の複雑さが、文献で確立されている$L^2$強誤差における収束の複雑さの下限よりもはるかに小さいことを示す。

&lt;img src=""/&gt;&lt;p&gt;Rishikesh Srinivasan Google DeepMind rishikeshsrini@google.com
&amp;Dheeraj Nagaraj Google DeepMind dheerajnagaraj@google.com&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07614v1</guid><pubDate>Mon, 09 Jun 2025 10:27:15 +0000</pubDate></item><item><title>G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems</title><link>http://arxiv.org/abs/2506.07398v1</link><description>大規模言語モデル（LLM）を搭載したマルチエージェントシステム（MAS）は、単一のLLMエージェントの能力をはるかに超える認知能力と実行能力を示していますが、自己進化の能力は、未発達なメモリアーキテクチャによって阻害されたままです。詳細な調査の結果、既存のMASメモリメカニズムは、（1）過度に単純化されており、エージェント間の微妙な連携軌跡を完全に無視し、（2）単一のエージェント向けに開発された表現力豊かなメモリとは対照的に、試行を跨いだエージェント固有のカスタマイズが欠如していることが判明し、憂慮しています。このギャップを埋めるために、組織記憶理論に触発された、MAS向けの階層的なエージェント型メモリシステムであるG-Memoryを導入します。これは、洞察、クエリ、インタラクショングラフの3層グラフ階層を通じて、長期にわたるMASインタラクションを管理します。新しいユーザーのクエリを受け取ると、G-Memoryは双方向のメモリトラバーサルを実行し、システムが試行を跨いだ知識を活用できるようにする$\textit{高レベルで汎用化可能な洞察}$と、以前の連携経験をコンパクトにエンコードする$\textit{詳細で凝縮されたインタラクション軌跡}$の両方を取得します。タスク実行時には、新しい連携軌跡を同化することで階層全体が進化し、エージェントチームの漸進的な進化を促進します。5つのベンチマーク、3つのLLMバックボーン、および3つの一般的なMASフレームワークにわたる広範な実験により、G-Memoryは、元のフレームワークを変更することなく、具現化されたアクションの成功率と知識QAの精度をそれぞれ最大$20.89\%$と$10.12\%$向上させることが示されています。私たちのコードはhttps://github.com/bingreeky/GMemoryで入手できます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07398v1</guid><pubDate>Mon, 09 Jun 2025 03:43:46 +0000</pubDate></item><item><title>The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning</title><link>http://arxiv.org/abs/2506.07619v1</link><description>機械学習は、分子特性予測や反応逆合成において目覚ましい成果を上げ、実験室化学の様相を変えると期待されています。しかし、化学データセットは、クリーニング、化学の徹底的な理解、または単に入手できないことが多いため、機械学習コミュニティにとってアクセスしにくいことがよくあります。本論文では、収率予測のための新しいデータセットを紹介し、1200以上のプロセス条件を網羅した、機械学習ベンチマークのための初の過渡フローデータセットを提供します。従来のデータセットが離散的なパラメータに焦点を当てているのに対し、私たちの実験セットアップでは、多数の連続的なプロセス条件をサンプリングすることができ、機械学習モデルに新たな課題を生み出します。特に理論的なモデル化が難しく、機械学習の応用が期待される溶媒選択に焦点を当てています。回帰アルゴリズム、転移学習アプローチ、特徴量エンジニアリング、アクティブラーニングのベンチマークを示し、溶媒置換や持続可能な製造に向けた重要な応用を示します。

&lt;img src="https://arxiv.org/html/2506.07619v1/extracted/6524982/figures/Project2_rxn.png"/&gt;&lt;p&gt;Becky D. Langdon, Imperial College, Jixiang Qing, Juan S. Campos, London, Toby Boyne, UK, UK Department of Chemistry, UK SOLVE Chemistry, Yilin Xie Department of Computing&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07619v1</guid><pubDate>Mon, 09 Jun 2025 10:34:14 +0000</pubDate></item><item><title>ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning</title><link>http://arxiv.org/abs/2506.07459v1</link><description>タンパク質生成モデルはタンパク質設計において目覚ましい可能性を示していますが、教師あり事前学習のための高品質なタンパク質データセットの不足により、成功率には依然として限界があります。本研究では、オンライン強化学習を通じて、逆フォールディングモデルのスケーラブルで自動化された継続的な自己改善を可能にする新しいフレームワークであるProteinZeroを提案します。計算量的に扱いやすいオンラインフィードバックを実現するために、ESM-foldに基づく効率的なプロキシ報酬モデルと、評価速度を大幅に向上させる新しい高速ddG予測器を導入します。ProteinZeroは、マルチ報酬の最大化、参照モデルからのKLダイバージェンス、およびより高い配列多様性を促進しながらモード崩壊を防ぐ新しいタンパク質埋め込みレベルの多様性正則化のバランスをとる一般的なRLフレームワークを採用しています。広範な実験を通じて、ProteinZeroはタンパク質設計におけるすべての主要な指標において既存の手法を大幅に上回り、構造精度、設計可能性、熱力学的安定性、および配列多様性において大幅な改善を達成することを示します。最も印象的なのは、ProteinZeroがProteinMPNN、ESM-IF、InstructPLMなどの広く使用されている手法と比較して、設計失敗率を約36％〜48％削減し、多様で複雑なタンパク質フォールド全体で一貫して90％を超える成功率を達成することです。特に、CATH-4.3でのRL実行全体は、報酬計算を含めて、8つのGPUノードで3日以内に完了できます。私たちの研究は、モデルが自身の生成された出力から継続的に進化するタンパク質設計の新しいパラダイムを確立し、広大なタンパク質設計空間を探索するための新しい可能性を開きます。

&lt;img src="https://arxiv.org/html/2506.07459v1/x3.png"/&gt;&lt;p&gt;Ziwen Wang University of Illinois Urbana-Champaign &amp;Jiajun Fan University of Illinois Urbana-Champaign &amp;Ruihan Guo University of Illinois Urbana-Champaign &amp;Thao Nguyen University of Illinois Urbana-Champaign &amp;Heng Ji University of Illinois Urbana-Champaign &amp;Ge Liu University of Illinois Urbana-Champaign&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07459v1</guid><pubDate>Mon, 09 Jun 2025 06:08:59 +0000</pubDate></item><item><title>Improving large language models with concept-aware fine-tuning</title><link>http://arxiv.org/abs/2506.07833v1</link><description>大規模言語モデル（LLM）は、現代AIの基礎となっています。しかし、既存の次トークン予測というパラダイムは、LLMが首尾一貫した高レベルの概念を形成する能力を根本的に制限しており、人間のような理解と推論に対する重大な障壁となっています。例えば、「リボ核酸」というフレーズを考えてみましょう。LLMはまず、それをトークン、つまり人工的なテキスト断片（「rib」、「on」、...）に分解し、フレーズを統一された首尾一貫した意味的エンティティとして把握するのではなく、各トークンを順番に学習します。この断片化された表現は、より深い概念理解を妨げ、最終的には真にインテリジェントなシステムの開発を阻害します。これに対し、我々はConcept-Aware Fine-Tuning（CAFT）という、LLMのファインチューニング方法を再定義する新しいマルチトークン学習法を導入します。この方法は、複数のトークンにまたがるシーケンスの学習を可能にすることで、より強力な概念認識学習を促進します。我々の実験では、テキスト要約のような従来のアプリケーションや、de novoタンパク質設計のようなドメイン固有のアプリケーションを含む、多様なタスクにおいて、従来の次トークンファインチューニング手法と比較して大幅な改善が示されました。マルチトークン予測は、以前は非常にコストのかかる事前学習段階でのみ可能でしたが、CAFTは、我々の知る限り、マルチトークン設定を事後学習段階に持ち込んだ最初の例であり、より広範な実務者および研究者のコミュニティにその利点を効果的に普及させます。最後に、提案手法の予想外の有効性は、機械学習研究コミュニティにとってより広範な意味合いを示唆しています。すべてのコードとデータは、https://github.com/michaelchen-lab/caft-llm で入手できます。

&lt;img src="https://arxiv.org/html/2506.07833v1/x1.png"/&gt;&lt;p&gt;Michael K. Chen Nanyang Technological University Singapore &amp;Xikun Zhang Nanyang Technological University Singapore Jiaxing Huang Nanyang Technological University Singapore &amp;Dacheng Tao Nanyang Technological University Singapore&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07833v1</guid><pubDate>Mon, 09 Jun 2025 14:55:00 +0000</pubDate></item><item><title>ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning</title><link>http://arxiv.org/abs/2506.07551v1</link><description>大規模言語モデル（LLM）は、化学タスクにおいて有望な能力を示していますが、依然として時代遅れの事前学習知識や、専門的な化学知識を取り込むことの難しさという課題に直面しています。これらの問題に対処するため、私たちは、基本的な情報検索から複雑な反応予測まで、137個の外部化学ツールを相乗的に統合するLLMベースのエージェントと、ファインチューニングと評価において効果的なツール選択と正確なパラメータ入力を促進するデータセットChemToolBenchを生成するデータセットキュレーションパイプラインを提案します。私たちは、ツール計画と実行の独立した最適化を可能にする階層的進化モンテカルロ木探索（HE-MCTS）フレームワークを導入します。自己生成されたデータを活用することで、私たちのアプローチは、ポリシーモデルのステップレベルのファインチューニング（FT）と、GPT-4oを超えるタスク適応型PRMおよびORMのトレーニングをサポートします。実験的評価により、私たちのアプローチが化学QAおよび発見タスクのパフォーマンスを大幅に向上させ、高度な化学アプリケーションのためにLLMと専門ツールを統合するための堅牢なソリューションを提供することが実証されました。すべてのデータセットとコードは、https://github.com/AI4Chem/ChemistryAgent で入手できます。

&lt;img src="https://arxiv.org/html/2506.07551v1/extracted/6524970/assets/ChemAgent.png"/&gt;&lt;p&gt;City University of Hong Kong, Shanghai Artificial Intelligence Laboratory, Soochow University, Zhejiang University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07551v1</guid><pubDate>Mon, 09 Jun 2025 08:41:39 +0000</pubDate></item><item><title>Automating Exploratory Multiomics Research via Language Models</title><link>http://arxiv.org/abs/2506.07591v1</link><description>本論文では、生のデータファイルからデータ駆動型の仮説を完全に自動生成するシステム、PROTEUSを紹介する。PROTEUSを臨床プロテオゲノミクスに応用する。この分野では、効果的な下流データ解析と仮説提案が、新規な発見を生み出すために不可欠である。PROTEUSは、オープンエンドなデータ探索から、特定の統計分析、仮説提案まで、科学的プロセスの異なる段階をシミュレートするために、個別のモジュールを使用する。複雑な研究プロセスを管理するために、統一されたグラフ構造を用いて、生物学的エンティティ間の関係として、研究の方向性、ツール、結果を定式化する。PROTEUSを、公開された研究からの10個の臨床マルチオミクスデータセットに適用し、合計360個の仮説に到達した。結果は、外部データ検証と自動オープンエンドスコアリングによって評価された。探索的かつ反復的な研究を通じて、このシステムは、信頼性と新規性のバランスが取れた仮説に到達するために、ハイスループットで異質なマルチオミクスデータをナビゲートすることができる。マルチオミクス解析を加速することに加えて、PROTEUSは、データからのオープンエンドな仮説生成を達成するために、一般的な自律システムを専門的な科学ドメインに適合させる道筋を示す。

&lt;img src="https://arxiv.org/html/2506.07591v1/x1.png"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07591v1</guid><pubDate>Mon, 09 Jun 2025 09:44:21 +0000</pubDate></item><item><title>GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition</title><link>http://arxiv.org/abs/2506.07553v1</link><description>光化学構造認識（OCSR）は、分子画像を機械可読な形式に変換することにより、化学知識をデジタル化するために不可欠です。近年のビジョン-言語モデル（VLM）はこのタスクで可能性を示していますが、その画像キャプションアプローチは、複雑な分子構造や一貫性のないアノテーションに苦戦することがよくあります。これらの課題を克服するために、私たちはGTR-Mol-VLMという新しいフレームワークを導入します。これは、(1) \textit{視覚的な思考連鎖としてのグラフ探索}メカニズムを備えており、原子-結合の逐次的な予測を通じて分子グラフを段階的に解析することで、人間の推論をエミュレートします。そして、(2) \textit{見たものを忠実に認識する}というデータ中心の原則は、画像内の省略された構造と、その拡張されたアノテーションとの間のミスマッチに対処します。モデル開発をサポートするために、私たちは綿密に修正されたアノテーションを含む大規模なインストラクションチューニングデータセットであるGTR-CoT-1.3Mを構築し、OCSRにおけるグラフ解析の精度を詳細に評価するために設計された最初のベンチマークであるMolRec-Benchを導入しました。包括的な実験により、GTR-Mol-VLMが、専門モデル、化学ドメインVLM、および商用汎用VLMと比較して、優れた結果を達成することが実証されています。特に、官能基の省略を含む分子画像を含むシナリオでは、GTR-Mol-VLMは、SMILESベースおよびグラフベースのメトリックの両方で、2番目に優れたベースラインを約14パーセントポイント上回っています。この研究がOCSR技術を推進し、現実世界のニーズをより効果的に満たし、それによってケモインフォマティクスと科学のためのAIの分野を前進させることを願っています。GTR-CoTはhttps://github.com/opendatalab/GTR-CoTで公開します。

&lt;img src="https://arxiv.org/html/2506.07553v1/x1.png"/&gt;&lt;p&gt;Chinese University of Hong Kong, East China Normal University, Fudan University, Northwestern Polytechnical University, Peking University, Shanghai Artificial Intelligence Laboratory, Shanghai University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07553v1</guid><pubDate>Mon, 09 Jun 2025 08:47:10 +0000</pubDate></item><item><title>Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation</title><link>http://arxiv.org/abs/2506.07820v1</link><description>人間の推論は柔軟で、適応力があり、過去の経験に基づいています。これは、大規模言語モデル（LLM）がまだ模倣に苦労している性質です。既存の手法は、推論時に多様な推論経路を探求するか、高コストな操作を通じて最適なワークフローを探索しますが、どちらも構造化された効率的な方法で複数の再利用可能な戦略を活用するには至りません。そこで、私たちはGuideline Forestというフレームワークを提案します。これは、検証済みの例から構造化された推論戦略（ガイドラインと呼ばれる）を誘導し、段階的な集約を通じてそれらを実行することで、LLMの推論能力を向上させます。テスト時の探索や単一経路の蒸留とは異なり、私たちの手法は、再利用可能なガイドラインを誘導し、それぞれを多様なバリアントに展開することで、検証済みの推論経験を活用します。人間の推論によく似て、これらのバリアントは代替思考パターンを反映し、並行して実行され、自己修正によって洗練され、段階的に集約されます。これにより、モデルは不確実性を適応的に解消し、堅牢な解決策を合成できます。私たちは、数学的およびプログラム的な推論にまたがる4つのベンチマーク（GSM8K、MATH-500、MBPP、HumanEval）でGuideline Forestを評価します。Guideline Forestは、CoT、ReAct、ToT、FoT、AFlowなどの強力なベースラインを一貫して上回っています。アブレーション研究は、マルチパス推論と段階的な集約の有効性をさらに強調し、Guideline Forestの適応性と汎化の可能性を裏付けています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07820v1</guid><pubDate>Mon, 09 Jun 2025 14:46:31 +0000</pubDate></item><item><title>MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents</title><link>http://arxiv.org/abs/2506.07672v1</link><description>LLM（大規模言語モデル）を搭載したコンピュータ利用エージェント（CUA）は、人間とコンピュータのインタラクションを自動化する革新的な技術として登場しています。しかし、既存のCUAベンチマークは主にGUIエージェントを対象としており、その評価方法はUIの変更に影響を受けやすく、Model Context Protocol（MCP）などのアプリケーションAPIによって公開される機能インタラクションを無視しています。そこで、API、GUI、およびAPI-GUIハイブリッドエージェント向けの初の自動CUAテストベッドであるMCPWorldを提案します。MCPWorldの重要な原則は、「ホワイトボックスアプリ」、つまりソースコードが利用可能で、必要に応じて修正/再コンパイルできるアプリ（例：MCPサポートの追加）を使用することであり、これには2つの注目すべき利点があります。
  (1) CUAの設計空間を大幅に広げます。たとえば、アプリのどの機能をCUAが呼び出し可能なAPIとして公開/抽出するかなどです。
  (2) MCPWorldは、動的コードインストルメンテーションなどの技術を通じてアプリケーションの動作を直接監視することにより、タスク完了をプログラムで検証できます。これにより、特定のエージェント実装やUIの状態から切り離された、堅牢で正確なCUA評価が提供されます。
  現在、MCPWorldには、多様なユースケースと難易度レベルを網羅する、適切にキュレーションおよびアノテーションされた201のユーザータスクが含まれています。MCPWorldは完全にコンテナ化されており、さまざまなOS/ハードウェア環境での柔軟な採用をサポートするGPUアクセラレーションも備えています。代表的なLLM搭載CUAフレームワークを使用した予備実験では、75.12％のタスク完了精度を達成し、MCPを活用したエージェント自動化の実用的な有効性に関する初期的な証拠を同時に提供しています。全体として、MCPWorldは、豊富な外部ツールを活用できる次世代のコンピュータ利用エージェントのベンチマークを促進し、標準化すると期待しています。私たちのコードとデータセットは、https://github.com/SAAgent/MCPWorld で公開されています。

&lt;img src="https://arxiv.org/html/2506.07672v1/x1.png"/&gt;&lt;p&gt;Beijing University of Posts, Jiajun Du, Pengcheng Laboratory Equal Contribution, Shihe Wang, Telecommunications, Yexuan Yang, Yunhe Yan, Yuxuan Shan&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07672v1</guid><pubDate>Mon, 09 Jun 2025 11:50:33 +0000</pubDate></item><item><title>SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling</title><link>http://arxiv.org/abs/2506.07636v1</link><description>大規模言語モデル（LLM）は、会話型問題解決から、ソフトウェアエンジニアリング（SWE）などのツール利用を伴う現実世界のタスクへの対応へと急速に進化しています。最近のOpenAI CodexやCursorのようなLLMを活用したツールキットは、ソフトウェア開発プロセスのエンドツーエンドの自動化を提供しています。しかし、効果的なSWEエージェントの構築は、高品質なトレーニングデータと効果的なテストケースの不足により、依然として困難です。この問題に対処するため、我々はオープンソースのLLM上に構築されたSWEエージェントであるSWE-Devを提案します。まず、パッチ評価のためのテストケースを合成する堅牢なパイプラインを開発します。次に、SWE-Devを構築するためのトレーニングデータを構築するために、エージェントの軌跡をスケールアップします。SWE-bench-Verifiedベンチマークでの実験結果は、SWE-DevモデルがすべてのオープンなSWEエージェントの中で最高のパフォーマンスを達成できることを示しています。具体的には、SWE-Devの7Bおよび32Bパラメータモデルの成功率はそれぞれ23.4%および36.6%に達し、最先端のオープンソースモデルを上回っています。すべてのコード、モデル、およびデータセットは、https://github.com/THUDM/SWE-Dev で公開されています。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07636v1</guid><pubDate>Mon, 09 Jun 2025 11:03:16 +0000</pubDate></item><item><title>FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling</title><link>http://arxiv.org/abs/2506.07902v1</link><description>生成モデリングにおける最近の進歩、特に拡散モデルとフローマッチングは、画像やビデオなどの離散データの合成において目覚ましい成功を収めています。しかし、これらのモデルを物理的な応用に適応させることは依然として困難です。なぜなら、対象となる量は複雑な物理法則に支配される連続関数だからです。そこで、本稿では、関数空間における生成モデリングのための新しいフレームワークである$\textbf{FunDiff}$を紹介します。FunDiffは、潜在拡散プロセスと関数オートエンコーダアーキテクチャを組み合わせることで、さまざまな離散化を持つ入力関数を処理し、任意の場所で評価可能な連続関数を生成し、物理的な事前知識をシームレスに組み込むことができます。これらの事前知識は、アーキテクチャの制約または物理情報に基づいた損失関数を通じて強制され、生成されたサンプルが基本的な物理法則を満たすことを保証します。関数空間における密度推定に対するミニマックス最適性の保証を理論的に確立し、拡散ベースの推定量が適切な正則性条件の下で最適な収束率を達成することを示します。流体ダイナミクスと固体力学における多様なアプリケーションにおいて、FunDiffの実用的な有効性を示します。実験結果は、我々の手法がターゲット分布に対して忠実度の高い物理的に一貫したサンプルを生成し、ノイズの多いデータや低解像度データに対するロバスト性を示すことを示しています。コードとデータセットは、https://github.com/sifanexisted/fundiff で公開されています。

&lt;img src="https://arxiv.org/html/2506.07902v1/x1.png"/&gt;&lt;p&gt;CT 06511, CT 06511 &amp;Tong-Rui Liu Department of Aeronautics Imperial College London London, CT 06511 &amp;Zehao Dou Department of Statistics, Data Science Yale University New Haven, SW7 2AZ &amp;Lu Lu Department of Statistics, Sifan Wang Institute for Foundations of Data Science Yale University New Haven&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07902v1</guid><pubDate>Mon, 09 Jun 2025 16:19:59 +0000</pubDate></item><item><title>Tunable Coloration in Core-Shell Plasmonic Nanopixels Based on Organic Conductive Polymers: A First-Principles and FDTD Study</title><link>http://arxiv.org/abs/2506.07544v1</link><description>雨粒から惑星まで、電磁場の散乱は、表示デバイスに利用できる興味深い現象をもたらします。本研究では、密度汎関数理論（DFT）に基づく第一原理計算と、有限差分時間領域（FDTD）法シミュレーションを用いて、4つのエレクトロクロミック有機導電性ポリマーを利用した、低消費電力で高速着色能力を持つナノスケールピクセルを実現するための、コアシェル構造を持つエレクトロクロミックナノ粒子オンミラー（eNPoM）構造を設計しました。Auナノ粒子は、エレクトロクロミック導電性ポリマー（PANI、PEDOT、PPy、PThなど）でコーティングされ、金属ミラー上に配置されます。電場増強とシェル厚の影響を分析しました。原子レベルの計算から得られたすべてのポリマーの誘電特性をFDTDシミュレーションに利用し、ポリマー構造と光学特性の直接的な関係を相関させるのに役立てました。特に、本研究では、PANI、PEDOT、PPy、PThシェルを使用して、それぞれ100nm、40nm、70nm、および40nm以上の顕著な波長可変性が明らかになりました。さらに、ミラー上にTiN層を使用した場合のRGBカラー生成の可能性も検討しました。今回初めて、ボウタイやギアなどの複雑な構造を、研究対象のナノピクセルをモデル化するために利用し、顕著な吸収ピークのシフトが観察されました。CIE 1931色空間およびCIELAB2000色差における色度座標は、酸化還元サイクル中の色の変化能力を定量化し、有機材料と無機材料の比較分析は、提案されたプラズモニックナノピクセルの見通しを強調しています。

&lt;img src="https://arxiv.org/html/2506.07544v1/extracted/6524886/device_structure.png"/&gt;&lt;p&gt;Ahmed Zubair, Md. Shariful Islam&lt;/p&gt;&lt;p&gt;[&lt;/p&gt;</description><guid isPermaLink="false">2506.07544v1</guid><pubDate>Mon, 09 Jun 2025 08:32:20 +0000</pubDate></item><item><title>First-principles Quantum Insights into Bandgap Engineering, Valley Quantum Hall Effect, and Nonlinear Optical Response of Ge-Doped Graphene for Potential Optoelectronic Applications</title><link>http://arxiv.org/abs/2506.07745v1</link><description>材料のバンド構造におけるバレー（谷）は、近年多くの注目を集めています。バレー自由度の有望な応用例としては、次世代のバレートロニクスデバイス、量子情報処理、量子コンピューティング、および光電子デバイスが挙げられます。グラフェンは、高いキャリア移動度とバンドギャップエンジニアリングの容易さから、高速バレートロニクスアプリケーションに最適な量子材料です。本研究では、第一原理密度汎関数理論アプローチを用いて、ゲルマニウムドーピングによるバンドギャップエンジニアリング戦略を採用し、グラフェン単層におけるバンドギャップを開き、バレー選択性を高めました。2%、3.125%、5.5%、および12.5%のGeドーパント濃度が、バレートロニクス、バレーホール効果、バレー輸送、および光学特性に及ぼす影響を調査しました。報告された結果は、ゲルマニウムのドーピング濃度を変化させることによって、バンドギャップ、バレー偏極、および二次高調波発生を効果的に調整できることを示しています。ベリー曲率プロファイルは、対応するKバレーとK'バレーに対して反対称であり、その結果、バレー依存の輸送特性と潜在的なバレーホール効果が生じます。最後に、2次の感受率は対応する光吸収ピークを示し、反転対称性の破れによる効率的な二次高調波発生を示唆しています。これらの発見は、非線形光学およびバレートロニクスアプリケーションにおけるGeドープグラフェンの可能性を強調するとともに、そのトポロジカル相と輸送特性に関する新たな洞察を提供します。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07745v1</guid><pubDate>Mon, 09 Jun 2025 13:26:25 +0000</pubDate></item><item><title>A Study on the Fine-Tuning Performance of Universal Machine-Learned Interatomic Potentials (U-MLIPs)</title><link>http://arxiv.org/abs/2506.07401v1</link><description>汎用的な機械学習原子間ポテンシャル（U-MLIP）は、多様な原子システムで有効性を示していますが、タスク固有の精度を得るためには微調整が必要となることがよくあります。本研究では、MACEベースの基盤モデルであるMACE-MP-0とその変種であるMACE-MP-0bの微調整について調査し、重要な知見を得ました。タスク固有のデータセットで微調整を行うことで精度が向上し、場合によってはゼロから学習させたモデルよりも優れた性能を発揮します。さらに、微調整されたモデルは、基盤モデルによって提供される強力な初期予測により、収束が速くなるという利点があります。微調整の成功は、慎重なデータセットの選択にも依存し、フィルタリングやアクティブラーニングを通じて最適化できます。原子シミュレーションにおける基盤モデルのより良い微調整を実現するための実践的な戦略についてさらに議論し、その開発と応用に関する将来の方向性を探ります。

&lt;img src="https://arxiv.org/html/2506.07401v1/x3.png"/&gt;&lt;p&gt;Kehan Zeng, Teng Zhao, Xiaoqing Liu, Yangshuai Wang&lt;/p&gt;&lt;p&gt;Department of Mathematics, National University of Singapore, Singapore.
Department of Mathematics, University of British Columbia, 1984 Mathematics Road, Vancouver, Canada.
Institute of Natural Sciences, MOE-LSC, and Shanghai National Center for Applied Mathematics, Shanghai Jiao Tong University, Shanghai 200240, China.
Shanghai Jiao Tong University-Chongqing Institute of Artificial Intelligence, Chongqing 401329, China.&lt;/p&gt;</description><guid isPermaLink="false">2506.07401v1</guid><pubDate>Mon, 09 Jun 2025 03:51:23 +0000</pubDate></item><item><title>Scaling up the transcorrelated density matrix renormalization group</title><link>http://arxiv.org/abs/2506.07441v1</link><description>明示的に相関のある手法、例えばヤストローまたはグッツウィラー相関子を波動関数からハミルトニアンに移すトランス相関法は、電子構造の高精度計算のために設計されているが、より大きな系への適用は計算コストによって妨げられてきた。我々は、トランス相関密度行列繰り込み群（DMRG）のための改良された技術を開発する。このDMRGでは、トランス相関ハミルトニアンの基底状態が行列積状態（MPS）として表現され、二次元フェルミ・ハバードモデルの基底状態エネルギーの大規模計算を実証する。我々の開発は、以下の3つの技術的発明に由来する。（i）低い結合次元と高い疎性を持つトランス相関ハミルトニアンの行列積演算子（MPO）の構築、（ii）MPS表現の精度を向上させるための基底状態のエンタングルメント構造の利用、（iii）トランス相関法の非変分的な性質を緩和するためのグッツウィラー相関子の非線形パラメータの最適化。我々は、最大$12 \times 12$格子点サイズの系を調べ、これは以前のトランス相関DMRG研究の4倍の大きさであり、トランス相関DMRGが同等の計算量で標準的な非トランス相関DMRGよりも大幅な改善をもたらすことを実証する。トランス相関DMRGは、基底状態エネルギーの誤差を$3\times$-$17 \times$減少させ、最小の改善はハーフフィリングの小さな系で見られ、最大の改善は希薄な閉殻系で見られる。

&lt;img src="https://arxiv.org/html/2506.07441v1/x1.png"/&gt;&lt;p&gt;Akimasa Miyake, Benjamin Corbett&lt;/p&gt;&lt;p&gt;Center for Quantum Information and Control, Department of Physics and Astronomy,
University of New Mexico, Albuquerque, New Mexico 87106, USA&lt;/p&gt;</description><guid isPermaLink="false">2506.07441v1</guid><pubDate>Mon, 09 Jun 2025 05:36:59 +0000</pubDate></item><item><title>Scalable Neural Quantum State based Kernel Polynomial Method for Optical Properties from the First Principle</title><link>http://arxiv.org/abs/2506.07430v1</link><description>ニューラルネットワーク量子状態表現の変分最適化は、基底状態計算においてFCI（完全配置相互作用）レベルの精度を達成していますが、励起状態を含む光学的特性の計算は依然として困難です。本研究では、第一原理吸収スペクトルに対するニューラルネットワークに基づく変分量子モンテカルロ法を提案します。並列バッチ自己回帰サンプリングとGPUサポートされた局所エネルギー並列化を活用し、複雑な系の基底状態を効率的に計算します。ニューラル量子基底状態をカーネル多項式法と統合することで、50個以上の電子を持つ大規模分子の吸収スペクトルをFCIレベルの精度で正確に計算します。提案されたアルゴリズムは、FCIと比較して優れたスケーラビリティと短縮された実行時間を示し、大規模量子系の光学的特性計算における大きな進歩を示しています。

&lt;img src="https://arxiv.org/html/2506.07430v1/x1.png"/&gt;&lt;p&gt;Rui-Hao Bi, Wei Liu&lt;/p&gt;&lt;p&gt;*
[&lt;/p&gt;</description><guid isPermaLink="false">2506.07430v1</guid><pubDate>Mon, 09 Jun 2025 05:04:20 +0000</pubDate></item><item><title>Scalable Machine Learning Models for Predicting Quantum Transport in Disordered 2D Hexagonal Materials</title><link>http://arxiv.org/abs/2506.07983v1</link><description>本稿では、磁気的無秩序を持つ二次元（2D）六角形材料における、2つの重要な量子輸送特性である透過係数T(E)と局所状態密度（LDOS）を正確に予測するための、スケーラブルな機械学習モデルを紹介します。タイトバインディングハミルトニアンと非平衡グリーン関数（NEGF）形式を組み合わせることで、グラフェン、ゲルマネン、シリセン、スタネンナノリボンにおいて、様々な形状、不純物濃度、エネルギー準位を持つ40万件以上のユニークな構成からなる大規模なデータセットを生成しました。本研究の中心的な貢献は、モデルが材料の種類やデバイスサイズを超えて汎化できるようにする、幾何学に基づいた、物理的に解釈可能な特徴空間の開発です。ランダムフォレスト回帰および分類モデルを、精度、安定性、および外挿能力の観点から評価しました。回帰は、ドメイン内のデータにおける連続的な輸送挙動の捕捉において、一貫して分類よりも優れています。しかし、外挿性能は著しく低下し、ツリーベースモデルが見慣れない領域における限界を明らかにしています。本研究は、量子輸送予測のためのスケーラブルなMLモデルの可能性と制約の両方を強調し、スピントロニクスおよびナノエレクトロニクスデバイス設計における汎化性能を向上させるための、物理情報に基づいた、またはグラフベースの学習アーキテクチャに関する将来の研究を動機づけます。

&lt;img src="https://arxiv.org/html/2506.07983v1/x1.png"/&gt;&lt;p&gt;Amirhossein Ahmadkhan Kordbacheh, Seyed Mahdi Mastoor&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07983v1</guid><pubDate>Mon, 09 Jun 2025 17:52:51 +0000</pubDate></item><item><title>Stability of bound states in multi-component DFT in absolute coordinate systems</title><link>http://arxiv.org/abs/2506.07990v1</link><description>均質な電子および原子核ガスを、多成分ハミルトニアンの絶対座標における局在化された試行密度に変換し、束縛状態形成の安定性を決定する。安定領域は、高密度領域と低密度領域の両方で見出され、中間密度領域では電子-原子核相関が重要な役割を果たす可能性がある。ガリレイ座標の使用は、密度汎関数理論において運動エネルギーおよびポテンシャル密度汎関数を開発するために動機付けられており、そこから電子-原子核相関を捉えるための適切な座標変換が適用される。

&lt;img src="https://arxiv.org/html/2506.07990v1/extracted/6519157/DeltaE.png"/&gt;&lt;p&gt;Bander Linjawi&lt;/p&gt;&lt;p&gt;Department of Mechanical Engineering, King Abdullah University of Science and Technology, Thuwal 23955-6900, Saudi Arabia&lt;/p&gt;</description><guid isPermaLink="false">2506.07990v1</guid><pubDate>Mon, 09 Jun 2025 17:56:31 +0000</pubDate></item><item><title>First-principles characterization of native defects and oxygen impurities in GaAs</title><link>http://arxiv.org/abs/2506.07954v1</link><description>ハイブリッド密度汎関数計算を用いて、ガリウム砒素（GaAs）中の固有点欠陥と酸素不純物の調査結果を示す。欠陥は、その構造的、電子的、光学的特性によって特徴付けられる。支配的な固有欠陥は、Gaアンチサイト（Ga$_{\rm As}$）、Asアンチサイト（As$_{\rm Ga}$）、および/またはGa空孔（$V_{\rm Ga}$）であり、Asリッチ条件下ではAs$_{\rm Ga}$と$V_{\rm Ga}$が電荷補償欠陥となる。計算された欠陥遷移レベルに基づいて、孤立したAs$_{\rm Ga}$は実験で報告されているEL2中心として識別できる可能性がある。しかし、この欠陥は非放射電子捕獲断面積が無視できるほど小さいため、一般に信じられているような「主要な電子トラップ」にはなり得ない。GaAsは、Asリッチ条件下で製造された場合、複数のO関連欠陥中心を持つ可能性があることがわかった。準置換型O不純物（O$_{\rm As}$）と、2つのAs$_{\rm Ga}$欠陥との複合体（O$_{\rm As}$-2As$_{\rm Ga}$）は、準安定で常磁性の中間（中性）電荷状態を持つ。これらの2つの欠陥は、大きな非放射電子捕獲断面積を持ち、効果的な再結合中心となり得る。

&lt;img src="https://arxiv.org/html/2506.07954v1/x1.png"/&gt;&lt;p&gt;Khang Hoang&lt;/p&gt;&lt;p&gt;Center for Computationally Assisted Science and Technology &amp; Department of Physics, North Dakota State University, Fargo, North Dakota 58108, United States&lt;/p&gt;</description><guid isPermaLink="false">2506.07954v1</guid><pubDate>Mon, 09 Jun 2025 17:19:51 +0000</pubDate></item><item><title>Experiment and k$\cdot$p analysis of the luminescence from modulation-doped CdTe/(Cd,Mg)Te quantum wells at magnetic field</title><link>http://arxiv.org/abs/2506.07776v1</link><description>CdTe/(Cd,Mg)Te量子井戸からの磁気発光に関する論文は多数存在するにもかかわらず、バンド構造計算に基づいて解析しようという試みはこれまでなかった。本論文では、これに取り組むことを提案する。Cd$_{0.7}$Mg$_{0.3}$Teバリアを持つ1つまたは10個のCdTe量子井戸を含むサンプルを、半絶縁性GaAs基板上に分子線エピタキシー法で成長させた。各井戸はヨウ素ドナーで変調ドープされており、井戸内に二次元電子ガスが生成される。偏光分解（$\sigma^+/\sigma^-$）フォトルミネッセンススペクトルを液体ヘリウム温度および最大9 Tの磁場下で測定した。結果は、伝導帯および価電子帯におけるランダウ準位のエネルギー計算に基づいて解釈される。後者の場合、Luttingerハミルトニアンを使用し、伝導帯は3準位k$\cdot$pモデルで記述する。どちらのモデルも、元々はバルク材料用に定式化されたものであるが、二次元構造に適合させた。観測されたすべての遷移の大部分は、この理論によってうまく再現されることがわかった。しかし、いくつかの強い遷移は再現されず、伝導帯と価電子帯の混合に起因するフォトルミネッセンス遷移の選択則を拡張したスキームを提案することが可能になった。価電子帯のランダウ準位で、最大7の指数を持つ遷移を観測する。価電子帯の深い位置にあるこれらの準位が光励起された正孔で占有される起源を理解するために、時間分解測定を実施したところ、光励起されたバリアが量子井戸にトンネルする長寿命の正孔の供給源であることが示された。伝導帯電子の有効g因子の計算は、電子のエネルギーと外部磁場によって大きく変化することを示している。

&lt;img src=""/&gt;&lt;p&gt;D. Yavorskiy, J. Łusakowski, K. P. Korona, K. Ryczko, K. Karpierz, M. Grymuza, M. Kubisa, P. Pfeffer, T. Wojtowicz, W. Solarska, Z. Adamus&lt;/p&gt;&lt;p&gt;CENTERA, CEZAMAT, Warsaw University of Technology, ul. Poleczki 19, 02-822 Warsaw, Poland
Faculty of Physics, University of Warsaw, L. Pasteura 5, 02-093 Warsaw, Poland
Institute of High Pressure Physics, Polish Academy of Sciences, ul. Sokołowska 29/37, 01-142 Warsaw, Poland
Institute of Physics, Polish Academy of Sciences, Aleja Lotników 32/46, PL-02-668 Warszawa, Poland
International Research Centre MagTop, Institute of Physics, Polish Academy of Sciences, al. Lotników 32/46, 02-668 Warsaw, Poland
Wrocław University of Science and Technology, Department of Experimental Physics,
Wybrzeże Wyspiańskiego 27, 50-370 Wrocław, Poland&lt;/p&gt;</description><guid isPermaLink="false">2506.07776v1</guid><pubDate>Mon, 09 Jun 2025 13:50:12 +0000</pubDate></item><item><title>$d$-Wave Flat Fermi Surface in Altermagnets Enables Maximum Charge-to-Spin Conversion</title><link>http://arxiv.org/abs/2506.07703v1</link><description>オルターマグネットは、反強磁性秩序と強磁性のようなスピン分裂を組み合わせたもので、この二重性によって超高速なスピン依存応答が可能になります。このユニークな特性は、従来の磁気メモリ技術におけるスピン移行トルクやスピン軌道トルクのアプローチの根本的な限界を克服し、前例のないスピン流生成の機会を創出します。本研究では、モデル解析と第一原理計算を組み合わせることにより、オルターマグネットにおけるフェルミ面形状と時間反転対称性の破れた（$\mathcal{T}$-odd）スピン流の間の基本的な関係を確立します。平坦なフェルミ面を持つ$d$波オルターマグネットが、電荷-スピン変換効率（CSE）の理論的な上限である100%を達成できることを示します。このメカニズムは、新たに発見された室温オルター磁性金属KV$_2$O$_2$Seで実現されており、電荷中性点において約78%のCSEを示し、RuO$_2$のほぼ2倍であり、$\mathcal{T}$-odd CSEの新たな記録を打ち立てています。電子ドープ下では、この効率はさらに約98%まで増加し、理論的な限界に近づきます。本研究は、フェルミ面形状エンジニアリングによる$\mathcal{T}$-oddスピン流の基本的な理解を深め、次世代のオルターマグネットベースのメモリデバイス開発のための重要な洞察を提供します。

&lt;img src="https://arxiv.org/html/2506.07703v1/x1.png"/&gt;&lt;p&gt;Guozhong Xing, Junwen Lai, Long Liu, Peitao Liu, Tianye Yu, Xing-Qiu Chen, Yan Sun&lt;/p&gt;&lt;p&gt;Institute of Microelectronics, Chinese Academy of Sciences, Beijing, 100029, China
School of Materials Science and Engineering, University of Science and Technology of China, Shenyang 110016, China.
Shenyang National Laboratory for Materials Science, Institute of Metal Research,Chinese Academy of Sciences, Shenyang 110016, China.
University of Chinese Academy of Sciences, Beijing, 100049, China&lt;/p&gt;</description><guid isPermaLink="false">2506.07703v1</guid><pubDate>Mon, 09 Jun 2025 12:41:31 +0000</pubDate></item><item><title>Ferroelectric switching of quantum anomalous Hall effects in MnBi2Te4 films</title><link>http://arxiv.org/abs/2506.07653v1</link><description>強誘電体とトポロジカル物質の統合は、量子材料デバイスの開発を促進する有望な道筋を提供する。本研究では、MnBi2Te4 (MBT) 薄膜と単層 In2Te3 の界面によって形成されるヘテロ構造における、トポロジカル状態と強誘電性の強い結合を探求する。第一原理計算により、In2Te3 の分極方向が MBT/In2Te3 ヘテロ構造の電子バンド構造を強く変化させ、面外分極のスイッチによって誘起されるバンド順序の変化に起因する、量子異常ホール (C = 1) 絶縁体状態と自明 (C = 0) 絶縁体状態の間のトポロジカル相転移さえも引き起こすことが示された。本研究は、再構成可能な量子デバイスの開発を支援し、高度なマイクロエレクトロニクスおよびスピントロニクスシステムの進歩のための新たな可能性を創造する、強誘電体-トポロジカルヘテロ構造の有望な可能性を強調する。

&lt;img src="https://arxiv.org/html/2506.07653v1/x1.png"/&gt;&lt;p&gt;Hongming Weng, Jiaheng Li, Quansheng Wu&lt;/p&gt;&lt;p&gt;Beijing National Laboratory for Condensed Matter Physics and Institute of Physics, Chinese Academy of Sciences, Beijing 100190, China
Songshan Lake Materials Laboratory, Dongguan, Guangdong 523808, China
University of Chinese academy of sciences, Beijing 100049, China&lt;/p&gt;</description><guid isPermaLink="false">2506.07653v1</guid><pubDate>Mon, 09 Jun 2025 11:20:46 +0000</pubDate></item><item><title>Beyond Scaling: Chemical Intuition as Emergent Ability of Universal Machine Learning Interatomic Potentials</title><link>http://arxiv.org/abs/2506.07579v1</link><description>機械学習原子間ポテンシャル（MLIP）は、スケーリング挙動、すなわち訓練性能のべき乗則的な向上を実証することに成功していますが、スケールにおける新たな能力の出現は未だ探求されていません。我々は、MLIPが明示的な教師なしで化学結合の物理的に意味のある局所表現を導き出す能力をどのように発達させるかを調査するために、Edge-wise Emergent Decomposition（E3D）フレームワークを開発しました。分子データ（SPICE~2）で訓練されたE(3)同変ネットワーク（Allegro）を用いることで、訓練されたMLIPが、グローバルなポテンシャルエネルギー地形を分解することにより、結合解離エネルギー（BDE）の表現を自発的に学習することを発見しました。学習されたBDE値は文献と定量的に一致し、そのスケーラビリティは多様な訓練データセットにわたってロバストであることがわかりました。これは、与えられた訓練情報以外にも、化学反応を忠実に捉える根底にある表現の存在を示唆しています。シャノンのエントロピーを利用した我々のE3D分析は、ポテンシャルエネルギー学習の分解可能性、学習のスケーラビリティ、および創発的な化学反応性の間に密接な相互作用があることを明らかにし、より物理的に解釈可能で予測的なシミュレーションに向けたスケーリングの限界と経路に関する新たな洞察を提供します。

&lt;img src="https://arxiv.org/html/2506.07579v1/x1.png"/&gt;&lt;p&gt;CA, Japan
&amp;Aiichiro Nakano Collaboratory for Advanced Computing, Japan &amp;Kohei Shimamura Department of Physics Kumamoto University Kumamoto, Kanagawa, Shinnosuke Hattori Advanced Research Laboratory Sony Group Corporation Atsugi, Simulation University of Southern California Los Angeles, USA, USA &amp;Ken-ichi Nomura Collaboratory for Advanced Computing, USA &amp;Priya Vashishta Collaboratory for Advanced Computing, USA &amp;Rajiv K. Kalia Collaboratory for Advanced Computing&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.07579v1</guid><pubDate>Mon, 09 Jun 2025 09:23:15 +0000</pubDate></item><item><title>Zeeman-type spin splittings in strained d-wave altermagnets</title><link>http://arxiv.org/abs/2506.07447v1</link><description>近年、オルター磁性材料は、強磁性体（例：スピン流）と反強磁性体（例：低迷遊磁場と超高速スピンダイナミクス）の利点を兼ね備えているため、非常に魅力的になっている。対称性の議論から、d波オルター磁性体は、ひずみによって誘起される非相対論的なゼーマン型スピン分裂（ZSS）を示す可能性があることが示唆されるが、理論的、数値的、実験的な正当性は依然として不足している。本研究では、共線スピン点群（SPG）を用いて、対称性解析を行い、ひずみによって誘起される非相対論的なZSSを示す15個のSPGを特定する。これらの15個のSPGは、文献で報告されているd波オルター磁性スピン分裂に関連するケースと一致する。さらに、第一原理数値シミュレーションによって解析を裏付け、2％のせん断ひずみが、CoF2、LiFe2F6、La2O3Mn2Se2のd波オルター磁性半導体において、それぞれ最大177、100、102 meVの大きな非相対論的ZSSを生成することを示す。本研究は、オルター磁性体におけるスピン流を生成するための代替ルートを示唆しており、オルター磁性体ベースのスピントロニクスデバイスの設計に利用できる可能性がある。

&lt;img src=""/&gt;&lt;p&gt;Hong Jian Zhao, Jian Lv, Longju Yu, Wei Zhang, Yahui Zhai&lt;/p&gt;&lt;p&gt;International Center of Future Science, Jilin University, Changchun 130012, China
Key Laboratory of Material Simulation Methods and Software of Ministry of Education, College of Physics, Jilin University, Changchun 130012, China
Key Laboratory of Physics and Technology for Advanced Batteries (Ministry of Education), College of Physics, Jilin University, Changchun 130012, China&lt;/p&gt;</description><guid isPermaLink="false">2506.07447v1</guid><pubDate>Mon, 09 Jun 2025 05:49:49 +0000</pubDate></item></channel></rss>