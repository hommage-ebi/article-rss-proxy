<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>今日のarXiv-AI4Science</title><link>https://hommage-ebi.github.io/article-rss-proxy/</link><description>今日のarXiv-AI4Science</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>ja</language><lastBuildDate>Thu, 12 Jun 2025 03:20:20 +0000</lastBuildDate><item><title>other arxiv papers 2025-06-12</title><link>https://arxiv.org/2025-06-12</link><description>&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09379v1"&gt;Richardson-Gaudin states of non-zero seniority II: Single-reference treatment of strong correlation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09906v1"&gt;Heavier chalcogenofenchones for fundamental gas-phase studies of molecular chirality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09908v1"&gt;Correlative angstrom-scale microscopy and spectroscopy of graphite-water interfaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09960v1"&gt;Refining ensemble $N$-representability of one-body density matrices from partial information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09761v1"&gt;Single Cu Atom Sites on Co3O4 Activate Interfacial Oxygen for Enhanced Reactivity and Selective Gas Sensing at Low Temperature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09971v1"&gt;Quantum block Krylov subspace projector algorithm for computing low-lying eigenenergies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09376v1"&gt;Revisiting Diffusion Models: From Generative Pre-training to One-Step Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09433v1"&gt;Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09454v1"&gt;NDCG-Consistent Softmax Approximation with Accelerated Convergence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09477v1"&gt;On a few pitfalls in KL divergence gradient estimation for RL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09544v1"&gt;STOAT: Spatial-Temporal Probabilistic Causal Inference Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09574v1"&gt;MOORL: A Framework for Integrating Offline-Online Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09593v1"&gt;Beyond Overconfidence: Foundation Models Redefine Calibration in Deep Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09594v1"&gt;Accelerating Large-Scale Regularized High-Order Tensor Recovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09613v1"&gt;SparseSSM: Efficient Selective Structured State Space Models Can Be Pruned in One-Shot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09625v1"&gt;GLGENN: A Novel Parameter-Light Equivariant Neural Networks Architecture Based on Clifford Geometric Algebras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09630v1"&gt;In-Context Bias Propagation in LLM-Based Tabular Data Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09674v1"&gt;Wavelet Scattering Transform and Fourier Representation for Offline Detection of Malicious Clients in Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09682v1"&gt;Wasserstein Hypergraph Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09714v1"&gt;Auto-Compressing Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09738v1"&gt;Towards Multi-modal Graph Large Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09816v1"&gt;Identifiability Challenges in Sparse Linear Ordinary Differential Equations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09824v1"&gt;Weighted Loss Methods for Robust Federated Learning under Data Heterogeneity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09867v1"&gt;Machine Learning-Based Classification of Oils Using Dielectric Properties and Microwave Resonant Sensing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09896v1"&gt;A look at adversarial attacks on radio waveforms from discrete latent space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09901v1"&gt;"What are my options?": Explaining RL Agents with Diverse Near-Optimal Alternatives (Extended)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09923v1"&gt;Apollo: A Posteriori Label-Only Membership Inference Attack Towards Machine Unlearning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09991v1"&gt;Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09347v1"&gt;ErrorEraser: Unlearning Data Bias for Improved Continual Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09366v1"&gt;SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation via Skill Blending&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09368v1"&gt;Anomaly Detection and Generation with Diffusion Models: A Survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09401v1"&gt;A theoretical basis for model collapse in recursive training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09404v1"&gt;Synergizing Reinforcement Learning and Genetic Algorithms for Neural Combinatorial Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09406v1"&gt;Scoop-and-Toss: Dynamic Object Collection for Quadrupedal Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09422v1"&gt;Time-Unified Diffusion Policy with Action Discrimination for Robotic Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09438v1"&gt;Generalization Error Analysis for Attack-Free and Byzantine-Resilient Decentralized Learning with Data Heterogeneity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09441v1"&gt;Attention-Bayesian Hybrid Approach to Modular Multiple Particle Tracking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09451v1"&gt;Safe Screening Rules for Group SLOPE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09457v1"&gt;Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09495v1"&gt;Bridging Online Behavior and Clinical Insight: A Longitudinal LLM-based Study of Suicidality on YouTube Reveals Novel Digital Markers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09499v1"&gt;A Unified Theory of Compositionality, Modularity, and Interpretability in Markov Decision Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09526v1"&gt;Neural Functions for Learning Periodic Signal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09562v1"&gt;TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor Attacks on Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09638v1"&gt;FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09640v1"&gt;Evasion Attacks Against Bayesian Predictive Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09647v1"&gt;Real-Time Network Traffic Forecasting with Missing Data: A Generative Model Approach&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09648v1"&gt;Scaling Laws for Uncertainty in Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09655v1"&gt;DipLLM: Fine-Tuning LLM for Strategic Decision-making in Diplomacy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09660v1"&gt;SyncFed: Time-Aware Federated Learning through Explicit Timestamping and Synchronization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09668v1"&gt;CINeMA: Conditional Implicit Neural Multi-Modal Atlas for a Spatio-Temporal Representation of the Perinatal Brain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09701v1"&gt;TRIDENT: Temporally Restricted Inference via DFA-Enhanced Neural Traversal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09730v1"&gt;Empirical and computer-aided robustness analysis of long-step and accelerated methods in smooth convex optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09742v1"&gt;Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09764v1"&gt;Alice and the Caterpillar: A more descriptive null model for assessing data mining results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09765v1"&gt;Learning to Optimize Package Picking for Large-Scale, Real-World Robot Induction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09769v1"&gt;Load-Aware Training Scheduling for Model Circulation-based Decentralized Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09773v1"&gt;Cross-Channel Unlabeled Sensing over a Union of Signal Subspaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09781v1"&gt;On the Similarities of Embeddings in Contrastive Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09785v1"&gt;A theoretical framework for self-supervised contrastive learning for continuous dependent data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09803v1"&gt;Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09805v1"&gt;Automatic Treatment Planning using Reinforcement Learning for High-dose-rate Prostate Brachytherapy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09813v1"&gt;Metritocracy: Representative Metrics for Lite Benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09832v1"&gt;A Deep Generative Model for the Simulation of Discrete Karst Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09928v1"&gt;Bayesian Probabilistic Matrix Factorization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09955v1"&gt;Canonical Latent Representations in Conditional Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09958v1"&gt;Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09987v1"&gt;A Shortcut-aware Video-QA Benchmark for Physical Understanding via Minimal Video Pairs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09998v1"&gt;Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09338v1"&gt;Know What You Don't Know: Uncertainty Calibration of Process Reward Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09340v1"&gt;RePO: Replay-Enhanced Policy Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09348v1"&gt;Adversarial Surrogate Risk Bounds for Binary Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09350v1"&gt;Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09373v1"&gt;LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09397v1"&gt;SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09434v1"&gt;When Is Diversity Rewarded in Cooperative Multi-Agent Learning?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09508v1"&gt;Efficient Preference-Based Reinforcement Learning: Randomized Exploration Meets Experimental Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09512v1"&gt;A Survey on the Role of Artificial Intelligence and Machine Learning in 6G-V2X Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09516v1"&gt;LLM-Powered CPI Prediction Inference with Online Text Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09532v1"&gt;Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09548v1"&gt;Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09566v1"&gt;From Symbolic to Neural and Back: Exploring Knowledge Graph-Large Language Model Synergies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09645v1"&gt;Learning Efficient and Generalizable Graph Retriever for Knowledge-Graph Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09659v1"&gt;Intent Factored Generation: Unleashing the Diversity in Your Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09681v1"&gt;Assessing the Quality of Denoising Diffusion Models in Wasserstein Distance: Noisy Score and Optimal Bounds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09691v1"&gt;Adding simple structure at inference improves Vision-Language Compositionality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09709v1"&gt;Training-Free Voice Conversion with Factorized Optimal Transport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09733v1"&gt;AtmosMJ: Revisiting Gating Mechanism for AI Weather Forecasting Beyond the Year Scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09792v1"&gt;Incorporating Linguistic Constraints from External Knowledge Source for Audio-Visual Target Speech Extraction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09804v1"&gt;Regularizing Learnable Feature Extraction for Automatic Speech Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09810v1"&gt;Generalizing Supervised Contrastive learning: A Projection Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09851v1"&gt;Advancing Exchange Rate Forecasting: Leveraging Machine Learning and AI for Enhanced Accuracy in Global Financial Markets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09862v1"&gt;Guided Graph Compression for Quantum Graph Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09874v1"&gt;UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09887v1"&gt;Learning single-index models via harmonic decomposition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09902v1"&gt;PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09940v1"&gt;The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09985v1"&gt;V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09988v1"&gt;EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09990v1"&gt;Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09993v1"&gt;Text-Aware Image Restoration with Diffusion Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09997v1"&gt;DGS-LRM: Real-Time Deformable 3D Gaussian Reconstruction From Monocular Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09420v1"&gt;A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09452v1"&gt;Learning Obfuscations Of LLM Embedding Sequences: Stained Glass Transform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09487v1"&gt;BemaGANv2: A Tutorial and Comparative Survey of GAN-based Vocoders for Long-Term Audio Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09650v1"&gt;HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09870v1"&gt;Private Aggregation for Byzantine-Resilient Heterogeneous Federated Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09344v1"&gt;Ming-Omni: A Unified Multimodal Model for Perception and Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09329v1"&gt;Towards Efficient and Effective Alignment of Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09349v1"&gt;OmniDRCA: Parallel Speech-Text Foundation Model via Dual-Resolution Speech Representations and Contrastive Alignment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09351v1"&gt;DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09359v1"&gt;Taming SQL Complexity: LLM-Based Equivalence Evaluation for Text-to-SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09381v1"&gt;Binary classification for perceived quality of headlines and links on worldwide news websites, 2018-2024&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09391v1"&gt;Comparing human and LLM politeness strategies in free production&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09393v1"&gt;A Hierarchical Probabilistic Framework for Incremental Knowledge Tracing in Classroom Settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09424v1"&gt;Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09501v1"&gt;Give Me FP32 or Give Me Death? Challenges and Solutions for Reproducible Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09542v1"&gt;KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09556v1"&gt;MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09558v1"&gt;Gender Bias in English-to-Greek Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09560v1"&gt;Towards Open Foundation Language Model and Corpus for Macedonian: A Low-Resource Language&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09591v1"&gt;Memorization in Language Models through the Lens of Intrinsic Dimension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09627v1"&gt;Benchmarking Debiasing Methods for LLM-based Parameter Estimates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09657v1"&gt;Bridging the Gap Between Open-Source and Proprietary LLMs in Table QA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09669v1"&gt;Query-Level Uncertainty in Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09684v1"&gt;Inv-Entropy: A Fully Probabilistic Framework for Uncertainty Quantification in Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09796v1"&gt;Do LLMs Give Psychometrically Plausible Responses in Educational Assessments?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09833v1"&gt;Error-Guided Pose Augmentation: Enhancing Rehabilitation Exercise Assessment through Targeted Data Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09917v1"&gt;Aspect-Based Opinion Summarization with Argumentation Schemes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09944v1"&gt;Query-Focused Retrieval Heads Improve Long-Context Reasoning and Re-ranking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09967v1"&gt;Resa: Transparent Reasoning Models via SAEs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09975v1"&gt;When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09983v1"&gt;Step-by-step Instructions and a Simple Tabular Output Format Improve the Dependency Parsing Accuracy of LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09992v1"&gt;Large Language Models for Toxic Language Detection in Low-Resource Balkan Languages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09342v1"&gt;Latent Multi-Head Attention for Small Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09367v1"&gt;COGENT: A Curriculum-oriented Framework for Generating Grade-appropriate Educational Content&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09408v1"&gt;Token Constraint Decoding Improves Robustness on Question Answering for Large Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09414v1"&gt;PGDA-KGQA: A Prompt-Guided Generative Framework with Multiple Data Augmentation Strategies for Knowledge Graph Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09428v1"&gt;Improved Supervised Fine-Tuning for Large Language Models to Mitigate Catastrophic Forgetting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09440v1"&gt;GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09450v1"&gt;UniToMBench: Integrating Perspective-Taking to Improve Theory of Mind in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09507v1"&gt;TransXSSM: A Hybrid Transformer State Space Model with Unified Rotary Position Embedding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09521v1"&gt;You Are What You Say: Exploiting Linguistic Content for VoicePrivacy Attacks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09643v1"&gt;Using Sign Language Production as Data Augmentation to enhance Sign Language Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09672v1"&gt;Is Fine-Tuning an Effective Solution? Reassessing Knowledge Editing for Unstructured Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09827v1"&gt;EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09886v1"&gt;Attention Head Embeddings with Trainable Deep Kernels for Hallucination Detection in LLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09890v1"&gt;The Emergence of Abstract Thought in Large Language Models Beyond Any Language&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09942v1"&gt;VerIF: Verification Engineering for Reinforcement Learning in Instruction Following&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09996v1"&gt;From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09331v1"&gt;Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09375v1"&gt;CoLMbo: Speaker Language Model for Descriptive Profiling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09448v1"&gt;OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09513v1"&gt;ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09522v1"&gt;Revisit What You See: Disclose Language Prior in Vision Tokens for Efficient Guided Decoding of LVLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09600v1"&gt;Effective Red-Teaming of Policy-Adherent Agents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09641v1"&gt;Modeling Probabilistic Reduction using Information Theory and Naive Discriminative Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09707v1"&gt;Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09847v1"&gt;Dataset of News Articles with Provenance Metadata for Media Relevance Assessment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09953v1"&gt;Outside Knowledge Conversational Video (OKCV) Dataset -- Dialoguing over Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/2506.09853v1"&gt;Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><guid isPermaLink="false">other-papers-2025-06-12</guid><pubDate>Thu, 12 Jun 2025 12:19:02 +0900</pubDate></item><item><title>ComfyUI-R1: Exploring Reasoning Models for Workflow Generation</title><link>http://arxiv.org/abs/2506.09790v1</link><description>AI生成コンテンツは、モノリシックなモデルからモジュール式のワークフローへと進化しており、特にComfyUIのようなプラットフォームでは、クリエイティブなパイプラインのカスタマイズが可能になっています。しかし、効果的なワークフローを作成するには、多数の専門的なコンポーネントを調整するための高度な専門知識が必要であり、ユーザーにとって急峻な学習曲線となっています。この課題に対処するため、自動ワークフロー生成のための初の大型推論モデルであるComfyUI-R1を導入します。4Kのワークフローのキュレーションされたデータセットから始めて、ノード選択、ワークフロー計画、コードレベルのワークフロー表現を含む、長い思考の連鎖（CoT）推論データを構築します。ComfyUI-R1は、2段階のフレームワークでトレーニングされます。（1）コールドスタートのためのCoTファインチューニング。モデルをComfyUIドメインに適応させます。（2）推論能力を促進するための強化学習。フォーマットの有効性、構造的整合性、ノードレベルの忠実度を保証する、きめ細かいルールメトリックハイブリッド報酬によって誘導されます。実験の結果、当社の7Bパラメータモデルは、97％のフォーマット有効率を達成し、高い合格率、ノードレベルおよびグラフレベルのF1スコアとともに、GPT-4oやClaudeシリーズなどの主要なクローズドソースモデルを使用する従来技術を大幅に上回っています。さらなる分析により、推論プロセスの重要な役割と、ワークフローをコードに変換することの利点が強調されています。定性的な比較により、多様なノードを持つ複雑なワークフローを合成する当社の強みが明らかになり、AIアート制作における長いCoT推論の可能性が強調されています。

&lt;img src="https://arxiv.org/html/2506.09790v1/x1.png"/&gt;&lt;p&gt;Baotian Hu, Kaifu Zhang, Longyue Wang, Min Zhang, Weihua Luo, Xue Yang, Yiyu Wang, Zhenran Xu&lt;/p&gt;&lt;p&gt;Alibaba International Digital Commerce Hangzhou China
Harbin Institute of Technology (Shenzhen) Shenzhen China&lt;/p&gt;</description><guid isPermaLink="false">2506.09790v1</guid><pubDate>Wed, 11 Jun 2025 14:35:15 +0000</pubDate></item><item><title>Causal Climate Emulation with Bayesian Filtering</title><link>http://arxiv.org/abs/2506.09891v1</link><description>従来の気候変動モデルは、地球システム全体の物理プロセスをシミュレートするために、連立方程式の複雑なシステムを使用しています。これらのシミュレーションは計算コストが非常に高く、気候変動の予測やその原因と影響の分析を制限しています。機械学習は、気候モデルからのデータを迅速にエミュレートする可能性を秘めていますが、現在のアプローチでは、物理に基づいた因果関係を組み込むことができません。そこで、本研究では、因果表現学習に基づいた解釈可能な気候モデルエミュレーターを開発します。安定した長期自己回帰エミュレーションのためのベイズフィルターを含む、物理に基づいたアプローチを導き出します。本エミュレーターが正確な気候ダイナミクスを学習することを実証し、現実的な合成データセットと、広く展開されている2つの気候モデルからのデータを用いて、各コンポーネントの重要性を示します。

&lt;img src="https://arxiv.org/html/2506.09891v1/x1.png"/&gt;&lt;p&gt;Sebastian Hickman &amp;Ilija Trajkovic &amp;Julia Kaltenborn &amp;Francis Pelletier &amp;Alex Archibald &amp;Yaniv Gurwicz &amp;Peer Nowack &amp;David Rolnick &amp;Julien Boussard&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.09891v1</guid><pubDate>Wed, 11 Jun 2025 16:00:55 +0000</pubDate></item><item><title>CoRT: Code-integrated Reasoning within Thinking</title><link>http://arxiv.org/abs/2506.09820v1</link><description>o1やDeepSeek-R1のような大規模推論モデル（LRM）は、長い思考連鎖（CoT）を用いた自然言語推論において目覚ましい進歩を見せていますが、複雑な数学的演算を扱う際には非効率的または不正確なままです。計算ツール（例えば、計算ライブラリや数式ソルバー）を通じてこれらの制限に対処することは有望ですが、技術的な課題が生じます。Code Interpreter（CI）はモデルの内部テキスト表現を超えた外部知識をもたらすため、直接的な組み合わせは効率的ではありません。本論文では、LRMがCIを効果的かつ効率的に活用できるように教えるための、事後学習フレームワークであるCoRTを紹介します。最初のステップとして、ヒントエンジニアリングを通じてコード統合された推論データを合成し、データ不足の問題に対処します。ヒントエンジニアリングは、LRM-CIの相互作用を最適化するために、適切な位置に異なるヒントを戦略的に挿入します。30個の高品質なサンプルを手動で作成し、それに基づいて15億から320億のパラメータを持つモデルを、教師ありファインチューニング、拒否ファインチューニング、強化学習を用いて事後学習させます。実験結果は、ヒントエンジニアリングモデルが、5つの困難な数学的推論データセットにおいて、DeepSeek-R1-Distill-Qwen-32BとDeepSeek-R1-Distill-Qwen-1.5Bでそれぞれ4％と8％の絶対的な改善を達成することを示しています。さらに、ヒントエンジニアリングモデルは、自然言語モデルと比較して、320億モデルで約30％、15億モデルで約50％少ないトークンを使用します。モデルとコードはhttps://github.com/ChengpengLi1003/CoRTで入手できます。

&lt;img src=""/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.09820v1</guid><pubDate>Wed, 11 Jun 2025 14:59:02 +0000</pubDate></item><item><title>Natural Language Guided Ligand-Binding Protein Design</title><link>http://arxiv.org/abs/2506.09332v1</link><description>AIタンパク質モデルは、人間の言語指示に従い、望ましい機能（例：リガンドへの結合）を持つタンパク質を設計できるか？特定のリガンドに結合するタンパク質を設計することは、生物学および化学における広範な応用において非常に重要である。従来のAIモデルのほとんどは、タンパク質-リガンド複合体のデータで訓練されているが、実験室での実験の高コストと時間的制約のため、このデータは不足している。対照的に、タンパク質-リガンド相互作用およびリガンド式に関する、人間がキュレーションしたテキスト記述が大量に存在する。本論文では、自然言語指示に従ってリガンド結合タンパク質を設計する、タンパク質生成モデルのファミリーであるInstructProを提案する。InstructProは、望ましい機能のテキスト記述とSMILES形式のリガンド式が与えられると、指定された指示と機能的に一致するタンパク質配列を生成する。モデルアーキテクチャ、トレーニング戦略、およびトレーニングと評価の両方をサポートする大規模データセットInstructProBenchを開発する。InstructProBenchは、(機能記述、リガンド式、タンパク質配列)の9,592,829個のトリプルで構成される。InstructPro-1B（10億パラメータ）とInstructPro-3B（30億パラメータ）の2つのモデルバリアントをトレーニングする。どちらのバリアントも、ProGen2、ESM3、Pinalなどの強力なベースラインを常に上回る性能を示す。特に、InstructPro-1Bは、最高のドッキング成功率（中程度の信頼度で81.52％）と、真の構造と比較して最も低い平均二乗平方根偏差（RMSD）（4.026Å）を達成する。InstructPro-3Bは、平均RMSDをさらに2.527Åに減少させ、InstructProが機能仕様に沿ったリガンド結合タンパク質を生成する能力を実証している。

&lt;img src="https://arxiv.org/html/2506.09332v1/x1.png"/&gt;&lt;p&gt;Zhenqiao Song Language Technologies Institute Carnegie Mellon University &amp;Ramith Hettiarachchi Computational Biology Department Carnegie Mellon University Chuan Li Lambda Lab &amp;Jianwen Xie Lambda Lab &amp;Lei Li Carnegie Mellon University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.09332v1</guid><pubDate>Wed, 11 Jun 2025 02:15:22 +0000</pubDate></item><item><title>EnerBridge-DPO: Energy-Guided Protein Inverse Folding with Markov Bridges and Direct Preference Optimization</title><link>http://arxiv.org/abs/2506.09496v1</link><description>最適なエネルギー安定性を持つタンパク質配列の設計は、タンパク質逆フォールディングにおける重要な課題です。なぜなら、現在の深層学習手法は主に配列回復率の最大化によって訓練されており、生成された配列のエネルギーをしばしば無視しているからです。本研究は、低エネルギーで安定したタンパク質配列を直接生成するモデルを開発することで、この限界を克服することを目的としています。我々は、低エネルギーで高安定性のタンパク質配列の生成に焦点を当てた、新しい逆フォールディングフレームワークであるEnerBridge-DPOを提案します。我々の主な革新は以下の点にあります。第一に、マルコフ橋をDirect Preference Optimization（DPO）と統合し、エネルギーベースの選好を用いてマルコフ橋モデルを微調整します。マルコフ橋は、情報豊富な事前配列から最適化を開始し、DPOに構造的に妥当な配列候補のプールを提供します。第二に、明示的なエネルギー制約損失を導入し、事前配列に基づくDPOのエネルギー駆動の性質を強化し、モデルが豊富な事前知識からエネルギー表現を効果的に学習し、配列エネルギー値を直接予測できるようにすることで、エネルギーランドスケープの定量的な特徴を捉えます。我々の評価は、EnerBridge-DPOが、最先端モデルと同等の配列回復率を維持しながら、より低いエネルギーを持つタンパク質複合体配列を設計でき、様々な配列間の$\Delta \Delta G$値を正確に予測できることを示しています。

&lt;img src="https://arxiv.org/html/2506.09496v1/x1.png"/&gt;&lt;p&gt;Dingyi Rong Shanghai Jiao Tong University &amp;Haotian Lu Shanghai Jiao Tong University Wenzhuo Zheng Shanghai Jiao Tong University Fan Zhang Shanghai Jiao Tong University &amp;Shuangjia Zheng Shanghai Jiao Tong University &amp;Ning Liu Shanghai Jiao Tong University&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.09496v1</guid><pubDate>Wed, 11 Jun 2025 08:12:26 +0000</pubDate></item><item><title>Efficient Prediction of SO(3)-Equivariant Hamiltonian Matrices via SO(2) Local Frames</title><link>http://arxiv.org/abs/2506.09398v1</link><description>物理学、化学、材料科学において重要な役割を果たす、電子構造計算を加速するためのハミルトニアン行列の予測という課題を検討します。ハミルトニアン行列の非対角ブロックとSO(2)局所フレームとの間に内在する関係に着想を得て、高価なSO(3)クレブシュ-ゴルダンテンソル積なしにグローバルなSO(3)同変性を実現する、QHNetV2と呼ばれる斬新で効率的なネットワークを提案します。これは、一連の新しい効率的で強力なSO(2)同変演算を導入し、すべての非対角特徴量の更新とメッセージパッシングをSO(2)局所フレーム内で行うことで、SO(3)テンソル積の必要性を排除することによって実現されます。さらに、対称縮約演算を模倣して、ノード特徴量を融合するために、各ノードのSO(2)局所フレーム内で連続的なSO(2)テンソル積が実行されます。大規模なQH9およびMD17データセットでの広範な実験により、提案モデルが幅広い分子構造および軌道にわたって優れた性能を達成し、その強力な汎化能力が強調されることが示されています。SO(2)局所フレーム上での提案されたSO(2)演算は、電子構造のスケーラブルで対称性を考慮した学習のための有望な方向性を提供します。私たちのコードは、AIRSライブラリの一部としてリリースされる予定です（https://github.com/divelab/AIRS）。

&lt;img src="https://arxiv.org/html/2506.09398v1/x1.png"/&gt;&lt;p&gt;Astronomy, Computer Engineering, Engineering, Haiyang Yu Yuchao Lin Xuan Zhang Department of Computer Science, Texas A&amp;M University, Texas A&amp;M University Department of Electrical, Texas A&amp;M University Department of Materials Science, Texas A&amp;M University Department of Physics&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.09398v1</guid><pubDate>Wed, 11 Jun 2025 05:04:29 +0000</pubDate></item><item><title>QMCTorch: Molecular Wavefunctions with Neural Components for Energy and Force Calculations</title><link>http://arxiv.org/abs/2506.09743v1</link><description>本論文では、小分子系の実空間量子モンテカルロ（QMC）シミュレーションのためのモジュール式フレームワークであるQMCTorchを用いて得られた結果を紹介します。広く普及している深層学習ライブラリPyTorch上に構築されたQMCTorchは、GPUネイティブであり、ニューラルネットワークのバックフロー変換やJastrow因子など、機械学習に着想を得たコンポーネントを波動関数アンザッツに統合し、効率的な最適化アルゴリズムを活用することを可能にします。QMCTorchは、原子軌道指数と分子軌道係数の初期値を提供する、広く使用されている2つの量子化学パッケージ（PySCFとADF）と連携します。本研究では、$H_2$, $LiH$, $Li_2$, および$CO$の4つの分子について、様々な波動関数アンザッツを用いた波動関数最適化の結果を示します。また、それらの解離エネルギー曲線と、これらの曲線に沿った対応する原子間力を計算します。我々の結果は、ベースライン計算と良好な一致を示し、相関エネルギーの大部分を回復しています。QMCTorchは、新しい波動関数アンザッツを迅速に試作し、その性能を評価し、最適化の結果を分析するための、モジュール式で拡張可能なプラットフォームを提供します。

&lt;img src="https://arxiv.org/html/2506.09743v1/extracted/6533062/picture/qmctorch.png"/&gt;&lt;p&gt;Nicolas Renaud Netherlands eScience Center Matrix THREE, Science Park 402 1098 XH Amsterdam, The Netherlands&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><guid isPermaLink="false">2506.09743v1</guid><pubDate>Wed, 11 Jun 2025 13:48:49 +0000</pubDate></item></channel></rss>