{"id": "2505.08164v1", "title": "Sliding and superlubric moiré twisting ferroelectric transition in HfO2", "link": "http://arxiv.org/abs/2505.08164v1", "summary": "Despite progress in HfO2 thin-film ferroelectrics, issues such as fatigue and\nhigh coercive fields persist, and the dynamics of emerging twisted\nferroelectricity remain largely unexplored. Here, we explore how interlayer\nsliding and twisting in bilayer HfO2 enables low barrier switching pathways.\nAmong 144 sliding configurations, two exhibit strong in-plane polarization\n(2360 pC/m) with a low switching barrier of 3.19 meV/atom. Twisting generates\npolar textures associated with moir\\'e patterns and quasi-flat bands, which\ndrive ferroelectricity via a soft zone-center optical mode, as revealed by\nmachine-learning-assisted first-principles calculations. At twist angles of\n21.79{\\deg} and 27.80{\\deg}, switching barriers drop to 0.58 and 0.06 meV/atom,\nindicating superlubric-like ferroelectric transitions. Notably, the 46.83{\\deg}\ntwisted bilayer shows an almost barrier-free polar evolution (0.009 meV/atom),\nattributed to sharply enhanced zone-center phonon linewidths. Our findings\nestablish a moir\\'e-engineered, ultra-low-energy switching route for 2D\nferroelectric applications.", "authors": ["Jie Sun", "Xin Li", "Tianlin Li", "Yu Yun", "Guodong Ren", "Yiheng Shen", "Tengfei Cao", "Li-Min Liu"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-13T01:58:07Z", "summary_ja": "HfO2薄膜強誘電体における進展にもかかわらず、疲労や高い抗電界といった問題が依然として残っており、新たに現れるねじれ強誘電体のダイナミクスはほとんど解明されていない。本研究では、二層HfO2における層間スライドとねじれが、いかに低障壁スイッチング経路を可能にするかを調査する。144のスライド配置のうち、2つが強い面内分極（2360 pC/m）と低いスイッチング障壁（3.19 meV/原子）を示す。ねじれは、モアレパターンと準平坦バンドに関連する分極テクスチャを生成し、機械学習支援第一原理計算によって明らかになったように、ソフトなゾーン中心光学モードを介して強誘電性を駆動する。ねじれ角が21.79°と27.80°の場合、スイッチング障壁はそれぞれ0.58 meV/原子と0.06 meV/原子に低下し、超潤滑のような強誘電性転移を示す。特に、46.83°ねじれた二層は、ゾーン中心フォノン線幅の急激な増強に起因する、ほぼ障壁のない分極進化（0.009 meV/原子）を示す。我々の発見は、2D強誘電体アプリケーションのためのモアレ工学による超低エネルギー・スイッチング経路を確立する。"}
{"id": "2505.08165v1", "title": "Neural Network-Driven Molecular Insights into Alkaline Wet Etching of GaN: Toward Atomistic Precision in Nanostructure Fabrication", "link": "http://arxiv.org/abs/2505.08165v1", "summary": "We present large-scale molecular dynamics (MD) simulations based on a\nmachine-learning interatomic potential to investigate the wet etching behavior\nof various GaN facets in alkaline solution-a process critical to the\nfabrication of nitride-based semiconductor devices. A Behler-Parrinello-type\nneural network potential (NNP) was developed by training on extensive DFT\ndatasets and iteratively refined to capture chemical reactions between GaN and\nKOH. To simulate the wet etching of GaN, we perform NNP-MD simulations using\nthe temperature-accelerated dynamics approach, which accurately reproduces the\nexperimentally observed structural modification of a GaN nanorod during\nalkaline etching. The etching simulations reveal surface-specific morphological\nevolutions: pyramidal etch pits emerge on the $-c$ plane, while truncated\npyramidal pits form on the $+c$ surface. The non-polar m and a surfaces exhibit\nlateral etch progression, maintaining planar morphologies. Analysis of MD\ntrajectories identifies key surface reactions governing the etching mechanisms.\nTo gain deeper insights into the etching kinetics, we conduct enhanced-sampling\nMD simulations and construct free-energy profiles for Ga dissolution, a process\nthat critically influences the overall etching rate. The $-c$, $a$, and $m$\nplanes exhibit moderate activation barriers, indicating the feasibility of\nalkaline wet etching. In contrast, the $+c$ surface displays a significantly\nhigher barrier, illustrating its strong resistance to alkaline etching.\nAdditionally, we show that Ga-O-Ga bridges can form on etched surfaces,\npotentially serving as carrier traps. By providing a detailed atomistic\nunderstanding of GaN wet etching, this work offers valuable guidance for\nsurface engineering in GaN-based device fabrication.", "authors": ["Purun-hanul Kim", "Jeong Min Choi", "Seungwu Han", "Youngho Kang"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-13T02:01:07Z", "summary_ja": "本研究では、窒化物系半導体デバイスの製造に不可欠なプロセスである、アルカリ溶液中における様々なGaNファセットのウェットエッチング挙動を調査するために、機械学習原子間ポテンシャルに基づく大規模分子動力学（MD）シミュレーションを実施した。広範なDFTデータセットで学習し、GaNとKOH間の化学反応を捉えるために反復的に改良された、Behler-Parrinello型ニューラルネットワークポテンシャル（NNP）を開発した。GaNのウェットエッチングをシミュレートするために、温度加速動力学アプローチを用いてNNP-MDシミュレーションを行い、アルカリエッチング中のGaNナノロッドの実験的に観察された構造変化を正確に再現した。エッチングシミュレーションにより、表面特異的な形態変化が明らかになった。すなわち、ピラミッド状のエッチピットが-c面に現れ、切頂ピラミッド状のピットが+c面に形成される。非極性のm面およびa面は、平面形状を維持しながら、横方向のエッチング進行を示す。MD軌道の解析により、エッチングメカニズムを支配する主要な表面反応が特定された。エッチング速度論に関するより深い洞察を得るために、拡張サンプリングMDシミュレーションを実施し、全体的なエッチング速度に大きく影響するGa溶解の自由エネルギープロファイルを構築した。-c面、a面、およびm面は、適度な活性化障壁を示し、アルカリウェットエッチングの実現可能性を示唆している。対照的に、+c面は著しく高い障壁を示し、アルカリエッチングに対する強い抵抗を示している。さらに、エッチングされた表面にGa-O-Gaブリッジが形成され、キャリアトラップとして機能する可能性があることを示した。GaNウェットエッチングの詳細な原子レベルの理解を提供することにより、本研究はGaNベースのデバイス製造における表面エンジニアリングのための貴重な指針を提供する。"}
{"id": "2505.08269v1", "title": "First-principles electron-phonon interactions with self-consistent Hubbard interaction: an application to transparent conductive oxides", "link": "http://arxiv.org/abs/2505.08269v1", "summary": "The ab initio computational method known as Hubbard-corrected density\nfunctional theory (DFT+$U$) captures well ground electronic structures of a set\nof solids that are poorly described by standard DFT alone. Since lattice\ndynamical properties are closely linked to electronic structures, the\nHubbard-corrected density functional perturbation theory (DFPT+$U$) can\ncalculate them at the same level of accuracy. To investigate the effects of $U$\non electron-phonon (el-ph) interactions, we implemented DFPT+$U$ with a\nHartree-Fock-based pseudohybrid functional formalism to determine $U$\nself-consistently and applied our method to compute optical and transport\nproperties of transparent conductive oxides of CdO and ZnO. For CdO, we find\nthat opening a band gap due to $U$ restores the long-range Fr\\\"ohlich\ninteraction and that its calculated mobility and absorption spectrum are in\nexcellent agreement with experiments. For ZnO where a band gap already appears\nat the DFT level, DFPT+$U$ brings the results into much closer alignment with\nexperiment, thus demonstrating improved accuracy of our method in dealing with\nel-ph interactions in these technologically important materials.", "authors": ["Wooil Yang", "Sabyasachi Tiwari", "Feliciano Giustino", "Young-Woo Son"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-13T06:35:05Z", "summary_ja": "Hubbard補正密度汎関数理論（DFT+$U$）として知られる第一原理計算手法は、標準的なDFTだけではうまく記述できない一連の固体の基底電子構造を良好に捉える。格子力学特性は電子構造と密接に関連しているため、Hubbard補正密度汎関数摂動理論（DFPT+$U$）を用いることで、同じレベルの精度でそれらを計算できる。電子-フォノン（el-ph）相互作用に対する$U$の効果を調査するために、Hartree-Fockベースの擬似ハイブリッド汎関数形式を用いて$U$を自己無撞着に決定するDFPT+$U$を実装し、CdOおよびZnOの透明導電性酸化物の光学的および輸送特性を計算するために我々の手法を適用した。CdOの場合、$U$によるバンドギャップの開放が長距離のFröhlich相互作用を回復させ、計算された移動度と吸収スペクトルが実験と非常によく一致することを見出した。DFTレベルですでにバンドギャップが現れるZnOの場合、DFPT+$U$は結果を実験とより密接に一致させ、これらの技術的に重要な材料におけるel-ph相互作用を扱う上での我々の手法の精度向上を実証している。"}
{"id": "2505.08684v1", "title": "First-principles dissociation pathways of BCl$_3$ on the Si(100)-2$\\times$1 surface", "link": "http://arxiv.org/abs/2505.08684v1", "summary": "One of the most promising acceptor precursors for atomic-precision\n$\\delta$-doping of silicon is BCl$_3$. The chemical pathway, and the resulting\nkinetics, through which BCl$_3$ adsorbs and dissociates on silicon, however,\nhas only been partially explained. In this work, we use density functional\ntheory to expand the dissociation reactions of BCl$_3$ to include reactions\nthat take place across multiple silicon dimer rows, and reactions which end in\na bare B atom either at the surface, substituted for a surface silicon, or in a\nsubsurface position. We further simulate resulting scanning tunneling\nmicroscopy images for each of these BCl$_x$ dissociation fragments,\ndemonstrating that they often display distinct features that may allow for\nrelatively confident experimental identification. Finally, we input the full\ndissociation pathway for BCl$_3$ into a kinetic Monte Carlo model, which\nsimulates realistic reaction pathways as a function of environmental conditions\nsuch as pressure and temperature of dosing. We find that BCl$_2$ is broadly\ndominant at low temperatures, while high temperatures and ample space on the\nsilicon surface for dissociation encourage the formation of bridging BCl\nfragments and B substitutions on the surface. This work provides the chemical\nmechanisms for understanding atomic-precision doping of Si with B, enabling a\nnumber of relevant quantum applications such as bipolar nanoelectronics,\nacceptor-based qubits, and superconducting Si.", "authors": ["Quinn T. Campbell", "Shashank Misra", "Jeffrey A. Ivie"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-13T15:44:17Z", "summary_ja": "シリコンの原子精度δドーピングにおいて最も有望なアクセプター前駆体の一つはBCl$_3$である。しかし、BCl$_3$がシリコンに吸着・解離する化学経路と、その結果生じる反応速度については、部分的にしか解明されていない。本研究では、密度汎関数理論を用いて、BCl$_3$の解離反応を拡張し、複数のシリコンダイマー列にまたがる反応や、表面、表面シリコンの置換、または表面下の位置にむき出しのB原子で終わる反応を含めた。さらに、これらのBCl$_x$解離フラグメントそれぞれについて、走査型トンネル顕微鏡像をシミュレーションし、それらがしばしば明確な特徴を示し、比較的確実な実験的同定を可能にすることを示す。最後に、BCl$_3$の完全な解離経路を速度論的モンテカルロモデルに入力し、ドーピングの圧力や温度などの環境条件の関数として現実的な反応経路をシミュレーションする。その結果、低温ではBCl$_2$が広く優勢であり、高温でシリコン表面に十分な解離スペースがある場合は、架橋BClフラグメントの形成と表面でのB置換が促進されることがわかった。本研究は、BによるSiの原子精度ドーピングを理解するための化学的メカニズムを提供し、バイポーラナノエレクトロニクス、アクセプターベースの量子ビット、超伝導Siなど、多くの関連する量子アプリケーションを可能にする。"}
{"id": "2505.08732v1", "title": "The structure and migration of twin boundaries in tetragonal $β$-Sn: an application of machine learning based interatomic potentials", "link": "http://arxiv.org/abs/2505.08732v1", "summary": "Although atomistic simulations have contributed significantly to our\nunderstanding of twin boundary structure and migration in metals and alloys\nwith hexagonal close packed (HCP) crystal structures, few direct atomistic\nstudies of twinning have been conducted for other types of low symmetry\nmaterials, in large part due to a lack of reliable interatomic potentials. In\nthis work, we examine twin boundary structure and migration in a tetragonal\nmaterial, $\\beta$-Sn, comparing high resolution Transmission Electron\nMicroscopy (TEM) images of deformation twins in $\\beta$-Sn to the results of\ndirect atomistic simulations using multiple interatomic potentials. ML-based\npotentials developed in this work are found to give results consistent with our\nexperimental data, revealing faceted twin boundary structures formed by the\nnucleation and motion of twinning disconnections. We use bicrystallographic\nmethods in combination with atomistic simulations to analyze the structure,\nenergy and shear coupled migration of observed twin facets in $\\beta$-Sn. In\nanalogy to Prismatic-Basal (PB/BP) interfaces in HCP metals, we discover low\nenergy asymmetric Prismatic-A-plane (PA/AP) interfaces important to twin growth\nin $\\beta$-Sn. A Moment Tensor Potential (MTP) and Rapid Artificial Neural\nNetwork (RANN) interatomic potential suitable for studying twinning and phase\ntransformations in Sn are made publicly available as part of this work.", "authors": ["Ian Chesser", "Mashroor Nitol", "Esther C. Hessong", "Himanshu Joshi", "Nikhil Admal", "Brandon Runnels", "Daniel N. Blaschke", "Khanh Dang", "Abigail Hunter", "Saryu Fensin"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-13T16:45:32Z", "summary_ja": "原子レベルシミュレーションは、六方最密充填（HCP）結晶構造を持つ金属および合金における双晶境界の構造と移動の理解に大きく貢献してきたが、信頼できる原子間ポテンシャルの不足により、他の種類の低対称性材料における双晶形成の直接的な原子レベル研究はほとんど行われていない。本研究では、正方晶材料であるβ-Snにおける双晶境界の構造と移動を調べ、β-Snにおける変形双晶の高分解能透過型電子顕微鏡（TEM）像と、複数の原子間ポテンシャルを用いた直接的な原子レベルシミュレーションの結果を比較する。本研究で開発された機械学習（ML）ベースのポテンシャルは、実験データと一致する結果を示し、双晶転位の核生成と運動によって形成されるファセット状の双晶境界構造を明らかにする。原子レベルシミュレーションと組み合わせた複結晶学的手法を用いて、β-Snで観察された双晶ファセットの構造、エネルギー、およびせん断結合移動を分析する。HCP金属におけるPrismatic-Basal（PB/BP）界面との類似性から、β-Snにおける双晶成長に重要な低エネルギー非対称Prismatic-A-plane（PA/AP）界面を発見する。Snにおける双晶形成と相転移の研究に適したMoment Tensor Potential（MTP）およびRapid Artificial Neural Network（RANN）原子間ポテンシャルは、本研究の一部として公開される。"}
{"id": "2505.08159v1", "title": "Enhancing the Efficiency of Complex Systems Crystal Structure Prediction by Active Learning Guided Machine Learning Potential", "link": "http://arxiv.org/abs/2505.08159v1", "summary": "Understanding multicomponent complex material systems is essential for design\nof advanced materials for a wide range of technological applications. While\nstate-of-the-art crystal structure prediction (CSP) methods effectively\nidentify new structures and assess phase stability, they face fundamental\nlimitations when applied to complex systems. This challenge stems from the\ncombinatorial explosion of atomic configurations and the vast stoichiometric\nspace, both of which contribute to computational demands that rapidly exceed\npractical feasibility. In this work, we propose a flexible and automated\nworkflow to build a highly generalizable and data-efficient machine learning\npotential (MLP), effectively unlocking the full potential of CSP algorithms.\nThe workflow is validated on both Mg-Ca-H ternary and Be-P-N-O quaternary\nsystems, demonstrating substantial machine learning acceleration in\nhigh-throughput structural optimization and enabling the efficient\nidentification of promising compounds. These results underscore the\neffectiveness of our approach in exploring complex material systems and\naccelerating the discovery of new multicomponent materials.", "authors": ["Jiaxiang Li", "Junwei Feng", "Jie Luo", "Bowen Jiang", "Xiangyu Zheng", "Jian Lv", "Keith Butler", "Hanyu Liu", "Congwei Xie", "Yu Xie", "Yanming Ma"], "category": "cs.LG", "updated": "2025-05-13T01:34:34Z", "summary_ja": "多成分複合材料系の理解は、広範な技術応用における先進材料の設計に不可欠である。最先端の結晶構造予測（CSP）法は、新しい構造の特定と相安定性の評価に効果的であるが、複雑な系に適用する際には根本的な限界に直面する。この課題は、原子配置の組み合わせ爆発と膨大な化学量論空間に起因し、どちらも計算需要を急速に増大させ、現実的な実行可能性を超える。本研究では、高度に汎用化可能でデータ効率の良い機械学習ポテンシャル（MLP）を構築するための、柔軟で自動化されたワークフローを提案し、CSPアルゴリズムの潜在能力を効果的に引き出す。このワークフローは、Mg-Ca-H三元系とBe-P-N-O四元系の両方で検証され、ハイスループット構造最適化における機械学習による大幅な加速を実証し、有望な化合物の効率的な特定を可能にする。これらの結果は、複雑な材料系の探索と新しい多成分材料の発見を加速する上での、我々のアプローチの有効性を強調する。"}
{"id": "2505.08397v1", "title": "Metal-Insulator Transition described by Natural Orbital Functional Theory", "link": "http://arxiv.org/abs/2505.08397v1", "summary": "The metal-insulator transition (MIT) is a fundamental phenomenon in condensed\nmatter physics and a hallmark of strong electronic correlations. Hydrogen-based\nsystems offer a simple yet powerful model for investigating the MIT, as their\ninsulating behavior arises purely from electron-electron interactions. In this\nwork, we study finite hydrogen clusters with cubic geometries using Natural\nOrbital Functional Theory (NOFT), a method capable of accurately describing\ncorrelated systems beyond mean-field approaches. We focus on two key signatures\nof the MIT: the fundamental energy gap and the harmonic average of the atomic\none-particle reduced density matrix. Our results show that NOFT captures the\ntransition from insulating to metallic behavior as the interatomic distance\ndecreases. By extrapolating the energy gap to the thermodynamic limit, we\nestimate a critical distance rc ~ 1.2 Ang, in excellent agreement with quantum\nMonte Carlo benchmarks. These findings demonstrate the reliability of NOFT for\ndescribing strong correlation effects in large-scale models.", "authors": ["Juan Felipe Huan Lew-Yee", "Mario Piris"], "category": "physics.chem-ph", "updated": "2025-05-13T09:52:18Z", "summary_ja": "金属-絶縁体転移（MIT）は凝縮系物理学における基本的な現象であり、強い電子相関の証です。水素をベースとした系は、絶縁体としての振る舞いが純粋に電子-電子相互作用から生じるため、MITを研究するためのシンプルながら強力なモデルを提供します。本研究では、平均場近似を超えた相関系を正確に記述できる手法である自然軌道汎関数理論（NOFT）を用いて、立方体形状を持つ有限の水素クラスターを研究します。MITの2つの重要な指標、すなわち、基本エネルギーギャップと原子の一粒子還元密度行列の調和平均に焦点を当てます。我々の結果は、原子間距離が減少するにつれて、NOFTが絶縁体から金属への振る舞いの転移を捉えることを示しています。エネルギーギャップを熱力学的極限に外挿することにより、量子モンテカルロベンチマークと非常によく一致する臨界距離rc ~ 1.2オングストロームを推定します。これらの発見は、大規模モデルにおける強い相関効果を記述するためのNOFTの信頼性を示しています。"}
{"id": "2505.08383v1", "title": "Simplified, Physically Motivated, and Universally Applicable Range-Separation Tuning", "link": "http://arxiv.org/abs/2505.08383v1", "summary": "Range-separated hybrid functionals with ``ionization energy'' and/or\n``optimal tuning'' of the screening parameter have proven to be among the most\npractical and accurate approaches for describing excited-state properties\nacross a wide range of systems, including condensed matter. However, this\nmethod typically requires multiple self-consistent calculations and can become\ncomputationally expensive and unstable, particularly for extended systems. In\nthis work, we propose a very simple and efficient alternative approach to\ndetermine the screening parameter, based solely on the total electron density\nof the system and the compressibility sum rule of density functional theory\n(DFT). This effective screening parameter achieves remarkable accuracy,\nparticularly for charge-transfer excitations, surpassing the performance of\npreviously suggested alternatives. Because it relies only on the electron\ndensity, the proposed approach is physically transparent and highly practical\nto automate DFT calculations in large and complex systems, including bulk\nsolids, where ``tuning'' is not possible.", "authors": ["Aditi Singh", "Subrata Jana", "Lucian A. Constantin", "Fabio Della Sala", "Prasanjit Samal", "Szymon Śmiga"], "category": "physics.chem-ph", "updated": "2025-05-13T09:30:54Z", "summary_ja": "スクリーニングパラメータの「イオン化エネルギー」および/または「最適チューニング」を用いたレンジ分離ハイブリッド汎関数は、凝縮系を含む広範囲の系における励起状態特性を記述するための最も実用的かつ正確なアプローチの一つであることが証明されている。しかし、この手法は通常、複数の自己無撞着計算を必要とし、特に拡張系においては計算コストが高く、不安定になる可能性がある。本研究では、系の全電子密度と密度汎関数理論（DFT）の圧縮率和則のみに基づいて、スクリーニングパラメータを決定するための非常にシンプルで効率的な代替アプローチを提案する。この有効スクリーニングパラメータは、特に電荷移動励起において、驚くべき精度を達成し、以前に提案された代替案の性能を凌駕する。提案されたアプローチは電子密度のみに依存するため、物理的に透明であり、バルク固体など「チューニング」が不可能な大規模で複雑な系におけるDFT計算を自動化するのに非常に実用的である。"}
{"id": "2505.08762v1", "title": "The Open Molecules 2025 (OMol25) Dataset, Evaluations, and Models", "link": "http://arxiv.org/abs/2505.08762v1", "summary": "Machine learning (ML) models hold the promise of transforming atomic\nsimulations by delivering quantum chemical accuracy at a fraction of the\ncomputational cost. Realization of this potential would enable high-throughout,\nhigh-accuracy molecular screening campaigns to explore vast regions of chemical\nspace and facilitate ab initio simulations at sizes and time scales that were\npreviously inaccessible. However, a fundamental challenge to creating ML models\nthat perform well across molecular chemistry is the lack of comprehensive data\nfor training. Despite substantial efforts in data generation, no large-scale\nmolecular dataset exists that combines broad chemical diversity with a high\nlevel of accuracy. To address this gap, Meta FAIR introduces Open Molecules\n2025 (OMol25), a large-scale dataset composed of more than 100 million density\nfunctional theory (DFT) calculations at the $\\omega$B97M-V/def2-TZVPD level of\ntheory, representing billions of CPU core-hours of compute. OMol25 uniquely\nblends elemental, chemical, and structural diversity including: 83 elements, a\nwide-range of intra- and intermolecular interactions, explicit solvation,\nvariable charge/spin, conformers, and reactive structures. There are ~83M\nunique molecular systems in OMol25 covering small molecules, biomolecules,\nmetal complexes, and electrolytes, including structures obtained from existing\ndatasets. OMol25 also greatly expands on the size of systems typically included\nin DFT datasets, with systems of up to 350 atoms. In addition to the public\nrelease of the data, we provide baseline models and a comprehensive set of\nmodel evaluations to encourage community engagement in developing the\nnext-generation ML models for molecular chemistry.", "authors": ["Daniel S. Levine", "Muhammed Shuaibi", "Evan Walter Clark Spotte-Smith", "Michael G. Taylor", "Muhammad R. Hasyim", "Kyle Michel", "Ilyes Batatia", "Gábor Csányi", "Misko Dzamba", "Peter Eastman", "Nathan C. Frey", "Xiang Fu", "Vahe Gharakhanyan", "Aditi S. Krishnapriyan", "Joshua A. Rackers", "Sanjeev Raja", "Ammar Rizvi", "Andrew S. Rosen", "Zachary Ulissi", "Santiago Vargas", "C. Lawrence Zitnick", "Samuel M. Blau", "Brandon M. Wood"], "category": "physics.chem-ph", "updated": "2025-05-13T17:29:49Z", "summary_ja": "機械学習（ML）モデルは、量子化学的な精度を計算コストのごく一部で実現することにより、原子シミュレーションを変革する可能性を秘めています。この可能性を実現することで、広大な化学空間を探求するためのハイスループットかつ高精度の分子スクリーニングキャンペーンが可能になり、これまでアクセスできなかったサイズと時間スケールでの第一原理計算が促進されます。しかし、分子化学全体で優れた性能を発揮するMLモデルを作成する上での根本的な課題は、トレーニングのための包括的なデータが不足していることです。データ生成における多大な努力にもかかわらず、広範な化学的多様性と高レベルの精度を兼ね備えた大規模な分子データセットは存在しません。このギャップを埋めるために、Meta FAIRはOpen Molecules 2025（OMol25）を発表します。これは、$\\omega$B97M-V/def2-TZVPDレベルの密度汎関数理論（DFT）計算を1億件以上含む大規模なデータセットであり、数十億CPUコア時間の計算量を表しています。OMol25は、83元素、広範囲の分子内および分子間相互作用、明示的な溶媒和、可変電荷/スピン、コンフォーマー、反応性構造など、元素、化学、構造の多様性を独自に組み合わせています。OMol25には、小分子、生体分子、金属錯体、電解質など、既存のデータセットから取得した構造を含む、約8300万のユニークな分子系が含まれています。OMol25はまた、DFTデータセットに通常含まれる系のサイズを大幅に拡張し、最大350原子の系を扱います。データの公開に加えて、分子化学のための次世代MLモデルの開発におけるコミュニティの参加を促すために、ベースラインモデルと包括的なモデル評価を提供します。"}
{"id": "2505.08357v1", "title": "Hamiltonian replica exchange augmented with diffusion-based generative models and importance sampling to assess biomolecular conformational basins and barriers", "link": "http://arxiv.org/abs/2505.08357v1", "summary": "Enhanced sampling techniques are essential for exploring biomolecular\nconformational dynamics that occur on timescales inaccessible to conventional\nmolecular dynamics (MD) simulations. This study introduces a framework that\ncombines Hamiltonian replica exchange (REST2) with denoising diffusion\nprobabilistic models (DDPMs) and importance sampling to enhance the mapping of\nconformational free-energy landscapes. Building on previous applications of\nDDPMs to temperature replica exchange (TREM), we propose two key improvements.\nFirst, we adapt the method to REST2 by treating potential energy as a\nfluctuating variable. This adaptation allows for more efficient sampling in\nlarge biomolecular systems. Second, to further improve resolution in\nhigh-barrier regions, we develop an iterative scheme combining replica\nexchange, DDPM, and importance sampling along known collective variables.\nBenchmarking on the mini-protein CLN025 demonstrates that DDPM-refined REST2\nachieves comparable accuracy to TREM while requiring fewer replicas.\nApplication to the enzyme PTP1B reveals a loop transition pathway consistent\nwith prior complex biased simulations, showcasing the approach's ability to\nuncover high-barrier transitions with minimal computational overhead with\nrespect to conventional replica exchange approaches. Overall, this hybrid\nstrategy enables more efficient exploration of free-energy landscapes,\nexpanding the utility of generative models in enhanced sampling simulations.", "authors": ["Zakarya Benayad", "Guillaume Stirnemann"], "category": "physics.chem-ph", "updated": "2025-05-13T09:02:28Z", "summary_ja": "強化されたサンプリング技術は、従来の分子動力学（MD）シミュレーションではアクセスできない時間スケールで起こる生体分子の構造ダイナミクスを探索するために不可欠である。本研究では、ハミルトニアンレプリカ交換（REST2）と、ノイズ除去拡散確率モデル（DDPM）および重点サンプリングを組み合わせ、構造自由エネルギー地形図のマッピングを強化するフレームワークを紹介する。DDPMの温度レプリカ交換（TREM）への以前の応用に基づき、2つの重要な改善点を提案する。第一に、ポテンシャルエネルギーを変動変数として扱うことで、この手法をREST2に適応させる。この適応により、大規模な生体分子系においてより効率的なサンプリングが可能になる。第二に、高障壁領域の解像度をさらに向上させるために、既知の集団変数に沿ってレプリカ交換、DDPM、および重点サンプリングを組み合わせた反復スキームを開発する。ミニタンパク質CLN025でのベンチマークにより、DDPMで洗練されたREST2は、より少ないレプリカ数でTREMと同等の精度を達成することが示された。酵素PTP1Bへの適用では、以前の複雑なバイアスシミュレーションと一致するループ遷移経路が明らかになり、従来型のレプリカ交換手法と比較して最小限の計算オーバーヘッドで高障壁遷移を明らかにするこのアプローチの能力が示された。全体として、このハイブリッド戦略により、自由エネルギー地形図のより効率的な探索が可能になり、強化されたサンプリングシミュレーションにおける生成モデルの有用性が拡大する。"}
{"id": "2505.08195v1", "title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations", "link": "http://arxiv.org/abs/2505.08195v1", "summary": "We have developed Aitomia - a platform powered by AI to assist in performing\nAI-driven atomistic and quantum chemical (QC) simulations. This intelligent\nassistant platform is equipped with chatbots and AI agents to help experts and\nguide non-experts in setting up and running the atomistic simulations,\nmonitoring their computation status, analyzing the simulation results, and\nsummarizing them for the user in text and graphical forms. We achieve these\ngoals by exploiting fine-tuned open-source large language models (LLMs),\nrule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia\nleverages the versatility of our MLatom ecosystem for AI-enhanced computational\nchemistry. This intelligent assistant is going to be integrated into the\nAitomistic Hub and XACS online computing services, with some functionality\nalready publicly available as described at http://mlatom.com/aitomia. Aitomia\nis expected to lower the barrier to performing atomistic simulations,\naccelerating research and development in the relevant fields.", "authors": ["Jinming Hu", "Hassan Nawaz", "Yuting Rui", "Lijie Chi", "Arif Ullah", "Pavlo O. Dral"], "category": "cs.LG", "updated": "2025-05-13T03:11:41Z", "summary_ja": "我々は、AI駆動の原子・量子化学(QC)シミュレーションの実行を支援するAI搭載プラットフォーム、Aitomiaを開発しました。このインテリジェントなアシスタントプラットフォームは、チャットボットとAIエージェントを備えており、専門家が原子シミュレーションのセットアップと実行を行い、計算状況を監視し、シミュレーション結果を分析し、テキストおよびグラフィカル形式でユーザーに要約するのを支援し、非専門家をガイドします。これらの目標は、ファインチューニングされたオープンソースの大規模言語モデル(LLM)、ルールベースのエージェント、および検索拡張生成(RAG)システムを活用することで達成されます。Aitomiaは、AI強化された計算化学のためのMLatomエコシステムの汎用性を活用しています。このインテリジェントなアシスタントは、Aitomistic HubおよびXACSオンラインコンピューティングサービスに統合される予定であり、一部の機能はhttp://mlatom.com/aitomiaで説明されているように既に公開されています。Aitomiaは、原子シミュレーションの実行への障壁を下げ、関連分野の研究開発を加速することが期待されます。"}
{"id": "2505.08174v1", "title": "$\\mathcal{H}$-HIGNN: A Scalable Graph Neural Network Framework with Hierarchical Matrix Acceleration for Simulation of Large-Scale Particulate Suspensions", "link": "http://arxiv.org/abs/2505.08174v1", "summary": "We present a fast and scalable framework, leveraging graph neural networks\n(GNNs) and hierarchical matrix ($\\mathcal{H}$-matrix) techniques, for\nsimulating large-scale particulate suspensions, which have broader impacts\nacross science and engineering. The framework draws on the Hydrodynamic\nInteraction Graph Neural Network (HIGNN) that employs GNNs to model the\nmobility tensor governing particle motion under hydrodynamic interactions (HIs)\nand external forces. HIGNN offers several advantages: it effectively captures\nboth short- and long-range HIs and their many-body nature; it realizes a\nsubstantial speedup over traditional methodologies, by requiring only a forward\npass through its neural networks at each time step; it provides explainability\nbeyond black-box neural network models, through direct correspondence between\ngraph connectivity and physical interactions; and it demonstrates\ntransferability across different systems, irrespective of particles' number,\nconcentration, configuration, or external forces. While HIGNN provides\nsignificant speedup, the quadratic scaling of its overall prediction cost (with\nrespect to the total number of particles), due to intrinsically slow-decaying\ntwo-body HIs, limits its scalability. To achieve superior efficiency across all\nscales, in the present work we integrate $\\mathcal{H}$-matrix techniques into\nHIGNN, reducing the prediction cost scaling to quasi-linear. Through\ncomprehensive evaluations, we validate $\\mathcal{H}$-HIGNN's accuracy, and\ndemonstrate its quasi-linear scalability and superior computational efficiency.\nIt requires only minimal computing resources; for example, a single mid-range\nGPU is sufficient for a system containing 10 million particles. Finally, we\ndemonstrate $\\mathcal{H}$-HIGNN's ability to efficiently simulate practically\nrelevant large-scale suspensions of both particles and flexible filaments.", "authors": ["Zhan Ma", "Zisheng Ye", "Ebrahim Safdarian", "Wenxiao Pan"], "category": "physics.comp-ph", "updated": "2025-05-13T02:25:43Z", "summary_ja": "本論文では、科学と工学に広範な影響を与える大規模な粒子懸濁液をシミュレーションするための、高速かつスケーラブルなフレームワークを提案する。このフレームワークは、グラフニューラルネットワーク（GNN）と階層行列（$\\mathcal{H}$-matrix）技術を活用している。具体的には、流体力学的相互作用（HI）と外力下での粒子の運動を支配するモビリティテンソルをGNNでモデル化する、流体力学的相互作用グラフニューラルネットワーク（HIGNN）に基づいている。HIGNNは、短距離および長距離のHIとその多体性を効果的に捉え、各タイムステップでニューラルネットワークの順伝播のみを必要とすることで、従来の手法よりも大幅な高速化を実現し、グラフの接続性と物理的な相互作用との直接的な対応により、ブラックボックスニューラルネットワークモデルを超えた説明可能性を提供し、粒子の数、濃度、構成、または外力に関係なく、異なるシステム間での転移可能性を示す、といったいくつかの利点がある。HIGNNは大幅な高速化を提供するものの、本質的に減衰の遅い二体HIのために、予測コストが粒子総数に対して二次スケールするため、スケーラビリティが制限される。すべてのスケールで優れた効率を実現するために、本研究では$\\mathcal{H}$-matrix技術をHIGNNに統合し、予測コストのスケーリングを準線形に削減する。包括的な評価を通じて、$\\mathcal{H}$-HIGNNの精度を検証し、その準線形スケーラビリティと優れた計算効率を実証する。必要な計算リソースは最小限であり、例えば、1000万個の粒子を含むシステムに対しては、単一の中程度のGPUで十分である。最後に、$\\mathcal{H}$-HIGNNが、粒子と柔軟なフィラメントの両方を含む、実用的に重要な大規模懸濁液を効率的にシミュレーションできる能力を示す。"}
{"id": "2505.08214v1", "title": "Adaptive and hybrid reduced order models to mitigate Kolmogorov barrier in a multiscale kinetic transport equation", "link": "http://arxiv.org/abs/2505.08214v1", "summary": "In this work, we develop reduced order models (ROMs) to predict solutions to\na multiscale kinetic transport equation with a diffusion limit under the\nparametric setting. When the underlying scattering effect is not sufficiently\nstrong, the system governed by this equation exhibits transport-dominated\nbehavior. Suffering from the Kolmogorov barrier for transport-dominant\nproblems, classical linear ROMs may become inefficient in this regime. To\naddress this issue, we first develop a piecewise linear ROM by introducing a\nnovel goal-oriented adaptive time partitioning strategy. To avoid local\nover-refinement or under-refinement, we propose an adaptive coarsening and\nrefinement strategy that remains robust with various initial empirical\npartitions. Additionally, for problems where a local linear approximation is\nnot sufficiently efficient, we further develop a hybrid ROM, which combines\nautoencoder-based nonlinear ROMs and piecewise linear ROMs. Compared to\nprevious autoencoder-based ROMs, this hybridized method reduces the offline\nautoencoder's training cost by only applying it to time intervals that are\nadaptively identified as the most challenging. Numerical experiments\ndemonstrate that our proposed approaches successfully predict full-order\nsolutions at unseen parameter values with both efficiency and accuracy. To the\nbest of our knowledge, this is the first attempt to address the Kolmogorov\nbarrier for multiscale kinetic transport problems with the coexistence of both\ntransport- and diffusion-dominant behaviors.", "authors": ["Tianyu Jin", "Zhichao Peng", "Yang Xiang"], "category": "physics.comp-ph", "updated": "2025-05-13T04:07:47Z", "summary_ja": "本研究では、パラメータ設定下において、拡散限界を持つ多重スケール運動輸送方程式の解を予測するための縮約次数モデル（ROM）を開発する。基礎となる散乱効果が十分に強くない場合、この方程式によって支配されるシステムは輸送支配的な挙動を示す。輸送支配的な問題に対するコルモゴロフ障壁に悩まされるため、古典的な線形ROMはこの領域では非効率になる可能性がある。この問題に対処するため、まず、新しい目標指向の適応的な時間分割戦略を導入することにより、区分的線形ROMを開発する。局所的な過剰な細分化または細分化不足を避けるために、さまざまな初期経験的分割に対してロバストな適応的な粗密化戦略を提案する。さらに、局所的な線形近似が十分に効率的でない問題に対して、自己符号化器ベースの非線形ROMと区分的線形ROMを組み合わせたハイブリッドROMを開発する。以前の自己符号化器ベースのROMと比較して、このハイブリッド化された方法は、最も困難であると適応的に識別された時間間隔にのみ適用することで、オフラインの自己符号化器のトレーニングコストを削減する。数値実験により、提案されたアプローチが、効率と精度の両方で、未知のパラメータ値におけるフルオーダー解を予測することに成功することが示されている。我々の知る限り、これは輸送支配的および拡散支配的な挙動が共存する多重スケール運動輸送問題に対するコルモゴロフ障壁に対処する最初の試みである。"}
{"id": "2505.08446v1", "title": "Agent-as-a-Service based on Agent Network", "link": "http://arxiv.org/abs/2505.08446v1", "summary": "The rise of large model-based AI agents has spurred interest in Multi-Agent\nSystems (MAS) for their capabilities in decision-making, collaboration, and\nadaptability. While the Model Context Protocol (MCP) addresses tool invocation\nand data exchange challenges via a unified protocol, it lacks support for\norganizing agent-level collaboration. To bridge this gap, we propose\nAgent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented\nparadigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN\nunifies the entire agent lifecycle, including construction, integration,\ninteroperability, and networked collaboration, through two core components: (1)\na dynamic Agent Network, which models agents and agent groups as vertexes that\nself-organize within the network based on task and role dependencies; (2)\nservice-oriented agents, incorporating service discovery, registration, and\ninteroperability protocols. These are orchestrated by a Service Scheduler,\nwhich leverages an Execution Graph to enable distributed coordination, context\ntracking, and runtime task management. We validate AaaS-AN on mathematical\nreasoning and application-level code generation tasks, which outperforms\nstate-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN\ncontaining agent groups, Robotic Process Automation (RPA) workflows, and MCP\nservers over 100 agent services. We also release a dataset containing 10,000\nlong-horizon multi-agent workflows to facilitate future research on long-chain\ncollaboration in MAS.", "authors": ["Yuhan Zhu", "Haojie Liu", "Jian Wang", "Bing Li", "Zikang Yin", "Yefei Liao"], "category": "cs.AI", "updated": "2025-05-13T11:15:19Z", "summary_ja": "大規模モデルベースのAIエージェントの台頭は、意思決定、協調、適応能力の観点から、マルチエージェントシステム（MAS）への関心を高めています。モデルコンテキストプロトコル（MCP）は、統一されたプロトコルを通じてツール呼び出しとデータ交換の課題に対処しますが、エージェントレベルの協調を組織化するためのサポートが不足しています。このギャップを埋めるために、Role-Goal-Process-Service（RGPS）標準に基づいたサービス指向パラダイムであるAgent Network（AaaS-AN）に基づくAgent-as-a-Serviceを提案します。AaaS-ANは、構築、統合、相互運用性、ネットワーク化された協調を含むエージェントのライフサイクル全体を、2つの主要なコンポーネントを通じて統合します。（1）動的なエージェントネットワーク。これは、タスクと役割の依存関係に基づいてネットワーク内で自己組織化する頂点としてエージェントとエージェントグループをモデル化します。（2）サービス指向エージェント。これには、サービスディスカバリ、登録、相互運用性プロトコルが組み込まれています。これらは、実行グラフを活用して分散協調、コンテキスト追跡、およびランタイムタスク管理を可能にするサービススケジューラによって調整されます。数学的推論およびアプリケーションレベルのコード生成タスクでAaaS-ANを検証し、最先端のベースラインを上回る性能を示しました。特に、100を超えるエージェントサービスにわたるエージェントグループ、ロボティックプロセスオートメーション（RPA）ワークフロー、およびMCPサーバーを含むAaaS-ANに基づくMASを構築しました。また、MASにおける長期的な協調に関する今後の研究を促進するために、10,000の長期的なマルチエージェントワークフローを含むデータセットも公開します。"}
{"id": "2505.08261v1", "title": "Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration", "link": "http://arxiv.org/abs/2505.08261v1", "summary": "The rapid progress in large language models (LLMs) has paved the way for\nnovel approaches in knowledge-intensive tasks. Among these, Cache-Augmented\nGeneration (CAG) has emerged as a promising alternative to Retrieval-Augmented\nGeneration (RAG). CAG minimizes retrieval latency and simplifies system design\nby preloading knowledge into the model's context. However, challenges persist\nin scaling CAG to accommodate large and dynamic knowledge bases effectively.\nThis paper introduces Adaptive Contextual Compression (ACC), an innovative\ntechnique designed to dynamically compress and manage context inputs, enabling\nefficient utilization of the extended memory capabilities of modern LLMs. To\nfurther address the limitations of standalone CAG, we propose a Hybrid CAG-RAG\nFramework, which integrates selective retrieval to augment preloaded contexts\nin scenarios requiring additional information. Comprehensive evaluations on\ndiverse datasets highlight the proposed methods' ability to enhance\nscalability, optimize efficiency, and improve multi-hop reasoning performance,\noffering practical solutions for real-world knowledge integration challenges.", "authors": ["Rishabh Agrawal", "Himanshu Kumar"], "category": "cs.CL", "updated": "2025-05-13T06:24:48Z", "summary_ja": "大規模言語モデル（LLM）の急速な進歩は、知識集約型タスクにおける新しいアプローチへの道を開きました。中でも、キャッシュ拡張生成（CAG）は、検索拡張生成（RAG）に代わる有望な手法として登場しました。CAGは、知識をモデルのコンテキストに事前にロードすることで、検索遅延を最小限に抑え、システム設計を簡素化します。しかし、CAGを大規模かつ動的な知識ベースに対応させるには、依然として課題が残っています。本論文では、適応的コンテキスト圧縮（ACC）という革新的な手法を紹介します。これは、コンテキスト入力を動的に圧縮および管理し、最新のLLMの拡張されたメモリ機能を効率的に活用できるように設計されています。さらに、スタンドアロンのCAGの限界に対処するために、ハイブリッドCAG-RAGフレームワークを提案します。これは、追加の情報を必要とするシナリオで、事前にロードされたコンテキストを補強するために選択的な検索を統合します。多様なデータセットでの包括的な評価により、提案された手法がスケーラビリティを向上させ、効率を最適化し、マルチホップ推論のパフォーマンスを改善する能力が強調され、現実世界の知識統合の課題に対する実用的なソリューションを提供します。"}
{"id": "2505.08265v1", "title": "LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification", "link": "http://arxiv.org/abs/2505.08265v1", "summary": "The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.", "authors": ["Hang Gao", "Wenxuan Huang", "Fengge Wu", "Junsuo Zhao", "Changwen Zheng", "Huaping Liu"], "category": "cs.LG", "updated": "2025-05-13T06:29:25Z", "summary_ja": "大規模言語モデル（LLM）を特徴量エンハンサーとして利用し、ノード表現を最適化し、それをグラフニューラルネットワーク（GNN）の入力として使用する手法は、グラフ表現学習において大きな可能性を示しています。しかし、このアプローチの基本的な特性は未だ十分に解明されていません。この問題に対処するため、インターチェンジ介入法に基づき、この問題についてより詳細な分析を行うことを提案します。まず、制御可能な因果関係を持つ合成グラフデータセットを構築し、意味的関係と因果モデリングを正確に操作できるようにすることで、分析のためのデータを提供します。このデータセットを用いて、インターチェンジ介入を行い、LLMエンハンサーとGNNのより深い特性を検証し、その根底にあるロジックと内部メカニズムを明らかにします。分析結果に基づいて、LLMエンハンサーとGNN間の情報伝達を改善するためのプラグアンドプレイ最適化モジュールを設計します。複数のデータセットとモデルにわたる実験により、提案されたモジュールが有効であることが検証されました。"}
{"id": "2505.08638v1", "title": "TRAIL: Trace Reasoning and Agentic Issue Localization", "link": "http://arxiv.org/abs/2505.08638v1", "summary": "The increasing adoption of agentic workflows across diverse domains brings a\ncritical need to scalably and systematically evaluate the complex traces these\nsystems generate. Current evaluation methods depend on manual, domain-specific\nhuman analysis of lengthy workflow traces - an approach that does not scale\nwith the growing complexity and volume of agentic outputs. Error analysis in\nthese settings is further complicated by the interplay of external tool outputs\nand language model reasoning, making it more challenging than traditional\nsoftware debugging. In this work, we (1) articulate the need for robust and\ndynamic evaluation methods for agentic workflow traces, (2) introduce a formal\ntaxonomy of error types encountered in agentic systems, and (3) present a set\nof 148 large human-annotated traces (TRAIL) constructed using this taxonomy and\ngrounded in established agentic benchmarks. To ensure ecological validity, we\ncurate traces from both single and multi-agent systems, focusing on real-world\napplications such as software engineering and open-world information retrieval.\nOur evaluations reveal that modern long context LLMs perform poorly at trace\ndebugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our\ndataset and code are made publicly available to support and accelerate future\nresearch in scalable evaluation for agentic workflows.", "authors": ["Darshan Deshpande", "Varun Gangal", "Hersh Mehta", "Jitin Krishnan", "Anand Kannappan", "Rebecca Qian"], "category": "cs.CL", "updated": "2025-05-13T14:55:31Z", "summary_ja": "エージェント型ワークフローの多様な分野での採用拡大に伴い、これらのシステムが生成する複雑なトレースをスケーラブルかつ体系的に評価する必要性が高まっています。現在の評価方法は、手作業によるドメイン固有の人間による長大なワークフローのトレース分析に依存しており、エージェント型出力の複雑さと量の増大に対応できません。これらの設定におけるエラー分析は、外部ツールの出力と言語モデルの推論の相互作用によってさらに複雑になり、従来型のソフトウェアデバッグよりも困難になっています。本研究では、(1) エージェント型ワークフローのトレースに対する堅牢かつ動的な評価手法の必要性を明確にし、(2) エージェント型システムで発生するエラータイプの正式な分類法を導入し、(3) この分類法を用いて構築され、確立されたエージェント型ベンチマークに基づいた、148件の大規模な人間によるアノテーション付きトレースのセット（TRAIL）を提示します。生態学的妥当性を確保するために、ソフトウェアエンジニアリングやオープンワールド情報検索などの現実世界のアプリケーションに焦点を当て、シングルエージェントシステムとマルチエージェントシステムの両方からトレースをキュレーションします。評価の結果、最新の長文脈LLMはトレースのデバッグにおいて性能が低く、最高のGemini-2.5-proモデルでもTRAILでわずか11%のスコアしか得られませんでした。エージェント型ワークフローのスケーラブルな評価に関する今後の研究を支援し加速するために、データセットとコードを公開します。"}
{"id": "2505.08687v1", "title": "AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks", "link": "http://arxiv.org/abs/2505.08687v1", "summary": "Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving\npartial differential equations (PDEs). Yet their original formulation is\ncomputationally and memory intensive, motivating the introduction of Chebyshev\nType-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed\nthe vanilla KANs architecture, our rigorous theoretical analysis reveals that\nthey still suffer from rank collapse, ultimately limiting their expressive\ncapacity. To overcome these limitations, we enhance Chebyshev1KANs by\nintegrating wavelet-activated MLPs with learnable parameters and an internal\nattention mechanism. We prove that this design preserves a full-rank Jacobian\nand is capable of approximating solutions to PDEs of arbitrary order.\nFurthermore, to alleviate the loss instability and imbalance introduced by the\nChebyshev polynomial basis, we externally incorporate a Residual Gradient\nAttention (RGA) mechanism that dynamically re-weights individual loss terms\naccording to their gradient norms and residual magnitudes. By jointly\nleveraging internal and external attention, we present AC-PKAN, a novel\narchitecture that constitutes an enhancement to weakly supervised\nPhysics-Informed Neural Networks (PINNs) and extends the expressive power of\nKANs. Experimental results from nine benchmark tasks across three domains show\nthat AC-PKAN consistently outperforms or matches state-of-the-art models such\nas PINNsFormer, establishing it as a highly effective tool for solving complex\nreal-world engineering problems in zero-data or data-sparse regimes. The code\nwill be made publicly available upon acceptance.", "authors": ["Hangwei Zhang", "Zhimu Huang", "Yan Wang"], "category": "cs.LG", "updated": "2025-05-13T15:46:10Z", "summary_ja": "コルモゴロフ-アーノルドネットワーク（KAN）は、偏微分方程式（PDE）の解法において最近有望性を示している。しかし、その元の構成は計算量とメモリ消費量が大きいため、チェビシェフ第一種に基づくKAN（Chebyshev1KAN）の導入が促された。Chebyshev1KANは従来のKANアーキテクチャよりも優れた性能を発揮しているものの、我々の厳密な理論的分析により、それらは依然としてランク崩壊に苦しみ、最終的にはその表現能力を制限することが明らかになった。これらの制限を克服するために、我々はウェーブレット活性化MLPと学習可能なパラメータ、および内部注意機構を統合することでChebyshev1KANを強化する。この設計がフルランクのヤコビアンを保持し、任意の次数のPDEの解を近似できることを証明する。さらに、チェビシェフ多項式基底によって導入される損失の不安定性と不均衡を軽減するために、勾配ノルムと残差の大きさに従って個々の損失項を動的に再重み付けする残差勾配注意（RGA）機構を外部的に組み込む。内部および外部の注意機構を共同で活用することにより、我々はAC-PKANという新しいアーキテクチャを提示する。これは、弱教師あり物理情報ニューラルネットワーク（PINN）の強化を構成し、KANの表現力を拡張するものである。3つのドメインにわたる9つのベンチマークタスクからの実験結果は、AC-PKANがPINNsFormerなどの最先端モデルを一貫して上回るか、それに匹敵する性能を示しており、ゼロデータまたはデータが少ない状況において、複雑な現実世界のエンジニアリング問題を解決するための非常に効果的なツールとして確立されている。コードは受理され次第公開される予定である。"}
{"id": "2505.08341v1", "title": "Benchmarking AI scientists in omics data-driven biological research", "link": "http://arxiv.org/abs/2505.08341v1", "summary": "The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.", "authors": ["Erpai Luo", "Jinmeng Jia", "Yifan Xiong", "Xiangyu Li", "Xiaobo Guo", "Baoqi Yu", "Lei Wei", "Xuegong Zhang"], "category": "cs.AI", "updated": "2025-05-13T08:33:54Z", "summary_ja": "大規模言語モデルとマルチエージェントシステムの台頭により、自律的な生物学的研究が可能なAI科学者への関心が高まっています。しかし、既存のベンチマークは、データなしの推論に焦点を当てるか、定義済みの統計的回答によるデータ分析に焦点を当てており、現実的なデータ駆動型の評価設定が欠けています。そこで、データ分析と外部知識を用いた推論を通じて、AI科学者が生物学的発見を生み出す能力を評価するために設計されたベンチマーク、Biological AI Scientist Benchmark (BaisBench) を導入します。BaisBenchは、31の専門家によってラベル付けされたシングルセルデータセットに対する細胞型アノテーションと、最近の41のシングルセル研究の生物学的洞察から導き出された198の多肢選択式質問に答えることによる科学的発見という、2つのタスクで構成されています。最先端のAI科学者とLLMエージェントに対する体系的な実験の結果、有望ではあるものの、現在のモデルは両方のタスクにおいて依然として人間の専門家を大幅に下回ることが示されました。BaisBenchがこのギャップを埋め、科学的発見のためのAIモデルの進歩と評価の基礎となることを願っています。ベンチマークは、https://github.com/EperLuo/BaisBench で公開されています。"}
{"id": "2505.08445v1", "title": "Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency", "link": "http://arxiv.org/abs/2505.08445v1", "summary": "Large language models achieve high task performance yet often hallucinate or\nrely on outdated knowledge. Retrieval-augmented generation (RAG) addresses\nthese gaps by coupling generation with external search. We analyse how\nhyperparameters influence speed and quality in RAG systems, covering Chroma and\nFaiss vector stores, chunking policies, cross-encoder re-ranking, and\ntemperature, and we evaluate six metrics: faithfulness, answer correctness,\nanswer relevancy, context precision, context recall, and answer similarity.\nChroma processes queries 13% faster, whereas Faiss yields higher retrieval\nprecision, revealing a clear speed-accuracy trade-off. Naive fixed-length\nchunking with small windows and minimal overlap outperforms semantic\nsegmentation while remaining the quickest option. Re-ranking provides modest\ngains in retrieval quality yet increases runtime by roughly a factor of 5, so\nits usefulness depends on latency constraints. These results help practitioners\nbalance computational cost and accuracy when tuning RAG systems for\ntransparent, up-to-date responses. Finally, we re-evaluate the top\nconfigurations with a corrective RAG workflow and show that their advantages\npersist when the model can iteratively request additional evidence. We obtain a\nnear-perfect context precision (99%), which demonstrates that RAG systems can\nachieve extremely high retrieval accuracy with the right combination of\nhyperparameters, with significant implications for applications where retrieval\nquality directly impacts downstream task performance, such as clinical decision\nsupport in healthcare.", "authors": ["Adel Ammar", "Anis Koubaa", "Omer Nacar", "Wadii Boulila"], "category": "cs.CL", "updated": "2025-05-13T11:13:27Z", "summary_ja": "大規模言語モデルは高いタスク性能を達成するものの、しばしば幻覚を見たり、古い知識に頼ったりする。検索拡張生成（RAG）は、生成と外部検索を組み合わせることで、これらのギャップに対処する。本研究では、ChromaとFaissのベクトルストア、チャンク化ポリシー、クロスエンコーダによる再ランキング、温度など、RAGシステムにおけるハイパーパラメータが速度と品質にどのように影響するかを分析し、忠実性、回答の正確性、回答の関連性、文脈の精度、文脈の再現率、回答の類似性という6つの指標で評価する。Chromaはクエリを13%高速に処理する一方、Faissはより高い検索精度をもたらし、明確な速度と精度のトレードオフが明らかになった。単純な固定長チャンク化は、小さなウィンドウと最小限のオーバーラップで、セマンティックセグメンテーションよりも優れた性能を発揮し、最も高速な選択肢である。再ランキングは検索品質にわずかな改善をもたらすものの、実行時間を約5倍に増加させるため、その有用性はレイテンシの制約に依存する。これらの結果は、RAGシステムを調整して透明性の高い最新の応答を得る際に、計算コストと精度をバランスさせるのに役立つ。最後に、修正的なRAGワークフローを用いて上位の構成を再評価し、モデルが追加の証拠を反復的に要求できる場合でも、それらの利点が持続することを示す。ほぼ完璧な文脈精度（99%）が得られ、RAGシステムが適切なハイパーパラメータの組み合わせによって極めて高い検索精度を達成できることを示しており、医療における臨床意思決定支援など、検索品質が下流のタスク性能に直接影響を与えるアプリケーションにとって重要な意味を持つ。"}
{"id": "2505.08487v1", "title": "An adaptive sampling algorithm for data-generation to build a data-manifold for physical problem surrogate modeling", "link": "http://arxiv.org/abs/2505.08487v1", "summary": "Physical models classically involved Partial Differential equations (PDE) and\ndepending of their underlying complexity and the level of accuracy required,\nand known to be computationally expensive to numerically solve them. Thus, an\nidea would be to create a surrogate model relying on data generated by such\nsolver. However, training such a model on an imbalanced data have been shown to\nbe a very difficult task. Indeed, if the distribution of input leads to a poor\nresponse manifold representation, the model may not learn well and\nconsequently, it may not predict the outcome with acceptable accuracy. In this\nwork, we present an Adaptive Sampling Algorithm for Data Generation (ASADG)\ninvolving a physical model. As the initial input data may not accurately\nrepresent the response manifold in higher dimension, this algorithm iteratively\nadds input data into it. At each step the barycenter of each simplicial\ncomplex, that the manifold is discretized into, is added as new input data, if\na certain threshold is satisfied. We demonstrate the efficiency of the data\nsampling algorithm in comparison with LHS method for generating more\nrepresentative input data. To do so, we focus on the construction of a harmonic\ntransport problem metamodel by generating data through a classical solver. By\nusing such algorithm, it is possible to generate the same number of input data\nas LHS while providing a better representation of the response manifold.", "authors": ["Chetra Mang", "Axel TahmasebiMoradi", "David Danan", "Mouadh Yagoubi"], "category": "cs.LG", "updated": "2025-05-13T12:17:10Z", "summary_ja": "物理モデルは古典的に偏微分方程式（PDE）を含み、その根底にある複雑さや要求される精度に応じて、数値的に解くには計算コストが高くなることが知られています。そこで、そのようなソルバーによって生成されたデータに依存する代替モデルを作成するというアイデアが考えられます。しかし、不均衡なデータでこのようなモデルを訓練することは非常に困難な作業であることが示されています。実際、入力の分布が貧弱な応答多様体表現につながる場合、モデルはうまく学習できず、結果として、許容できる精度で結果を予測できない可能性があります。本研究では、物理モデルを含むデータ生成のための適応サンプリングアルゴリズム（ASADG）を提案します。初期入力データが高次元での応答多様体を正確に表現していない可能性があるため、このアルゴリズムは反復的に入力データを追加します。各ステップで、多様体が離散化される各単体複体の重心が、特定の閾値が満たされた場合に新しい入力データとして追加されます。より代表的な入力データを生成するためのLHS法と比較して、データサンプリングアルゴリズムの効率を実証します。そのために、古典的なソルバーを通じてデータを生成することにより、調和輸送問題メタモデルの構築に焦点を当てます。このようなアルゴリズムを使用することで、LHSと同じ数の入力データを生成しながら、応答多様体のより良い表現を提供することが可能になります。"}
{"id": "2505.08783v1", "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation", "link": "http://arxiv.org/abs/2505.08783v1", "summary": "Partial differential equations (PDEs) are fundamental to modeling physical\nsystems, yet solving them remains a complex challenge. Traditional numerical\nsolvers rely on expert knowledge to implement and are computationally\nexpensive, while neural-network-based solvers require large training datasets\nand often lack interpretability. In this work, we frame PDE solving as a code\ngeneration task and introduce CodePDE, the first inference framework for\ngenerating PDE solvers using large language models (LLMs). Leveraging advanced\ninference-time algorithms and scaling strategies, CodePDE unlocks critical\ncapacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and\ntest-time scaling -- all without task-specific tuning. CodePDE achieves\nsuperhuman performance across a range of representative PDE problems. We also\npresent a systematic empirical analysis of LLM generated solvers, analyzing\ntheir accuracy, efficiency, and numerical scheme choices. Our findings\nhighlight the promise and the current limitations of LLMs in PDE solving,\noffering a new perspective on solver design and opportunities for future model\ndevelopment. Our code is available at https://github.com/LithiumDA/CodePDE.", "authors": ["Shanda Li", "Tanya Marwah", "Junhong Shen", "Weiwei Sun", "Andrej Risteski", "Yiming Yang", "Ameet Talwalkar"], "category": "cs.CL", "updated": "2025-05-13T17:58:08Z", "summary_ja": "偏微分方程式（PDE）は物理システムをモデル化する上で不可欠ですが、その解法は依然として複雑な課題です。従来の数値解法は実装に専門家の知識を必要とし、計算コストも高くなります。一方、ニューラルネットワークに基づく解法は、大規模なトレーニングデータセットを必要とし、解釈可能性に欠けることがよくあります。本研究では、PDEの解法をコード生成タスクとして捉え、大規模言語モデル（LLM）を用いてPDEソルバーを生成する初の推論フレームワークであるCodePDEを導入します。高度な推論時アルゴリズムとスケーリング戦略を活用することで、CodePDEはPDE解法におけるLLMの重要な能力、すなわち、推論、デバッグ、自己改善、テスト時のスケーリングを、タスク固有のチューニングなしに引き出します。CodePDEは、代表的なPDE問題の範囲にわたって、人間を超える性能を達成します。また、LLMによって生成されたソルバーの体系的な実証分析を行い、その精度、効率、数値スキームの選択を分析します。我々の発見は、PDE解法におけるLLMの有望性と現在の限界を浮き彫りにし、ソルバー設計に関する新たな視点と、将来のモデル開発の機会を提供します。我々のコードはhttps://github.com/LithiumDA/CodePDEで入手可能です。"}
{"id": "2505.08410v1", "title": "Understanding molecular ratios in the carbon and oxygen poor outer Milky Way with interpretable machine learning", "link": "http://arxiv.org/abs/2505.08410v1", "summary": "Context. The outer Milky Way has a lower metallicity than our solar\nneighbourhood, but still many molecules are detected in the region. Molecular\nline ratios can serve as probes to better understand the chemistry and physics\nin these regions. Aims. We use interpretable machine learning to study 9\ndifferent molecular ratios, helping us understand the forward connection\nbetween the physics of these environments and the carbon and oxygen\nchemistries. Methods. Using a large grid of astrochemical models generated\nusing UCLCHEM, we study the properties of molecular clouds of low oxygen and\ncarbon initial abundance. We first try to understand the line ratios using a\nclassical analysis. We then move on to using interpretable machine learning,\nnamely Shapley Additive Explanations (SHAP), to understand the higher order\ndependencies of the ratios over the entire parameter grid. Lastly we use the\nUniform Manifold Approximation and Projection technique (UMAP) as a reduction\nmethod to create intuitive groupings of models. Results. We find that the\nparameter space is well covered by the line ratios, allowing us to investigate\nall input parameters. SHAP analysis shows that the temperature and density are\nthe most important features, but the carbon and oxygen abundances are important\nin parts of the parameter space. Lastly, we find that we can group different\ntypes of ratios using UMAP. Conclusions. We show the chosen ratios are mostly\nsensitive to changes in the carbon initial abundance, together with the\ntemperature and density. Especially the CN/HCN and HNC/HCN ratio are shown to\nbe sensitive to the initial carbon abundance, making them excellent probes for\nthis parameter. Out of the ratios, only CS/SO shows a sensitivity to the oxygen\nabundance.", "authors": ["Gijs Vermariën", "Serena Viti", "Johannes Heyl", "Francesco Fontani"], "category": "cs.LG", "updated": "2025-05-13T10:08:37Z", "summary_ja": "背景：天の川銀河の外縁部は太陽近傍よりも金属量が少ないが、それでも多くの分子が検出されている。分子輝線比は、これらの領域の化学と物理をより良く理解するための探針として役立つ。\n\n目的：解釈可能な機械学習を用いて9種類の分子輝線比を研究し、これらの環境の物理と炭素および酸素化学との間の順方向のつながりを理解する。\n\n方法：UCLCHEMを用いて生成された大規模な天体化学モデルのグリッドを用いて、初期の酸素および炭素存在量が少ない分子雲の特性を研究する。まず、古典的な解析を用いて輝線比を理解しようと試みる。次に、解釈可能な機械学習、特にShapley Additive Explanations（SHAP）を用いて、パラメータグリッド全体における輝線比の高次の依存関係を理解する。最後に、Uniform Manifold Approximation and Projection（UMAP）技術を次元削減法として用い、モデルの直感的なグループ化を作成する。\n\n結果：パラメータ空間は輝線比によって十分にカバーされており、すべての入力パラメータを調査できることがわかった。SHAP解析により、温度と密度が最も重要な特徴量であることが示されたが、炭素と酸素の存在量もパラメータ空間の一部で重要である。最後に、UMAPを用いて異なる種類の輝線比をグループ化できることがわかった。\n\n結論：選択された輝線比は、主に初期炭素存在量の変化、および温度と密度に敏感であることが示された。特に、CN/HCN比とHNC/HCN比は初期炭素存在量に敏感であることが示されており、このパラメータの優れた探針となる。輝線比の中で、CS/SOのみが酸素存在量に対する感度を示した。"}
{"id": "2505.08497v1", "title": "A new methodology to decompose a parametric domain using reduced order data manifold in machine learning", "link": "http://arxiv.org/abs/2505.08497v1", "summary": "We propose a new methodology for parametric domain decomposition using\niterative principal component analysis. Starting with iterative principle\ncomponent analysis, the high dimension manifold is reduced to the lower\ndimension manifold. Moreover, two approaches are developed to reconstruct the\ninverse projector to project from the lower data component to the original one.\nAfterward, we provide a detailed strategy to decompose the parametric domain\nbased on the low dimension manifold. Finally, numerical examples of harmonic\ntransport problem are given to illustrate the efficiency and effectiveness of\nthe proposed method comparing to the classical meta-models such as neural\nnetworks.", "authors": ["Chetra Mang", "Axel TahmasebiMoradi", "Mouadh Yagoubi"], "category": "cs.LG", "updated": "2025-05-13T12:25:16Z", "summary_ja": "我々は、反復主成分分析を用いたパラメトリック領域分割のための新しい方法論を提案する。反復主成分分析から始め、高次元多様体を低次元多様体へと縮約する。さらに、低次元データ成分から元のデータ成分へ投影するための逆プロジェクターを再構築する2つのアプローチを開発する。その後、低次元多様体に基づいてパラメトリック領域を分割するための詳細な戦略を提供する。最後に、提案手法の効率性と有効性を、ニューラルネットワークのような古典的なメタモデルと比較するために、調和輸送問題の数値例を示す。"}
{"id": "2505.08740v1", "title": "Sensitivity-Constrained Fourier Neural Operators for Forward and Inverse Problems in Parametric Differential Equations", "link": "http://arxiv.org/abs/2505.08740v1", "summary": "Parametric differential equations of the form du/dt = f(u, x, t, p) are\nfundamental in science and engineering. While deep learning frameworks such as\nthe Fourier Neural Operator (FNO) can efficiently approximate solutions, they\nstruggle with inverse problems, sensitivity estimation (du/dp), and concept\ndrift. We address these limitations by introducing a sensitivity-based\nregularization strategy, called Sensitivity-Constrained Fourier Neural\nOperators (SC-FNO). SC-FNO achieves high accuracy in predicting solution paths\nand consistently outperforms standard FNO and FNO with physics-informed\nregularization. It improves performance in parameter inversion tasks, scales to\nhigh-dimensional parameter spaces (tested with up to 82 parameters), and\nreduces both data and training requirements. These gains are achieved with a\nmodest increase in training time (30% to 130% per epoch) and generalize across\nvarious types of differential equations and neural operators. Code and selected\nexperiments are available at: https://github.com/AMBehroozi/SC_Neural_Operators", "authors": ["Abdolmehdi Behroozi", "Chaopeng Shen and", "Daniel Kifer"], "category": "cs.LG", "updated": "2025-05-13T16:54:10Z", "summary_ja": "du/dt = f(u, x, t, p) の形式のパラメータ付き微分方程式は、科学と工学において基礎的である。フーリエニューラルオペレータ（FNO）のような深層学習フレームワークは効率的に解を近似できるが、逆問題、感度推定（du/dp）、およびコンセプトドリフトに苦戦する。我々は、感度制約付きフーリエニューラルオペレータ（SC-FNO）と呼ばれる、感度に基づく正則化戦略を導入することで、これらの制限に対処する。SC-FNOは、解の経路の予測において高い精度を達成し、標準的なFNOおよび物理情報に基づく正則化を用いたFNOを一貫して上回る性能を示す。パラメータ反転タスクにおける性能を向上させ、高次元パラメータ空間（最大82パラメータでテスト）にスケールし、データとトレーニングの要件を削減する。これらの利点は、トレーニング時間のわずかな増加（エポックあたり30％〜130％）で達成され、さまざまな種類の微分方程式とニューラルオペレータに一般化される。コードと選択された実験は、https://github.com/AMBehroozi/SC_Neural_Operators で入手可能である。"}
{"id": "2505.08683v1", "title": "Uncertainty-Aware Surrogate-based Amortized Bayesian Inference for Computationally Expensive Models", "link": "http://arxiv.org/abs/2505.08683v1", "summary": "Bayesian inference typically relies on a large number of model evaluations to\nestimate posterior distributions. Established methods like Markov Chain Monte\nCarlo (MCMC) and Amortized Bayesian Inference (ABI) can become computationally\nchallenging. While ABI enables fast inference after training, generating\nsufficient training data still requires thousands of model simulations, which\nis infeasible for expensive models. Surrogate models offer a solution by\nproviding approximate simulations at a lower computational cost, allowing the\ngeneration of large data sets for training. However, the introduced\napproximation errors and uncertainties can lead to overconfident posterior\nestimates. To address this, we propose Uncertainty-Aware Surrogate-based\nAmortized Bayesian Inference (UA-SABI) - a framework that combines surrogate\nmodeling and ABI while explicitly quantifying and propagating surrogate\nuncertainties through the inference pipeline. Our experiments show that this\napproach enables reliable, fast, and repeated Bayesian inference for\ncomputationally expensive models, even under tight time constraints.", "authors": ["Stefania Scheurer", "Philipp Reiser", "Tim Brünnette", "Wolfgang Nowak", "Anneli Guthke", "Paul-Christian Bürkner"], "category": "cs.LG", "updated": "2025-05-13T15:44:10Z", "summary_ja": "ベイズ推論は通常、事後分布を推定するために多数のモデル評価に依存します。マルコフ連鎖モンテカルロ（MCMC）や償却ベイズ推論（ABI）のような確立された手法は、計算量的に困難になる可能性があります。ABIは学習後の高速な推論を可能にする一方で、十分な学習データを生成するには依然として数千回のモデルシミュレーションが必要であり、これは計算コストの高いモデルでは実現不可能です。代替モデルは、より低い計算コストで近似シミュレーションを提供することで解決策となり、学習のための大規模なデータセットの生成を可能にします。しかし、導入された近似誤差と不確実性は、過度に自信のある事後推定につながる可能性があります。これに対処するために、我々は不確実性認識型代替モデルベース償却ベイズ推論（UA-SABI）を提案します。これは、代替モデルとABIを組み合わせ、代替モデルの不確実性を明示的に定量化し、推論パイプラインを通じて伝播させるフレームワークです。我々の実験は、このアプローチが、厳しい時間制約下でも、計算コストの高いモデルに対して、信頼性が高く、高速で、反復可能なベイズ推論を可能にすることを示しています。"}
{"id": "2505.08686v1", "title": "CAD-Coder:Text-Guided CAD Files Code Generation", "link": "http://arxiv.org/abs/2505.08686v1", "summary": "Computer-aided design (CAD) is a way to digitally create 2D drawings and 3D\nmodels of real-world products. Traditional CAD typically relies on hand-drawing\nby experts or modifications of existing library files, which doesn't allow for\nrapid personalization. With the emergence of generative artificial\nintelligence, convenient and efficient personalized CAD generation has become\npossible. However, existing generative methods typically produce outputs that\nlack interactive editability and geometric annotations, limiting their\npractical applications in manufacturing. To enable interactive generative CAD,\nwe propose CAD-Coder, a framework that transforms natural language instructions\ninto CAD script codes, which can be executed in Python environments to generate\nhuman-editable CAD files (.Dxf). To facilitate the generation of editable CAD\nsketches with annotation information, we construct a comprehensive dataset\ncomprising 29,130 Dxf files with their corresponding script codes, where each\nsketch preserves both editability and geometric annotations. We evaluate\nCAD-Coder on various 2D/3D CAD generation tasks against existing methods,\ndemonstrating superior interactive capabilities while uniquely providing\neditable sketches with geometric annotations.", "authors": ["Changqi He", "Shuhan Zhang", "Liguo Zhang", "Jiajun Miao"], "category": "cs.LG", "updated": "2025-05-13T15:45:46Z", "summary_ja": "コンピュータ支援設計（CAD）は、現実世界の製品の2D図面や3Dモデルをデジタルで作成する方法です。従来のCADは通常、専門家による手描きや既存のライブラリファイルの修正に依存しており、迅速なパーソナライズには対応できません。生成AIの登場により、便利で効率的なパーソナライズされたCAD生成が可能になりました。しかし、既存の生成手法は通常、インタラクティブな編集機能や幾何学的アノテーションが欠けており、製造における実用的な応用が制限されています。インタラクティブな生成CADを可能にするために、我々はCAD-Coderを提案します。これは、自然言語の指示をCADスクリプトコードに変換し、Python環境で実行して人間が編集可能なCADファイル（.Dxf）を生成するフレームワークです。アノテーション情報付きの編集可能なCADスケッチの生成を促進するために、対応するスクリプトコードを持つ29,130個のDxfファイルからなる包括的なデータセットを構築しました。各スケッチは編集可能性と幾何学的アノテーションの両方を保持しています。既存の手法と比較して、様々な2D/3D CAD生成タスクでCAD-Coderを評価し、優れたインタラクティブ機能を示すとともに、幾何学的アノテーション付きの編集可能なスケッチを独自に提供できることを示しました。"}
{"id": "2505.08402v1", "title": "TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers", "link": "http://arxiv.org/abs/2505.08402v1", "summary": "Recently, large language models(LLMs) have played an increasingly important\nrole in solving a wide range of NLP tasks, leveraging their capabilities of\nnatural language understanding and generating. Integration with external tools\nfurther enhances LLMs' effectiveness, providing more precise, timely, and\nspecialized responses. However, LLMs still encounter difficulties with\nnon-executable actions and improper actions, which are primarily attributed to\nincorrect parameters. The process of generating parameters by LLMs is confined\nto the tool level, employing the coarse-grained strategy without considering\nthe different difficulties of various tools. To address this issue, we propose\nTUMS, a novel framework designed to enhance the tool-use capabilities of LLMs\nby transforming tool-level processing into parameter-level processing.\nSpecifically, our framework consists of four key components: (1) an intent\nrecognizer that identifies the user's intent to help LLMs better understand the\ntask; (2) a task decomposer that breaks down complex tasks into simpler\nsubtasks, each involving a tool call; (3) a subtask processor equipped with\nmulti-structure handlers to generate accurate parameters; and (4) an executor.\nOur empirical studies have evidenced the effectiveness and efficiency of the\nTUMS framework with an average of 19.6\\% and 50.6\\% improvement separately on\neasy and hard benchmarks of ToolQA, meanwhile, we demonstrated the key\ncontribution of each part with ablation experiments, offering more insights and\nstimulating future research on Tool-augmented LLMs.", "authors": ["Aiyao He", "Sijia Cui", "Shuai Xu", "Yanna Wang", "Bo Xu"], "category": "cs.CL", "updated": "2025-05-13T09:57:28Z", "summary_ja": "近年、大規模言語モデル（LLM）は、自然言語の理解と生成能力を活用し、幅広いNLPタスクを解決する上でますます重要な役割を果たしています。外部ツールとの統合は、LLMの有効性をさらに高め、より正確でタイムリーかつ専門的な応答を提供します。しかし、LLMは依然として、実行不可能なアクションや不適切なアクションに遭遇する困難を抱えており、これは主に不正確なパラメータに起因します。LLMによるパラメータ生成のプロセスはツールレベルに限定されており、さまざまなツールの難易度の違いを考慮しない粗い粒度の戦略を採用しています。この問題に対処するために、ツールレベルの処理をパラメータレベルの処理に変換することにより、LLMのツール使用能力を強化するように設計された新しいフレームワークであるTUMSを提案します。具体的には、私たちのフレームワークは、4つの主要なコンポーネントで構成されています。（1）LLMがタスクをより良く理解するのを助けるために、ユーザーの意図を識別する意図認識器、（2）複雑なタスクを、それぞれがツール呼び出しを含むより単純なサブタスクに分解するタスク分解器、（3）正確なパラメータを生成するためのマルチ構造ハンドラーを備えたサブタスクプロセッサ、（4）実行器です。私たちの実証研究は、ToolQAの簡単なベンチマークと難しいベンチマークでそれぞれ平均19.6％と50.6％の改善を示し、TUMSフレームワークの有効性と効率性を証明しました。同時に、アブレーション実験により各部分の重要な貢献を示し、Tool拡張LLMに関するより多くの洞察を提供し、将来の研究を刺激します。"}
{"id": "2505.08450v1", "title": "IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation", "link": "http://arxiv.org/abs/2505.08450v1", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a way to complement the\nin-context knowledge of Large Language Models (LLMs) by integrating external\ndocuments. However, real-world applications demand not only accuracy but also\ninterpretability. While dense retrieval methods provide high accuracy, they\nlack interpretability; conversely, sparse retrieval methods offer transparency\nbut often fail to capture the full intent of queries due to their reliance on\nkeyword matching. To address these issues, we introduce IterKey, an LLM-driven\niterative keyword generation framework that enhances RAG via sparse retrieval.\nIterKey consists of three LLM-driven stages: generating keywords for retrieval,\ngenerating answers based on retrieved documents, and validating the answers. If\nvalidation fails, the process iteratively repeats with refined keywords. Across\nfour QA tasks, experimental results show that IterKey achieves 5% to 20%\naccuracy improvements over BM25-based RAG and simple baselines. Its performance\nis comparable to dense retrieval-based RAG and prior iterative query refinement\nmethods using dense models. In summary, IterKey is a novel BM25-based approach\nleveraging LLMs to iteratively refine RAG, effectively balancing accuracy with\ninterpretability.", "authors": ["Kazuki Hayashi", "Hidetaka Kamigaito", "Shinya Kouda", "Taro Watanabe"], "category": "cs.CL", "updated": "2025-05-13T11:25:15Z", "summary_ja": "検索拡張生成 (RAG) は、大規模言語モデル (LLM) のインコンテキストな知識を外部ドキュメントと統合することで補完する手段として登場しました。しかし、現実世界のアプリケーションでは、精度だけでなく解釈可能性も求められます。高密度検索手法は高い精度を提供する一方で、解釈可能性に欠けます。逆に、疎な検索手法は透明性を提供しますが、キーワードマッチングに依存するため、クエリの意図を完全に捉えられないことがよくあります。これらの問題に対処するため、我々は IterKey という、LLM駆動の反復的なキーワード生成フレームワークを導入し、疎な検索を通じて RAG を強化します。IterKey は、検索のためのキーワード生成、検索されたドキュメントに基づく回答生成、回答の検証という、LLM駆動の3つの段階で構成されています。検証に失敗した場合、プロセスは洗練されたキーワードで反復的に繰り返されます。4つのQAタスクにわたる実験結果は、IterKey が BM25 ベースの RAG および単純なベースラインと比較して、5% から 20% の精度向上を達成することを示しています。その性能は、高密度検索ベースの RAG および高密度モデルを使用した既存の反復的なクエリ改善手法に匹敵します。要するに、IterKey は、LLM を活用して RAG を反復的に洗練し、精度と解釈可能性のバランスを効果的に取る、斬新な BM25 ベースのアプローチです。"}
{"id": "2505.08690v1", "title": "Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation", "link": "http://arxiv.org/abs/2505.08690v1", "summary": "Event extraction (EE) is a fundamental task in natural language processing\n(NLP) that involves identifying and extracting event information from\nunstructured text. Effective EE in real-world scenarios requires two key steps:\nselecting appropriate schemas from hundreds of candidates and executing the\nextraction process. Existing research exhibits two critical gaps: (1) the rigid\nschema fixation in existing pipeline systems, and (2) the absence of benchmarks\nfor evaluating joint schema matching and extraction. Although large language\nmodels (LLMs) offer potential solutions, their schema hallucination tendencies\nand context window limitations pose challenges for practical deployment. In\nresponse, we propose Adaptive Schema-aware Event Extraction (ASEE), a novel\nparadigm combining schema paraphrasing with schema retrieval-augmented\ngeneration. ASEE adeptly retrieves paraphrased schemas and accurately generates\ntargeted structures. To facilitate rigorous evaluation, we construct the\nMulti-Dimensional Schema-aware Event Extraction (MD-SEE) benchmark, which\nsystematically consolidates 12 datasets across diverse domains, complexity\nlevels, and language settings. Extensive evaluations on MD-SEE show that our\nproposed ASEE demonstrates strong adaptability across various scenarios,\nsignificantly improving the accuracy of event extraction.", "authors": ["Sheng Liang", "Hang Lv", "Zhihao Wen", "Yaxiong Wu", "Yongyue Zhang", "Hao Wang", "Yong Liu"], "category": "cs.CL", "updated": "2025-05-13T15:47:54Z", "summary_ja": "イベント抽出（EE）は、非構造化テキストからイベント情報を識別し抽出する、自然言語処理（NLP）における基本的なタスクです。現実世界のシナリオで効果的なEEを実現するには、数百の候補から適切なスキーマを選択し、抽出プロセスを実行するという2つの重要なステップが必要です。既存の研究には、(1)既存のパイプラインシステムにおける硬直的なスキーマ固定、(2)スキーママッチングと抽出の同時評価のためのベンチマークの欠如という2つの重大なギャップがあります。大規模言語モデル（LLM）は潜在的な解決策を提供しますが、スキーマのハルシネーション傾向とコンテキストウィンドウの制限により、実用的な展開には課題があります。これに対し、我々は、スキーマの言い換えとスキーマ検索拡張生成を組み合わせた、新しいパラダイムであるAdaptive Schema-aware Event Extraction（ASEE）を提案します。ASEEは、言い換えられたスキーマを巧みに検索し、ターゲット構造を正確に生成します。厳密な評価を促進するために、Multi-Dimensional Schema-aware Event Extraction（MD-SEE）ベンチマークを構築しました。これは、多様なドメイン、複雑さのレベル、および言語設定にわたる12のデータセットを体系的に統合したものです。MD-SEEでの広範な評価により、提案するASEEはさまざまなシナリオで強力な適応性を示し、イベント抽出の精度を大幅に向上させることが示されています。"}
{"id": "2505.08750v1", "title": "AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models", "link": "http://arxiv.org/abs/2505.08750v1", "summary": "Actual causality (AC), a fundamental aspect of causal reasoning (CR), is\nresponsible for attribution and responsibility assignment in real-world\nscenarios. However, existing LLM-based methods lack grounding in formal AC\ntheory, resulting in limited interpretability. Therefore, we propose AC-Reason,\na semi-formal reasoning framework that identifies causally relevant events\nwithin an AC scenario, infers the values of their formal causal factors (e.g.,\nsufficiency, necessity, and normality), and answers AC queries via a\ntheory-guided algorithm with explanations. While AC-Reason does not explicitly\nconstruct a causal graph, it operates over variables in the underlying causal\nstructure to support principled reasoning. To enable comprehensive evaluation,\nwe introduce AC-Bench, a new benchmark built upon and substantially extending\nBig-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully\nannotated samples, each with detailed reasoning steps and focuses solely on\nactual causation. The case study shows that synthesized samples in AC-Bench\npresent greater challenges for LLMs. Extensive experiments on BBH-CJ and\nAC-Bench show that AC-Reason consistently improves LLM performance over\nbaselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy\nof 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +\nAC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further\nenables fine-grained analysis of reasoning faithfulness, revealing that only\nQwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful\nreasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation\nstudy proves that integrating AC theory into LLMs is highly effective, with the\nproposed algorithm contributing the most significant performance gains.", "authors": ["Yanxi Zhang", "Xin Cong", "Zhong Zhang", "Xiao Liu", "Dongyan Zhao", "Yesai Wu"], "category": "cs.CL", "updated": "2025-05-13T17:02:33Z", "summary_ja": "実際の因果関係（AC）は、因果推論（CR）の基本的な側面であり、現実世界のシナリオにおける帰属と責任の割り当てを担っています。しかし、既存のLLMベースの手法は、形式的なAC理論に根ざしておらず、解釈可能性が限られています。そこで、AC-Reasonという半形式的な推論フレームワークを提案します。これは、ACシナリオ内の因果的に関連するイベントを特定し、それらの形式的な因果因子（例えば、十分性、必要性、正常性）の値を推論し、説明付きの理論に基づいたアルゴリズムを通じてACクエリに答えます。AC-Reasonは明示的に因果グラフを構築しませんが、原理に基づいた推論をサポートするために、基礎となる因果構造の変数上で動作します。包括的な評価を可能にするために、Big-Bench Hard Causal Judgment（BBH-CJ）を基に大幅に拡張した新しいベンチマークであるAC-Benchを導入します。AC-Benchは、詳細な推論ステップを含む約1,000個の慎重にアノテーションされたサンプルで構成され、実際の因果関係のみに焦点を当てています。ケーススタディでは、AC-Benchで合成されたサンプルがLLMにとってより大きな課題を提示することが示されています。BBH-CJとAC-Benchでの広範な実験により、AC-Reasonが一貫してベースラインよりもLLMのパフォーマンスを向上させることが示されています。BBH-CJでは、テストされたすべてのLLMが平均的な人間の評価者の精度69.60%を超え、GPT-4 + AC-Reasonは75.04%を達成しています。AC-Benchでは、GPT-4 + AC-Reasonが再び最高の精度71.82%を達成しています。AC-Benchはさらに、推論の忠実度の詳細な分析を可能にし、Qwen-2.5-72B-Instruct、Claude-3.5-Sonnet、およびGPT-4oのみが忠実な推論を示す一方、GPT-4はショートカットを利用する傾向があることを明らかにしています。最後に、我々のアブレーション研究は、AC理論をLLMに統合することが非常に効果的であり、提案されたアルゴリズムが最も大きなパフォーマンス向上に貢献していることを証明しています。"}
