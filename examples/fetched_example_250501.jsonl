{"id": "2504.21286v1", "title": "NEP89: Universal neuroevolution potential for inorganic and organic\n  materials across 89 elements", "link": "http://arxiv.org/abs/2504.21286v1", "summary": "Machine-learned potentials (MLPs) offer near-first-principles accuracy for\natomistic simulations, but many models are material-specific or computationally\nintensive, limiting their broader use. Here, we introduce NEP89, a foundation\nmodel based on the neuroevolution potential (NEP) architecture, delivering\nempirical-potential-like speed and high accuracy across 89 chemical elements. A\ncompact yet comprehensive training dataset covering inorganic and organic\nmaterials across 89 elements was curated through descriptor-space subsampling\nand an iterative active-learning-like process applied to multiple datasets. We\nrigorously evaluated NEP89's predictive performance against representative\nfoundation models, demonstrating its reliability and competitive accuracy\nacross diverse benchmark studies. NEP89 is 3-4 orders of magnitude more\ncomputationally efficient than comparable models, enabling previously\nimpractical large-scale atomistic simulations for both inorganic and organic\nsystems. It also supports fine-tuning on small datasets, allowing rapid\nadaptation to user-specific applications. This work marks a significant\nadvancement in MLPs, enabling high-performance atomistic simulations across\ndiverse research fields and communities.", "authors": ["Ting Liang", "Ke Xu", "Eric Lindgren", "Zherui Chen", "Rui Zhao", "Jiahui Liu", "Benrui Tang", "Bohan Zhang", "Yanzhou Wang", "Keke Song", "Penghua Ying", "Haikuan Dong", "Shunda Chen", "Paul Erhart", "Zheyong Fan", "Tapio Ala-Nissila", "Jianbin Xu"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T03:36:50Z"}
{"id": "2504.21418v1", "title": "Thermodynamic formulation of the spin magnetic octupole moment in bulk\n  crystals", "link": "http://arxiv.org/abs/2504.21418v1", "summary": "The discovery of unconventional antiferromagnets, such as altermagnets, has\ndrawn significant attention to higher-rank magnetic multipoles. Despite the\nadvances in research, a fundamental understanding of multipole moments,\nparticularly octupole moments, remains limited due to the challenges of\naccurately treating the position operator in bulk crystals, which is integral\nto their definitions. In this paper, we overcome this problem by using a\nthermodynamic relation and derive a formula of the spin magnetic octupole\nmoment (SMOM) that can be used in bulk crystals. The resulting formula is gauge\ninvariant and satisfies St\\v{r}eda formulas, which relate the SMOM to the spin\nmagnetoelectric dipole-quadrupole susceptibilities. Furthermore, we apply this\nformula to several models and examine the fundamental properties of the SMOM.\nOne particularly important property is that the SMOM of $d$-wave altermagnets\nis dominated by nonrelativistic SMOMs regardless of spin-orbit coupling.\nMoreover, these nonrelativistic SMOMs exhibit a N\\'{e}el order dependence that\nis predicted by the Landau theory of $d$-wave altermagnetism [Phys. Rev. Lett.\n$\\textbf{132}$, 176702 (2024)].", "authors": ["Jun Ōiké", "Robert Peters", "Koki Shinada"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T08:20:36Z"}
{"id": "2504.21422v1", "title": "Ultralow-Temperature Thermodynamics and Optical Coherence of Narrow\n  Linewidth Optical Emitters", "link": "http://arxiv.org/abs/2504.21422v1", "summary": "The coherence properties of optical emitters in crystals are critical for\nquantum technologies and optical frequency metrology. Cooling to sub-kelvin\ntemperatures can significantly enhance their coherence, making it essential to\nidentify the key parameters governing emitter and host crystal behavior in this\nultra cold regime. We investigate a Czochralski-grown europium doped yttrium\northosilicate crystal, and we report measurements of the heat capacity, a\nparameter fundamental to evaluating thermal noise limits in metrology schemes\nbased on spectral hole stabilization in such samples. In parallel, we\ncharacterize optical coherence via photon echo measurements as a function of\ntemperature. Below 1 K, where phonon contributions diminish, two-level systems\n(TLS) associated with crystal imperfections may emerge as a limiting factor. A\nlinear-in-temperature term in the heat capacity serves as a signature of TLS,\nand from our data, we establish an upper bound on this contribution. This,\ncombined with the optical homogeneous linewidth from photon-echo measurements\nbeing constant in the interval from 300 mK to 2 K demonstrates a minimal\nTLSrelated effects in our sample. These findings highlight the promise of\nultralow-temperature operation for enhancing the performance of optical quantum\ndevices based on doped crystals.", "authors": ["Thierry Klein", "C Marcenat", "D Serrano", "P Goldner", "M T Hartman", "B Fang", "Y Le Coq", "S Seidelin"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T08:27:58Z"}
{"id": "2504.21462v1", "title": "High-Quality Ultra-Fast Total Scattering and Pair Distribution Function\n  Data using an X-ray Free Electron Laser", "link": "http://arxiv.org/abs/2504.21462v1", "summary": "High-quality total scattering data, a key tool for understanding atomic-scale\nstructure in disordered materials, require stable instrumentation and access to\nhigh momentum transfers. This is now routine at dedicated synchrotron\ninstrumentation using high-energy X-ray beams, but it is very challenging to\nmeasure a total scattering dataset in less than a few microseconds. This limits\ntheir effectiveness for capturing structural changes that occur at the much\nfaster timescales of atomic motion. Current X-ray free-electron lasers (XFELs)\nprovide femtosecond-pulsed X-ray beams with maximum energies of approximately\n24 keV, giving the potential to measure total scattering and the attendant pair\ndistribution functions (PDFs) on femtosecond timescales. Here, we show that\nthis potential has been realised using the HED scientific instrument at the\nEuropean XFEL and present normalised total scattering data for 0.35 \\r{A}-1 < Q\n< 16.6 \\r{A}-1 and their PDFs from a broad spectrum of materials, including\ncrystalline, nanocrystalline and amorphous solids, liquids, and clusters in\nsolution. We analyse the data using a variety of methods, including Rietveld\nrefinement, small-box PDF refinement, joint reciprocal-real space refinement,\ncluster refinement, and Debye scattering analysis. The resolution function of\nthe setup is also thoroughly characterised. We conclusively show that\nhigh-quality data can be obtained from a single approximately 30 fs XFEL pulse.\nOur efforts not only significantly increase the existing maximum reported\nQ-range for an S(Q) measured at an XFEL but also mean that XFELs are now a\nviable X-ray source for the broad community of people using reciprocal space\ntotal scattering and PDF methods in their research.", "authors": ["Adam F. Sapnik", "Philip A. Chater", "Dean S. Keeble", "John S. O. Evans", "Federica Bertolotti", "Antonietta Guagliardi", "Lise J. Støckler", "Elodie A. Harbourne", "Anders B. Borup", "Rebecca S. Silberg", "Adrien Descamps", "Clemens Prescher", "Benjamin D. Klee", "Axel Phelipeau", "Imran Ullah", "Kárel G. Medina", "Tobias A. Bird", "Viktoria Kaznelson", "William Lynn", "Andrew L. Goodwin", "Bo B. Iversen", "Celine Crepisson", "Emil S. Bozin", "Kirsten M. Ø. Jensen", "Emma E. McBride", "Reinhard B. Neder", "Ian Robinson", "Justin Wark", "Michal Andrzejewski", "Ulrike Boesenberg", "Erik Brambrink", "Carolina Camarda", "Valerio Cerantola", "Sebastian Goede", "Hauke Höppner", "Oliver S. Humphries", "Zuzana Konopkova", "Naresh Kujala", "Thomas Michelat", "Motoaki Nakatsutsumi", "Thomas R. Preston", "Lisa Randolph", "Andreas Schmidt", "Cornelius Strohm", "Minxue Tang", "Ulf Zastrau", "Karen Appel", "David A. Keen"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T09:31:22Z"}
{"id": "2504.21588v1", "title": "Theoretical modeling of synergistic effect of pores and grains on\n  transmittance in transparent piezoelectric ceramics", "link": "http://arxiv.org/abs/2504.21588v1", "summary": "Transparent piezoelectric ceramics (TPCs) have great application potential in\nelectro-optical-mechanical multi-functional devices. Preparing high-performance\nTPCs, especially improving the transparency through microstructure regulation,\nhas recently caused extensive discussion. However, there is still controversy\nabout the influence of grains and pores on the transmittance of ceramics, and\nthere is arbitrariness in the estimation of the theoretical transmittance\nlimit. In this paper, taking PMN-PT-based ceramics as an example, theoretical\nmechanisms for the transmittance are discussed. An inhomogeneous reflection\nmodel is derived to improve the theoretical limit of transmittance. The effects\nof pores and grains scattering on transmittance are investigated. Rayleigh and\nRGD approximation are discussed to reveal the underlying scattering mechanisms.\nIt is found that Rayleigh approximation is suitable for describing pore\nscattering, while RGD approximation is suitable for grain scattering. Thus, a\nRayleigh-RGD combined model is proposed to describe light scattering in TPCs\nand successfully employed to fit experimentally measured transmittance curves.", "authors": ["Zixiang Xiong", "Jian Zhu", "Xueqian Geng", "Zheng Wen", "Yongcheng Zhang", "Jianyi Liu"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T12:46:08Z"}
{"id": "2504.21733v1", "title": "The role of terminal groups in non-chiral rod-like compounds on the\n  formation of polar fluids", "link": "http://arxiv.org/abs/2504.21733v1", "summary": "The emergence of ferroelectric mesophases in non-chiral liquid crystal (LCs)\nhas sparked fundamental interest in the molecular mechanisms governing\npolarity. In this study, we investigate how terminal molecular groups influence\nthe formation and stability of polar phases by analyzing six compounds from\nthree homologous series. Specifically, we compare newly synthesized homologs\nwith a nitro group, which predominantly exhibit polar mesophases, to previously\nreported structurally related analogs containing either a cyano group or a\nfluorine atom as terminal fragment. Density Functional Theory (DFT)\ncalculations provide insights into electronic surface potential (ESP)\ndistributions, revealing alternating regions of positive and negative charge\ndensity along the molecular axis, consistent with Madhusudana model of polar\nphase stabilization. We propose the ESP-derived parameter quantifying terminal\nelectrostatic charge, revealing a direct correlation between the negative to\npositive charge ratio at the molecular termini and the formation of\nferroelectric or antiferroelectric mesophases. To validate this hypothesis, we\nanalyze the molecular structure-mesomorphic behavior relationship of other\nknown non-chiral compounds that exhibit polar phases, demonstrating the\ncritical role of terminal groups in determining mesophase polarity. Our\nfindings enhance the understanding of the molecular origins of ferroelectricity\nin non-chiral LCs, paving the way for the rational design of next-generation\nfunctional polar soft materials.", "authors": ["Michał Czerwiński", "Mateusz Mrukiewicz", "Mateusz Filipow", "Damian Pociecha", "Natalia Podoliak", "Dalibor Repcek", "Monika Zając", "Dorota Węgłowska"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T15:22:39Z"}
{"id": "2505.00074v1", "title": "SDW driven \"magnetic breakdown\" in a d-wave altermagnet KV$_2$Se$_2$O", "link": "http://arxiv.org/abs/2505.00074v1", "summary": "Altermagnets, combining zero net magnetization with intrinsic spin splitting,\ndemonstrate unique quantum phenomena crucial for spintronic applications.\nKV$_2$Se$_2$O is proven to be a d-wave altermagnet with phase transition from a\ncheckerboard-type (C-type) antiferromagnetic (AFM) state to a spin density wave\n(SDW) state as the temperature decreases. After phase transition, the apparent\nparadox emerges where angle-resolved photoemission spectroscopy (ARPES) reveals\nnegligible Fermi surface modifications, while physical property measurement\nsystem (PPMS) measurements uncover substantial changes in transport properties.\nOur study explores the microscopic mechanisms governing phase-dependent\ntransport properties of KV$_2$Se$_2$O base on first-principles calculations.\nThe spin canting driven by periodic spin modulation in the SDW phase reduces\nthe magnetic symmetry of KV$_2$Se$_2$O. The resultant band degeneracy lifting\nand Fermi surface reconstruction induce the ``magnetic breakdown\" phenomenon,\nwhich alters carrier trajectories, modifies carrier concentration, strengthens\nelectron-hole compensation, and ultimately accounts for the contrasting\nmagnetic-field-dependent Hall resistivity relative to the C-type AFM state. Our\nwork proposes an innovative method for identifying the electronic structure\nevolution across phase transitions from transport signatures, providing a novel\nparadigm for altermagnets research.", "authors": ["Xu Yan", "Ziyin Song", "Juntao Song", "Zhong Fang", "Hongming Weng", "Quansheng Wu"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T18:00:02Z"}
{"id": "2505.00076v1", "title": "Materials discovery acceleration by using condition generative\n  methodology", "link": "http://arxiv.org/abs/2505.00076v1", "summary": "With the rapid advancement of AI technologies, generative models have been\nincreasingly employed in the exploration of novel materials. By integrating\ntraditional computational approaches such as density functional theory (DFT)\nand molecular dynamics (MD), existing generative models, including diffusion\nmodels and autoregressive models, have demonstrated remarkable potential in the\ndiscovery of novel materials. However, their efficiency in goal-directed\nmaterials design remains suboptimal. In this work we developed a highly\ntransferable, efficient and robust conditional generation framework, PODGen, by\nintegrating a general generative model with multiple property prediction\nmodels. Based on PODGen, we designed a workflow for the high-throughput\ncrystals conditional generation which is used to search new topological\ninsulators (TIs). Our results show that the success rate of generating TIs\nusing our framework is 5.3 times higher than that of the unconstrained\napproach. More importantly, while general methods rarely produce gapped TIs,\nour framework succeeds consistently, highlighting an effectively $\\infty$\nimprovement. This demonstrates that conditional generation significantly\nenhances the efficiency of targeted material discovery. Using this method, we\ngenerated tens of thousands of new topological materials and conducted further\nfirst-principles calculations on those with promising application potential.\nFurthermore, we identified promising, synthesizable topological (crystalline)\ninsulators such as CsHgSb, NaLaB$_{12}$, Bi$_4$Sb$_2$Se$_3$, Be$_3$Ta$_2$Si and\nBe$_2$W.", "authors": ["Caiyuan Ye", "Yuzhi Wang", "Xintian Xie", "Tiannian Zhu", "Jiaxuan Liu", "Yuqing He", "Lili Zhang", "Junwei Zhang", "Zhong Fang", "Lei Wang", "Zhipan Liu", "Hongming Weng", "Quansheng Wu"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T18:00:03Z"}
{"id": "2504.21246v1", "title": "Rate Analysis of Dislocations Overcoming Elastic Barriers: Effects of\n  Entropy and Langevin Friction via Kramers Theory", "link": "http://arxiv.org/abs/2504.21246v1", "summary": "Thermal activation of dislocations is critical for predicting the mechanical\nresponse of materials under common experimental conditions. According to\ntransition state theory (TST), the rate for the system to overcome free energy\nbarriers depends on an attempt frequency, activation free energy, and\ntemperature. We computed the rate for edge and screw dislocation dipoles to\novercome their interaction fields at various temperatures, Langevin friction\ncoefficients, and shear stresses using Molecular Dynamics (MD), Schoeck entropy\nformalism and compared with Kramers rate theory. Rates computed dynamically\nshow dependence on Langevin friction, increasing with weaker friction and\nshowing more correlated events. Statically, using Schoeck formalism and\ncomputing the minimum energy path (MEP), we found significant entropic effects\nat high temperature and a transition from Arrhenius to non-Arrhenius behavior\nnear the critical resolved shear stress values for both edge and screw\ncharacters.", "authors": ["Mohammadhossein Nahavandian", "Liam Myhill", "Enrique Martinez"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T01:03:50Z"}
{"id": "2504.21331v2", "title": "Towards Space Group Determination from EBSD Patterns: The Role of Deep\n  Learning and High-throughput Dynamical Simulations", "link": "http://arxiv.org/abs/2504.21331v2", "summary": "The design of novel materials hinges on the understanding of\nstructure-property relationships. However, in recent times, our capability to\nsynthesize a large number of materials has outpaced our speed at characterizing\nthem. While the overall chemical constituents can be readily known during\nsynthesis, the structural evolution and characterization of newly synthesized\nsamples remains a bottleneck for the ultimate goal of high throughput\nnanomaterials discovery. Thus, scalable methods for crystal symmetry\ndetermination that can analyze a large volume of material samples within a\nshort time-frame are especially needed. Kikuchi diffraction in the SEM is a\npromising technique for this due to its sensitivity to dynamical scattering,\nwhich may provide information beyond just the seven crystal systems and\nfourteen Bravais lattices. After diffraction patterns are collected from\nmaterial samples, deep learning methods may be able to classify the space group\nsymmetries using the patterns as input, which paired with the elemental\ncomposition, would help enable the determination of the crystal structure. To\ninvestigate the feasibility of this solution, neural networks were trained to\npredict the space group type of background corrected EBSD patterns. Our\nnetworks were first trained and tested on an artificial dataset of EBSD\npatterns of 5,148 different cubic phases, created through physics-based\ndynamical simulations. Next, Maximum Classifier Discrepancy, an unsupervised\ndeep learning-based domain adaptation method, was utilized to train neural\nnetworks to make predictions for experimental EBSD patterns. We introduce a\nrelabeling scheme, which enables our models to achieve accuracy scores higher\nthan 90% on simulated and experimental data, suggesting that neural networks\nare capable of making predictions of crystal symmetry from an EBSD pattern.", "authors": ["Alfred Yan", "Muhammad Nur Talha Kilic", "Gert Nolze", "Ankit Agrawal", "Alok Choudhary", "Roberto dos Reis", "Vinayak Dravid"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-02T07:38:57Z"}
{"id": "2504.21557v1", "title": "Optimizing carrier balance in CsPbBr3 nanocrystal LEDs: The role of\n  alkyl ligands and polar electron transport layers", "link": "http://arxiv.org/abs/2504.21557v1", "summary": "The study of lead halide perovskite nanocrystal based light-emitting diodes\n(LEDs) has advanced significantly, with notable improvements in stability and\noptical properties. However, optimizing charge carrier injection and transport\nremains a challenge. Efficient electroluminescence requires a balanced\ntransport of both holes and electrons within the emitting material. Here, we\ninvestigate cubic CsPbBr\\textsubscript{3} nanocrystals passivated with\noleylamine and oleic acid, comparing them to ligand-exchanged nanocrystals with\ndidodecyldimethylammonium bromide (DDABr). Nuclear magnetic resonance\nspectroscopy and transmission electron microscopy confirm successful ligand\nexchange, revealing reduced ligand coverage in DDABr-treated nanocrystals.\nPhotoelectron spectroscopy, spectroelectrochemistry, and single-carrier devices\nindicate improved hole injection in DDABr-capped nanocrystals. Density\nfunctional theory calculations further reveal the influence of ligand type and\ncoverage on energy levels, with oleic acid introducing localized states in\nnative nanocrystals. Additionally, incorporation of a polar electron transport\nlayer (ETL) enhances LED performance by over an order of magnitude in\nDDABr-capped nanocrystals, driven by improved charge balance arising from the\nspontaneous orientation polarization (SOP) of the ETL. These findings highlight\nthe critical role of ligand selection, passivation degree, and charge transport\ncontrol by the adjacent organic transport layers in optimizing LED efficiency.", "authors": ["Roshini Jayabalan", "Girish K. Hanumantharaju", "Theresa Hettiger", "Arup Sarkar", "Fengshuo Zu", "Aladin Ullrich", "Norbert Koch", "Denis Andrienko", "Marcus Scheele", "Wolfgang Brütting"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T11:54:43Z"}
{"id": "2504.21651v1", "title": "Pressure and strain effects on the $\\textit{ab initio}$ $GW$ electronic\n  structure of La$_3$Ni$_2$O$_7$", "link": "http://arxiv.org/abs/2504.21651v1", "summary": "The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ at a critical\ntemperature above 80~K points to a non-conventional pairing mechanism in\nnickelates as in cuprates, possibly due to electronic correlations. We have\ncalculated from first principles the electronic structure of La$_3$Ni$_2$O$_7$\nunder the effect of pressure and epitaxial strain including correlations by the\n$GW$ approximation to the many-body self-energy. We find that the Fermi surface\nis composed of a characteristic cuprate-shape sheet $\\beta$ plus a\nnickelate-specific cylinder $\\alpha$, both from Ni $e_g$ orbitals, with a\nnon-negligible drop in the quasiparticle weight and an effective 1D character.\nThis topology results from a delicate balance between the Ni-3$d_{z^2}$ hole\npocket $\\gamma$, which is suppressed by correlations, and an emerging\nLa-5$d_{x^2-y^2}$ electron pocket induced by both correlation and\npressure/strain effects and whose role at low energy has been neglected so far.\nUnlike cuprates, the electronic structure of La$_3$Ni$_2$O$_7$ is already\ncorrectly described from ab initio and in agreement with the experiment without\nthe need to introduce Hubbard $U$ adjustable parameters or to invoke a strongly\ncorrelated physics.", "authors": ["Jean-Baptiste de Vaulx", "Quintin N. Meier", "Pierre Toulemonde", "Andrés Cano", "Valerio Olevano"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T13:55:45Z"}
{"id": "2504.21673v1", "title": "Effect of Magnetic Anisotropy and Gradient-Induced Dzyaloshinskii-Moriya\n  Interaction on the Formation of Magnetic Skyrmions", "link": "http://arxiv.org/abs/2504.21673v1", "summary": "Topological spin textures (e.g. skyrmions) can be stabilized by interfacial\nDzyaloshinskii-Moriya interaction (DMI) in the magnetic multilayer, which has\nbeen intensively studied. Recently, Bloch-type magnetic skyrmions stabilized by\ncomposition gradient-induced DMI (g-DMI) have been observed in 10-nm thick CoPt\nsingle layer. However, magnetic anisotropy in gradient-composition engineered\nCoPt (g-CoPt) films is highly sensitive to both the relative Co/Pt composition\nand the film thickness, leading to a complex interplay with g-DMI. The\nstability of skyrmions under the combined influence of magnetic anisotropy and\ng-DMI is crucial yet remains poorly understood. Here, we conduct a systematic\nstudy on the characteristics of magnetic skyrmions as a function of gradient\npolarity and effective gradient strength (defined as gradient/thickness) in\ng-CoPt single layers (thickness of 10-30 nm) using magnetic force microscopy\n(MFM), bulk magnetometry, and topological Hall effect measurements. Brillouin\nlight scattering confirms that both the sign and magnitude of g-DMI depend on\nthe polarity and amplitude of the composition gradient in g-CoPt films. MFM\nreveals that skyrmion size and density vary with g-CoPt film thickness,\ngradient polarity, and applied magnetic field. An increased skyrmion density is\nobserved in samples exhibiting higher magnetic anisotropy, in agreement with\nmicromagnetic simulations and energy barrier calculations.", "authors": ["Adam Erickson", "Qihan Zhang", "Hamed Vakili", "Edward Schwartz", "Suvechhya Lamichhane", "Chaozhong Li", "Boyu Li", "Dongsheng Song", "Guozhi Chai", "Sy-Hwang Liou", "Alexey A. Kovalev", "Jingsheng Chen", "Abdelghani Laraoui"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T14:13:08Z"}
{"id": "2504.21737v1", "title": "Observation of Intrinsic and LED Light-Enhanced Memristor Performance in\n  In-Plane Ferroelectric NbOI2", "link": "http://arxiv.org/abs/2504.21737v1", "summary": "Two-dimensional (2D) layered ferroelectrics, as an emerging area of research,\nhave attracted extensive attention, while memristors based on new 2D\nferroelectric materials have yet to be fully explored, thereby limiting their\napplications in modern nanoelectronics. In this work, we report the observation\nof intrinsic memristive behavior in a newly discovered 2D in-plane\nferroelectric material, NbOI2, and the giant enhancement of the memristive\nperformance using LED visible light. The results show that NbOI2 exhibits\nintrinsically strong memristive response with a current on/off ratio of up to\n10^4 and stable switching cycles, which is independent of back-gate voltage.\nUnder LED visible light illumination, the current on/off ratio in NbOI2 is over\none order of magnitude higher than that without light, meanwhile, the coercive\nfield is significantly reduced to less than 1.22 kVcm-1, much lower than other\n2D ferroelectric material-based memristors. Interestingly, both the intrinsic\nand the light-enhanced resistive switching phenomena only occur along the\nin-plane b-axis direction, indicating that the memristive behavior in NbOI2 is\ndriven by electric field-induced and optical field-enhanced ferroelectric\npolarization switching mechanisms, as evidenced by a combined\norientation-dependent electrical/optoelectrical measurement and sweep\ncycle-induced structural evolution analysis. Our study not only provides a\nmaterials strategy based on new 2D ferroelectrics for designing memristor\napplications, but also offers a simple optical method to enhance its\nperformance, paving the path for its implementation in novel nanoelectronics\nand optoelectronics.", "authors": ["Zheng Hao", "Gaolei Zhao", "Haoran Li", "Jizhang Zhang", "Jiabin Liu", "Fanyi Kong", "Konstantin Kozadaev", "Yongjiang Li", "Xue Han", "Hong Li", "Huolin Huang", "Changsen Sun", "Alexei Tolstik", "Andrey Novitsky", "Lujun Pan", "Dawei Li"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T15:33:37Z"}
{"id": "2504.21820v1", "title": "Two lock-in amplifiers based $3ω$ technique: a practical guide for\n  thermal conductivity experiments in bulk samples", "link": "http://arxiv.org/abs/2504.21820v1", "summary": "The accurate determination of thermal conductivity $\\kappa(T)$ in bulk\nmaterials is essential to assess their performance as candidates for specific\napplications. The 3$\\omega$ technique is an established methodology for\nstudying the thermal conductivity of thin films and becomes particularly\nsuitable in the case of bulk specimens at room temperature and above, where\nstandard stationary techniques require significant corrections for radiative\nlosses. Although this method has been employed in several works, it remains not\nwidely adopted because its implementation demands considerable sophistication,\nincluding experiment design, thin film deposition techniques and choices of the\ngeometry of the current/heat transducer, electronics, and analytical treatment\nof the signals. This work reviews the technique's most crucial technical\naspects, providing practical support for a quick and user-friendly\nimplementation, from the design phase to the execution and analysis. We release\na Python-based graphical user interface that supports a quick quantitative\nestimation of the investigated temperature profiles based on the geometrical\nparameters (width/length) of the deposited transducer (heater/thermometer metal\nline) before an experiment, guaranteeing an optimal engineering of the\nexperimental conditions for each given material under scrutiny.", "authors": ["Alexandre Henriques", "Murilo Santoma", "Steffen Wirth", "Julio Larrea Jiménez", "Valentina Martelli"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T17:24:55Z"}
{"id": "2505.00086v1", "title": "Nonlinear thermoelectric effects as a means to probe quantum geometry", "link": "http://arxiv.org/abs/2505.00086v1", "summary": "The quantum geometric tensor, which has the quantum metric and Berry\ncurvature as its real and imaginary parts, plays a key role in the transport\nproperties of condensed matter systems. In the nonlinear regime, the quantum\nmetric dipole and Berry curvature dipole provide two distinct mechanisms for\ngenerating nonlinear Hall effects, which can both be experimentally observed in\nsystems with suitable symmetries. In this work, we investigate the role of\nquantum geometry in nonlinear thermoelectric responses. We derive a series of\nnonlinear thermoelectric effects governed by the Berry curvature dipole and the\nquantum metric dipole, respectively. Among them, we identify a particularly\ninteresting quantized thermoelectric response that directly measures the total\nchirality of Weyl points below the Fermi level. For general nonlinear\nresponses, we derive the nonlinear analogs of the Wiedemann-Franz law and\nMott's formula. These provide a means to estimate the magnitude of nonlinear\nthermoelectric responses based on existing nonlinear Hall measurements. Our\nestimates suggest that these effects should be observable in several candidate\nmaterials, with In-doped Pb$_{1-x}$Sn$_x$Te standing out as the most promising.\nOur work offers new insights into the experimental study of quantum geometry\nthrough nonlinear thermoelectric measurements.", "authors": ["Xu Yang", "Brian Skinner"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T18:00:21Z"}
{"id": "2505.00117v1", "title": "Interlayer Coupling-Induced Quantum Phase Transition in Quantum\n  Anomalous Hall Multilayers", "link": "http://arxiv.org/abs/2505.00117v1", "summary": "A quantum phase transition arises from competition between different ground\nstates and is typically accessed by varying a single physical parameter near\nabsolute zero temperature. The quantum anomalous Hall (QAH) effect with high\nChern number C has recently been achieved in magnetic topological insulator\n(TI) multilayers. In this work, we employ molecular beam epitaxy to synthesize\na series of magnetic TI penta-layers by varying the thickness of the middle\nmagnetic TI layer, designated as m quintuple layers. Electrical transport\nmeasurements demonstrate a quantum phase transition between C = 1 and C = 2 QAH\nstates. For m 1 and m 2, the sample exhibits the well-quantized C = 1 and C = 2\nQAH states, respectively. For 1 m 2, we observe a monotonic decrease in Hall\nresistance from h/e2 to h/2e2 with increasing m, accompanied by a peak in the\nlongitudinal resistance. The quantum phase transition between C = 1 and C = 2\nQAH states is attributed to the weakening of the interlayer coupling between\nthe top and the bottom C = 1 QAH layers. Our findings provide a scalable\nstrategy for engineering QAH devices with a tunable Chern number. This approach\nenables precise control and enhanced functionality in chiral edge current-based\nelectronic devices.", "authors": ["Ling-Jie Zhou", "Deyi Zhuo", "Ruobing Mei", "Yi-Fan Zhao", "Kaijie Yang", "Ruoxi Zhang", "Zijie Yan", "Han Tay", "Moses H. W. Chan", "Chao-Xing Liu", "Cui-Zu Chang"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T18:40:44Z"}
{"id": "2505.00123v1", "title": "Twist Engineering of Anisotropic Excitonic and Optical Properties of a\n  Two-Dimensional Magnetic Semiconductor", "link": "http://arxiv.org/abs/2505.00123v1", "summary": "Two dimensional (2D) van der Waals (vdW) magnetic semiconductors are a new\nclass of quantum materials for studying the emergent physics of excitons and\nspins in the 2D limit. Twist engineering provides a powerful tool to manipulate\nthe fundamental properties of 2D vdW materials. Here, we show that twist\nengineering of the anisotropic ferromagnetic monolayer semiconductor, CrSBr,\nleads to bilayer magnetic semiconductors with continuously tunable magnetic\nmoment, dielectric anisotropy, exciton energy and linear dichroism. We\nfurthermore provide a model for exciton energy in the media with tunable\nanisotropy. These results advance fundamental studies on 2D vdW materials and\nopen doors to applications to nano-optics, twistronics, and spintronics.", "authors": ["Qiuyang Li", "Xiaohan Wan", "Senlei Li", "Adam Alfrey", "Wenhao Liu", "Zixin Zhai", "Wyatt Alpers", "Yujie Yang", "Irmina Wladyszewska", "Christiano W. Beach", "Liuyan Zhao", "Bing Lv", "Chunhui Rita Du", "Kai Sun", "Hui Deng"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T18:45:46Z"}
{"id": "2505.00125v1", "title": "Roadmap on Advancements of the FHI-aims Software Package", "link": "http://arxiv.org/abs/2505.00125v1", "summary": "Electronic-structure theory is the foundation of the description of materials\nincluding multiscale modeling of their properties and functions. Obviously,\nwithout sufficient accuracy at the base, reliable predictions are unlikely at\nany level that follows. The software package FHI-aims has proven to be a game\nchanger for accurate free-energy calculations because of its scalability,\nnumerical precision, and its efficient handling of density functional theory\n(DFT) with hybrid functionals and van der Waals interactions. It treats\nmolecules, clusters, and extended systems (solids and liquids) on an equal\nfooting. Besides DFT, FHI-aims also includes quantum-chemistry methods,\ndescriptions for excited states and vibrations, and calculations of various\ntypes of transport. Recent advancements address the integration of FHI-aims\ninto an increasing number of workflows and various artificial intelligence (AI)\nmethods. This Roadmap describes the state-of-the-art of FHI-aims and\nadvancements that are currently ongoing or planned.", "authors": ["Joseph W. Abbott", "Carlos Mera Acosta", "Alaa Akkoush", "Alberto Ambrosetti", "Viktor Atalla", "Alexej Bagrets", "Jörg Behler", "Daniel Berger", "Björn Bieniek", "Jonas Björk", "Volker Blum", "Saeed Bohloul", "Connor L. Box", "Nicholas Boyer", "Danilo Simoes Brambila", "Gabriel A. Bramley", "Kyle R. Bryenton", "María Camarasa-Gómez", "Christian Carbogno", "Fabio Caruso", "Sucismita Chutia", "Michele Ceriotti", "Gábor Csányi", "William Dawson", "Francisco A. Delesma", "Fabio Della Sala", "Bernard Delley", "Robert A. DiStasio Jr.", "Maria Dragoumi", "Sander Driessen", "Marc Dvorak", "Simon Erker", "Ferdinand Evers", "Eduardo Fabiano", "Matthew R. Farrow", "Florian Fiebig", "Jakob Filser", "Lucas Foppa", "Lukas Gallandi", "Alberto Garcia", "Ralf Gehrke", "Simiam Ghan", "Luca M. Ghiringhelli", "Mark Glass", "Stefan Goedecker", "Dorothea Golze", "James A. Green", "Andrea Grisafi", "Andreas Grüneis", "Jan Günzl", "Stefan Gutzeit", "Samuel J. Hall", "Felix Hanke", "Ville Havu", "Xingtao He", "Joscha Hekele", "Olle Hellman", "Uthpala Herath", "Jan Hermann", "Daniel Hernangómez-Pérez", "Oliver T. Hofmann", "Johannes Hoja", "Simon Hollweger", "Lukas Hörmann", "Ben Hourahine", "Wei Bin How", "William P. Huhn", "Marcel Hülsberg", "Sara Panahian Jand", "Hong Jiang", "Erin R. Johnson", "Werner Jürgens", "J. Matthias Kahk", "Yosuke Kanai", "Kisung Kang", "Petr Karpov", "Elisabeth Keller", "Roman Kempt", "Danish Khan", "Matthias Kick", "Benedikt P. Klein", "Jan Kloppenburg", "Alexander Knoll", "Florian Knoop", "Franz Knuth", "Simone S. Köcher", "Jannis Kockläuner", "Sebastian Kokott", "Thomas Körzdörfer", "Hagen-Henrik Kowalski", "Peter Kratzer", "Pavel Kůs", "Raul Laasner", "Bruno Lang", "Björn Lange", "Marcel F. Langer", "Ask Hjorth Larsen", "Hermann Lederer", "Susi Lehtola", "Maja-Olivia Lenz-Himmer", "Moritz Leucke", "Sergey Levchenko", "Alan Lewis", "O. Anatole von Lilienfeld", "Konstantin Lion", "Werner Lipsunen", "Johannes Lischner", "Yair Litman", "Chi Liu", "Qing-Long Liu", "Andrew J. Logsdail", "Michael Lorke", "Zekun Lou", "Iuliia Mandzhieva", "Andreas Marek", "Johannes T. Margraf", "Reinhard J. Maurer", "Tobias Melson", "Florian Merz", "Jörg Meyer", "Georg S. Michelitsch", "Teruyasu Mizoguchi", "Evgeny Moerman", "Dylan Morgan", "Jack Morgenstein", "Jonathan Moussa", "Akhil S. Nair", "Lydia Nemec", "Harald Oberhofer", "Alberto Otero-de-la-Roza", "Ramón L. Panadés-Barrueta", "Thanush Patlolla", "Mariia Pogodaeva", "Alexander Pöppl", "Alastair J. A. Price", "Thomas A. R. Purcell", "Jingkai Quan", "Nathaniel Raimbault", "Markus Rampp", "Karsten Rasim", "Ronald Redmer", "Xinguo Ren", "Karsten Reuter", "Norina A. Richter", "Stefan Ringe", "Patrick Rinke", "Simon P. Rittmeyer", "Herzain I. Rivera-Arrieta", "Matti Ropo", "Mariana Rossi", "Victor Ruiz", "Nikita Rybin", "Andrea Sanfilippo", "Matthias Scheffler", "Christoph Scheurer", "Christoph Schober", "Franziska Schubert", "Tonghao Shen", "Christopher Shepard", "Honghui Shang", "Kiyou Shibata", "Andrei Sobolev", "Ruyi Song", "Aloysius Soon", "Daniel T. Speckhard", "Pavel V. Stishenko", "Muhammad Tahir", "Izumi Takahara", "Jun Tang", "Zechen Tang", "Thomas Theis", "Franziska Theiss", "Alexandre Tkatchenko", "Milica Todorović", "George Trenins", "Oliver T. Unke", "Álvaro Vázquez-Mayagoitia", "Oscar van Vuren", "Daniel Waldschmidt", "Han Wang", "Yanyong Wang", "Jürgen Wieferink", "Jan Wilhelm", "Scott Woodley", "Jianhang Xu", "Yong Xu", "Yi Yao", "Yingyu Yao", "Mina Yoon", "Victor Wen-zhe Yu", "Zhenkun Yuan", "Marios Zacharias", "Igor Ying Zhang", "Min-Ye Zhang", "Wentao Zhang", "Rundong Zhao", "Shuo Zhao", "Ruiyi Zhou", "Yuanyuan Zhou", "Tong Zhu"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T18:46:21Z"}
{"id": "2505.00226v1", "title": "Wilson polygons and the topology of zero-dimensional systems", "link": "http://arxiv.org/abs/2505.00226v1", "summary": "We show that zero-dimensional (0-D) systems can host non-trivial topology\nanalogous to macroscopic topological materials in greater dimensions. Unlike\nmacroscopic periodic systems with translational symmetry, zero-dimensional\nmaterials such as molecules, clusters and quantum dots can exhibit discrete\nrotation symmetry. The eigenstates can thus be grouped into discrete bands and\nBloch-like wave functions. Since the symmetry is discrete, the Berry phase and\nthe topological indices must be defined by discrete Wilson polygons. Here, we\ndemonstrate non-trivial Z2 orders in two representative 0-D molecules,\n[m]-Cycloparaphenylene and [m]-iso-thianaphthene, where topological transitions\noccur when modifying the coupling between the repeating units. Similar to\nmacroscopic topological systems in greater dimensions, localized boundary\nstates emerge in composite nanohoops formed by segments that are topologically\ndistinct. This opens up the possibility of non-trivial topological phases in\n0-D systems.", "authors": ["Gen Yin", "Rameswar Bhattacharjee", "Miklos Kertesz"], "category": "cond-mat.mtrl-sci", "updated": "2025-05-01T00:27:45Z"}
{"id": "2504.21426v1", "title": "Topotactical hydrogen induced single-band $d$-wave superconductivity in\n  La$_2$NiO$_4$", "link": "http://arxiv.org/abs/2504.21426v1", "summary": "La$_2$NiO$_4$ is an antiferromagnetic insulator with a structural resemblance\nto its cuprate counterpart, La$_2$CuO$_4$. However, La$_2$CuO$_4$ has a\nCu$^{2+}$ or 3$d^9$ electronic configuration that needs to be hole or electron\ndoped for superconductivity, whereas La$_2$NiO$_4$ is 3$d^8$ with divalent\nNi$^{2+}$. Making a cuprate analog through conventional electron doping is\nimpractical due to the rarity of trivalent substituents for La. In this work,\nwe propose an alternative route: intercalating topotactical hydrogen which is\npossible through electric-field-controlled protonation and transforms\nLa$_2$NiO$_4$ into a 3$d_{x^2-y^2}$ single-band two-dimensional\nanti-ferromagnetic Mott insulator analogous to La$_2$CuO$_4$. This we find\nthrough density-functional theory and dynamical mean-field theory calculations.\nThe furthergoing dynamical vertex approximation predicts that H-La$_2$NiO$_4$\ncan host $d$-wave superconductivity under 15\\% hole doping with a critical\ntemperature above 20\\,K. Our findings not only suggest a new method for tuning\nthe electronic structure of layered nickelates but also provides theoretical\nevidence for a new nickelate superconductor, awaiting experimental synthesis.", "authors": ["Ying Gao", "Wenfeng Wu", "Zhaoxin Liu", "Karsten Held", "Liang Si"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T08:33:43Z"}
{"id": "2504.21608v1", "title": "No Evidence of Anomalous Diffusion in Yukawa Crystals", "link": "http://arxiv.org/abs/2504.21608v1", "summary": "Diffusion in Yukawa crystals is stochastic due to the thermally activated\nformation of vacancy-interstitial pairs, which have poor statistics in\nsimulations. This makes it difficult to argue if Yukawa crystals exhibit normal\ndiffusion, or if they could be subdiffusive or superdiffusive. To resolve this,\nwe run a long molecular dynamics simulation of an idealized Yukawa crystal for\na billion timesteps. We find no evidence of anomalous diffusion in the pure\ncrystal, but also caution readers against overinterpreting this result as real\ncrystals have complicated structures including grains and defects.", "authors": ["Matthew E. Caplan", "Dany Yaacoub"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T13:08:01Z"}
{"id": "2504.21485v1", "title": "Monolayer C$_{60}$ networks: A first-principles perspective", "link": "http://arxiv.org/abs/2504.21485v1", "summary": "Monolayer fullerene (C$_{60}$) networks combine molecular-level rigidity with\ncrystalline connectivity, offering a promising platform for numerous\napplications. In this Feature article, we review the physical and chemical\nproperties of fullerene monolayers, focusing on first-principles studies. We\nfirst explore the structural stability of monolayer phases and investigate\ntheir thermal expansion behaviours. We then outline criteria for photocatalytic\nwater splitting and introduce theoretical predictions which are supported by\nrecent experimental verification. Finally, we show how interlayer stacking,\nmolecular size, and dimensional tuning (from 2D monolayers into 3D crystals, 1D\nchains, or nanoribbons) offer versatile approaches to modulate their chemical\nfunctionality. Together, these insights establish fullerene networks as a novel\nclass of carbon-based materials with tailored properties for catalysis,\nphotovoltaics, and flexible electronics.", "authors": ["Bo Peng", "Michele Pizzochero"], "category": "cond-mat.mtrl-sci", "updated": "2025-04-30T10:09:45Z"}
{"id": "2504.21621v1", "title": "Effect of eccentric mixing parameters on chaotic characteristics and\n  mixing time for viscous liquid based on sound decibels", "link": "http://arxiv.org/abs/2504.21621v1", "summary": "Eccentric mixing is a typical chaotic mixing method, and the study of its\nmixing characteristics is beneficial to the optimization of the mixing process.\nIn this study, the effects of eccentricity (E/R) and rotational speed (N) on\nthe mixing time are quantified through tracer staining experiments and image\ngrayscale analysis, and the method of calculating the Lyapunov exponent (LLE)\nbased on the sound decibel value time series is proposed. Experiments show that\nsound decibel value time series can better characterize the chaotic dynamics of\nthe system. Based on the control variable method, the mixing time and LLE all\nshow a nonlinear trend of decreasing and then increasing, or increasing and\nthen decreasing, with the increase of eccentricity and rotational speed. When\nE/R=0.4 and the rotational speed N=450rpm, the mixing time was shortened by 48%\ncompared with the center mixing, and the degree of chaos reached the peak. The\ndimensionless chaos indicator model is further constructed to reveal the\nquantitative relationship between the eccentric stirring parameters and the\nchaos intensity. This method provides a theoretical basis for the real-time\nmonitoring of the chaotic characteristics of complex flow fields and the\noptimization of industrial mixing equipment.", "authors": ["Ronfgang Wang", "Lijun Zhao", "Yunshi Yao"], "category": "physics.chem-ph", "updated": "2025-04-30T13:24:24Z"}
{"id": "2505.04635v1", "title": "Enhanced Biogas Production via Anaerobic Co-Digestion of Slaughterhouse\n  and Food Waste Using Ferric Oxide as a Sustainable Conductive Material", "link": "http://arxiv.org/abs/2505.04635v1", "summary": "The anaerobic co-digestion of slaughterhouse wastewater and food waste offers\na sustainable approach to waste treatment and biogas production. However,\nlimited literature was found on the study of ferric oxide as conductive\nmaterial in co-digestion of the two substrates. This study evaluates the effect\nof ferric oxide on biogas yield, organic matter removal, and kinetics of\nanaerobic co-digestion. Five batch tests were performed: four with varying\nferric oxide doses and one control. Results showed that ferric oxide\nsignificantly enhanced total solids (TS) and volatile solids (VS) reduction.\nThe reactor with 0.5 g ferric oxide per 800 mL working volume achieved the\nhighest TS and VS reduction, corresponding to the maximum methane yield of\n9878.95 L methane per kg volatile solid. At this optimal dosage, biogas\nproduction increased by 81 percent compared to the control. However, further\nincreases in ferric oxide above the optimal dosage concentration decreases\nbiogas yield, indicating a threshold beyond which inhibitory effects occur. In\naddition, at this optimal dosage, reduction in BOD and COD was observed due to\nenhanced microbial activity. Furthermore, ferric oxide stabilizes anaerobic\ndigestion by mitigating inhibitory compounds and promoting direct interspecies\nelectron transfer, leading to improved methane yield. Kinetic modeling using\nthe Logistic Function accurately predicted methane production trends,\ndemonstrating its potential for industrial-scale application. Overall, the\nstudy confirms that ferric oxide at an optimal dose significantly enhance\nbiogas yield and system performance during the anaerobic co-digestion.", "authors": ["Michelle C. Almendrala", "Kyle Adrienne T. Valenzuela", "Steffany Marie Nina B. Santos", "Louise Grace S. Avena-Ardeta"], "category": "physics.chem-ph", "updated": "2025-04-30T20:28:33Z"}
{"id": "2504.21381v1", "title": "From expNN to sinNN: automatic generation of sum-of-products models for\n  potential energy surfaces in internal coordinates using neural networks and\n  sparse grid sampling", "link": "http://arxiv.org/abs/2504.21381v1", "summary": "Potential Energy Surfaces are generally required for simulating quantum\ndynamics. Specifically, having an analytical expression of the PES enables a\nmore efficient dynamics workflow compared to the currently popular direct\ndynamics approaches. When using the MCTDH method, there is also a strong\nadvantage to express the PES in sum-of-products form for solving the\ntime-dependent nuclear Schr\\\"odinger equation. Nevertheless, obtaining an\naccurate expression for the PES of molecular systems that contain more than a\nfew atoms presents challenges. The objectives of this work are twofold. First,\nthe practicality of a single-layer artificial neural network with sinusoidal\nactivation functions for representing potential energy surfaces in\nsum-of-products form will be evaluated. Second, the efficiency and ability of a\nhomogeneous sampling strategy based on sparse grids to provide unbiased\ncoverage of configuration space for generating training data will be assessed.\nThe fitting approach, named sinNN, is applied to modeling the PES of HONO,\ncovering both the trans and cis isomers. Refitting is first explored with\ncomparison to the expNN fitting method. Second, fitting from potential energies\nobtained from the machine learning model MLatom/AIQM2 is considered. The sinNN\nPES model obtained from MLatom/AIQM2 energies was able to reproduce available\nexperimental fundamental vibrational transition energies with a root mean\nsquare error of about 17 cm-1. sinNN combined with sparse grids sampling\napproach proves to be of practical use for the chosen system, both at refitting\nand direct fitting tasks. The ability of MLatom/AIQM models to accurately\nreproduce global PESs beyond equilibrium geometries is of particular interest.", "authors": ["Antoine Aerts"], "category": "physics.chem-ph", "updated": "2025-04-30T07:31:32Z"}
{"id": "2504.21663v1", "title": "Reducing Weighted Ensemble Variance With Optimal Trajectory Management", "link": "http://arxiv.org/abs/2504.21663v1", "summary": "Weighted ensemble (WE) is an enhanced path-sampling method that is\nconceptually simple, widely applicable, and statistically exact. In a WE\nsimulation, an ensemble of trajectories is periodically pruned or replicated to\nenhance sampling of rare transitions and improve estimation of mean first\npassage times (MFPTs). However, poor choices of the parameters governing\npruning and replication can lead to high-variance MFPT estimates. Our previous\nwork [J. Chem. Phys. 158, 014108 (2023)] presented an optimal WE\nparameterization strategy and applied it in low-dimensional example systems.\nThe strategy harnesses estimated local MFPTs from different initial\nconfigurations to a single target state. In the present work, we apply the\noptimal parameterization strategy to more challenging, high-dimensional\nmolecular models, namely, synthetic molecular dynamics (MD) models of Trp-cage\nfolding and unfolding, as well as atomistic MD models of NTL9 folding in\nhigh-friction and low-friction continuum solvents. In each system we use WE to\nestimate the MFPT for folding or unfolding events. We show that the optimal\nparameterization reduces the variance of MFPT estimates in three of four\nsystems, with dramatic improvement in the most challenging atomistic system.\nOverall, the parameterization strategy improves the accuracy and reliability of\nWE estimates for the kinetics of biophysical processes.", "authors": ["Won Hee Ryu", "John D. Russo", "Mats S. Johnson", "Jeremy T. Copperman", "Jeffrey P. Thompson", "David N. LeBard", "Robert J. Webber", "Gideon Simpson", "David Aristoff", "Daniel M. Zuckerman"], "category": "physics.chem-ph", "updated": "2025-04-30T14:03:58Z"}
{"id": "2504.21825v1", "title": "Rovibrational computation of H$_3^+$ with permutationally invariant\n  Pekeris coordinates", "link": "http://arxiv.org/abs/2504.21825v1", "summary": "The Pekeris coordinates provide a permutationally invariant set of\ncoordinates for H$_3^+$. They are defined as the linear combination of the\nthree internuclear distances that automatically fulfils the triangle inequality\nfor all non-negative coordinate values. In this work, we test three discrete\nvariable representations (DVR) for tightly converging the rovibrational\nenergies up to and beyond the barrier to linearity using the Pekeris\ncoordinates. The best performing representation is a cot-DVR-type approach\nadapted to the Pekeris problem. The two- and three-proton near coalescence\nregion, which is also part of the direct product Pekeris grid but dynamically\nnot relevant, is avoided by coordinate mapping.", "authors": ["Gustavo Avila", "Edit Mátyus"], "category": "physics.chem-ph", "updated": "2025-04-30T17:30:04Z"}
{"id": "2505.00125v1", "title": "Roadmap on Advancements of the FHI-aims Software Package", "link": "http://arxiv.org/abs/2505.00125v1", "summary": "Electronic-structure theory is the foundation of the description of materials\nincluding multiscale modeling of their properties and functions. Obviously,\nwithout sufficient accuracy at the base, reliable predictions are unlikely at\nany level that follows. The software package FHI-aims has proven to be a game\nchanger for accurate free-energy calculations because of its scalability,\nnumerical precision, and its efficient handling of density functional theory\n(DFT) with hybrid functionals and van der Waals interactions. It treats\nmolecules, clusters, and extended systems (solids and liquids) on an equal\nfooting. Besides DFT, FHI-aims also includes quantum-chemistry methods,\ndescriptions for excited states and vibrations, and calculations of various\ntypes of transport. Recent advancements address the integration of FHI-aims\ninto an increasing number of workflows and various artificial intelligence (AI)\nmethods. This Roadmap describes the state-of-the-art of FHI-aims and\nadvancements that are currently ongoing or planned.", "authors": ["Joseph W. Abbott", "Carlos Mera Acosta", "Alaa Akkoush", "Alberto Ambrosetti", "Viktor Atalla", "Alexej Bagrets", "Jörg Behler", "Daniel Berger", "Björn Bieniek", "Jonas Björk", "Volker Blum", "Saeed Bohloul", "Connor L. Box", "Nicholas Boyer", "Danilo Simoes Brambila", "Gabriel A. Bramley", "Kyle R. Bryenton", "María Camarasa-Gómez", "Christian Carbogno", "Fabio Caruso", "Sucismita Chutia", "Michele Ceriotti", "Gábor Csányi", "William Dawson", "Francisco A. Delesma", "Fabio Della Sala", "Bernard Delley", "Robert A. DiStasio Jr.", "Maria Dragoumi", "Sander Driessen", "Marc Dvorak", "Simon Erker", "Ferdinand Evers", "Eduardo Fabiano", "Matthew R. Farrow", "Florian Fiebig", "Jakob Filser", "Lucas Foppa", "Lukas Gallandi", "Alberto Garcia", "Ralf Gehrke", "Simiam Ghan", "Luca M. Ghiringhelli", "Mark Glass", "Stefan Goedecker", "Dorothea Golze", "James A. Green", "Andrea Grisafi", "Andreas Grüneis", "Jan Günzl", "Stefan Gutzeit", "Samuel J. Hall", "Felix Hanke", "Ville Havu", "Xingtao He", "Joscha Hekele", "Olle Hellman", "Uthpala Herath", "Jan Hermann", "Daniel Hernangómez-Pérez", "Oliver T. Hofmann", "Johannes Hoja", "Simon Hollweger", "Lukas Hörmann", "Ben Hourahine", "Wei Bin How", "William P. Huhn", "Marcel Hülsberg", "Sara Panahian Jand", "Hong Jiang", "Erin R. Johnson", "Werner Jürgens", "J. Matthias Kahk", "Yosuke Kanai", "Kisung Kang", "Petr Karpov", "Elisabeth Keller", "Roman Kempt", "Danish Khan", "Matthias Kick", "Benedikt P. Klein", "Jan Kloppenburg", "Alexander Knoll", "Florian Knoop", "Franz Knuth", "Simone S. Köcher", "Jannis Kockläuner", "Sebastian Kokott", "Thomas Körzdörfer", "Hagen-Henrik Kowalski", "Peter Kratzer", "Pavel Kůs", "Raul Laasner", "Bruno Lang", "Björn Lange", "Marcel F. Langer", "Ask Hjorth Larsen", "Hermann Lederer", "Susi Lehtola", "Maja-Olivia Lenz-Himmer", "Moritz Leucke", "Sergey Levchenko", "Alan Lewis", "O. Anatole von Lilienfeld", "Konstantin Lion", "Werner Lipsunen", "Johannes Lischner", "Yair Litman", "Chi Liu", "Qing-Long Liu", "Andrew J. Logsdail", "Michael Lorke", "Zekun Lou", "Iuliia Mandzhieva", "Andreas Marek", "Johannes T. Margraf", "Reinhard J. Maurer", "Tobias Melson", "Florian Merz", "Jörg Meyer", "Georg S. Michelitsch", "Teruyasu Mizoguchi", "Evgeny Moerman", "Dylan Morgan", "Jack Morgenstein", "Jonathan Moussa", "Akhil S. Nair", "Lydia Nemec", "Harald Oberhofer", "Alberto Otero-de-la-Roza", "Ramón L. Panadés-Barrueta", "Thanush Patlolla", "Mariia Pogodaeva", "Alexander Pöppl", "Alastair J. A. Price", "Thomas A. R. Purcell", "Jingkai Quan", "Nathaniel Raimbault", "Markus Rampp", "Karsten Rasim", "Ronald Redmer", "Xinguo Ren", "Karsten Reuter", "Norina A. Richter", "Stefan Ringe", "Patrick Rinke", "Simon P. Rittmeyer", "Herzain I. Rivera-Arrieta", "Matti Ropo", "Mariana Rossi", "Victor Ruiz", "Nikita Rybin", "Andrea Sanfilippo", "Matthias Scheffler", "Christoph Scheurer", "Christoph Schober", "Franziska Schubert", "Tonghao Shen", "Christopher Shepard", "Honghui Shang", "Kiyou Shibata", "Andrei Sobolev", "Ruyi Song", "Aloysius Soon", "Daniel T. Speckhard", "Pavel V. Stishenko", "Muhammad Tahir", "Izumi Takahara", "Jun Tang", "Zechen Tang", "Thomas Theis", "Franziska Theiss", "Alexandre Tkatchenko", "Milica Todorović", "George Trenins", "Oliver T. Unke", "Álvaro Vázquez-Mayagoitia", "Oscar van Vuren", "Daniel Waldschmidt", "Han Wang", "Yanyong Wang", "Jürgen Wieferink", "Jan Wilhelm", "Scott Woodley", "Jianhang Xu", "Yong Xu", "Yi Yao", "Yingyu Yao", "Mina Yoon", "Victor Wen-zhe Yu", "Zhenkun Yuan", "Marios Zacharias", "Igor Ying Zhang", "Min-Ye Zhang", "Wentao Zhang", "Rundong Zhao", "Shuo Zhao", "Ruiyi Zhou", "Yuanyuan Zhou", "Tong Zhu"], "category": "physics.chem-ph", "updated": "2025-04-30T18:46:21Z"}
{"id": "2505.00126v1", "title": "Tree tensor network hierarchical equations of motion based on\n  time-dependent variational principle for efficient open quantum dynamics in\n  structured thermal environments", "link": "http://arxiv.org/abs/2505.00126v1", "summary": "We introduce an efficient method TTN-HEOM for exactly calculating the open\nquantum dynamics for driven quantum systems interacting with highly structured\nbosonic baths by combining the tree tensor network (TTN) decomposition scheme\nto the bexcitonic generalization of the numerically-exact hierarchical\nequations of motion (HEOM). The method yields a series of quantum master\nequations for all core tensors in the TTN that efficiently and accurately\ncapture the open quantum dynamics for non-Markovian environments to all orders\nin the system-bath interaction. These master equations are constructed based on\nthe time-dependent Dirac-Frenkel variational principle which isolates the\noptimal dynamics for the core tensors given the TTN ansatz. The dynamics\nconverges to the HEOM when increasing the rank of the core tensors, a limit in\nwhich the TTN ansatz becomes exact. We introduce TENSO, Tensor Equations for\nNon-Markovian Structured Open systems, as a general-purpose Python code to\npropagate the TTN-HEOM dynamics. We implement three general propagators for the\ncoupled master equations: Two fixed-rank methods that require a constant memory\nfootprint during the dynamics, and one adaptive-rank method with variable\nmemory footprint controlled by the target level of computational error. We\nexemplify the utility of these methods by simulating a two-level system coupled\nto a structured bath containing one Drude-Lorentzian component and eight\nBrownian oscillators, which is beyond what can presently be computed using the\nstandard HEOM. Our results show that the TTN-HEOM is capable to simulate both\ndephasing and relaxation dynamics of driven quantum system interacting with\nstructured baths, even those of chemical complexity, with affordable\ncomputational cost.", "authors": ["Xinxian Chen", "Ignacio Franco"], "category": "physics.chem-ph", "updated": "2025-04-30T18:48:05Z"}
{"id": "2505.00188v1", "title": "Thermodynamic potentials from a probabilistic view on the\n  system-environment interaction energy", "link": "http://arxiv.org/abs/2505.00188v1", "summary": "In open systems with strong coupling, the interaction energy between the\nsystem and the environment is significant, so thermodynamic quantities cannot\nbe reliably obtained by traditional statistical mechanics methods. The\nHamiltonian of mean force $\\mathcal{H}^{*}_{\\beta}$ offers an in principle\naccurate theoretical basis by explicitly accounting for the interaction energy.\nHowever, calculating the Hamiltonian of mean force is challenging both\ntheoretically and computationally. We demonstrate that when the condition\n$\\text{Var}_{\\mathcal{E}_0} (e^{-\\beta {V}_{\\mathcal{SE}}}) = 0$ is met, the\ndependence of thermodynamic variables can be shifted from\n$\\{P_{\\beta}(x_{\\mathcal{S}}), \\mathcal{H}^{*}_{\\beta}(x_{\\mathcal{S}})\\}$ to\n$\\{P_{\\beta}(x_{\\mathcal{S}}), P(V_{\\mathcal{SE}})\\}$. This change simplifies\nthermodynamic measurements. As a central result, we derive a general equality\nthat holds for arbitrary coupling strengths and from which an inequality\nfollows - aligned with Jensen's inequality applied to the\nGibbs-Bogoliubov-Feynman bound. This equality, analogous in importance to the\nJarzynski equality, offers deeper insight into free energy differences in\nstrongly coupled systems. Finally, by combining our result with said Jarzynski\nequality, we derive additional relations that further clarify thermodynamic\nbehavior in strongly coupled open systems.", "authors": ["Mohammad Rahbar", "Christopher J. Stein"], "category": "physics.chem-ph", "updated": "2025-04-30T21:06:42Z"}
{"id": "2505.00192v1", "title": "A probabilistic approach to system-environment coupling", "link": "http://arxiv.org/abs/2505.00192v1", "summary": "We introduce a unified statistical framework for quantifying\nsystem-environment coupling by treating the interaction energy $V_\\mathcal{SE}$\nas a stochastic variable. Using a reference-particle decomposition, we derive\nexact, closed-form expressions for the mean and variance of $V_\\mathcal{SE}$ in\nterms of the single-particle density and up to four-body correlation functions.\nWhen $V_\\mathcal{SE}$ is approximately Gaussian, these two moments suffice to\ncompute the free energy shift of the strongly coupled system. To validate our\nframework, we ran explicit Monte Carlo simulations of the full\nsystem-environment configurations across a range of system sizes, generating\nreference distributions of the interaction energy $V_\\mathcal{SE}$. We then\napplied our derived analytical formulas to predict these distributions and\nfound excellent agreement in both the weak- and strong-coupling regimes.", "authors": ["Mohammad Rahbar", "Christopher J. Stein"], "category": "physics.chem-ph", "updated": "2025-04-30T21:20:47Z"}
{"id": "2504.21449v1", "title": "Imperfect diffusion-controlled reactions on a torus and on a pair of\n  balls", "link": "http://arxiv.org/abs/2504.21449v1", "summary": "We employ a general spectral approach based on the Steklov eigenbasis to\ndescribe imperfect diffusion-controlled reactions on bounded reactive targets\nin three dimensions. The steady-state concentration and the total diffusive\nflux onto the target are expressed in terms of the eigenvalues and\neigenfunctions of the exterior Steklov problem. In particular, the eigenvalues\nare shown to provide the geometric lengthscales of the target that are relevant\nfor diffusion-controlled reactions. Using toroidal and bispherical coordinates,\nwe propose an efficient procedure for analyzing and solving numerically this\nspectral problem for an arbitrary torus and a pair of balls, respectively. A\nsimple two-term approximation for the diffusive flux is established and\nvalidated. Implications of these results in the context of chemical physics and\nbeyond are discussed.", "authors": ["Denis S. Grebenkov"], "category": "physics.chem-ph", "updated": "2025-04-30T09:12:47Z"}
{"id": "2504.21727v1", "title": "Steering reaction flux by coupling product channels", "link": "http://arxiv.org/abs/2504.21727v1", "summary": "We demonstrate a method for controlling the outcome of an ultracold chemical\nfew-body reaction by redirecting a tunable fraction of reaction flux from one\nselected product channel to another one. In the reaction, three ultracold atoms\ncollide to form a diatomic molecule. This product molecule can be produced in\nvarious internal states, characterizing the different product channels of the\nreaction. Our scheme relies on the coupling between two such product channels\nat an avoided molecular energy level crossing in the presence of an external\nmagnetic field. The degree of coupling can be set by the magnetic field\nstrength and allows for a widely tunable flux control between the two channels.\nThis scheme is quite general and also holds great promise for a large variety\nof chemical processes with diverse species, since molecular energy level\ncrossings are ubiquitous in molecular systems and are often easily accessible\nby standard laboratory equipment.", "authors": ["Dominik Dorer", "Shinsuke Haze", "Jing-Lun Li", "José P. D'Incao", "Eberhard Tiemann", "Paul S. Julienne", "Markus Deiß", "Johannes Hecker Denschlag"], "category": "physics.chem-ph", "updated": "2025-04-30T15:19:08Z"}
{"id": "2504.21485v1", "title": "Monolayer C$_{60}$ networks: A first-principles perspective", "link": "http://arxiv.org/abs/2504.21485v1", "summary": "Monolayer fullerene (C$_{60}$) networks combine molecular-level rigidity with\ncrystalline connectivity, offering a promising platform for numerous\napplications. In this Feature article, we review the physical and chemical\nproperties of fullerene monolayers, focusing on first-principles studies. We\nfirst explore the structural stability of monolayer phases and investigate\ntheir thermal expansion behaviours. We then outline criteria for photocatalytic\nwater splitting and introduce theoretical predictions which are supported by\nrecent experimental verification. Finally, we show how interlayer stacking,\nmolecular size, and dimensional tuning (from 2D monolayers into 3D crystals, 1D\nchains, or nanoribbons) offer versatile approaches to modulate their chemical\nfunctionality. Together, these insights establish fullerene networks as a novel\nclass of carbon-based materials with tailored properties for catalysis,\nphotovoltaics, and flexible electronics.", "authors": ["Bo Peng", "Michele Pizzochero"], "category": "physics.chem-ph", "updated": "2025-04-30T10:09:45Z"}
{"id": "2504.21440v1", "title": "QuantumToolbox.jl: An efficient Julia framework for simulating open\n  quantum systems", "link": "http://arxiv.org/abs/2504.21440v1", "summary": "We present QuantumToolbox.jl, an open-source Julia package for simulating\nopen quantum systems. Designed with a syntax familiar to users of QuTiP\n(Quantum Toolbox in Python), it harnesses Julia's high-performance ecosystem to\ndeliver fast and scalable simulations. The package includes a suite of\ntime-evolution solvers supporting distributed computing and GPU acceleration,\nenabling efficient simulation of large-scale quantum systems. We also show how\nQuantumToolbox.jl can integrate with automatic differentiation tools, making it\nwell-suited for gradient-based optimization tasks such as quantum optimal\ncontrol. Benchmark comparisons demonstrate substantial performance gains over\nexisting frameworks. With its flexible design and computational efficiency,\nQuantumToolbox.jl serves as a powerful tool for both theoretical studies and\npractical applications in quantum science.", "authors": ["Alberto Mercurio", "Yi-Te Huang", "Li-Xun Cai", "Yueh-Nan Chen", "Vincenzo Savona", "Franco Nori"], "category": "physics.comp-ph", "updated": "2025-04-30T08:56:12Z"}
{"id": "2504.21663v1", "title": "Reducing Weighted Ensemble Variance With Optimal Trajectory Management", "link": "http://arxiv.org/abs/2504.21663v1", "summary": "Weighted ensemble (WE) is an enhanced path-sampling method that is\nconceptually simple, widely applicable, and statistically exact. In a WE\nsimulation, an ensemble of trajectories is periodically pruned or replicated to\nenhance sampling of rare transitions and improve estimation of mean first\npassage times (MFPTs). However, poor choices of the parameters governing\npruning and replication can lead to high-variance MFPT estimates. Our previous\nwork [J. Chem. Phys. 158, 014108 (2023)] presented an optimal WE\nparameterization strategy and applied it in low-dimensional example systems.\nThe strategy harnesses estimated local MFPTs from different initial\nconfigurations to a single target state. In the present work, we apply the\noptimal parameterization strategy to more challenging, high-dimensional\nmolecular models, namely, synthetic molecular dynamics (MD) models of Trp-cage\nfolding and unfolding, as well as atomistic MD models of NTL9 folding in\nhigh-friction and low-friction continuum solvents. In each system we use WE to\nestimate the MFPT for folding or unfolding events. We show that the optimal\nparameterization reduces the variance of MFPT estimates in three of four\nsystems, with dramatic improvement in the most challenging atomistic system.\nOverall, the parameterization strategy improves the accuracy and reliability of\nWE estimates for the kinetics of biophysical processes.", "authors": ["Won Hee Ryu", "John D. Russo", "Mats S. Johnson", "Jeremy T. Copperman", "Jeffrey P. Thompson", "David N. LeBard", "Robert J. Webber", "Gideon Simpson", "David Aristoff", "Daniel M. Zuckerman"], "category": "physics.comp-ph", "updated": "2025-04-30T14:03:58Z"}
{"id": "2504.21837v1", "title": "TRIMEG-GKX: an electromagnetic gyrokinetic particle code with a\n  Piecewise Field-Aligned Finite Element Method for Micro- and\n  Macro-Instability Studies in Tokamak Core Plasmas", "link": "http://arxiv.org/abs/2504.21837v1", "summary": "The features of the TRIMEG-GKX code are described with emphasis on the\nexploration using novel/different schemes compared to other gyrokinetic codes,\nparticularly the use of object-oriented programming, filter/buffer-free\ntreatment, and a high-order piecewise field-aligned finite element method. The\nTRIMEG-GKX code solves the electromagnetic gyrokinetic equation using the\nparticle-in-cell scheme, taking into account multi-species effects and shear\nAlfv\\'en physics. The mixed-variable/pullback scheme has been implemented to\nenable electromagnetic studies. This code is parallelized using particle\ndecomposition and domain cloning among computing nodes, replacing traditional\ndomain decomposition techniques. The applications to study the micro- and\nmacro-instabilities are demonstrated, including the energetic-particle-driven\nAlfv\\'en eigenmode, ion temperature gradient mode, and kinetic ballooning mode.\nGood performance is achieved in both ad hoc and experimentally reconstructed\nequilibria, such as those of the ASDEX Upgrade (AUG), Tokamak \\`a configuration\nvariable (TCV), and the Joint European Torus (JET). Future studies of edge\nphysics using the high-order $C^1$ finite element method for triangular meshes\nin the TRIMEG-C1 code will be built upon the same numerical methods.", "authors": ["Zhixin Lu", "Guo Meng", "Roman Hatzky", "Philipp Lauber", "Matthias Hoelzl"], "category": "physics.comp-ph", "updated": "2025-04-30T17:47:31Z"}
{"id": "2505.03783v1", "title": "A general physics-constrained method for the modelling of equation's\n  closure terms with sparse data", "link": "http://arxiv.org/abs/2505.03783v1", "summary": "Accurate modeling of closure terms is a critical challenge in engineering and\nscientific research, particularly when data is sparse (scarse or incomplete),\nmaking widely applicable models difficult to develop. This study proposes a\nnovel approach for constructing closure models in such challenging scenarios.\nWe introduce a Series-Parallel Multi-Network Architecture that integrates\nPhysics-Informed Neural Networks (PINNs) to incorporate physical constraints\nand heterogeneous data from multiple initial and boundary conditions, while\nemploying dedicated subnetworks to independently model unknown closure terms,\nenhancing generalizability across diverse problems. These closure models are\nintegrated into an accurate Partial Differential Equation (PDE) solver,\nenabling robust solutions to complex predictive simulations in engineering\napplications.", "authors": ["Tian Chen", "Shengping Liu", "Li Liu", "Heng Yong"], "category": "physics.comp-ph", "updated": "2025-04-30T14:41:18Z"}
{"id": "2504.21450v1", "title": "Coalescing MPI communication in 6D Vlasov simulations: solving ghost\n  domains in Vlasiator", "link": "http://arxiv.org/abs/2504.21450v1", "summary": "High-performance computing is used for diverse simulations, some of which\nparallelize over the Message Passing Interface (MPI) with ease, whilst others\nmay have challenges related to uniform balancing of computational load and\ncommunication between simulation domains. We introduce an alternative approach\nto solving advection equations, specifically in an application to solving the\nsix-dimensional Vlasov equation for modelling space plasmas. Communicating\nlarger ghost domains around the partition assigned to each MPI task and\ncomputing on these ghost cells allows for coalescing several discrete\ncommunication calls into one. This approach needs more overall data\ncommunication and computation, but provides interesting new avenues for the\nbalancing of computational load between MPI tasks. We discuss this trade-off,\nhow it may assist in developing other algorithmic improvements, and how the\ntransition to heterogeneous CPU-GPU architectures may impact its usefulness.", "authors": ["Markus Battarbee", "Urs Ganse", "Yann Pfau-Kempf", "Markku Alho", "Konstantinos Papadakis", "Minna Palmroth"], "category": "physics.comp-ph", "updated": "2025-04-30T09:13:44Z"}
{"id": "2504.21666v1", "title": "Quantum Annealing Algorithms for Estimating Ising Partition Functions", "link": "http://arxiv.org/abs/2504.21666v1", "summary": "Estimating partition functions of Ising spin glasses is crucial in\nstatistical physics, optimization, and machine learning, yet remains\nclassically intractable due to its #P-hard complexity. While Jarzynski's\nequality offers a theoretical approach, it becomes unreliable at low\ntemperatures due to rare divergent statistical fluctuations. Here, we present a\nprotocol that overcomes this limitation by synergizing reverse quantum\nannealing with tailored nonequilibrium initial distributions. Our method can\ndramatically suppress the estimator variance, achieving saturation in the\nlow-temperature regime. Numerical benchmarks on the Sherrington-Kirkpatrick\nspin glass and the 3-SAT problem demonstrate that our protocol reduces scaling\nexponents by over an order of magnitude (e.g., from ~8.5 to ~0.5), despite\nretaining exponential system-size dependences. Crucially, our protocol\ncircumvents stringent adiabatic constraints, making it feasible for near-term\nquantum devices like superconducting qubits, trapped ions, and Rydberg atom\narrays. This work bridges quantum dynamics with computational complexity,\noffering a practical pathway to quantum advantage in spin glass thermodynamics\nand beyond.", "authors": ["Haowei Li", "Zhiyuan Yao", "Xingze Qiu"], "category": "physics.comp-ph", "updated": "2025-04-30T14:09:40Z"}
{"id": "2504.21765v1", "title": "Evaluation of In Vivo Subject-Specific Mechanical Modeling of the Optic\n  Nerve Head for Robust Assessment of Ocular Mechanics", "link": "http://arxiv.org/abs/2504.21765v1", "summary": "To establish the tissue regions necessary to accurately represent the\nmechanics of the optic nerve head (ONH), imaging data of the ONH from 2 healthy\nsubjects were used to create in vivo subject-specific eye mechanical models\nconsidering distinct properties for all major ocular tissues. Tests were\nperformed to evaluate the effect of the material properties and the inclusion\nof these tissues on the mechanics of the lamina cribrosa (LC), retina, and\noptic nerve. Then, the LC mechanical response due to variations in intraocular\nand intracranial pressures was evaluated to validate the modeling approach. The\nsclera stiffness has the largest impact on the mechanics of the LC, retina, and\noptic nerve, while Bruchs membrane has a negligible effect on these tissues\nresponse. The validation tests showed increased LC strain with increased\npressure and highest strains in the inferior and temporal subregion, as seen in\nliterature studies. Consequently, accurate ONH mechanical representation can be\nobtained by only including those tissue regions identified as necessary.", "authors": ["Soumaya Ouhsousou", "Lucy Q. Shen", "Chhavi Saini", "Amin Pourasghar", "Mengyu Wang", "John C. Brigham"], "category": "physics.comp-ph", "updated": "2025-04-30T16:05:50Z"}
{"id": "2504.21786v1", "title": "Improved Lanczos Algorithm using Matrix Product States", "link": "http://arxiv.org/abs/2504.21786v1", "summary": "We improve the Lanczos algorithm using the matrix product state\nrepresentation proposed in Phys. Rev. B 85, 205119 (2012). As an alternative to\nthe density matrix renormalization group (DMRG), the Lanczos algorithm avoids\nlocal minima and can directly find multiple low-lying eigenstates. However, its\nperformance and accuracy are affected by the truncation required to maintain\nthe efficiency of the tensor network representation. In this work, we enhance\nits convergence by restarting with multiple states. We benchmark our method on\none-dimensional instances of the Fermi-Hubbard model with 8 sites and the\nHeisenberg model with 16 sites in an external field, using numerical\nexperiments targeting the first five lowest eigenstates. Across these tests,\nour approach obtains accuracy improvements of three to seven orders of\nmagnitude. Finally, we extend the Heisenberg model simulation to a lattice with\n30 sites to highlight its scalability.", "authors": ["Yu Wang", "Zhangyu Yang", "Christian B. Mendl"], "category": "physics.comp-ph", "updated": "2025-04-30T16:45:25Z"}
{"id": "2505.00097v1", "title": "superB/NRPy: Scalable, Task-Based Numerical Relativity for 3G\n  Gravitational Wave Science", "link": "http://arxiv.org/abs/2505.00097v1", "summary": "Modern gravitational-wave science demands increasingly accurate and\ncomputationally intensive numerical relativity (NR) simulations. The\nPython-based, open-source NRPy framework generates optimized C/C++ code for NR,\nincluding the complete NR code BlackHoles@Home (BH@H), which leverages\ncurvilinear coordinates well-suited to many astrophysical scenarios.\nHistorically, BH@H was limited to single-node OpenMP CPU parallelism. To\naddress this, we introduce superB, an open-source extension to NRPy that\nenables automatic generation of scalable, task-based, distributed-memory\nCharm++ code from existing BH@H modules. The generated code partitions the\nstructured grids used by NRPy/BH@H, managing communication between them. Its\ncorrectness is validated through bit-identical results with the standard OpenMP\nversion on a single node and via a head-on binary black hole simulation in\ncylindrical-like coordinates, accurately reproducing quasi-normal modes (up to\n$\\ell=8$). The superB/NRPy-generated code demonstrates excellent strong\nscaling, achieving an $\\approx 45$x speedup on 64 nodes (7168 cores) compared\nto the original single-node OpenMP code for a large 3D vacuum test. This\nscalable infrastructure benefits demanding simulations and lays the groundwork\nfor future multi-patch grid support, targeting long inspirals, extreme\nparameter studies, and rapid follow-ups. This infrastructure readily integrates\nwith other NRPy/BH@H-based projects, enabling performant scaling for the\ngeneral relativistic hydrodynamics code GRoovy, and facilitating future\ncoupling with GPU acceleration via the NRPy-CUDA project.", "authors": ["Nishita Jadoo", "Terrence Pierre Jacques", "Zachariah B. Etienne"], "category": "physics.comp-ph", "updated": "2025-04-30T18:10:12Z"}
{"id": "2505.00222v1", "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders", "link": "http://arxiv.org/abs/2505.00222v1", "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.", "authors": ["Peter Yichen Chen", "Pingchuan Ma", "Niklas Hagemann", "John Romanishin", "Wei Wang", "Daniela Rus", "Wojciech Matusik"], "category": "physics.comp-ph", "updated": "2025-04-30T23:55:44Z"}
{"id": "2504.21277v1", "title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large\n  Language Models", "link": "http://arxiv.org/abs/2504.21277v1", "summary": "The integration of reinforcement learning (RL) into the reasoning\ncapabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as\na transformative research direction. While MLLMs significantly extend Large\nLanguage Models (LLMs) to handle diverse modalities such as vision, audio, and\nvideo, enabling robust reasoning across multimodal inputs remains a major\nchallenge. This survey systematically reviews recent advances in RL-based\nreasoning for MLLMs, covering key algorithmic designs, reward mechanism\ninnovations, and practical applications. We highlight two main RL\nparadigms--value-free and value-based methods--and analyze how RL enhances\nreasoning abilities by optimizing reasoning trajectories and aligning\nmultimodal information. Furthermore, we provide an extensive overview of\nbenchmark datasets, evaluation protocols, and existing limitations, and propose\nfuture research directions to address current bottlenecks such as sparse\nrewards, inefficient cross-modal reasoning, and real-world deployment\nconstraints. Our goal is to offer a comprehensive and structured guide to\nresearchers interested in advancing RL-based reasoning in the multimodal era.", "authors": ["Guanghao Zhou", "Panjia Qiu", "Cen Chen", "Jie Wang", "Zheming Yang", "Jian Xu", "Minghui Qiu"], "category": "cs.AI", "updated": "2025-04-30T03:14:28Z"}
{"id": "2504.21370v1", "title": "ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length\n  for Efficient Reasoning", "link": "http://arxiv.org/abs/2504.21370v1", "summary": "Reasoning models such as OpenAI o3 and DeepSeek-R1 have demonstrated strong\nperformance on reasoning-intensive tasks through extended Chain-of-Thought\n(CoT) prompting. While longer reasoning traces can facilitate a more thorough\nexploration of solution paths for complex problems, researchers have observed\nthat these models often \"overthink\", leading to inefficient inference. In this\npaper, we introduce ShorterBetter, a simple yet effective reinforcement\nlearning methed that enables reasoning language models to discover their own\noptimal CoT lengths without human intervention. By sampling multiple outputs\nper problem and defining the Sample Optimal Length (SOL) as the shortest\ncorrect response among all the outputs, our method dynamically guides the model\ntoward optimal inference lengths. Applied to the DeepSeek-Distill-Qwen-1.5B\nmodel, ShorterBetter achieves up to an 80% reduction in output length on both\nin-domain and out-of-domain reasoning tasks while maintaining accuracy. Our\nanalysis shows that overly long reasoning traces often reflect loss of\nreasoning direction, and thus suggests that the extended CoT produced by\nreasoning models is highly compressible.", "authors": ["Jingyang Yi", "Jiazheng Wang"], "category": "cs.AI", "updated": "2025-04-30T07:04:19Z"}
{"id": "2504.21433v1", "title": "NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities\n  to Achieve Artificial General Intelligence", "link": "http://arxiv.org/abs/2504.21433v1", "summary": "This paper argues that the next generation of AI agent (NGENT) should\nintegrate across-domain abilities to advance toward Artificial General\nIntelligence (AGI). Although current AI agents are effective in specialized\ntasks such as robotics, role-playing, and tool-using, they remain confined to\nnarrow domains. We propose that future AI agents should synthesize the\nstrengths of these specialized systems into a unified framework capable of\noperating across text, vision, robotics, reinforcement learning, emotional\nintelligence, and beyond. This integration is not only feasible but also\nessential for achieving the versatility and adaptability that characterize\nhuman intelligence. The convergence of technologies across AI domains, coupled\nwith increasing user demand for cross-domain capabilities, suggests that such\nintegration is within reach. Ultimately, the development of these versatile\nagents is a critical step toward realizing AGI. This paper explores the\nrationale for this shift, potential pathways for achieving it.", "authors": ["Zhicong Li", "Hangyu Mao", "Jiangjin Yin", "Mingzhe Xing", "Zhiwei Xu", "Yuanxing Zhang", "Yang Xiao"], "category": "cs.AI", "updated": "2025-04-30T08:46:14Z"}
{"id": "2504.21568v1", "title": "A Study on Group Decision Making Problem Based on Fuzzy Reasoning and\n  Bayesian Networks", "link": "http://arxiv.org/abs/2504.21568v1", "summary": "Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.", "authors": ["Shui-jin Rong", "Wei Guo", "Da-qing Zhang"], "category": "cs.AI", "updated": "2025-04-30T12:14:48Z"}
{"id": "2504.21683v1", "title": "Extension-ranking Semantics for Abstract Argumentation Preprint", "link": "http://arxiv.org/abs/2504.21683v1", "summary": "In this paper, we present a general framework for ranking sets of arguments\nin abstract argumentation based on their plausibility of acceptance. We present\na generalisation of Dung's extension semantics as extension-ranking semantics,\nwhich induce a preorder over the power set of all arguments, allowing us to\nstate that one set is \"closer\" to being acceptable than another. To evaluate\nthe extension-ranking semantics, we introduce a number of principles that a\nwell-behaved extension-ranking semantics should satisfy. We consider several\nsimple base relations, each of which models a single central aspect of\nargumentative reasoning. The combination of these base relations provides us\nwith a family of extension-ranking semantics. We also adapt a number of\napproaches from the literature for ranking extensions to be usable in the\ncontext of extension-ranking semantics, and evaluate their behaviour.", "authors": ["Kenneth Skiba", "Tjitze Rienstra", "Matthias Thimm", "Jesse Heyninck", "Gabriele Kern-Isberner"], "category": "cs.AI", "updated": "2025-04-30T14:19:42Z"}
{"id": "2504.21694v1", "title": "Automatic Mapping of AutomationML Files to Ontologies for Graph Queries\n  and Validation", "link": "http://arxiv.org/abs/2504.21694v1", "summary": "AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.", "authors": ["Tom Westermann", "Malte Ramonat", "Johannes Hujer", "Felix Gehlhoff", "Alexander Fay"], "category": "cs.AI", "updated": "2025-04-30T14:34:56Z"}
{"id": "2504.21774v1", "title": "Is Intermediate Fusion All You Need for UAV-based Collaborative\n  Perception?", "link": "http://arxiv.org/abs/2504.21774v1", "summary": "Collaborative perception enhances environmental awareness through inter-agent\ncommunication and is regarded as a promising solution to intelligent\ntransportation systems. However, existing collaborative methods for Unmanned\nAerial Vehicles (UAVs) overlook the unique characteristics of the UAV\nperspective, resulting in substantial communication overhead. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on late-intermediate fusion, dubbed LIF. The core concept is to\nexchange informative and compact detection results and shift the fusion stage\nto the feature representation level. In particular, we leverage vision-guided\npositional embedding (VPE) and box-based virtual augmented feature (BoBEV) to\neffectively integrate complementary information from various agents.\nAdditionally, we innovatively introduce an uncertainty-driven communication\nmechanism that uses uncertainty evaluation to select high-quality and reliable\nshared areas. Experimental results demonstrate that our LIF achieves superior\nperformance with minimal communication bandwidth, proving its effectiveness and\npracticality. Code and models are available at https://github.com/uestchjw/LIF.", "authors": ["Jiuwu Hao", "Liguo Sun", "Yuting Wan", "Yueyang Wu", "Ti Xiang", "Haolin Song", "Pin Lv"], "category": "cs.AI", "updated": "2025-04-30T16:22:14Z"}
{"id": "2505.00174v2", "title": "Real-World Gaps in AI Governance Research", "link": "http://arxiv.org/abs/2505.00174v2", "summary": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.", "authors": ["Ilan Strauss", "Isobel Moure", "Tim O'Reilly", "Sruly Rosenblat"], "category": "cs.AI", "updated": "2025-05-05T21:12:46Z"}
{"id": "2505.00204v1", "title": "RAIL in the Wild: Operationalizing Responsible AI Evaluation Using\n  Anthropic's Value Dataset", "link": "http://arxiv.org/abs/2505.00204v1", "summary": "As AI systems become embedded in real-world applications, ensuring they meet\nethical standards is crucial. While existing AI ethics frameworks emphasize\nfairness, transparency, and accountability, they often lack actionable\nevaluation methods. This paper introduces a systematic approach using the\nResponsible AI Labs (RAIL) framework, which includes eight measurable\ndimensions to assess the normative behavior of large language models (LLMs). We\napply this framework to Anthropic's \"Values in the Wild\" dataset, containing\nover 308,000 anonymized conversations with Claude and more than 3,000 annotated\nvalue expressions. Our study maps these values to RAIL dimensions, computes\nsynthetic scores, and provides insights into the ethical behavior of LLMs in\nreal-world use.", "authors": ["Sumit Verma", "Pritam Prasun", "Arpit Jaiswal", "Pritish Kumar"], "category": "cs.AI", "updated": "2025-04-30T22:03:26Z"}
{"id": "2504.21276v1", "title": "Assessing LLM code generation quality through path planning tasks", "link": "http://arxiv.org/abs/2504.21276v1", "summary": "As LLM-generated code grows in popularity, more evaluation is needed to\nassess the risks of using such tools, especially for safety-critical\napplications such as path planning. Existing coding benchmarks are insufficient\nas they do not reflect the context and complexity of safety-critical\napplications. To this end, we assessed six LLMs' abilities to generate the code\nfor three different path-planning algorithms and tested them on three maps of\nvarious difficulties. Our results suggest that LLM-generated code presents\nserious hazards for path planning applications and should not be applied in\nsafety-critical contexts without rigorous testing.", "authors": ["Wanyi Chen", "Meng-Wen Su", "Mary L. Cummings"], "category": "cs.AI", "updated": "2025-04-30T03:11:54Z"}
{"id": "2504.21289v1", "title": "Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for\n  High-Dimensional Data and Its Application in Stock Trend Prediction", "link": "http://arxiv.org/abs/2504.21289v1", "summary": "Biclustering is an effective technique in data mining and pattern\nrecognition. Biclustering algorithms based on traditional clustering face two\nfundamental limitations when processing high-dimensional data: (1) The distance\nconcentration phenomenon in high-dimensional spaces leads to data sparsity,\nrendering similarity measures ineffective; (2) Mainstream linear dimensionality\nreduction methods disrupt critical local structural patterns. To apply\nbiclustering to high-dimensional datasets, we propose an orthogonal\nfactor-based biclustering algorithm (BCBOF). First, we constructed orthogonal\nfactors in the vector space of the high-dimensional dataset. Then, we performed\nclustering using the coordinates of the original data in the orthogonal\nsubspace as clustering targets. Finally, we obtained biclustering results of\nthe original dataset. Since dimensionality reduction was applied before\nclustering, the proposed algorithm effectively mitigated the data sparsity\nproblem caused by high dimensionality. Additionally, we applied this\nbiclustering algorithm to stock technical indicator combinations and stock\nprice trend prediction. Biclustering results were transformed into fuzzy rules,\nand we incorporated profit-preserving and stop-loss rules into the rule set,\nultimately forming a fuzzy inference system for stock price trend predictions\nand trading signals. To evaluate the performance of BCBOF, we compared it with\nexisting biclustering methods using multiple evaluation metrics. The results\nshowed that our algorithm outperformed other biclustering techniques. To\nvalidate the effectiveness of the fuzzy inference system, we conducted virtual\ntrading experiments using historical data from 10 A-share stocks. The\nexperimental results showed that the generated trading strategies yielded\nhigher returns for investors.", "authors": ["Yan Huang", "Da-Qing Zhang"], "category": "cs.AI", "updated": "2025-04-30T03:49:08Z"}
{"id": "2504.21296v1", "title": "Fairness in Graph Learning Augmented with Machine Learning: A Survey", "link": "http://arxiv.org/abs/2504.21296v1", "summary": "Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.", "authors": ["Renqiang Luo", "Ziqi Xu", "Xikun Zhang", "Qing Qing", "Huafei Huang", "Enyan Dai", "Zhe Wang", "Bo Yang"], "category": "cs.AI", "updated": "2025-04-30T04:02:23Z"}
{"id": "2504.21318v1", "title": "Phi-4-reasoning Technical Report", "link": "http://arxiv.org/abs/2504.21318v1", "summary": "We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that\nachieves strong performance on complex reasoning tasks. Trained via supervised\nfine-tuning of Phi-4 on carefully curated set of \"teachable\" prompts-selected\nfor the right level of complexity and diversity-and reasoning demonstrations\ngenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chains\nthat effectively leverage inference-time compute. We further develop\nPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer\nreasoning traces. Across a wide range of reasoning tasks, both models\noutperform significantly larger open-weight models such as\nDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full\nDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and\nscientific reasoning, coding, algorithmic problem solving, planning, and\nspatial understanding. Interestingly, we observe a non-trivial transfer of\nimprovements to general-purpose benchmarks as well. In this report, we provide\ninsights into our training data, our training methodologies, and our\nevaluations. We show that the benefit of careful data curation for supervised\nfine-tuning (SFT) extends to reasoning language models, and can be further\namplified by reinforcement learning (RL). Finally, our evaluation points to\nopportunities for improving how we assess the performance and robustness of\nreasoning models.", "authors": ["Marah Abdin", "Sahaj Agarwal", "Ahmed Awadallah", "Vidhisha Balachandran", "Harkirat Behl", "Lingjiao Chen", "Gustavo de Rosa", "Suriya Gunasekar", "Mojan Javaheripi", "Neel Joshi", "Piero Kauffmann", "Yash Lara", "Caio César Teodoro Mendes", "Arindam Mitra", "Besmira Nushi", "Dimitris Papailiopoulos", "Olli Saarikivi", "Shital Shah", "Vaishnavi Shrivastava", "Vibhav Vineet", "Yue Wu", "Safoora Yousefi", "Guoqing Zheng"], "category": "cs.AI", "updated": "2025-04-30T05:05:09Z"}
{"id": "2504.21326v1", "title": "Q-function Decomposition with Intervention Semantics with Factored\n  Action Spaces", "link": "http://arxiv.org/abs/2504.21326v1", "summary": "Many practical reinforcement learning environments have a discrete factored\naction space that induces a large combinatorial set of actions, thereby posing\nsignificant challenges. Existing approaches leverage the regular structure of\nthe action space and resort to a linear decomposition of Q-functions, which\navoids enumerating all combinations of factored actions. In this paper, we\nconsider Q-functions defined over a lower dimensional projected subspace of the\noriginal action space, and study the condition for the unbiasedness of\ndecomposed Q-functions using causal effect estimation from the no unobserved\nconfounder setting in causal statistics. This leads to a general scheme which\nwe call action decomposed reinforcement learning that uses the projected\nQ-functions to approximate the Q-function in standard model-free reinforcement\nlearning algorithms. The proposed approach is shown to improve sample\ncomplexity in a model-based reinforcement learning setting. We demonstrate\nimprovements in sample efficiency compared to state-of-the-art baselines in\nonline continuous control environments and a real-world offline sepsis\ntreatment environment.", "authors": ["Junkyu Lee", "Tian Gao", "Elliot Nelson", "Miao Liu", "Debarun Bhattacharjya", "Songtao Lu"], "category": "cs.AI", "updated": "2025-04-30T05:26:51Z"}
{"id": "2504.21347v1", "title": "IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces", "link": "http://arxiv.org/abs/2504.21347v1", "summary": "We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent\ndesigned to represent remote colleagues in shared office spaces, creating\nopportunities for real-time exchanges even in their absence. IRL Ditto offers a\nunique hybrid experience by allowing in-person colleagues to encounter a\ndigital version of their remote teammates, initiating greetings, updates, or\nsmall talk as they might in person. Our research question examines: How can the\nIRL Ditto influence interactions and relationships among colleagues in a shared\noffice space? Through a four-day study, we assessed IRL Ditto's ability to\nstrengthen social ties by simulating presence and enabling meaningful\ninteractions across different levels of social familiarity. We find that\nenhancing social relationships depended deeply on the foundation of the\nrelationship participants had with the source of the IRL Ditto. This study\nprovides insights into the role of embodied agents in enriching workplace\ndynamics for distributed teams.", "authors": ["Seonghee Lee", "Denae Ford", "John Tang", "Sasa Junuzovic", "Asta Roseway", "Ed Cutrell", "Kori Inkpen"], "category": "cs.AI", "updated": "2025-04-30T06:16:32Z"}
{"id": "2504.21356v2", "title": "Nexus-Gen: A Unified Model for Image Understanding, Generation, and\n  Editing", "link": "http://arxiv.org/abs/2504.21356v2", "summary": "Unified multimodal large language models (MLLMs) aim to integrate multimodal\nunderstanding and generation abilities through a single framework. Despite\ntheir versatility, existing open-source unified models exhibit performance gaps\nagainst domain-specific architectures. To bridge this gap, we present\nNexus-Gen, a unified model that synergizes the language reasoning capabilities\nof LLMs with the image synthesis power of diffusion models. To align the\nembedding space of the LLM and diffusion model, we conduct a dual-phase\nalignment training process. (1) The autoregressive LLM learns to predict image\nembeddings conditioned on multimodal inputs, while (2) the vision decoder is\ntrained to reconstruct high-fidelity images from these embeddings. During\ntraining the LLM, we identified a critical discrepancy between the\nautoregressive paradigm's training and inference phases, where error\naccumulation in continuous embedding space severely degrades generation\nquality. To avoid this issue, we introduce a prefilled autoregression strategy\nthat prefills input sequence with position-embedded special tokens instead of\ncontinuous embeddings. Through dual-phase training, Nexus-Gen has developed the\nintegrated capability to comprehensively address the image understanding,\ngeneration and editing tasks. All models, datasets, and codes are published at\nhttps://github.com/modelscope/Nexus-Gen.git to facilitate further advancements\nacross the field.", "authors": ["Hong Zhang", "Zhongjie Duan", "Xingjun Wang", "Yuze Zhao", "Weiyi Lu", "Zhipeng Di", "Yixuan Xu", "Yingda Chen", "Yu Zhang"], "category": "cs.AI", "updated": "2025-05-08T08:58:12Z"}
{"id": "2504.21358v1", "title": "A comparative study of deep learning and ensemble learning to extend the\n  horizon of traffic forecasting", "link": "http://arxiv.org/abs/2504.21358v1", "summary": "Traffic forecasting is vital for Intelligent Transportation Systems, for\nwhich Machine Learning (ML) methods have been extensively explored to develop\ndata-driven Artificial Intelligence (AI) solutions. Recent research focuses on\nmodelling spatial-temporal correlations for short-term traffic prediction,\nleaving the favourable long-term forecasting a challenging and open issue. This\npaper presents a comparative study on large-scale real-world signalized\narterials and freeway traffic flow datasets, aiming to evaluate promising ML\nmethods in the context of large forecasting horizons up to 30 days. Focusing on\nmodelling capacity for temporal dynamics, we develop one ensemble ML method,\neXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods,\nincluding Recurrent Neural Network (RNN)-based methods and the state-of-the-art\nTransformer-based method. Time embedding is leveraged to enhance their\nunderstanding of seasonality and event factors. Experimental results highlight\nthat while the attention mechanism/Transformer framework is effective for\ncapturing long-range dependencies in sequential data, as the forecasting\nhorizon extends, the key to effective traffic forecasting gradually shifts from\ntemporal dependency capturing to periodicity modelling. Time embedding is\nparticularly effective in this context, helping naive RNN outperform Informer\nby 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust\nmodel, XGBoost, while learning solely from time features, performs\ncompetitively with DL methods. Moreover, we investigate the impacts of various\nfactors like input sequence length, holiday traffic, data granularity, and\ntraining data size. The findings offer valuable insights and serve as a\nreference for future long-term traffic forecasting research and the improvement\nof AI's corresponding learning capabilities.", "authors": ["Xiao Zheng", "Saeed Asadi Bagloee", "Majid Sarvi"], "category": "cs.AI", "updated": "2025-04-30T06:31:21Z"}
{"id": "2504.21366v1", "title": "DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic\n  Gating Fusion", "link": "http://arxiv.org/abs/2504.21366v1", "summary": "Current Audio-Visual Source Separation methods primarily adopt two design\nstrategies. The first strategy involves fusing audio and visual features at the\nbottleneck layer of the encoder, followed by processing the fused features\nthrough the decoder. However, when there is a significant disparity between the\ntwo modalities, this approach may lead to the loss of critical information. The\nsecond strategy avoids direct fusion and instead relies on the decoder to\nhandle the interaction between audio and visual features. Nonetheless, if the\nencoder fails to integrate information across modalities adequately, the\ndecoder may be unable to effectively capture the complex relationships between\nthem. To address these issues, this paper proposes a dynamic fusion method\nbased on a gating mechanism that dynamically adjusts the modality fusion\ndegree. This approach mitigates the limitations of solely relying on the\ndecoder and facilitates efficient collaboration between audio and visual\nfeatures. Additionally, an audio attention module is introduced to enhance the\nexpressive capacity of audio features, thereby further improving model\nperformance. Experimental results demonstrate that our method achieves\nsignificant performance improvements on two benchmark datasets, validating its\neffectiveness and advantages in Audio-Visual Source Separation tasks.", "authors": ["Yinfeng Yu", "Shiyu Sun"], "category": "cs.AI", "updated": "2025-04-30T06:55:24Z"}
{"id": "2504.21368v1", "title": "Revisiting Diffusion Autoencoder Training for Image Reconstruction\n  Quality", "link": "http://arxiv.org/abs/2504.21368v1", "summary": "Diffusion autoencoders (DAEs) are typically formulated as a noise prediction\nmodel and trained with a linear-$\\beta$ noise schedule that spends much of its\nsampling steps at high noise levels. Because high noise levels are associated\nwith recovering large-scale image structures and low noise levels with\nrecovering details, this configuration can result in low-quality and blurry\nimages. However, it should be possible to improve details while spending fewer\nsteps recovering structures because the latent code should already contain\nstructural information. Based on this insight, we propose a new DAE training\nmethod that improves the quality of reconstructed images. We divide training\ninto two phases. In the first phase, the DAE is trained as a vanilla\nautoencoder by always setting the noise level to the highest, forcing the\nencoder and decoder to populate the latent code with structural information. In\nthe second phase, we incorporate a noise schedule that spends more time in the\nlow-noise region, allowing the DAE to learn how to perfect the details. Our\nmethod results in images that have accurate high-level structures and low-level\ndetails while still preserving useful properties of the latent codes.", "authors": ["Pramook Khungurn", "Sukit Seripanitkarn", "Phonphrm Thawatdamrongkit", "Supasorn Suwajanakorn"], "category": "cs.AI", "updated": "2025-04-30T07:00:33Z"}
{"id": "2504.21372v1", "title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction", "link": "http://arxiv.org/abs/2504.21372v1", "summary": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.", "authors": ["Máté Gedeon"], "category": "cs.AI", "updated": "2025-04-30T07:10:10Z"}
{"id": "2504.21383v1", "title": "FAST-Q: Fast-track Exploration with Adversarially Balanced State\n  Representations for Counterfactual Action Estimation in Offline Reinforcement\n  Learning", "link": "http://arxiv.org/abs/2504.21383v1", "summary": "Recent advancements in state-of-the-art (SOTA) offline reinforcement learning\n(RL) have primarily focused on addressing function approximation errors, which\ncontribute to the overestimation of Q-values for out-of-distribution actions, a\nchallenge that static datasets exacerbate. However, high stakes applications\nsuch as recommendation systems in online gaming, introduce further complexities\ndue to player's psychology (intent) driven by gameplay experiences and the\ninherent volatility on the platform. These factors create highly sparse,\npartially overlapping state spaces across policies, further influenced by the\nexperiment path selection logic which biases state spaces towards specific\npolicies. Current SOTA methods constrain learning from such offline data by\nclipping known counterfactual actions as out-of-distribution due to poor\ngeneralization across unobserved states. Further aggravating conservative\nQ-learning and necessitating more online exploration. FAST-Q introduces a novel\napproach that (1) leverages Gradient Reversal Learning to construct balanced\nstate representations, regularizing the policy-specific bias between the\nplayer's state and action thereby enabling counterfactual estimation; (2)\nsupports offline counterfactual exploration in parallel with static data\nexploitation; and (3) proposes a Q-value decomposition strategy for\nmulti-objective optimization, facilitating explainable recommendations over\nshort and long-term objectives. These innovations demonstrate superiority of\nFAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent\nincrease in player returns, 2 percent improvement in lifetime value (LTV), 0.4\npercent enhancement in the recommendation driven engagement, 2 percent\nimprovement in the player's platform dwell time and an impressive 10 percent\nreduction in the costs associated with the recommendation, on our volatile\ngaming platform.", "authors": ["Pulkit Agrawal", "Rukma Talwadker", "Aditya Pareek", "Tridib Mukherjee"], "category": "cs.AI", "updated": "2025-04-30T07:32:40Z"}
{"id": "2504.21415v2", "title": "Optimizing Mouse Dynamics for User Authentication by Machine Learning:\n  Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model\n  Performance Challenges", "link": "http://arxiv.org/abs/2504.21415v2", "summary": "User authentication is essential to ensure secure access to computer systems,\nyet traditional methods face limitations in usability, cost, and security.\nMouse dynamics authentication, based on the analysis of users' natural\ninteraction behaviors with mouse devices, offers a cost-effective,\nnon-intrusive, and adaptable solution. However, challenges remain in\ndetermining the optimal data volume, balancing accuracy and practicality, and\neffectively capturing temporal behavioral patterns. In this study, we propose a\nstatistical method using Gaussian kernel density estimate (KDE) and\nKullback-Leibler (KL) divergence to estimate the sufficient data volume for\ntraining authentication models. We introduce the Mouse Authentication Unit\n(MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for\nefficient and accurate behavioral representation. Furthermore, we design the\nLocal-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet\nfor local feature extraction and GRU for modeling long-term temporal\ndependencies. Taking the Balabit and DFL datasets as examples, we significantly\nreduced the data scale, particularly by a factor of 10 for the DFL dataset,\ngreatly alleviating the training burden. Additionally, we determined the\noptimal input recognition unit length for the user authentication system on\ndifferent datasets based on the slope of Approximate Entropy. Training with\nimbalanced samples, our model achieved a successful defense AUC 98.52% for\nblind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing\nthe current sota performance.", "authors": ["Yi Wang", "Chengyv Wu", "Yang Liao", "Maowei You"], "category": "cs.AI", "updated": "2025-05-11T05:42:14Z"}
{"id": "2504.21427v1", "title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of\n  Clustering-Based Classifiers", "link": "http://arxiv.org/abs/2504.21427v1", "summary": "Accurate classification of EEG signals is crucial for brain-computer\ninterfaces (BCIs) and neuroprosthetic applications, yet many existing methods\nfail to account for the non-Euclidean, manifold structure of EEG data,\nresulting in suboptimal performance. Preserving this manifold information is\nessential to capture the true geometry of EEG signals, but traditional\nclassification techniques largely overlook this need. To this end, we propose\nMPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based\nClassifiers), that introduces two key innovations: (1) a feature engineering\nphase that combines covariance matrices and Radial Basis Function (RBF) kernels\nto capture both linear and non-linear relationships among EEG channels, and (2)\na clustering phase that employs a modified K-means algorithm tailored for the\nRiemannian manifold space, ensuring local geometric sensitivity. Ensembling\nmultiple clustering-based classifiers, MPEC achieves superior results,\nvalidated by significant improvements on the BCI Competition IV dataset 2a.", "authors": ["Shermin Shahbazi", "Mohammad-Reza Nasiri", "Majid Ramezani"], "category": "cs.AI", "updated": "2025-04-30T08:34:15Z"}
{"id": "2504.21447v1", "title": "Rethinking Visual Layer Selection in Multimodal LLMs", "link": "http://arxiv.org/abs/2504.21447v1", "summary": "Multimodal large language models (MLLMs) have achieved impressive performance\nacross a wide range of tasks, typically using CLIP-ViT as their visual encoder\ndue to its strong text-image alignment capabilities. While prior studies\nsuggest that different CLIP-ViT layers capture different types of information,\nwith shallower layers focusing on fine visual details and deeper layers\naligning more closely with textual semantics, most MLLMs still select visual\nfeatures based on empirical heuristics rather than systematic analysis. In this\nwork, we propose a Layer-wise Representation Similarity approach to group\nCLIP-ViT layers with similar behaviors into {shallow, middle, and deep}\ncategories and assess their impact on MLLM performance. Building on this\nfoundation, we revisit the visual layer selection problem in MLLMs at scale,\ntraining LLaVA-style models ranging from 1.4B to 7B parameters. Through\nextensive experiments across 10 datasets and 4 tasks, we find that: (1) deep\nlayers are essential for OCR tasks; (2) shallow and middle layers substantially\noutperform deep layers on reasoning tasks involving counting, positioning, and\nobject localization; (3) a lightweight fusion of features across shallow,\nmiddle, and deep layers consistently outperforms specialized fusion baselines\nand single-layer selections, achieving gains on 9 out of 10 datasets. Our work\noffers the first principled study of visual layer selection in MLLMs, laying\nthe groundwork for deeper investigations into visual representation learning\nfor MLLMs.", "authors": ["Haoran Chen", "Junyan Lin", "Xinhao Chen", "Yue Fan", "Xin Jin", "Hui Su", "Jianfeng Dong", "Jinlan Fu", "Xiaoyu Shen"], "category": "cs.AI", "updated": "2025-04-30T09:07:10Z"}
{"id": "2504.21454v1", "title": "SimPRIVE: a Simulation framework for Physical Robot Interaction with\n  Virtual Environments", "link": "http://arxiv.org/abs/2504.21454v1", "summary": "The use of machine learning in cyber-physical systems has attracted the\ninterest of both industry and academia. However, no general solution has yet\nbeen found against the unpredictable behavior of neural networks and\nreinforcement learning agents. Nevertheless, the improvements of\nphoto-realistic simulators have paved the way towards extensive testing of\ncomplex algorithms in different virtual scenarios, which would be expensive and\ndangerous to implement in the real world.\n  This paper presents SimPRIVE, a simulation framework for physical robot\ninteraction with virtual environments, which operates as a vehicle-in-the-loop\nplatform, rendering a virtual world while operating the vehicle in the real\nworld.\n  Using SimPRIVE, any physical mobile robot running on ROS 2 can easily be\nconfigured to move its digital twin in a virtual world built with the Unreal\nEngine 5 graphic engine, which can be populated with objects, people, or other\nvehicles with programmable behavior.\n  SimPRIVE has been designed to accommodate custom or pre-built virtual worlds\nwhile being light-weight to contain execution times and allow fast rendering.\nIts main advantage lies in the possibility of testing complex algorithms on the\nfull software and hardware stack while minimizing the risks and costs of a test\ncampaign. The framework has been validated by testing a reinforcement learning\nagent trained for obstacle avoidance on an AgileX Scout Mini rover that\nnavigates a virtual office environment where everyday objects and people are\nplaced as obstacles. The physical rover moves with no collision in an indoor\nlimited space, thanks to a LiDAR-based heuristic.", "authors": ["Federico Nesti", "Gianluca D'Amico", "Mauro Marinoni", "Giorgio Buttazzo"], "category": "cs.AI", "updated": "2025-04-30T09:22:55Z"}
{"id": "2504.21457v1", "title": "xEEGNet: Towards Explainable AI in EEG Dementia Classification", "link": "http://arxiv.org/abs/2504.21457v1", "summary": "This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.", "authors": ["Andrea Zanola", "Louis Fabrice Tshimanga", "Federico Del Pup", "Marco Baiesi", "Manfredo Atzori"], "category": "cs.AI", "updated": "2025-04-30T09:24:50Z"}
{"id": "2504.21474v1", "title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner\n  for Subject Tagging", "link": "http://arxiv.org/abs/2504.21474v1", "summary": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject\nTagging, which focuses on automatically assigning subject labels to technical\nrecords from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage\nOntoAligner, a modular ontology alignment toolkit, to address this task by\nintegrating retrieval-augmented generation (RAG) techniques. Our approach\nformulates the subject tagging problem as an alignment task, where records are\nmatched to GND categories based on semantic similarity. We evaluate\nOntoAligner's adaptability for subject indexing and analyze its effectiveness\nin handling multilingual records. Experimental results demonstrate the\nstrengths and limitations of this method, highlighting the potential of\nalignment techniques for improving subject tagging in digital libraries.", "authors": ["Hadi Bayrami Asl Tekanlou", "Jafar Razmara", "Mahsa Sanaei", "Mostafa Rahgouy", "Hamed Babaei Giglou"], "category": "cs.AI", "updated": "2025-04-30T09:52:51Z"}
{"id": "2504.21476v2", "title": "GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal\n  Diffusion Transformers", "link": "http://arxiv.org/abs/2504.21476v2", "summary": "Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present GarmentDiffusion, a\nnew generative model capable of producing centimeter-precise, vectorized 3D\nsewing patterns from multimodal inputs (text, image, and incomplete sewing\npattern). Our method efficiently encodes 3D sewing pattern parameters into\ncompact edge token representations, achieving a sequence length that is 10\ntimes shorter than that of the autoregressive SewingGPT in DressCode. By\nemploying a diffusion transformer, we simultaneously denoise all edge tokens\nalong the temporal axis, while maintaining a constant number of denoising steps\nregardless of dataset-specific edge and panel statistics. With all combination\nof designs of our model, the sewing pattern generation speed is accelerated by\n100 times compared to SewingGPT. We achieve new state-of-the-art results on\nDressCodeData, as well as on the largest sewing pattern dataset, namely\nGarmentCodeData. The project website is available at\nhttps://shenfu-research.github.io/Garment-Diffusion/.", "authors": ["Xinyu Li", "Qi Yao", "Yuanda Wang"], "category": "cs.AI", "updated": "2025-05-10T13:14:47Z"}
{"id": "2504.21489v2", "title": "TRIED: Truly Innovative and Effective AI Detection Benchmark, developed\n  by WITNESS", "link": "http://arxiv.org/abs/2504.21489v2", "summary": "The proliferation of generative AI and deceptive synthetic media threatens\nthe global information ecosystem, especially across the Global Majority. This\nreport from WITNESS highlights the limitations of current AI detection tools,\nwhich often underperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policy actors, and standards bodies to\ndesign accountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.", "authors": ["Shirin Anlen", "Zuzanna Wojciak"], "category": "cs.AI", "updated": "2025-05-01T13:38:27Z"}
{"id": "2504.21545v1", "title": "Meta knowledge assisted Evolutionary Neural Architecture Search", "link": "http://arxiv.org/abs/2504.21545v1", "summary": "Evolutionary computation (EC)-based neural architecture search (NAS) has\nachieved remarkable performance in the automatic design of neural\narchitectures. However, the high computational cost associated with evaluating\nsearched architectures poses a challenge for these methods, and a fixed form of\nlearning rate (LR) schedule means greater information loss on diverse searched\narchitectures. This paper introduces an efficient EC-based NAS method to solve\nthese problems via an innovative meta-learning framework. Specifically, a\nmeta-learning-rate (Meta-LR) scheme is used through pretraining to obtain a\nsuitable LR schedule, which guides the training process with lower information\nloss when evaluating each individual. An adaptive surrogate model is designed\nthrough an adaptive threshold to select the potential architectures in a few\nepochs and then evaluate the potential architectures with complete epochs.\nAdditionally, a periodic mutation operator is proposed to increase the\ndiversity of the population, which enhances the generalizability and\nrobustness. Experiments on CIFAR-10, CIFAR-100, and ImageNet1K datasets\ndemonstrate that the proposed method achieves high performance comparable to\nthat of many state-of-the-art peer methods, with lower computational cost and\ngreater robustness.", "authors": ["Yangyang Li", "Guanlong Liu", "Ronghua Shang", "Licheng Jiao"], "category": "cs.AI", "updated": "2025-04-30T11:43:07Z"}
{"id": "2504.21562v1", "title": "eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes", "link": "http://arxiv.org/abs/2504.21562v1", "summary": "Wireless Capsule Endoscopy is a non-invasive imaging method for the entire\ngastrointestinal tract, and is a pain-free alternative to traditional\nendoscopy. It generates extensive video data that requires significant review\ntime, and localizing the capsule after ingestion is a challenge. Techniques\nlike bleeding detection and depth estimation can help with localization of\npathologies, but deep learning models are typically too large to run directly\non the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and\ndepth estimation are trained on capsule endoscopic images. For monocular depth\nestimation, we distill a large foundation model into the lean NCA architecture,\nby treating the outputs of the foundation model as pseudo ground truth. We then\nport the trained NCA to the ESP32 microcontroller, enabling efficient image\nprocessing on hardware as small as a camera capsule. NCA are more accurate\n(Dice) than other portable segmentation models, while requiring more than 100x\nfewer parameters stored in memory than other small-scale models. The visual\nresults of NCA depth estimation look convincing, and in some cases beat the\nrealism and detail of the pseudo ground truth. Runtime optimizations on the\nESP32-S3 accelerate the average inference speed significantly, by more than\nfactor 3. With several algorithmic adjustments and distillation, it is possible\nto eNCApsulate NCA models into microcontrollers that fit into wireless capsule\nendoscopes. This is the first work that enables reliable bleeding segmentation\nand depth estimation on a miniaturized device, paving the way for precise\ndiagnosis combined with visual odometry as a means of precise localization of\nthe capsule -- on the capsule.", "authors": ["Henry John Krumb", "Anirban Mukhopadhyay"], "category": "cs.AI", "updated": "2025-04-30T12:06:56Z"}
{"id": "2504.21565v1", "title": "Towards proactive self-adaptive AI for non-stationary environments with\n  dataset shifts", "link": "http://arxiv.org/abs/2504.21565v1", "summary": "Artificial Intelligence (AI) models deployed in production frequently face\nchallenges in maintaining their performance in non-stationary environments.\nThis issue is particularly noticeable in medical settings, where temporal\ndataset shifts often occur. These shifts arise when the distributions of\ntraining data differ from those of the data encountered during deployment over\ntime. Further, new labeled data to continuously retrain AI is not typically\navailable in a timely manner due to data access limitations. To address these\nchallenges, we propose a proactive self-adaptive AI approach, or pro-adaptive,\nwhere we model the temporal trajectory of AI parameters, allowing us to\nshort-term forecast parameter values. To this end, we use polynomial spline\nbases, within an extensible Functional Data Analysis framework. We validate our\nmethodology with a logistic regression model addressing prior probability\nshift, covariate shift, and concept shift. This validation is conducted on both\na controlled simulated dataset and a publicly available real-world COVID-19\ndataset from Mexico, with various shifts occurring between 2020 and 2024. Our\nresults indicate that this approach enhances the performance of AI against\nshifts compared to baseline stable models trained at different time distances\nfrom the present, without requiring updated training data. This work lays the\nfoundation for pro-adaptive AI research against dynamic, non-stationary\nenvironments, being compatible with data protection, in resilient AI production\nenvironments for health.", "authors": ["David Fernández Narro", "Pablo Ferri", "Juan M. García-Gómez", "Carlos Sáez"], "category": "cs.AI", "updated": "2025-04-30T12:09:59Z"}
{"id": "2504.21582v1", "title": "MF-LLM: Simulating Collective Decision Dynamics via a Mean-Field Large\n  Language Model Framework", "link": "http://arxiv.org/abs/2504.21582v1", "summary": "Simulating collective decision-making involves more than aggregating\nindividual behaviors; it arises from dynamic interactions among individuals.\nWhile large language models (LLMs) show promise for social simulation, existing\napproaches often exhibit deviations from real-world data. To address this gap,\nwe propose the Mean-Field LLM (MF-LLM) framework, which explicitly models the\nfeedback loop between micro-level decisions and macro-level population. MF-LLM\nalternates between two models: a policy model that generates individual actions\nbased on personal states and group-level information, and a mean field model\nthat updates the population distribution from the latest individual decisions.\nTogether, they produce rollouts that simulate the evolving trajectories of\ncollective decision-making. To better match real-world data, we introduce\nIB-Tune, a fine-tuning method for LLMs grounded in the information bottleneck\nprinciple, which maximizes the relevance of population distributions to future\nactions while minimizing redundancy with historical data. We evaluate MF-LLM on\na real-world social dataset, where it reduces KL divergence to human population\ndistributions by 47 percent over non-mean-field baselines, and enables accurate\ntrend forecasting and intervention planning. It generalizes across seven\ndomains and four LLM backbones, providing a scalable foundation for\nhigh-fidelity social simulation.", "authors": ["Qirui Mi", "Mengyue Yang", "Xiangning Yu", "Zhiyu Zhao", "Cheng Deng", "Bo An", "Haifeng Zhang", "Xu Chen", "Jun Wang"], "category": "cs.AI", "updated": "2025-04-30T12:41:51Z"}
{"id": "2504.21596v1", "title": "Leveraging Pre-trained Large Language Models with Refined Prompting for\n  Online Task and Motion Planning", "link": "http://arxiv.org/abs/2504.21596v1", "summary": "With the rapid advancement of artificial intelligence, there is an increasing\ndemand for intelligent robots capable of assisting humans in daily tasks and\nperforming complex operations. Such robots not only require task planning\ncapabilities but must also execute tasks with stability and robustness. In this\npaper, we present a closed-loop task planning and acting system, LLM-PAS, which\nis assisted by a pre-trained Large Language Model (LLM). While LLM-PAS plans\nlong-horizon tasks in a manner similar to traditional task and motion planners,\nit also emphasizes the execution phase of the task. By transferring part of the\nconstraint-checking process from the planning phase to the execution phase,\nLLM-PAS enables exploration of the constraint space and delivers more accurate\nfeedback on environmental anomalies during execution. The reasoning\ncapabilities of the LLM allow it to handle anomalies that cannot be addressed\nby the robust executor. To further enhance the system's ability to assist the\nplanner during replanning, we propose the First Look Prompting (FLP) method,\nwhich induces LLM to generate effective PDDL goals. Through comparative\nprompting experiments and systematic experiments, we demonstrate the\neffectiveness and robustness of LLM-PAS in handling anomalous conditions during\ntask execution.", "authors": ["Huihui Guo", "Huilong Pi", "Yunchuan Qin", "Zhuo Tang", "Kenli Li"], "category": "cs.AI", "updated": "2025-04-30T12:53:53Z"}
{"id": "2504.21635v1", "title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model", "link": "http://arxiv.org/abs/2504.21635v1", "summary": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools.", "authors": ["Zeina Aldallal", "Sara Chrouf", "Khalil Hennara", "Mohamed Motaism Hamed", "Muhammad Hreden", "Safwan AlModhayan"], "category": "cs.AI", "updated": "2025-04-30T13:37:24Z"}
{"id": "2504.21643v1", "title": "Designing Control Barrier Function via Probabilistic Enumeration for\n  Safe Reinforcement Learning Navigation", "link": "http://arxiv.org/abs/2504.21643v1", "summary": "Achieving safe autonomous navigation systems is critical for deploying robots\nin dynamic and uncertain real-world environments. In this paper, we propose a\nhierarchical control framework leveraging neural network verification\ntechniques to design control barrier functions (CBFs) and policy correction\nmechanisms that ensure safe reinforcement learning navigation policies. Our\napproach relies on probabilistic enumeration to identify unsafe regions of\noperation, which are then used to construct a safe CBF-based control layer\napplicable to arbitrary policies. We validate our framework both in simulation\nand on a real robot, using a standard mobile robot benchmark and a highly\ndynamic aquatic environmental monitoring task. These experiments demonstrate\nthe ability of the proposed solution to correct unsafe actions while preserving\nefficient navigation behavior. Our results show the promise of developing\nhierarchical verification-based systems to enable safe and robust navigation\nbehaviors in complex scenarios.", "authors": ["Luca Marzari", "Francesco Trotti", "Enrico Marchesini", "Alessandro Farinelli"], "category": "cs.AI", "updated": "2025-04-30T13:47:25Z"}
{"id": "2504.21659v1", "title": "AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning\n  Optimization", "link": "http://arxiv.org/abs/2504.21659v1", "summary": "Recently, long-thought reasoning models achieve strong performance on complex\nreasoning tasks, but often incur substantial inference overhead, making\nefficiency a critical concern. Our empirical analysis reveals that the benefit\nof using Long-CoT varies across problems: while some problems require elaborate\nreasoning, others show no improvement, or even degraded accuracy. This\nmotivates adaptive reasoning strategies that tailor reasoning depth to the\ninput. However, prior work primarily reduces redundancy within long reasoning\npaths, limiting exploration of more efficient strategies beyond the Long-CoT\nparadigm. To address this, we propose a novel two-stage framework for adaptive\nand efficient reasoning. First, we construct a hybrid reasoning model by\nmerging long and short CoT models to enable diverse reasoning styles. Second,\nwe apply bi-level preference training to guide the model to select suitable\nreasoning styles (group-level), and prefer concise and correct reasoning within\neach style group (instance-level). Experiments demonstrate that our method\nsignificantly reduces inference costs compared to other baseline approaches,\nwhile maintaining performance. Notably, on five mathematical datasets, the\naverage length of reasoning is reduced by more than 50%, highlighting the\npotential of adaptive strategies to optimize reasoning efficiency in large\nlanguage models. Our code is coming soon at https://github.com/StarDewXXX/AdaR1", "authors": ["Haotian Luo", "Haiying He", "Yibo Wang", "Jinluan Yang", "Rui Liu", "Naiqiang Tan", "Xiaochun Cao", "Dacheng Tao", "Li Shen"], "category": "cs.AI", "updated": "2025-04-30T14:01:45Z"}
{"id": "2504.21685v1", "title": "Enhancing Health Mention Classification Performance: A Study on\n  Advancements in Parameter Efficient Tuning", "link": "http://arxiv.org/abs/2504.21685v1", "summary": "Health Mention Classification (HMC) plays a critical role in leveraging\nsocial media posts for real-time tracking and public health monitoring.\nNevertheless, the process of HMC presents significant challenges due to its\nintricate nature, primarily stemming from the contextual aspects of health\nmentions, such as figurative language and descriptive terminology, rather than\nexplicitly reflecting a personal ailment. To address this problem, we argue\nthat clearer mentions can be achieved through conventional fine-tuning with\nenhanced parameters of biomedical natural language methods (NLP). In this\nstudy, we explore different techniques such as the utilisation of\npart-of-speech (POS) tagger information, improving on PEFT techniques, and\ndifferent combinations thereof. Extensive experiments are conducted on three\nwidely used datasets: RHDM, PHM, and Illness. The results incorporated POS\ntagger information, and leveraging PEFT techniques significantly improves\nperformance in terms of F1-score compared to state-of-the-art methods across\nall three datasets by utilising smaller models and efficient training.\nFurthermore, the findings highlight the effectiveness of incorporating POS\ntagger information and leveraging PEFT techniques for HMC. In conclusion, the\nproposed methodology presents a potentially effective approach to accurately\nclassifying health mentions in social media posts while optimising the model\nsize and training efficiency.", "authors": ["Reem Abdel-Salam", "Mary Adewunmi"], "category": "cs.AI", "updated": "2025-04-30T14:21:54Z"}
{"id": "2504.21692v1", "title": "Enhancing Self-Supervised Fine-Grained Video Object Tracking with\n  Dynamic Memory Prediction", "link": "http://arxiv.org/abs/2504.21692v1", "summary": "Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.", "authors": ["Zihan Zhou", "Changrui Dai", "Aibo Song", "Xiaolin Fang"], "category": "cs.AI", "updated": "2025-04-30T14:29:04Z"}
{"id": "2504.21695v1", "title": "Self-Supervised Monocular Visual Drone Model Identification through\n  Improved Occlusion Handling", "link": "http://arxiv.org/abs/2504.21695v1", "summary": "Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.", "authors": ["Stavrow A. Bahnam", "Christophe De Wagter", "Guido C. H. E. de Croon"], "category": "cs.AI", "updated": "2025-04-30T14:38:01Z"}
{"id": "2504.21706v1", "title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "link": "http://arxiv.org/abs/2504.21706v1", "summary": "Detecting plant diseases is a crucial aspect of modern agriculture - it plays\na key role in maintaining crop health and increasing overall yield. Traditional\napproaches, though still valuable, often rely on manual inspection or\nconventional machine learning techniques, both of which face limitations in\nscalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as\na promising alternative, offering benefits such as improved handling of\nlong-range dependencies and better scalability for visual tasks. This survey\nexplores the application of ViTs in precision agriculture, covering tasks from\nclassification to detection and segmentation. We begin by introducing the\nfoundational architecture of ViTs and discuss their transition from Natural\nLanguage Processing (NLP) to computer vision. The discussion includes the\nconcept of inductive bias in traditional models like Convolutional Neural\nNetworks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive\nreview of recent literature, focusing on key methodologies, datasets, and\nperformance metrics. The survey also includes a comparative analysis of CNNs\nand ViTs, with a look at hybrid models and performance enhancements. Technical\nchallenges - such as data requirements, computational demands, and model\ninterpretability - are addressed alongside potential solutions. Finally, we\noutline potential research directions and technological advancements that could\nfurther support the integration of ViTs in real-world agricultural settings.\nOur goal with this study is to offer practitioners and researchers a deeper\nunderstanding of how ViTs are poised to transform smart and precision\nagriculture.", "authors": ["Saber Mehdipour", "Seyed Abolghasem Mirroshandel", "Seyed Amirhossein Tabatabaei"], "category": "cs.AI", "updated": "2025-04-30T14:50:02Z"}
{"id": "2504.21772v2", "title": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets\n  and an Audio Restoration Deep Learning Pipeline", "link": "http://arxiv.org/abs/2504.21772v2", "summary": "Short video platforms like YouTube Shorts and TikTok face significant\ncopyright compliance challenges, as infringers frequently embed arbitrary\nbackground music (BGM) to obscure original soundtracks (OST) and evade content\noriginality detection. To tackle this issue, we propose a novel pipeline that\nintegrates Music Source Separation (MSS) and cross-modal video-music retrieval\n(CMVMR). Our approach effectively separates arbitrary BGM from the original\nOST, enabling the restoration of authentic video audio tracks. To support this\nwork, we introduce two domain-specific datasets: OASD-20K for audio separation\nand OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips\nfeaturing mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset\ncomprising 1,121 video and mixed-audio pairs, specifically designed for short\nvideo restoration tasks. Experimental results demonstrate that our pipeline not\nonly removes arbitrary BGM with high accuracy but also restores OSTs, ensuring\ncontent integrity. This approach provides an ethical and scalable solution to\ncopyright challenges in user-generated content on short video platforms.", "authors": ["Minwoo Oh", "Minsu Park", "Eunil Park"], "category": "cs.AI", "updated": "2025-05-03T12:54:39Z"}
{"id": "2504.21773v1", "title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced\n  Knowledge Boundary Awareness", "link": "http://arxiv.org/abs/2504.21773v1", "summary": "With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.", "authors": ["Junsheng Huang", "Zhitao He", "Sandeep Polisetty", "Qingyun Wang", "May Fung"], "category": "cs.AI", "updated": "2025-04-30T16:17:53Z"}
{"id": "2504.21775v1", "title": "Learning Heterogeneous Performance-Fairness Trade-offs in Federated\n  Learning", "link": "http://arxiv.org/abs/2504.21775v1", "summary": "Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.", "authors": ["Rongguang Ye", "Ming Tang"], "category": "cs.AI", "updated": "2025-04-30T16:25:02Z"}
{"id": "2504.21801v1", "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via\n  Reinforcement Learning for Subgoal Decomposition", "link": "http://arxiv.org/abs/2504.21801v1", "summary": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.", "authors": ["Z. Z. Ren", "Zhihong Shao", "Junxiao Song", "Huajian Xin", "Haocheng Wang", "Wanjia Zhao", "Liyue Zhang", "Zhe Fu", "Qihao Zhu", "Dejian Yang", "Z. F. Wu", "Zhibin Gou", "Shirong Ma", "Hongxuan Tang", "Yuxuan Liu", "Wenjun Gao", "Daya Guo", "Chong Ruan"], "category": "cs.AI", "updated": "2025-04-30T16:57:48Z"}
{"id": "2504.21831v1", "title": "Early Exit and Multi Stage Knowledge Distillation in VLMs for Video\n  Summarization", "link": "http://arxiv.org/abs/2504.21831v1", "summary": "We introduce DEEVISum (Distilled Early Exit Vision language model for\nSummarization), a lightweight, efficient, and scalable vision language model\ndesigned for segment wise video summarization. Leveraging multi modal prompts\nthat combine textual and audio derived signals, DEEVISum incorporates Multi\nStage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance\nbetween performance and efficiency. MSKD offers a 1.33% absolute F1 improvement\nover baseline distillation (0.5%), while EE reduces inference time by\napproximately 21% with a 1.3 point drop in F1. Evaluated on the TVSum dataset,\nour best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing\nthe performance of significantly larger models, all while maintaining a lower\ncomputational footprint. We publicly release our code and processed dataset to\nsupport further research.", "authors": ["Anas Anwarul Haq Khan", "Utkarsh Verma", "Prateek Chanda", "Ganesh Ramakrishnan"], "category": "cs.AI", "updated": "2025-04-30T17:37:55Z"}
{"id": "2504.21851v1", "title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and\n  Structured Assessments", "link": "http://arxiv.org/abs/2504.21851v1", "summary": "Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.", "authors": ["Sichang Tu", "Abigail Powers", "Stephen Doogan", "Jinho D. Choi"], "category": "cs.AI", "updated": "2025-04-30T17:58:06Z"}
{"id": "2505.00050v1", "title": "Emotional Analysis of Fashion Trends Using Social Media and AI:\n  Sentiment Analysis on Twitter for Fashion Trend Forecasting", "link": "http://arxiv.org/abs/2505.00050v1", "summary": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories.", "authors": ["Aayam Bansal", "Agneya Tharun"], "category": "cs.AI", "updated": "2025-04-30T07:27:06Z"}
{"id": "2505.00091v2", "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In\n  Low-altitude Urban Scenarios", "link": "http://arxiv.org/abs/2505.00091v2", "summary": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes.", "authors": ["Tengchao Zhang", "Yonglin Tian", "Fei Lin", "Jun Huang", "Patrik P. Süli", "Rui Qin", "Fei-Yue Wang"], "category": "cs.AI", "updated": "2025-05-03T16:45:20Z"}
{"id": "2505.00114v1", "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of\n  Lebanese", "link": "http://arxiv.org/abs/2505.00114v1", "summary": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github.", "authors": ["Silvana Yakhni", "Ali Chehab"], "category": "cs.AI", "updated": "2025-04-30T18:33:53Z"}
{"id": "2505.00127v1", "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning\n  Length and correctness in LLMs", "link": "http://arxiv.org/abs/2505.00127v1", "summary": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation.", "authors": ["Jinyan Su", "Jennifer Healey", "Preslav Nakov", "Claire Cardie"], "category": "cs.AI", "updated": "2025-04-30T18:48:06Z"}
{"id": "2505.00169v1", "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D\n  Molecule Generation", "link": "http://arxiv.org/abs/2505.00169v1", "summary": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.", "authors": ["Filipp Nikitin", "Ian Dunn", "David Ryan Koes", "Olexandr Isayev"], "category": "cs.AI", "updated": "2025-04-30T20:29:22Z"}
{"id": "2505.00171v1", "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence\n  Prediction", "link": "http://arxiv.org/abs/2505.00171v1", "summary": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels.", "authors": ["Saram Abbas", "Naeem Soomro", "Rishad Shafik", "Rakesh Heer", "Kabita Adhikari"], "category": "cs.AI", "updated": "2025-04-30T20:39:33Z"}
{"id": "2505.00190v1", "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders", "link": "http://arxiv.org/abs/2505.00190v1", "summary": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off.", "authors": ["Hans Peter", "Anders Søgaard"], "category": "cs.AI", "updated": "2025-04-30T21:08:32Z"}
{"id": "2505.00225v1", "title": "Predicting Estimated Times of Restoration for Electrical Outages Using\n  Longitudinal Tabular Transformers", "link": "http://arxiv.org/abs/2505.00225v1", "summary": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities.", "authors": ["Bogireddy Sai Prasanna Teja", "Valliappan Muthukaruppan", "Carls Benjamin"], "category": "cs.AI", "updated": "2025-05-01T00:25:43Z"}
{"id": "2505.00232v1", "title": "Scaling On-Device GPU Inference for Large Generative Models", "link": "http://arxiv.org/abs/2505.00232v1", "summary": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines.", "authors": ["Jiuqiang Tang", "Raman Sarokin", "Ekaterina Ignasheva", "Grant Jensen", "Lin Chen", "Juhyun Lee", "Andrei Kulik", "Matthias Grundmann"], "category": "cs.AI", "updated": "2025-05-01T00:44:13Z"}
{"id": "2505.00749v1", "title": "The Coral Protocol: Open Infrastructure Connecting The Internet of\n  Agents", "link": "http://arxiv.org/abs/2505.00749v1", "summary": "The Coral Protocol is an open and decentralized collaboration infrastructure\nthat enables communication, coordination, trust and payments for The Internet\nof Agents. It addresses the growing need for interoperability in a world where\norganizations are deploying multiple specialized AI agents that must work\ntogether across domains and vendors. As a foundational platform for multi-agent\nAI ecosystems, Coral establishes a common language and coordination framework\nallowing any agent to participate in complex workflows with others. Its design\nemphasizes broad compatibility, security, and vendor neutrality, ensuring that\nagent interactions are efficient and trustworthy. In particular, Coral\nintroduces standardized messaging formats for agent communication, a modular\ncoordination mechanism for orchestrating multi-agent tasks, and secure team\nformation capabilities for dynamically assembling trusted groups of agents.\nTogether, these innovations position Coral Protocol as a cornerstone of the\nemerging \"Internet of Agents,\" unlocking new levels of automation, collective\nintelligence, and business value through open agent collaboration.", "authors": ["Roman J. Georgio", "Caelum Forder", "Suman Deb", "Peter Carroll", "Önder Gürcan"], "category": "cs.AI", "updated": "2025-04-30T22:17:13Z"}
{"id": "2504.21261v1", "title": "Multi-Domain Causal Discovery in Bijective Causal Models", "link": "http://arxiv.org/abs/2504.21261v1", "summary": "We consider the problem of causal discovery (a.k.a., causal structure\nlearning) in a multi-domain setting. We assume that the causal functions are\ninvariant across the domains, while the distribution of the exogenous noise may\nvary. Under causal sufficiency (i.e., no confounders exist), we show that the\ncausal diagram can be discovered under less restrictive functional assumptions\ncompared to previous work. What enables causal discovery in this setting is\nbijective generation mechanisms (BGM), which ensures that the functional\nrelation between the exogenous noise $E$ and the endogenous variable $Y$ is\nbijective and differentiable in both directions at every level of the cause\nvariable $X = x$. BGM generalizes a variety of models including additive noise\nmodel, LiNGAM, post-nonlinear model, and location-scale noise model. Further,\nwe derive a statistical test to find the parents set of the target variable.\nExperiments on various synthetic and real-world datasets validate our\ntheoretical findings.", "authors": ["Kasra Jalaldoust", "Saber Salehkaleybar", "Negar Kiyavash"], "category": "cs.AI", "updated": "2025-04-30T02:30:10Z"}
{"id": "2504.21323v1", "title": "How to Backdoor the Knowledge Distillation", "link": "http://arxiv.org/abs/2504.21323v1", "summary": "Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.", "authors": ["Chen Wu", "Qian Ma", "Prasenjit Mitra", "Sencun Zhu"], "category": "cs.AI", "updated": "2025-04-30T05:19:23Z"}
{"id": "2504.21344v1", "title": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early\n  Lung Cancer Detection", "link": "http://arxiv.org/abs/2504.21344v1", "summary": "Objective: A number of machine learning models have utilized semantic\nfeatures, deep features, or both to assess lung nodule malignancy. However,\ntheir reliance on manual annotation during inference, limited interpretability,\nand sensitivity to imaging variations hinder their application in real-world\nclinical settings. Thus, this research aims to integrate semantic features\nderived from radiologists' assessments of nodules, allowing the model to learn\nclinically relevant, robust, and explainable features for predicting lung\ncancer. Methods: We obtained 938 low-dose CT scans from the National Lung\nScreening Trial with 1,246 nodules and semantic features. The Lung Image\nDatabase Consortium dataset contains 1,018 CT scans, with 2,625 lesions\nannotated for nodule characteristics. Three external datasets were obtained\nfrom UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We\nfinetuned a pretrained Contrastive Language-Image Pretraining model with a\nparameter-efficient fine-tuning approach to align imaging and semantic features\nand predict the one-year lung cancer diagnosis. Results: We evaluated the\nperformance of the one-year diagnosis of lung cancer with AUROC and AUPRC and\ncompared it to three state-of-the-art models. Our model demonstrated an AUROC\nof 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on\nexternal datasets. Using CLIP, we also obtained predictions on semantic\nfeatures, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and\npleural attachment (0.84), that can be used to explain model predictions.\nConclusion: Our approach accurately classifies lung nodules as benign or\nmalignant, providing explainable outputs, aiding clinicians in comprehending\nthe underlying meaning of model predictions. This approach also prevents the\nmodel from learning shortcuts and generalizes across clinical settings.", "authors": ["Luoting Zhuang", "Seyed Mohammad Hossein Tabatabaei", "Ramin Salehi-Rad", "Linh M. Tran", "Denise R. Aberle", "Ashley E. Prosper", "William Hsu"], "category": "cs.AI", "updated": "2025-04-30T06:11:34Z"}
{"id": "2504.21411v1", "title": "Galvatron: An Automatic Distributed System for Efficient Foundation\n  Model Training", "link": "http://arxiv.org/abs/2504.21411v1", "summary": "Galvatron is a distributed system for efficiently training large-scale\nFoundation Models. It overcomes the complexities of selecting optimal\nparallelism strategies by automatically identifying the most efficient hybrid\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\nparallelism, along with recomputation. The system's architecture includes a\nprofiler for hardware and model analysis, a search engine for strategy\noptimization using decision trees and dynamic programming, and a runtime for\nexecuting these strategies efficiently. Benchmarking on various clusters\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\nThis open-source system offers user-friendly interfaces and comprehensive\ndocumentation, making complex distributed training accessible and efficient.\nThe source code of Galvatron is available at\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.", "authors": ["Xinyi Liu", "Yujie Wang", "Shenhan Zhu", "Fangcheng Fu", "Qingshuo Liu", "Guangming Lin", "Bin Cui"], "category": "cs.AI", "updated": "2025-04-30T08:11:45Z"}
{"id": "2504.21428v1", "title": "UAV Marketplace Simulation Tool for BVLOS Operations", "link": "http://arxiv.org/abs/2504.21428v1", "summary": "We present a simulation tool for evaluating team formation in autonomous\nmulti-UAV (Unmanned Aerial Vehicle) missions that operate Beyond Visual Line of\nSight (BVLOS). The tool models UAV collaboration and mission execution in\ndynamic and adversarial conditions, where Byzantine UAVs attempt to disrupt\noperations. Our tool allows researchers to integrate and compare various team\nformation strategies in a controlled environment with configurable mission\nparameters and adversarial behaviors. The log of each simulation run is stored\nin a structured way along with performance metrics so that statistical analysis\ncould be done straightforwardly. The tool is versatile for testing and\nimproving UAV coordination strategies in real-world applications.", "authors": ["Kıvanç Şerefoğlu", "Önder Gürcan", "Reyhan Aydoğan"], "category": "cs.AI", "updated": "2025-04-30T08:36:22Z"}
{"id": "2504.21435v2", "title": "SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding", "link": "http://arxiv.org/abs/2504.21435v2", "summary": "With the rapid development of Multi-modal Large Language Models (MLLMs), an\nincreasing number of benchmarks have been established to evaluate the video\nunderstanding capabilities of these models. However, these benchmarks focus on\nstandalone videos and mainly assess \"visual elements\" like human actions and\nobject states. In reality, contemporary videos often encompass complex and\ncontinuous narratives, typically presented as a series. To address this\nchallenge, we propose SeriesBench, a benchmark consisting of 105 carefully\ncurated narrative-driven series, covering 28 specialized tasks that require\ndeep narrative understanding. Specifically, we first select a diverse set of\ndrama series spanning various genres. Then, we introduce a novel long-span\nnarrative annotation method, combined with a full-information transformation\napproach to convert manual annotations into diverse task formats. To further\nenhance model capacity for detailed analysis of plot structures and character\nrelationships within series, we propose a novel narrative reasoning framework,\nPC-DCoT. Extensive results on SeriesBench indicate that existing MLLMs still\nface significant challenges in understanding narrative-driven series, while\nPC-DCoT enables these MLLMs to achieve performance improvements. Overall, our\nSeriesBench and PC-DCoT highlight the critical necessity of advancing model\ncapabilities to understand narrative-driven series, guiding the future\ndevelopment of MLLMs. SeriesBench is publicly available at\nhttps://github.com/zackhxn/SeriesBench-CVPR2025.", "authors": ["Chenkai Zhang", "Yiming Lei", "Zeming Liu", "Haitao Leng", "Shaoguo Liu", "Tingting Gao", "Qingjie Liu", "Yunhong Wang"], "category": "cs.AI", "updated": "2025-05-08T09:08:01Z"}
{"id": "2504.21475v1", "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based\n  Approach with Dataset Construction Guidelines", "link": "http://arxiv.org/abs/2504.21475v1", "summary": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.", "authors": ["Serry Sibaee", "Samar Ahmed", "Abdullah Al Harbi", "Omer Nacar", "Adel Ammar", "Yasser Habashi", "Wadii Boulila"], "category": "cs.AI", "updated": "2025-04-30T09:56:36Z"}
{"id": "2504.21480v1", "title": "A Comprehensive Study of Exploitable Patterns in Smart Contracts: From\n  Vulnerability to Defense", "link": "http://arxiv.org/abs/2504.21480v1", "summary": "With the rapid advancement of blockchain technology, smart contracts have\nenabled the implementation of increasingly complex functionalities. However,\nensuring the security of smart contracts remains a persistent challenge across\nthe stages of development, compilation, and execution. Vulnerabilities within\nsmart contracts not only undermine the security of individual applications but\nalso pose significant risks to the broader blockchain ecosystem, as\ndemonstrated by the growing frequency of attacks since 2016, resulting in\nsubstantial financial losses. This paper provides a comprehensive analysis of\nkey security risks in Ethereum smart contracts, specifically those written in\nSolidity and executed on the Ethereum Virtual Machine (EVM). We focus on two\nprevalent and critical vulnerability types (reentrancy and integer overflow) by\nexamining their underlying mechanisms, replicating attack scenarios, and\nassessing effective countermeasures.", "authors": ["Yuchen Ding", "Hongli Peng", "Xiaoqi Li"], "category": "cs.AI", "updated": "2025-04-30T10:00:36Z"}
{"id": "2504.21491v1", "title": "ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic\n  Segmentation of Remote Sensing Imagery", "link": "http://arxiv.org/abs/2504.21491v1", "summary": "We propose a result-level category-specific fusion architecture called\nClassWise-CRF. This architecture employs a two-stage process: first, it selects\nexpert networks that perform well in specific categories from a pool of\ncandidate networks using a greedy algorithm; second, it integrates the\nsegmentation predictions of these selected networks by adaptively weighting\ntheir contributions based on their segmentation performance in each category.\nInspired by Conditional Random Field (CRF), the ClassWise-CRF architecture\ntreats the segmentation predictions from multiple networks as confidence vector\nfields. It leverages segmentation metrics (such as Intersection over Union)\nfrom the validation set as priors and employs an exponential weighting strategy\nto fuse the category-specific confidence scores predicted by each network. This\nfusion method dynamically adjusts the weights of each network for different\ncategories, achieving category-specific optimization. Building on this, the\narchitecture further optimizes the fused results using unary and pairwise\npotentials in CRF to ensure spatial consistency and boundary accuracy. To\nvalidate the effectiveness of ClassWise-CRF, we conducted experiments on two\nremote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced\nsemantic segmentation networks. The results show that the ClassWise-CRF\narchitecture significantly improves segmentation performance: on the LoveDA\ndataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on\nthe validation set and by 0.68% on the test set; on the Vaihingen dataset, the\nmIoU improved by 0.87% on the validation set and by 0.91% on the test set.\nThese results fully demonstrate the effectiveness and generality of the\nClassWise-CRF architecture in semantic segmentation of remote sensing images.\nThe full code is available at https://github.com/zhuqinfeng1999/ClassWise-CRF.", "authors": ["Qinfeng Zhu", "Yunxi Jiang", "Lei Fan"], "category": "cs.AI", "updated": "2025-04-30T10:19:21Z"}
{"id": "2504.21559v1", "title": "Black-Box Visual Prompt Engineering for Mitigating Object Hallucination\n  in Large Vision Language Models", "link": "http://arxiv.org/abs/2504.21559v1", "summary": "Large Vision Language Models (LVLMs) often suffer from object hallucination,\nwhich undermines their reliability. Surprisingly, we find that simple\nobject-based visual prompting -- overlaying visual cues (e.g., bounding box,\ncircle) on images -- can significantly mitigate such hallucination; however,\ndifferent visual prompts (VPs) vary in effectiveness. To address this, we\npropose Black-Box Visual Prompt Engineering (BBVPE), a framework to identify\noptimal VPs that enhance LVLM responses without needing access to model\ninternals. Our approach employs a pool of candidate VPs and trains a router\nmodel to dynamically select the most effective VP for a given input image. This\nblack-box approach is model-agnostic, making it applicable to both open-source\nand proprietary LVLMs. Evaluations on benchmarks such as POPE and CHAIR\ndemonstrate that BBVPE effectively reduces object hallucination.", "authors": ["Sangmin Woo", "Kang Zhou", "Yun Zhou", "Shuai Wang", "Sheng Guan", "Haibo Ding", "Lin Lee Cheong"], "category": "cs.AI", "updated": "2025-04-30T11:58:30Z"}
{"id": "2504.21585v1", "title": "Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based\n  Reinforcement Learning", "link": "http://arxiv.org/abs/2504.21585v1", "summary": "This paper tackles the challenge of learning multi-goal dexterous hand\nmanipulation tasks using model-based Reinforcement Learning. We propose\nGoal-Conditioned Probabilistic Model Predictive Control (GC-PMPC) by designing\nprobabilistic neural network ensembles to describe the high-dimensional\ndexterous hand dynamics and introducing an asynchronous MPC policy to meet the\ncontrol frequency requirements in real-world dexterous hand systems. Extensive\nevaluations on four simulated Shadow Hand manipulation scenarios with randomly\ngenerated goals demonstrate GC-PMPC's superior performance over\nstate-of-the-art baselines. It successfully drives a cable-driven Dexterous\nhand, DexHand 021 with 12 Active DOFs and 5 tactile sensors, to learn\nmanipulating a cubic die to three goal poses within approximately 80 minutes of\ninteractions, demonstrating exceptional learning efficiency and control\nperformance on a cost-effective dexterous hand platform.", "authors": ["Yingzhuo Jiang", "Wenjun Huang", "Rongdun Lin", "Chenyang Miao", "Tianfu Sun", "Yunduan Cui"], "category": "cs.AI", "updated": "2025-04-30T12:44:38Z"}
{"id": "2504.21586v1", "title": "One Net to Rule Them All: Domain Randomization in Quadcopter Racing\n  Across Different Platforms", "link": "http://arxiv.org/abs/2504.21586v1", "summary": "In high-speed quadcopter racing, finding a single controller that works well\nacross different platforms remains challenging. This work presents the first\nneural network controller for drone racing that generalizes across physically\ndistinct quadcopters. We demonstrate that a single network, trained with domain\nrandomization, can robustly control various types of quadcopters. The network\nrelies solely on the current state to directly compute motor commands. The\neffectiveness of this generalized controller is validated through real-world\ntests on two substantially different crafts (3-inch and 5-inch race\nquadcopters). We further compare the performance of this generalized controller\nwith controllers specifically trained for the 3-inch and 5-inch drone, using\ntheir identified model parameters with varying levels of domain randomization\n(0%, 10%, 20%, 30%). While the generalized controller shows slightly slower\nspeeds compared to the fine-tuned models, it excels in adaptability across\ndifferent platforms. Our results show that no randomization fails sim-to-real\ntransfer while increasing randomization improves robustness but reduces speed.\nDespite this trade-off, our findings highlight the potential of domain\nrandomization for generalizing controllers, paving the way for universal AI\ncontrollers that can adapt to any platform.", "authors": ["Robin Ferede", "Till Blaha", "Erin Lucassen", "Christophe De Wagter", "Guido C. H. E. de Croon"], "category": "cs.AI", "updated": "2025-04-30T12:44:41Z"}
{"id": "2504.21589v1", "title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for\n  Automated Subject Indexing", "link": "http://arxiv.org/abs/2504.21589v1", "summary": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.", "authors": ["Lisa Kluge", "Maximilian Kähler"], "category": "cs.AI", "updated": "2025-04-30T12:47:09Z"}
{"id": "2504.21605v1", "title": "RDF-Based Structured Quality Assessment Representation of Multilingual\n  LLM Evaluations", "link": "http://arxiv.org/abs/2504.21605v1", "summary": "Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\nsystematically assessing their reliability with conflicting information remains\ndifficult. We propose an RDF-based framework to assess multilingual LLM\nquality, focusing on knowledge conflicts. Our approach captures model responses\nacross four distinct context conditions (complete, incomplete, conflicting, and\nno-context information) in German and English. This structured representation\nenables the comprehensive analysis of knowledge leakage-where models favor\ntraining data over provided context-error detection, and multilingual\nconsistency. We demonstrate the framework through a fire safety domain\nexperiment, revealing critical patterns in context prioritization and\nlanguage-specific performance, and demonstrating that our vocabulary was\nsufficient to express every assessment facet encountered in the 28-question\nstudy.", "authors": ["Jonas Gwozdz", "Andreas Both"], "category": "cs.AI", "updated": "2025-04-30T13:06:40Z"}
{"id": "2504.21634v1", "title": "Quantitative Auditing of AI Fairness with Differentially Private\n  Synthetic Data", "link": "http://arxiv.org/abs/2504.21634v1", "summary": "Fairness auditing of AI systems can identify and quantify biases. However,\ntraditional auditing using real-world data raises security and privacy\nconcerns. It exposes auditors to security risks as they become custodians of\nsensitive information and targets for cyberattacks. Privacy risks arise even\nwithout direct breaches, as data analyses can inadvertently expose confidential\ninformation. To address these, we propose a framework that leverages\ndifferentially private synthetic data to audit the fairness of AI systems. By\napplying privacy-preserving mechanisms, it generates synthetic data that\nmirrors the statistical properties of the original dataset while ensuring\nprivacy. This method balances the goal of rigorous fairness auditing and the\nneed for strong privacy protections. Through experiments on real datasets like\nAdult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real\ndata. By analyzing the alignment and discrepancies between these metrics, we\nassess the capacity of synthetic data to preserve the fairness properties of\nreal data. Our results demonstrate the framework's ability to enable meaningful\nfairness evaluations while safeguarding sensitive information, proving its\napplicability across critical and sensitive domains.", "authors": ["Chih-Cheng Rex Yuan", "Bow-Yaw Wang"], "category": "cs.AI", "updated": "2025-04-30T13:36:27Z"}
{"id": "2504.21700v1", "title": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs", "link": "http://arxiv.org/abs/2504.21700v1", "summary": "Large Language Models are fundamental actors in the modern IT landscape\ndominated by AI solutions. However, security threats associated with them might\nprevent their reliable adoption in critical application scenarios such as\ngovernment organizations and medical institutions. For this reason, commercial\nLLMs typically undergo a sophisticated censoring mechanism to eliminate any\nharmful output they could possibly produce. In response to this, LLM\nJailbreaking is a significant threat to such protections, and many previous\napproaches have already demonstrated its effectiveness across diverse domains.\nExisting jailbreak proposals mostly adopt a generate-and-test strategy to craft\nmalicious input. To improve the comprehension of censoring mechanisms and\ndesign a targeted jailbreak attack, we propose an Explainable-AI solution that\ncomparatively analyzes the behavior of censored and uncensored models to derive\nunique exploitable alignment patterns. Then, we propose XBreaking, a novel\njailbreak attack that exploits these unique patterns to break the security\nconstraints of LLMs by targeted noise injection. Our thorough experimental\ncampaign returns important insights about the censoring mechanisms and\ndemonstrates the effectiveness and performance of our attack.", "authors": ["Marco Arazzi", "Vignesh Kumar Kembu", "Antonino Nocera", "Vinod P"], "category": "cs.AI", "updated": "2025-04-30T14:44:24Z"}
{"id": "2504.21716v1", "title": "LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in\n  Household Robotics", "link": "http://arxiv.org/abs/2504.21716v1", "summary": "We present an embodied robotic system with an LLM-driven agent-orchestration\narchitecture for autonomous household object management. The system integrates\nmemory-augmented task planning, enabling robots to execute high-level user\ncommands while tracking past actions. It employs three specialized agents: a\nrouting agent, a task planning agent, and a knowledge base agent, each powered\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\nneed for explicit model training. RAG enables the system to retrieve context\nfrom past interactions, enhancing long-term object tracking. A combination of\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\nsemantic scene understanding for task planning. Evaluation across three\nhousehold scenarios demonstrates high task planning accuracy and an improvement\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\navailable at: https://github.com/marc1198/chat-hsr.", "authors": ["Marc Glocker", "Peter Hönig", "Matthias Hirschmanner", "Markus Vincze"], "category": "cs.AI", "updated": "2025-04-30T15:00:20Z"}
{"id": "2504.21719v1", "title": "Sionna RT: Technical Report", "link": "http://arxiv.org/abs/2504.21719v1", "summary": "Sionna is an open-source, GPU-accelerated library that, as of version 0.14,\nincorporates a ray tracer for simulating radio wave propagation. A unique\nfeature of Sionna RT is differentiability, enabling the calculation of\ngradients for the channel impulse responses (CIRs), radio maps, and other\nrelated metrics with respect to system and environmental parameters, such as\nmaterial properties, antenna patterns, and array geometries. The release of\nSionna 1.0 provides a complete overhaul of the ray tracer, significantly\nimproving its speed, memory efficiency, and extensibility. This document\ndetails the algorithms employed by Sionna RT to simulate radio wave propagation\nefficiently, while also addressing their current limitations. Given that the\ncomputation of CIRs and radio maps requires distinct algorithms, these are\ndetailed in separate sections. For CIRs, Sionna RT integrates shooting and\nbouncing of rays (SBR) with the image method and uses a hashing-based mechanism\nto efficiently eliminate duplicate paths. Radio maps are computed using a\npurely SBR-based approach.", "authors": ["Fayçal Aït Aoudia", "Jakob Hoydis", "Merlin Nimier-David", "Sebastian Cammerer", "Alexander Keller"], "category": "cs.AI", "updated": "2025-04-30T15:05:20Z"}
{"id": "2504.21730v1", "title": "Cert-SSB: Toward Certified Sample-Specific Backdoor Defense", "link": "http://arxiv.org/abs/2504.21730v1", "summary": "Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an\nattacker manipulates a small portion of the training data to implant hidden\nbackdoors into the model. The compromised model behaves normally on clean\nsamples but misclassifies backdoored samples into the attacker-specified target\nclass, posing a significant threat to real-world DNN applications. Currently,\nseveral empirical defense methods have been proposed to mitigate backdoor\nattacks, but they are often bypassed by more advanced backdoor techniques. In\ncontrast, certified defenses based on randomized smoothing have shown promise\nby adding random noise to training and testing samples to counteract backdoor\nattacks. In this paper, we reveal that existing randomized smoothing defenses\nimplicitly assume that all samples are equidistant from the decision boundary.\nHowever, it may not hold in practice, leading to suboptimal certification\nperformance. To address this issue, we propose a sample-specific certified\nbackdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic\ngradient ascent to optimize the noise magnitude for each sample, ensuring a\nsample-specific noise level that is then applied to multiple poisoned training\nsets to retrain several smoothed models. After that, Cert-SSB aggregates the\npredictions of multiple smoothed models to generate the final robust\nprediction. In particular, in this case, existing certification methods become\ninapplicable since the optimized noise varies across different samples. To\nconquer this challenge, we introduce a storage-update-based certification\nmethod, which dynamically adjusts each sample's certification region to improve\ncertification performance. We conduct extensive experiments on multiple\nbenchmark datasets, demonstrating the effectiveness of our proposed method. Our\ncode is available at https://github.com/NcepuQiaoTing/Cert-SSB.", "authors": ["Ting Qiao", "Yingjia Wang", "Xing Liu", "Sixing Wu", "Jianbing Li", "Yiming Li"], "category": "cs.AI", "updated": "2025-04-30T15:21:25Z"}
{"id": "2504.21731v1", "title": "Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement\n  Learning", "link": "http://arxiv.org/abs/2504.21731v1", "summary": "Mixed Reality (MR) could assist users' tasks by continuously integrating\nvirtual content with their view of the physical environment. However, where and\nhow to place these content to best support the users has been a challenging\nproblem due to the dynamic nature of MR experiences. In contrast to prior work\nthat investigates optimization-based methods, we are exploring how\nreinforcement learning (RL) could assist with continuous 3D content placement\nthat is aware of users' poses and their surrounding environments. Through an\ninitial exploration and preliminary evaluation, our results demonstrate the\npotential of RL to position content that maximizes the reward for users on the\ngo. We further identify future directions for research that could harness the\npower of RL for personalized and optimized UI and content placement in MR.", "authors": ["Feiyu Lu", "Mengyu Chen", "Hsiang Hsu", "Pranav Deshpande", "Cheng Yao Wang", "Blair MacIntyre"], "category": "cs.AI", "updated": "2025-04-30T15:21:36Z"}
{"id": "2504.21776v1", "title": "WebThinker: Empowering Large Reasoning Models with Deep Research\n  Capability", "link": "http://arxiv.org/abs/2504.21776v1", "summary": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.", "authors": ["Xiaoxi Li", "Jiajie Jin", "Guanting Dong", "Hongjin Qian", "Yutao Zhu", "Yongkang Wu", "Ji-Rong Wen", "Zhicheng Dou"], "category": "cs.AI", "updated": "2025-04-30T16:25:25Z"}
{"id": "2504.21798v1", "title": "SWE-smith: Scaling Data for Software Engineering Agents", "link": "http://arxiv.org/abs/2504.21798v1", "summary": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.", "authors": ["John Yang", "Kilian Leret", "Carlos E. Jimenez", "Alexander Wettig", "Kabir Khandpur", "Yanzhe Zhang", "Binyuan Hui", "Ofir Press", "Ludwig Schmidt", "Diyi Yang"], "category": "cs.AI", "updated": "2025-04-30T16:56:06Z"}
{"id": "2504.21800v2", "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in\n  Prolonged Exposure Dialogues", "link": "http://arxiv.org/abs/2504.21800v2", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "category": "cs.AI", "updated": "2025-05-01T16:44:18Z"}
{"id": "2504.21846v1", "title": "Active Light Modulation to Counter Manipulation of Speech Visual Content", "link": "http://arxiv.org/abs/2504.21846v1", "summary": "High-profile speech videos are prime targets for falsification, owing to\ntheir accessibility and influence. This work proposes Spotlight, a low-overhead\nand unobtrusive system for protecting live speech videos from visual\nfalsification of speaker identity and lip and facial motion. Unlike predominant\nfalsification detection methods operating in the digital domain, Spotlight\ncreates dynamic physical signatures at the event site and embeds them into all\nvideo recordings via imperceptible modulated light. These physical signatures\nencode semantically-meaningful features unique to the speech event, including\nthe speaker's identity and facial motion, and are cryptographically-secured to\nprevent spoofing. The signatures can be extracted from any video downstream and\nvalidated against the portrayed speech content to check its integrity. Key\nelements of Spotlight include (1) a framework for generating extremely compact\n(i.e., 150-bit), pose-invariant speech video features, based on\nlocality-sensitive hashing; and (2) an optical modulation scheme that embeds\n>200 bps into video while remaining imperceptible both in video and live.\nPrototype experiments on extensive video datasets show Spotlight achieves AUCs\n$\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified\nvideos. Further, Spotlight is highly robust across recording conditions, video\npost-processing techniques, and white-box adversarial attacks on its video\nfeature extraction methodologies.", "authors": ["Hadleigh Schwartz", "Xiaofeng Yan", "Charles J. Carver", "Xia Zhou"], "category": "cs.AI", "updated": "2025-04-30T17:55:24Z"}
{"id": "2504.21848v1", "title": "Characterizing AI Agents for Alignment and Governance", "link": "http://arxiv.org/abs/2504.21848v1", "summary": "The creation of effective governance mechanisms for AI agents requires a\ndeeper understanding of their core properties and how these properties relate\nto questions surrounding the deployment and operation of agents in the world.\nThis paper provides a characterization of AI agents that focuses on four\ndimensions: autonomy, efficacy, goal complexity, and generality. We propose\ndifferent gradations for each dimension, and argue that each dimension raises\nunique questions about the design, operation, and governance of these systems.\nMoreover, we draw upon this framework to construct \"agentic profiles\" for\ndifferent kinds of AI agents. These profiles help to illuminate cross-cutting\ntechnical and non-technical governance challenges posed by different classes of\nAI agents, ranging from narrow task-specific assistants to highly autonomous\ngeneral-purpose systems. By mapping out key axes of variation and continuity,\nthis framework provides developers, policymakers, and members of the public\nwith the opportunity to develop governance approaches that better align with\ncollective societal goals.", "authors": ["Atoosa Kasirzadeh", "Iason Gabriel"], "category": "cs.AI", "updated": "2025-04-30T17:55:48Z"}
{"id": "2504.21849v1", "title": "Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and\n  Regulation Support", "link": "http://arxiv.org/abs/2504.21849v1", "summary": "Governance institutions must respond to societal risks, including those posed\nby generative AI. This study empirically examines how public trust in\ninstitutions and AI technologies, along with perceived risks, shape preferences\nfor AI regulation. Using the nationally representative 2023 Artificial\nIntelligence, Morality, and Sentience (AIMS) survey, we assess trust in\ngovernment, AI companies, and AI technologies, as well as public support for\nregulatory measures such as slowing AI development or outright bans on advanced\nAI. Our findings reveal broad public support for AI regulation, with risk\nperception playing a significant role in shaping policy preferences.\nIndividuals with higher trust in government favor regulation, while those with\ngreater trust in AI companies and AI technologies are less inclined to support\nrestrictions. Trust in government and perceived risks significantly predict\npreferences for both soft (e.g., slowing development) and strong (e.g., banning\nAI systems) regulatory interventions. These results highlight the importance of\npublic opinion in AI governance. As AI capabilities advance, effective\nregulation will require balancing public concerns about risks with trust in\ninstitutions. This study provides a foundational empirical baseline for\npolicymakers navigating AI governance and underscores the need for further\nresearch into public trust, risk perception, and regulatory strategies in the\nevolving AI landscape.", "authors": ["Justin B. Bullock", "Janet V. T. Pauketat", "Hsini Huang", "Yi-Fan Wang", "Jacy Reese Anthis"], "category": "cs.AI", "updated": "2025-04-30T17:56:23Z"}
{"id": "2505.00060v1", "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business\n  Intelligence Using Exaone 3.5", "link": "http://arxiv.org/abs/2505.00060v1", "summary": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.", "authors": ["Jeho Choi"], "category": "cs.AI", "updated": "2025-04-30T14:42:18Z"}
{"id": "2505.00100v1", "title": "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use\n  of Generative AI in Early Undergraduate Computer Science Courses", "link": "http://arxiv.org/abs/2505.00100v1", "summary": "Generative AI (GenAI) is rapidly entering computer science education, yet its\neffects on student learning, skill development, and perceptions remain\nunderexplored. Concerns about overreliance coexist with a gap in research on\nstructured scaffolding to guide tool use in formal courses. This study examines\nthe impact of a dedicated \"AI-Lab\" intervention -- emphasizing guided\nscaffolding and mindful engagement -- on undergraduate students in Data\nStructures and Algorithms, Competitive Programming, and first-year engineering\ncourses at Purdue University.\n  Over three semesters, we integrated AI-Lab modules into four mandatory and\nelective courses, yielding 831 matched pre- and post-intervention survey\nresponses, alongside focus group discussions. Employing a mixed-methods\napproach, we analyzed quantitative shifts in usage patterns and attitudes as\nwell as qualitative narratives of student experiences.\n  While the overall frequency of GenAI usage for homework or programming\nprojects remained largely stable, we observed large effect sizes in comfort and\nopenness across conceptual, debugging, and homework problems. Notably, usage\npatterns for debugging also shifted statistically significantly, reflecting\nstudents' more mindful and deliberate approach. Focus group discussions\ncorroborated these results, suggesting that the intervention \"bridged the gap\"\nbetween naive GenAI usage and more nuanced, reflective integration of AI tools\ninto coursework, ultimately heightening students' awareness of their own skill\ndevelopment.\n  These findings suggest that structured, scaffolded interventions can enable\nstudents to harness GenAI's benefits without undermining essential\ncompetencies. We offer evidence-based recommendations for educators seeking to\nintegrate GenAI responsibly into computing curricula and identify avenues for\nfuture research on GenAI-supported pedagogy.", "authors": ["Ethan Dickey", "Andres Bejarano", "Rhianna Kuperus", "Bárbara Fagundes"], "category": "cs.AI", "updated": "2025-04-30T18:12:42Z"}
{"id": "2505.00136v1", "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks", "link": "http://arxiv.org/abs/2505.00136v1", "summary": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications.", "authors": ["Maksim Helmann", "Alexander Strack", "Dirk Pflüger"], "category": "cs.AI", "updated": "2025-04-30T19:08:51Z"}
{"id": "2505.00150v1", "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with\n  Vision-Language Models", "link": "http://arxiv.org/abs/2505.00150v1", "summary": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments.", "authors": ["Minh-Hao Van", "Xintao Wu"], "category": "cs.AI", "updated": "2025-04-30T19:48:12Z"}
{"id": "2505.00173v1", "title": "First Order Logic with Fuzzy Semantics for Describing and Recognizing\n  Nerves in Medical Images", "link": "http://arxiv.org/abs/2505.00173v1", "summary": "This article deals with the description and recognition of fiber bundles, in\nparticular nerves, in medical images, based on the anatomical description of\nthe fiber trajectories. To this end, we propose a logical formalization of this\nanatomical knowledge. The intrinsically imprecise description of nerves, as\nfound in anatomical textbooks, leads us to propose fuzzy semantics combined\nwith first-order logic. We define a language representing spatial entities,\nrelations between these entities and quantifiers. A formula in this language is\nthen a formalization of the natural language description. The semantics are\ngiven by fuzzy representations in a concrete domain and satisfaction degrees of\nrelations. Based on this formalization, a spatial reasoning algorithm is\nproposed for segmentation and recognition of nerves from anatomical and\ndiffusion magnetic resonance images, which is illustrated on pelvic nerves in\npediatric imaging, enabling surgeons to plan surgery.", "authors": ["Isabelle Bloch", "Enzo Bonnot", "Pietro Gori", "Giammarco La Barbera", "Sabine Sarnacki"], "category": "cs.AI", "updated": "2025-04-30T20:41:04Z"}
{"id": "2505.00186v1", "title": "Neuroevolution of Self-Attention Over Proto-Objects", "link": "http://arxiv.org/abs/2505.00186v1", "summary": "Proto-objects - image regions that share common visual properties - offer a\npromising alternative to traditional attention mechanisms based on\nrectangular-shaped image patches in neural networks. Although previous work\ndemonstrated that evolving a patch-based hard-attention module alongside a\ncontroller network could achieve state-of-the-art performance in visual\nreinforcement learning tasks, our approach leverages image segmentation to work\nwith higher-level features. By operating on proto-objects rather than fixed\npatches, we significantly reduce the representational complexity: each image\ndecomposes into fewer proto-objects than regular patches, and each proto-object\ncan be efficiently encoded as a compact feature vector. This enables a\nsubstantially smaller self-attention module that processes richer semantic\ninformation. Our experiments demonstrate that this proto-object-based approach\nmatches or exceeds the state-of-the-art performance of patch-based\nimplementations with 62% less parameters and 2.6 times less training time.", "authors": ["Rafael C. Pinto", "Anderson R. Tavares"], "category": "cs.AI", "updated": "2025-04-30T21:01:20Z"}
{"id": "2505.00216v1", "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box\n  Encoders", "link": "http://arxiv.org/abs/2505.00216v1", "summary": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored.", "authors": ["Xuwei Yang", "Fatemeh Tavakoli", "David B. Emerson", "Anastasis Kratsios"], "category": "cs.AI", "updated": "2025-04-30T23:19:37Z"}
{"id": "2505.00737v1", "title": "A Survey on 3D Reconstruction Techniques in Plant Phenotyping: From\n  Classical Methods to Neural Radiance Fields (NeRF), 3D Gaussian Splatting\n  (3DGS), and Beyond", "link": "http://arxiv.org/abs/2505.00737v1", "summary": "Plant phenotyping plays a pivotal role in understanding plant traits and\ntheir interactions with the environment, making it crucial for advancing\nprecision agriculture and crop improvement. 3D reconstruction technologies have\nemerged as powerful tools for capturing detailed plant morphology and\nstructure, offering significant potential for accurate and automated\nphenotyping. This paper provides a comprehensive review of the 3D\nreconstruction techniques for plant phenotyping, covering classical\nreconstruction methods, emerging Neural Radiance Fields (NeRF), and the novel\n3D Gaussian Splatting (3DGS) approach. Classical methods, which often rely on\nhigh-resolution sensors, are widely adopted due to their simplicity and\nflexibility in representing plant structures. However, they face challenges\nsuch as data density, noise, and scalability. NeRF, a recent advancement,\nenables high-quality, photorealistic 3D reconstructions from sparse viewpoints,\nbut its computational cost and applicability in outdoor environments remain\nareas of active research. The emerging 3DGS technique introduces a new paradigm\nin reconstructing plant structures by representing geometry through Gaussian\nprimitives, offering potential benefits in both efficiency and scalability. We\nreview the methodologies, applications, and performance of these approaches in\nplant phenotyping and discuss their respective strengths, limitations, and\nfuture prospects (https://github.com/JiajiaLi04/3D-Reconstruction-Plants).\nThrough this review, we aim to provide insights into how these diverse 3D\nreconstruction techniques can be effectively leveraged for automated and\nhigh-throughput plant phenotyping, contributing to the next generation of\nagricultural technology.", "authors": ["Jiajia Li", "Xinda Qi", "Seyed Hamidreza Nabaei", "Meiqi Liu", "Dong Chen", "Xin Zhang", "Xunyuan Yin", "Zhaojian Li"], "category": "cs.AI", "updated": "2025-04-30T02:04:23Z"}
{"id": "2505.00742v1", "title": "Zoomer: Adaptive Image Focus Optimization for Black-box MLLM", "link": "http://arxiv.org/abs/2505.00742v1", "summary": "Recent advancements in multimodal large language models (MLLMs) have\nbroadened the scope of vision-language tasks, excelling in applications like\nimage captioning and interactive question-answering. However, these models\nstruggle with accurately processing visual data, particularly in tasks\nrequiring precise object recognition and fine visual details. Stringent token\nlimits often result in the omission of critical information, hampering\nperformance. To address these limitations, we introduce \\SysName, a novel\nvisual prompting mechanism designed to enhance MLLM performance while\npreserving essential visual details within token limits. \\SysName features\nthree key innovations: a prompt-aware strategy that dynamically highlights\nrelevant image regions, a spatial-preserving orchestration schema that\nmaintains object integrity, and a budget-aware prompting method that balances\nglobal context with crucial visual details. Comprehensive evaluations across\nmultiple datasets demonstrate that \\SysName consistently outperforms baseline\nmethods, achieving up to a $26.9\\%$ improvement in accuracy while significantly\nreducing token consumption.", "authors": ["Jiaxu Qian", "Chendong Wang", "Yifan Yang", "Chaoyun Zhang", "Huiqiang Jiang", "Xufang Luo", "Yu Kang", "Qingwei Lin", "Anlan Zhang", "Shiqi Jiang", "Ting Cao", "Tianjun Mao", "Suman Banerjee", "Guyue Liu", "Saravan Rajmohan", "Dongmei Zhang", "Yuqing Yang", "Qi Zhang", "Lili Qiu"], "category": "cs.AI", "updated": "2025-04-30T02:51:10Z"}
{"id": "2505.03780v1", "title": "GPU Performance Portability needs Autotuning", "link": "http://arxiv.org/abs/2505.03780v1", "summary": "As LLMs grow in complexity, achieving state-of-the-art performance requires\ntight co-design across algorithms, software, and hardware. Today's reliance on\na single dominant platform limits portability, creates vendor lock-in, and\nraises barriers for new AI hardware. In this work, we make the case for\ncombining just-in-time (JIT) compilation with kernel parameter autotuning to\nenable portable, state-of-the-art performance LLM execution without code\nchanges. Focusing on flash attention -- a widespread performance-critical LLM\nkernel -- we demonstrate that this approach explores up to 15x more kernel\nparameter configurations, produces significantly more diverse code across\nmultiple dimensions, and even outperforms vendor-optimized implementations by\nup to 230%, all while reducing kernel code size by 70x and eliminating manual\ncode optimizations. Our results highlight autotuning as a promising path to\nunlocking model portability across GPU vendors.", "authors": ["Burkhard Ringlein", "Thomas Parnell", "Radu Stoica"], "category": "cs.AI", "updated": "2025-04-30T12:57:21Z"}
{"id": "2505.03787v1", "title": "ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual\n  Explanations for ECG Arrhythmia Classification", "link": "http://arxiv.org/abs/2505.03787v1", "summary": "Cardiac arrhythmias are a leading cause of life-threatening cardiac events,\nhighlighting the urgent need for accurate and timely detection.\nElectrocardiography (ECG) remains the clinical gold standard for arrhythmia\ndiagnosis; however, manual interpretation is time-consuming, dependent on\nclinical expertise, and prone to human error. Although deep learning has\nadvanced automated ECG analysis, many existing models abstract away the\nsignal's intrinsic temporal and morphological features, lack interpretability,\nand are computationally intensive-hindering their deployment on\nresource-constrained platforms. In this work, we propose two novel lightweight\n1D convolutional neural networks, ArrhythmiNet V1 and V2, optimized for\nefficient, real-time arrhythmia classification on edge devices. Inspired by\nMobileNet's depthwise separable convolutional design, these models maintain\nmemory footprints of just 302.18 KB and 157.76 KB, respectively, while\nachieving classification accuracies of 0.99 (V1) and 0.98 (V2) on the MIT-BIH\nArrhythmia Dataset across five classes: Normal Sinus Rhythm, Left Bundle Branch\nBlock, Right Bundle Branch Block, Atrial Premature Contraction, and Premature\nVentricular Contraction. In order to ensure clinical transparency and\nrelevance, we integrate Shapley Additive Explanations and Gradient-weighted\nClass Activation Mapping, enabling both local and global interpretability.\nThese techniques highlight physiologically meaningful patterns such as the QRS\ncomplex and T-wave that contribute to the model's predictions. We also discuss\nperformance-efficiency trade-offs and address current limitations related to\ndataset diversity and generalizability. Overall, our findings demonstrate the\nfeasibility of combining interpretability, predictive accuracy, and\ncomputational efficiency in practical, wearable, and embedded ECG monitoring\nsystems.", "authors": ["Zuraiz Baig", "Sidra Nasir", "Rizwan Ahmed Khan", "Muhammad Zeeshan Ul Haque"], "category": "cs.AI", "updated": "2025-04-30T18:22:45Z"}
{"id": "2505.03788v1", "title": "Calibrating Uncertainty Quantification of Multi-Modal LLMs using\n  Grounding", "link": "http://arxiv.org/abs/2505.03788v1", "summary": "We introduce a novel approach for calibrating uncertainty quantification (UQ)\ntailored for multi-modal large language models (LLMs). Existing\nstate-of-the-art UQ methods rely on consistency among multiple responses\ngenerated by the LLM on an input query under diverse settings. However, these\napproaches often report higher confidence in scenarios where the LLM is\nconsistently incorrect. This leads to a poorly calibrated confidence with\nrespect to accuracy. To address this, we leverage cross-modal consistency in\naddition to self-consistency to improve the calibration of the multi-modal\nmodels. Specifically, we ground the textual responses to the visual inputs. The\nconfidence from the grounding model is used to calibrate the overall\nconfidence. Given that using a grounding model adds its own uncertainty in the\npipeline, we apply temperature scaling - a widely accepted parametric\ncalibration technique - to calibrate the grounding model's confidence in the\naccuracy of generated responses. We evaluate the proposed approach across\nmultiple multi-modal tasks, such as medical question answering (Slake) and\nvisual question answering (VQAv2), considering multi-modal models such as\nLLaVA-Med and LLaVA. The experiments demonstrate that the proposed framework\nachieves significantly improved calibration on both tasks.", "authors": ["Trilok Padhi", "Ramneet Kaur", "Adam D. Cobb", "Manoj Acharya", "Anirban Roy", "Colin Samplawski", "Brian Matejek", "Alexander M. Berenbeim", "Nathaniel D. Bastian", "Susmit Jha"], "category": "cs.AI", "updated": "2025-04-30T19:19:21Z"}
{"id": "2504.21297v1", "title": "Participatory AI, Public Sector AI, Differential Privacy, Conversational\n  Interfaces, Explainable AI, Citizen Engagement in AI", "link": "http://arxiv.org/abs/2504.21297v1", "summary": "This paper introduces a conversational interface system that enables\nparticipatory design of differentially private AI systems in public sector\napplications. Addressing the challenge of balancing mathematical privacy\nguarantees with democratic accountability, we propose three key contributions:\n(1) an adaptive $\\epsilon$-selection protocol leveraging TOPSIS multi-criteria\ndecision analysis to align citizen preferences with differential privacy (DP)\nparameters, (2) an explainable noise-injection framework featuring real-time\nMean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and\n(3) an integrated legal-compliance mechanism that dynamically modulates privacy\nbudgets based on evolving regulatory constraints. Our results advance\nparticipatory AI practices by demonstrating how conversational interfaces can\nenhance public engagement in algorithmic privacy mechanisms, ensuring that\nprivacy-preserving AI in public sector governance remains both mathematically\nrobust and democratically accountable.", "authors": ["Wenjun Yang", "Eyhab Al-Masri"], "category": "cs.AI", "updated": "2025-04-30T04:10:50Z"}
{"id": "2505.00222v1", "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders", "link": "http://arxiv.org/abs/2505.00222v1", "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.", "authors": ["Peter Yichen Chen", "Pingchuan Ma", "Niklas Hagemann", "John Romanishin", "Wei Wang", "Daniela Rus", "Wojciech Matusik"], "category": "cs.AI", "updated": "2025-04-30T23:55:44Z"}
{"id": "2505.01453v1", "title": "Safe and Efficient CAV Lane Changing using Decentralised Safety Shields", "link": "http://arxiv.org/abs/2505.01453v1", "summary": "Lane changing is a complex decision-making problem for Connected and\nAutonomous Vehicles (CAVs) as it requires balancing traffic efficiency with\nsafety. Although traffic efficiency can be improved by using vehicular\ncommunication for training lane change controllers using Multi-Agent\nReinforcement Learning (MARL), ensuring safety is difficult. To address this\nissue, we propose a decentralised Hybrid Safety Shield (HSS) that combines\noptimisation and a rule-based approach to guarantee safety. Our method applies\ncontrol barrier functions to constrain longitudinal and lateral control inputs\nof a CAV to ensure safe manoeuvres. Additionally, we present an architecture to\nintegrate HSS with MARL, called MARL-HSS, to improve traffic efficiency while\nensuring safety. We evaluate MARL-HSS using a gym-like environment that\nsimulates an on-ramp merging scenario with two levels of traffic densities,\nsuch as light and moderate densities. The results show that HSS provides a\nsafety guarantee by strictly enforcing a dynamic safety constraint defined on a\ntime headway, even in moderate traffic density that offers challenging lane\nchange scenarios. Moreover, the proposed method learns stable policies compared\nto the baseline, a state-of-the-art MARL lane change controller without a\nsafety shield. Further policy evaluation shows that our method achieves a\nbalance between safety and traffic efficiency with zero crashes and comparable\naverage speeds in light and moderate traffic densities.", "authors": ["Bharathkumar Hegde", "Melanie Bouroche"], "category": "cs.AI", "updated": "2025-04-30T09:11:09Z"}
{"id": "2504.21707v1", "title": "Recursive KL Divergence Optimization: A Dynamic Framework for\n  Representation Learning", "link": "http://arxiv.org/abs/2504.21707v1", "summary": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.", "authors": ["Anthony D Martin"], "category": "cs.AI", "updated": "2025-04-30T14:51:27Z"}
{"id": "2504.21304v1", "title": "Unsupervised Feature Transformation via In-context Generation,\n  Generator-critic LLM Agents, and Duet-play Teaming", "link": "http://arxiv.org/abs/2504.21304v1", "summary": "Feature transformation involves generating a new set of features from the\noriginal dataset to enhance the data's utility. In certain domains like\nmaterial performance screening, dimensionality is large and collecting labels\nis expensive and lengthy. It highly necessitates transforming feature spaces\nefficiently and without supervision to enhance data readiness and AI utility.\nHowever, existing methods fall short in efficient navigation of a vast space of\nfeature combinations, and are mostly designed for supervised settings. To fill\nthis gap, our unique perspective is to leverage a generator-critic duet-play\nteaming framework using LLM agents and in-context learning to derive\npseudo-supervision from unsupervised data. The framework consists of three\ninterconnected steps: (1) Critic agent diagnoses data to generate actionable\nadvice, (2) Generator agent produces tokenized feature transformations guided\nby the critic's advice, and (3) Iterative refinement ensures continuous\nimprovement through feedback between agents. The generator-critic framework can\nbe generalized to human-agent collaborative generation, by replacing the critic\nagent with human experts. Extensive experiments demonstrate that the proposed\nframework outperforms even supervised baselines in feature transformation\nefficiency, robustness, and practical applicability across diverse datasets.", "authors": ["Nanxu Gong", "Xinyuan Wang", "Wangyang Ying", "Haoyue Bai", "Sixun Dong", "Haifeng Chen", "Yanjie Fu"], "category": "cs.LG", "updated": "2025-04-30T04:26:03Z"}
{"id": "2504.21327v1", "title": "A Generalized Meta Federated Learning Framework with Theoretical\n  Convergence Guarantees", "link": "http://arxiv.org/abs/2504.21327v1", "summary": "Meta federated learning (FL) is a personalized variant of FL, where multiple\nagents collaborate on training an initial shared model without exchanging raw\ndata samples. The initial model should be trained in a way that current or new\nagents can easily adapt it to their local datasets after one or a few\nfine-tuning steps, thus improving the model personalization. Conventional meta\nFL approaches minimize the average loss of agents on the local models obtained\nafter one step of fine-tuning. In practice, agents may need to apply several\nfine-tuning steps to adapt the global model to their local data, especially\nunder highly heterogeneous data distributions across agents. To this end, we\npresent a generalized framework for the meta FL by minimizing the average loss\nof agents on their local model after any arbitrary number $\\nu$ of fine-tuning\nsteps. For this generalized framework, we present a variant of the well-known\nfederated averaging (FedAvg) algorithm and conduct a comprehensive theoretical\nconvergence analysis to characterize the convergence speed as well as behavior\nof the meta loss functions in both the exact and approximated cases. Our\nexperiments on real-world datasets demonstrate superior accuracy and faster\nconvergence for the proposed scheme compared to conventional approaches.", "authors": ["Mohammad Vahid Jamali", "Hamid Saber", "Jung Hyun Bae"], "category": "cs.LG", "updated": "2025-04-30T05:29:46Z"}
{"id": "2504.21375v1", "title": "Synergy-CLIP: Extending CLIP with Multi-modal Integration for Robust\n  Representation Learning", "link": "http://arxiv.org/abs/2504.21375v1", "summary": "Multi-modal representation learning has become a pivotal area in artificial\nintelligence, enabling the integration of diverse modalities such as vision,\ntext, and audio to solve complex problems. However, existing approaches\npredominantly focus on bimodal interactions, such as image-text pairs, which\nlimits their ability to fully exploit the richness of multi-modal data.\nFurthermore, the integration of modalities in equal-scale environments remains\nunderexplored due to the challenges of constructing large-scale, balanced\ndatasets. In this study, we propose Synergy-CLIP, a novel framework that\nextends the contrastive language-image pre-training (CLIP) architecture to\nenhance multi-modal representation learning by integrating visual, textual, and\naudio modalities. Unlike existing methods that focus on adapting individual\nmodalities to vanilla-CLIP, Synergy-CLIP aligns and captures latent information\nacross three modalities equally. To address the high cost of constructing\nlarge-scale multi-modal datasets, we introduce VGG-sound+, a triple-modal\ndataset designed to provide equal-scale representation of visual, textual, and\naudio data. Synergy-CLIP is validated on various downstream tasks, including\nzero-shot classification, where it outperforms existing baselines.\nAdditionally, we introduce a missing modality reconstruction task,\ndemonstrating Synergy-CLIP's ability to extract synergy among modalities in\nrealistic application scenarios. These contributions provide a robust\nfoundation for advancing multi-modal representation learning and exploring new\nresearch directions.", "authors": ["Sangyeon Cho", "Jangyeong Jeon", "Mingi Kim", "Junyeong Kim"], "category": "cs.LG", "updated": "2025-04-30T07:14:58Z"}
{"id": "2504.21389v2", "title": "Enhanced semi-supervised stamping process monitoring with\n  physically-informed feature extraction", "link": "http://arxiv.org/abs/2504.21389v2", "summary": "In tackling frequent batch anomalies in high-speed stamping processes, this\nstudy introduces a novel semi-supervised in-process anomaly monitoring\nframework, utilizing accelerometer signals and physics information, to capture\nthe process anomaly effectively. The proposed framework facilitates the\nconstruction of a monitoring model with imbalanced sample distribution, which\nenables in-process condition monitoring in real-time to prevent batch\nanomalies, which helps to reduce batch defects risk and enhance production\nyield. Firstly, to effectively capture key features from raw data containing\nredundant information, a hybrid feature extraction algorithm is proposed to\nutilize data-driven methods and physical mechanisms simultaneously. Secondly,\nto address the challenge brought by imbalanced sample distribution, a\nsemi-supervised anomaly detection model is established, which merely employs\nnormal samples to build a golden baseline model, and a novel deviation score is\nproposed to quantify the anomaly level of each online stamping stroke. The\neffectiveness of the proposed feature extraction method is validated with\nvarious classification algorithms. A real-world in-process dataset from\nstamping manufacturing workshop is employed to illustrate the superiority of\nproposed semi-supervised framework with enhance performance for process anomaly\nmonitoring.", "authors": ["Jianyu Zhang"], "category": "cs.LG", "updated": "2025-05-09T01:48:38Z"}
{"id": "2504.21501v1", "title": "Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary\n  Variables", "link": "http://arxiv.org/abs/2504.21501v1", "summary": "In this paper, we develop a new optimization framework for the least squares\nlearning problem via fully connected neural networks or physics-informed neural\nnetworks. The gradient descent sometimes behaves inefficiently in deep learning\nbecause of the high non-convexity of loss functions and the vanishing gradient\nissue. Our idea is to introduce auxiliary variables to separate the layers of\nthe deep neural networks and reformulate the loss functions for ease of\noptimization. We design the self-adaptive weights to preserve the consistency\nbetween the reformulated loss and the original mean squared loss, which\nguarantees that optimizing the new loss helps optimize the original problem.\nNumerical experiments are presented to verify the consistency and show the\neffectiveness and robustness of our models over gradient descent.", "authors": ["Yaru Liu", "Yiqi Gu", "Michael K. Ng"], "category": "cs.LG", "updated": "2025-04-30T10:43:13Z"}
{"id": "2504.21662v1", "title": "On Advancements of the Forward-Forward Algorithm", "link": "http://arxiv.org/abs/2504.21662v1", "summary": "The Forward-Forward algorithm has evolved in machine learning research,\ntackling more complex tasks that mimic real-life applications. In the last\nyears, it has been improved by several techniques to perform better than its\noriginal version, handling a challenging dataset like CIFAR10 without losing\nits flexibility and low memory usage. We have shown in our results that\nimprovements are achieved through a combination of convolutional channel\ngrouping, learning rate schedules, and independent block structures during\ntraining that lead to a 20\\% decrease in test error percentage. Additionally,\nto approach further implementations on low-capacity hardware projects we have\npresented a series of lighter models that achieve low test error percentages\nwithin (21$\\pm$6)\\% and number of trainable parameters between 164,706 and\n754,386. This serving also as a basis for our future study on complete\nverification and validation of these kinds of neural networks.", "authors": ["Mauricio Ortiz Torres", "Markus Lange", "Arne P. Raulf"], "category": "cs.LG", "updated": "2025-04-30T14:03:52Z"}
{"id": "2505.00189v1", "title": "Chronic Diseases Prediction using Machine Learning and Deep Learning\n  Methods", "link": "http://arxiv.org/abs/2505.00189v1", "summary": "Chronic diseases, such as cardiovascular disease, diabetes, chronic kidney\ndisease, and thyroid disorders, are the leading causes of premature mortality\nworldwide. Early detection and intervention are crucial for improving patient\noutcomes, yet traditional diagnostic methods often fail due to the complex\nnature of these conditions. This study explores the application of machine\nlearning (ML) and deep learning (DL) techniques to predict chronic disease and\nthyroid disorders. We used a variety of models, including Logistic Regression\n(LR), Random Forest (RF), Gradient Boosted Trees (GBT), Neural Networks (NN),\nDecision Trees (DT) and Native Bayes (NB), to analyze and predict disease\noutcomes. Our methodology involved comprehensive data pre-processing, including\nhandling missing values, categorical encoding, and feature aggregation,\nfollowed by model training and evaluation. Performance metrics such ad\nprecision, recall, accuracy, F1-score, and Area Under the Curve (AUC) were used\nto assess the effectiveness of each model. The results demonstrated that\nensemble methods like Random Forest and Gradient Boosted Trees consistently\noutperformed. Neutral Networks also showed superior performance, particularly\nin capturing complex data patterns. The findings highlight the potential of ML\nand DL in revolutionizing chronic disease prediction, enabling early diagnosis\nand personalized treatment strategies. However, challenges such as data\nquality, model interpretability, and the need for advanced computational\ntechniques in healthcare to improve patient outcomes and reduce the burden of\nchronic diseases. This study was conducted as part of Big Data class project\nunder the supervision of our professors Mr. Abderrahmane EZ-ZAHOUT and Mr.\nAbdessamad ESSAIDI.", "authors": ["Houda Belhad", "Asmae Bourbia", "Salma Boughanja"], "category": "cs.LG", "updated": "2025-04-30T21:08:16Z"}
{"id": "2505.01449v1", "title": "COSMOS: Predictable and Cost-Effective Adaptation of LLMs", "link": "http://arxiv.org/abs/2505.01449v1", "summary": "Large language models (LLMs) achieve remarkable performance across numerous\ntasks by using a diverse array of adaptation strategies. However, optimally\nselecting a model and adaptation strategy under resource constraints is\nchallenging and often requires extensive experimentation. We investigate\nwhether it is possible to accurately predict both performance and cost without\nexpensive trials. We formalize the strategy selection problem for LLMs and\nintroduce COSMOS, a unified prediction framework that efficiently estimates\nadaptation outcomes at minimal cost. We instantiate and study the capability of\nour framework via a pair of powerful predictors: embedding-augmented\nlightweight proxy models to predict fine-tuning performance, and low-sample\nscaling laws to forecast retrieval-augmented in-context learning. Extensive\nevaluation across eight representative benchmarks demonstrates that COSMOS\nachieves high prediction accuracy while reducing computational costs by 92.72%\non average, and up to 98.71% in resource-intensive scenarios. Our results show\nthat efficient prediction of adaptation outcomes is not only feasible but can\nsubstantially reduce the computational overhead of LLM deployment while\nmaintaining performance standards.", "authors": ["Jiayu Wang", "Aws Albarghouthi", "Frederic Sala"], "category": "cs.LG", "updated": "2025-04-30T02:06:26Z"}
{"id": "2505.01450v1", "title": "Towards Film-Making Production Dialogue, Narration, Monologue Adaptive\n  Moving Dubbing Benchmarks", "link": "http://arxiv.org/abs/2505.01450v1", "summary": "Movie dubbing has advanced significantly, yet assessing the real-world\neffectiveness of these models remains challenging. A comprehensive evaluation\nbenchmark is crucial for two key reasons: 1) Existing metrics fail to fully\ncapture the complexities of dialogue, narration, monologue, and actor\nadaptability in movie dubbing. 2) A practical evaluation system should offer\nvaluable insights to improve movie dubbing quality and advancement in film\nproduction. To this end, we introduce Talking Adaptive Dubbing Benchmarks\n(TA-Dubbing), designed to improve film production by adapting to dialogue,\nnarration, monologue, and actors in movie dubbing. TA-Dubbing offers several\nkey advantages: 1) Comprehensive Dimensions: TA-Dubbing covers a variety of\ndimensions of movie dubbing, incorporating metric evaluations for both movie\nunderstanding and speech generation. 2) Versatile Benchmarking: TA-Dubbing is\ndesigned to evaluate state-of-the-art movie dubbing models and advanced\nmulti-modal large language models. 3) Full Open-Sourcing: We fully open-source\nTA-Dubbing at https://github.com/woka- 0a/DeepDubber- V1 including all video\nsuits, evaluation methods, annotations. We also continuously integrate new\nmovie dubbing models into the TA-Dubbing leaderboard at\nhttps://github.com/woka- 0a/DeepDubber-V1 to drive forward the field of movie\ndubbing.", "authors": ["Chaoyi Wang", "Junjie Zheng", "Zihao Chen", "Shiyu Xia", "Chaofan Ding", "Xiaohao Zhang", "Xi Tao", "Xiaoming He", "Xinhan Di"], "category": "cs.LG", "updated": "2025-04-30T02:36:18Z"}
{"id": "2505.03775v1", "title": "Hierarchical Multi-Label Generation with Probabilistic Level-Constraint", "link": "http://arxiv.org/abs/2505.03775v1", "summary": "Hierarchical Extreme Multi-Label Classification poses greater difficulties\ncompared to traditional multi-label classification because of the intricate\nhierarchical connections of labels within a domain-specific taxonomy and the\nsubstantial number of labels. Some of the prior research endeavors centered on\nclassifying text through several ancillary stages such as the cluster algorithm\nand multiphase classification. Others made attempts to leverage the assistance\nof generative methods yet were unable to properly control the output of the\ngenerative model. We redefine the task from hierarchical multi-Label\nclassification to Hierarchical Multi-Label Generation (HMG) and employ a\ngenerative framework with Probabilistic Level Constraints (PLC) to generate\nhierarchical labels within a specific taxonomy that have complex hierarchical\nrelationships. The approach we proposed in this paper enables the framework to\ngenerate all relevant labels across levels for each document without relying on\npreliminary operations like clustering. Meanwhile, it can control the model\noutput precisely in terms of count, length, and level aspects. Experiments\ndemonstrate that our approach not only achieves a new SOTA performance in the\nHMG task, but also has a much better performance in constrained the output of\nmodel than previous research work.", "authors": ["Linqing Chen", "Weilei Wang", "Wentao Wu", "Hanmeng Zhong"], "category": "cs.LG", "updated": "2025-04-30T07:56:53Z"}
{"id": "2505.03776v1", "title": "PAPN: Proximity Attention Encoder and Pointer Network Decoder for Parcel\n  Pickup Route Prediction", "link": "http://arxiv.org/abs/2505.03776v1", "summary": "Optimization of the last-mile delivery and first-mile pickup of parcels is an\nintegral part of the broader logistics optimization pipeline as it entails both\ncost and resource efficiency as well as a heightened service quality. Such\noptimization requires accurate route and time prediction systems to adapt to\ndifferent scenarios in advance. This work tackles the first building block,\nnamely route prediction. This is done by introducing a novel Proximity\nAttention mechanism in an encoder-decoder architecture utilizing a Pointer\nNetwork in the decoding process (Proximity Attention Encoder and Pointer\nNetwork decoder: PAPN) to leverage the underlying connections between the\ndifferent visitable pickup positions at each timestep. To this local attention\nprocess is coupled global context computing via a multi-head attention\ntransformer encoder. The obtained global context is then mixed to an aggregated\nversion of the local embedding thus achieving a mix of global and local\nattention for complete modeling of the problems. Proximity attention is also\nused in the decoding process to skew predictions towards the locations with the\nhighest attention scores and thus using inter-connectivity of locations as a\nbase for next-location prediction. This method is trained, validated and tested\non a large industry-level dataset of real-world, large-scale last-mile delivery\nand first-mile pickup named LaDE[1]. This approach shows noticeable promise,\noutperforming all state-of-the-art supervised systems in terms of most metrics\nused for benchmarking methods on this dataset while still being competitive\nwith the best-performing reinforcement learning method named DRL4Route[2].", "authors": ["Hansi Denis", "Siegfried Mercelis", "Ngoc-Quang Luong"], "category": "cs.LG", "updated": "2025-04-30T08:24:41Z"}
{"id": "2505.03777v2", "title": "MolMole: Molecule Mining from Scientific Literature", "link": "http://arxiv.org/abs/2505.03777v2", "summary": "The extraction of molecular structures and reaction data from scientific\ndocuments is challenging due to their varied, unstructured chemical formats and\ncomplex document layouts. To address this, we introduce MolMole, a vision-based\ndeep learning framework that unifies molecule detection, reaction diagram\nparsing, and optical chemical structure recognition (OCSR) into a single\npipeline for automating the extraction of chemical data directly from\npage-level documents. Recognizing the lack of a standard page-level benchmark\nand evaluation metric, we also present a testset of 550 pages annotated with\nmolecule bounding boxes, reaction labels, and MOLfiles, along with a novel\nevaluation metric. Experimental results demonstrate that MolMole outperforms\nexisting toolkits on both our benchmark and public datasets. The benchmark\ntestset will be publicly available, and the MolMole toolkit will be accessible\nsoon through an interactive demo on the LG AI Research website. For commercial\ninquiries, please contact us at\n\\href{mailto:contact_ddu@lgresearch.ai}{contact\\_ddu@lgresearch.ai}.", "authors": ["LG AI Research", "Sehyun Chun", "Jiye Kim", "Ahra Jo", "Yeonsik Jo", "Seungyul Oh", "Seungjun Lee", "Kwangrok Ryoo", "Jongmin Lee", "Seung Hwan Kim", "Byung Jun Kang", "Soonyoung Lee", "Jun Ha Park", "Chanwoo Moon", "Jiwon Ham", "Haein Lee", "Heejae Han", "Jaeseung Byun", "Soojong Do", "Minju Ha", "Dongyun Kim", "Kyunghoon Bae", "Woohyung Lim", "Edward Hwayoung Lee", "Yongmin Park", "Jeongsang Yu", "Gerrard Jeongwon Jo", "Yeonjung Hong", "Kyungjae Yoo", "Sehui Han", "Jaewan Lee", "Changyoung Park", "Kijeong Jeon", "Sihyuk Yi"], "category": "cs.LG", "updated": "2025-05-08T02:48:54Z"}
{"id": "2505.03778v1", "title": "Dragonfly: a modular deep reinforcement learning library", "link": "http://arxiv.org/abs/2505.03778v1", "summary": "Dragonfly is a deep reinforcement learning library focused on modularity, in\norder to ease experimentation and developments. It relies on a json\nserialization that allows to swap building blocks and perform parameter sweep,\nwhile minimizing code maintenance. Some of its features are specifically\ndesigned for CPU-intensive environments, such as numerical simulations. Its\nperformance on standard agents using common benchmarks compares favorably with\nthe literature.", "authors": ["Jonathan Viquerat", "Paul Garnier", "Amirhossein Bateni", "Elie Hachem"], "category": "cs.LG", "updated": "2025-04-30T11:39:00Z"}
{"id": "2505.03779v1", "title": "Neural Co-Optimization of Structural Topology, Manufacturable Layers,\n  and Path Orientations for Fiber-Reinforced Composites", "link": "http://arxiv.org/abs/2505.03779v1", "summary": "We propose a neural network-based computational framework for the\nsimultaneous optimization of structural topology, curved layers, and path\norientations to achieve strong anisotropic strength in fiber-reinforced\nthermoplastic composites while ensuring manufacturability. Our framework\nemploys three implicit neural fields to represent geometric shape, layer\nsequence, and fiber orientation. This enables the direct formulation of both\ndesign and manufacturability objectives - such as anisotropic strength,\nstructural volume, machine motion control, layer curvature, and layer thickness\n- into an integrated and differentiable optimization process. By incorporating\nthese objectives as loss functions, the framework ensures that the resultant\ncomposites exhibit optimized mechanical strength while remaining its\nmanufacturability for filament-based multi-axis 3D printing across diverse\nhardware platforms. Physical experiments demonstrate that the composites\ngenerated by our co-optimization method can achieve an improvement of up to\n33.1% in failure loads compared to composites with sequentially optimized\nstructures and manufacturing sequences.", "authors": ["Tao Liu", "Tianyu Zhang", "Yongxue Chen", "Weiming Wang", "Yu Jiang", "Yuming Huang", "Charlie C. L. Wang"], "category": "cs.LG", "updated": "2025-04-30T11:52:28Z"}
{"id": "2505.03781v1", "title": "ALFRED: Ask a Large-language model For Reliable ECG Diagnosis", "link": "http://arxiv.org/abs/2505.03781v1", "summary": "Leveraging Large Language Models (LLMs) with Retrieval-Augmented Generation\n(RAG) for analyzing medical data, particularly Electrocardiogram (ECG), offers\nhigh accuracy and convenience. However, generating reliable, evidence-based\nresults in specialized fields like healthcare remains a challenge, as RAG alone\nmay not suffice. We propose a Zero-shot ECG diagnosis framework based on RAG\nfor ECG analysis that incorporates expert-curated knowledge to enhance\ndiagnostic accuracy and explainability. Evaluation on the PTB-XL dataset\ndemonstrates the framework's effectiveness, highlighting the value of\nstructured domain expertise in automated ECG interpretation. Our framework is\ndesigned to support comprehensive ECG analysis, addressing diverse diagnostic\nneeds with potential applications beyond the tested dataset.", "authors": ["Jin Yu", "JaeHo Park", "TaeJun Park", "Gyurin Kim", "JiHyun Lee", "Min Sung Lee", "Joon-myoung Kwon", "Jeong Min Son", "Yong-Yeon Jo"], "category": "cs.LG", "updated": "2025-04-30T12:59:06Z"}
{"id": "2505.03784v1", "title": "Insulin Resistance Prediction From Wearables and Routine Blood\n  Biomarkers", "link": "http://arxiv.org/abs/2505.03784v1", "summary": "Insulin resistance, a precursor to type 2 diabetes, is characterized by\nimpaired insulin action in tissues. Current methods for measuring insulin\nresistance, while effective, are expensive, inaccessible, not widely available\nand hinder opportunities for early intervention. In this study, we remotely\nrecruited the largest dataset to date across the US to study insulin resistance\n(N=1,165 participants, with median BMI=28 kg/m2, age=45 years, HbA1c=5.4%),\nincorporating wearable device time series data and blood biomarkers, including\nthe ground-truth measure of insulin resistance, homeostatic model assessment\nfor insulin resistance (HOMA-IR). We developed deep neural network models to\npredict insulin resistance based on readily available digital and blood\nbiomarkers. Our results show that our models can predict insulin resistance by\ncombining both wearable data and readily available blood biomarkers better than\neither of the two data sources separately (R2=0.5, auROC=0.80, Sensitivity=76%,\nand specificity 84%). The model showed 93% sensitivity and 95% adjusted\nspecificity in obese and sedentary participants, a subpopulation most\nvulnerable to developing type 2 diabetes and who could benefit most from early\nintervention. Rigorous evaluation of model performance, including\ninterpretability, and robustness, facilitates generalizability across larger\ncohorts, which is demonstrated by reproducing the prediction performance on an\nindependent validation cohort (N=72 participants). Additionally, we\ndemonstrated how the predicted insulin resistance can be integrated into a\nlarge language model agent to help understand and contextualize HOMA-IR values,\nfacilitating interpretation and safe personalized recommendations. This work\noffers the potential for early detection of people at risk of type 2 diabetes\nand thereby facilitate earlier implementation of preventative strategies.", "authors": ["Ahmed A. Metwally", "A. Ali Heydari", "Daniel McDuff", "Alexandru Solot", "Zeinab Esmaeilpour", "Anthony Z Faranesh", "Menglian Zhou", "David B. Savage", "Conor Heneghan", "Shwetak Patel", "Cathy Speed", "Javier L. Prieto"], "category": "cs.LG", "updated": "2025-04-30T16:10:20Z"}
{"id": "2504.21254v2", "title": "ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph\n  Representation Learning", "link": "http://arxiv.org/abs/2504.21254v2", "summary": "Effective and efficient graph representation learning is essential for\nenabling critical downstream tasks, such as node classification, link\nprediction, and subgraph search. However, existing graph neural network (GNN)\narchitectures often struggle to adapt to diverse and complex graph structures,\nlimiting their ability to produce structure-aware and task-discriminative\nrepresentations. To address this challenge, we propose ABG-NAS, a novel\nframework for automated graph neural network architecture search tailored for\nefficient graph representation learning. ABG-NAS encompasses three key\ncomponents: a Comprehensive Architecture Search Space (CASS), an Adaptive\nGenetic Optimization Strategy (AGOS), and a Bayesian-Guided Tuning Module\n(BGTM). CASS systematically explores diverse propagation (P) and transformation\n(T) operations, enabling the discovery of GNN architectures capable of\ncapturing intricate graph characteristics. AGOS dynamically balances\nexploration and exploitation, ensuring search efficiency and preserving\nsolution diversity. BGTM further optimizes hyperparameters periodically,\nenhancing the scalability and robustness of the resulting architectures.\nEmpirical evaluations on benchmark datasets (Cora, PubMed, Citeseer, and\nCoraFull) demonstrate that ABG-NAS consistently outperforms both manually\ndesigned GNNs and state-of-the-art neural architecture search (NAS) methods.\nThese results highlight the potential of ABG-NAS to advance graph\nrepresentation learning by providing scalable and adaptive solutions for\ndiverse graph structures. Our code is publicly available at\nhttps://github.com/sserranw/ABG-NAS.", "authors": ["Sixuan Wang", "Jiao Yin", "Jinli Cao", "MingJian Tang", "Hua Wang", "Yanchun Zhang"], "category": "cs.LG", "updated": "2025-05-05T23:11:03Z"}
{"id": "2504.21259v1", "title": "LSTM+Geo with xgBoost Filtering: A Novel Approach for Race and Ethnicity\n  Imputation with Reduced Bias", "link": "http://arxiv.org/abs/2504.21259v1", "summary": "Accurate imputation of race and ethnicity (R&E) is crucial for analyzing\ndisparities and informing policy. Methods like Bayesian Improved Surname\nGeocoding (BISG) are widely used but exhibit limitations, including systematic\nmisclassification biases linked to socioeconomic status. This paper introduces\nLSTM+Geo, a novel approach enhancing Long Short-Term Memory (LSTM) networks\nwith census tract geolocation information. Using a large voter dataset, we\ndemonstrate that LSTM+Geo (88.7% accuracy) significantly outperforms standalone\nLSTM (86.4%) and Bayesian methods like BISG (82.9%) and BIFSG (86.8%) in\naccuracy and F1-score on a held-out validation set. LSTM+Geo reduces the rate\nat which non-White individuals are misclassified as White (White FPR 19.3%)\ncompared to name-only LSTMs (White FPR 24.6%). While sophisticated ensemble\nmethods incorporating XGBoost achieve the highest overall accuracy (up to\n89.4%) and lowest White FPR (17.8%), LSTM+Geo offers strong standalone\nperformance with improved bias characteristics compared to baseline models.\nIntegrating LSTM+Geo into an XGBoost ensemble further boosts accuracy,\nhighlighting its utility as both a standalone model and a component for\nadvanced systems. We give a caution at the end regarding the appropriate use of\nthese methods.", "authors": ["S. Chalavadi", "A. Pastor", "T. Leitch"], "category": "cs.LG", "updated": "2025-04-30T02:20:08Z"}
{"id": "2504.21289v1", "title": "Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for\n  High-Dimensional Data and Its Application in Stock Trend Prediction", "link": "http://arxiv.org/abs/2504.21289v1", "summary": "Biclustering is an effective technique in data mining and pattern\nrecognition. Biclustering algorithms based on traditional clustering face two\nfundamental limitations when processing high-dimensional data: (1) The distance\nconcentration phenomenon in high-dimensional spaces leads to data sparsity,\nrendering similarity measures ineffective; (2) Mainstream linear dimensionality\nreduction methods disrupt critical local structural patterns. To apply\nbiclustering to high-dimensional datasets, we propose an orthogonal\nfactor-based biclustering algorithm (BCBOF). First, we constructed orthogonal\nfactors in the vector space of the high-dimensional dataset. Then, we performed\nclustering using the coordinates of the original data in the orthogonal\nsubspace as clustering targets. Finally, we obtained biclustering results of\nthe original dataset. Since dimensionality reduction was applied before\nclustering, the proposed algorithm effectively mitigated the data sparsity\nproblem caused by high dimensionality. Additionally, we applied this\nbiclustering algorithm to stock technical indicator combinations and stock\nprice trend prediction. Biclustering results were transformed into fuzzy rules,\nand we incorporated profit-preserving and stop-loss rules into the rule set,\nultimately forming a fuzzy inference system for stock price trend predictions\nand trading signals. To evaluate the performance of BCBOF, we compared it with\nexisting biclustering methods using multiple evaluation metrics. The results\nshowed that our algorithm outperformed other biclustering techniques. To\nvalidate the effectiveness of the fuzzy inference system, we conducted virtual\ntrading experiments using historical data from 10 A-share stocks. The\nexperimental results showed that the generated trading strategies yielded\nhigher returns for investors.", "authors": ["Yan Huang", "Da-Qing Zhang"], "category": "cs.LG", "updated": "2025-04-30T03:49:08Z"}
{"id": "2504.21296v1", "title": "Fairness in Graph Learning Augmented with Machine Learning: A Survey", "link": "http://arxiv.org/abs/2504.21296v1", "summary": "Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.", "authors": ["Renqiang Luo", "Ziqi Xu", "Xikun Zhang", "Qing Qing", "Huafei Huang", "Enyan Dai", "Zhe Wang", "Bo Yang"], "category": "cs.LG", "updated": "2025-04-30T04:02:23Z"}
{"id": "2504.21314v1", "title": "Capturing Conditional Dependence via Auto-regressive Diffusion Models", "link": "http://arxiv.org/abs/2504.21314v1", "summary": "Diffusion models have demonstrated appealing performance in both image and\nvideo generation. However, many works discover that they struggle to capture\nimportant, high-level relationships that are present in the real world. For\nexample, they fail to learn physical laws from data, and even fail to\nunderstand that the objects in the world exist in a stable fashion. This is due\nto the fact that important conditional dependence structures are not adequately\ncaptured in the vanilla diffusion models. In this work, we initiate an in-depth\nstudy on strengthening the diffusion model to capture the conditional\ndependence structures in the data. In particular, we examine the efficacy of\nthe auto-regressive (AR) diffusion models for such purpose and develop the\nfirst theoretical results on the sampling error of AR diffusion models under\n(possibly) the mildest data assumption. Our theoretical findings indicate that,\ncompared with typical diffusion models, the AR variant produces samples with a\nreduced gap in approximating the data conditional distribution. On the other\nhand, the overall inference time of the AR-diffusion models is only moderately\nlarger than that for the vanilla diffusion models, making them still practical\nfor large scale applications. We also provide empirical results showing that\nwhen there is clear conditional dependence structure in the data, the AR\ndiffusion models captures such structure, whereas vanilla DDPM fails to do so.\nOn the other hand, when there is no obvious conditional dependence across\npatches of the data, AR diffusion does not outperform DDPM.", "authors": ["Xunpeng Huang", "Yujin Han", "Difan Zou", "Yian Ma", "Tong Zhang"], "category": "cs.LG", "updated": "2025-04-30T04:57:12Z"}
{"id": "2504.21326v1", "title": "Q-function Decomposition with Intervention Semantics with Factored\n  Action Spaces", "link": "http://arxiv.org/abs/2504.21326v1", "summary": "Many practical reinforcement learning environments have a discrete factored\naction space that induces a large combinatorial set of actions, thereby posing\nsignificant challenges. Existing approaches leverage the regular structure of\nthe action space and resort to a linear decomposition of Q-functions, which\navoids enumerating all combinations of factored actions. In this paper, we\nconsider Q-functions defined over a lower dimensional projected subspace of the\noriginal action space, and study the condition for the unbiasedness of\ndecomposed Q-functions using causal effect estimation from the no unobserved\nconfounder setting in causal statistics. This leads to a general scheme which\nwe call action decomposed reinforcement learning that uses the projected\nQ-functions to approximate the Q-function in standard model-free reinforcement\nlearning algorithms. The proposed approach is shown to improve sample\ncomplexity in a model-based reinforcement learning setting. We demonstrate\nimprovements in sample efficiency compared to state-of-the-art baselines in\nonline continuous control environments and a real-world offline sepsis\ntreatment environment.", "authors": ["Junkyu Lee", "Tian Gao", "Elliot Nelson", "Miao Liu", "Debarun Bhattacharjya", "Songtao Lu"], "category": "cs.LG", "updated": "2025-04-30T05:26:51Z"}
{"id": "2504.21338v1", "title": "A Memetic Algorithm based on Variational Autoencoder for Black-Box\n  Discrete Optimization with Epistasis among Parameters", "link": "http://arxiv.org/abs/2504.21338v1", "summary": "Black-box discrete optimization (BB-DO) problems arise in many real-world\napplications, such as neural architecture search and mathematical model\nestimation. A key challenge in BB-DO is epistasis among parameters where\nmultiple variables must be modified simultaneously to effectively improve the\nobjective function. Estimation of Distribution Algorithms (EDAs) provide a\npowerful framework for tackling BB-DO problems. In particular, an EDA\nleveraging a Variational Autoencoder (VAE) has demonstrated strong performance\non relatively low-dimensional problems with epistasis while reducing\ncomputational cost. Meanwhile, evolutionary algorithms such as DSMGA-II and P3,\nwhich integrate bit-flip-based local search with linkage learning, have shown\nexcellent performance on high-dimensional problems. In this study, we propose a\nnew memetic algorithm that combines VAE-based sampling with local search. The\nproposed method inherits the strengths of both VAE-based EDAs and local\nsearch-based approaches: it effectively handles high-dimensional problems with\nepistasis among parameters without incurring excessive computational overhead.\nExperiments on NK landscapes -- a challenging benchmark for BB-DO involving\nepistasis among parameters -- demonstrate that our method outperforms\nstate-of-the-art VAE-based EDA methods, as well as leading approaches such as\nP3 and DSMGA-II.", "authors": ["Aoi Kato", "Kenta Kojima", "Masahiro Nomura", "Isao Ono"], "category": "cs.LG", "updated": "2025-04-30T05:56:22Z"}
{"id": "2504.21340v1", "title": "Towards Improved Cervical Cancer Screening: Vision Transformer-Based\n  Classification and Interpretability", "link": "http://arxiv.org/abs/2504.21340v1", "summary": "We propose a novel approach to cervical cell image classification for\ncervical cancer screening using the EVA-02 transformer model. We developed a\nfour-step pipeline: fine-tuning EVA-02, feature extraction, selecting important\nfeatures through multiple machine learning models, and training a new\nartificial neural network with optional loss weighting for improved\ngeneralization. With this design, our best model achieved an F1-score of\n0.85227, outperforming the baseline EVA-02 model (0.84878). We also utilized\nKernel SHAP analysis and identified key features correlating with cell\nmorphology and staining characteristics, providing interpretable insights into\nthe decision-making process of the fine-tuned model. Our code is available at\nhttps://github.com/Khoa-NT/isbi2025_ps3c.", "authors": ["Khoa Tuan Nguyen", "Ho-min Park", "Gaeun Oh", "Joris Vankerschaver", "Wesley De Neve"], "category": "cs.LG", "updated": "2025-04-30T05:59:56Z"}
{"id": "2504.21353v1", "title": "Generative QoE Modeling: A Lightweight Approach for Telecom Networks", "link": "http://arxiv.org/abs/2504.21353v1", "summary": "Quality of Experience (QoE) prediction plays a crucial role in optimizing\nresource management and enhancing user satisfaction across both\ntelecommunication and OTT services. While recent advances predominantly rely on\ndeep learning models, this study introduces a lightweight generative modeling\nframework that balances computational efficiency, interpretability, and\npredictive accuracy. By validating the use of Vector Quantization (VQ) as a\npreprocessing technique, continuous network features are effectively\ntransformed into discrete categorical symbols, enabling integration with a\nHidden Markov Model (HMM) for temporal sequence modeling. This VQ-HMM pipeline\nenhances the model's capacity to capture dynamic QoE patterns while supporting\nprobabilistic inference on new and unseen data. Experimental results on\npublicly available time-series datasets incorporating both objective indicators\nand subjective QoE scores demonstrate the viability of this approach in\nreal-time and resource-constrained environments, where inference latency is\nalso critical. The framework offers a scalable alternative to complex deep\nlearning methods, particularly in scenarios with limited computational\nresources or where latency constraints are critical.", "authors": ["Vinti Nayar", "Kanica Sachdev", "Brejesh Lall"], "category": "cs.LG", "updated": "2025-04-30T06:19:37Z"}
{"id": "2504.21358v1", "title": "A comparative study of deep learning and ensemble learning to extend the\n  horizon of traffic forecasting", "link": "http://arxiv.org/abs/2504.21358v1", "summary": "Traffic forecasting is vital for Intelligent Transportation Systems, for\nwhich Machine Learning (ML) methods have been extensively explored to develop\ndata-driven Artificial Intelligence (AI) solutions. Recent research focuses on\nmodelling spatial-temporal correlations for short-term traffic prediction,\nleaving the favourable long-term forecasting a challenging and open issue. This\npaper presents a comparative study on large-scale real-world signalized\narterials and freeway traffic flow datasets, aiming to evaluate promising ML\nmethods in the context of large forecasting horizons up to 30 days. Focusing on\nmodelling capacity for temporal dynamics, we develop one ensemble ML method,\neXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods,\nincluding Recurrent Neural Network (RNN)-based methods and the state-of-the-art\nTransformer-based method. Time embedding is leveraged to enhance their\nunderstanding of seasonality and event factors. Experimental results highlight\nthat while the attention mechanism/Transformer framework is effective for\ncapturing long-range dependencies in sequential data, as the forecasting\nhorizon extends, the key to effective traffic forecasting gradually shifts from\ntemporal dependency capturing to periodicity modelling. Time embedding is\nparticularly effective in this context, helping naive RNN outperform Informer\nby 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust\nmodel, XGBoost, while learning solely from time features, performs\ncompetitively with DL methods. Moreover, we investigate the impacts of various\nfactors like input sequence length, holiday traffic, data granularity, and\ntraining data size. The findings offer valuable insights and serve as a\nreference for future long-term traffic forecasting research and the improvement\nof AI's corresponding learning capabilities.", "authors": ["Xiao Zheng", "Saeed Asadi Bagloee", "Majid Sarvi"], "category": "cs.LG", "updated": "2025-04-30T06:31:21Z"}
{"id": "2504.21380v1", "title": "Sparse-to-Sparse Training of Diffusion Models", "link": "http://arxiv.org/abs/2504.21380v1", "summary": "Diffusion models (DMs) are a powerful type of generative models that have\nachieved state-of-the-art results in various image synthesis tasks and have\nshown potential in other domains, such as natural language processing and\ntemporal data modeling. Despite their stable training dynamics and ability to\nproduce diverse high-quality samples, DMs are notorious for requiring\nsignificant computational resources, both in the training and inference stages.\nPrevious work has focused mostly on increasing the efficiency of model\ninference. This paper introduces, for the first time, the paradigm of\nsparse-to-sparse training to DMs, with the aim of improving both training and\ninference efficiency. We focus on unconditional generation and train sparse DMs\nfrom scratch (Latent Diffusion and ChiroDiff) on six datasets using three\ndifferent methods (Static-DM, RigL-DM, and MagRan-DM) to study the effect of\nsparsity in model performance. Our experiments show that sparse DMs are able to\nmatch and often outperform their Dense counterparts, while substantially\nreducing the number of trainable parameters and FLOPs. We also identify safe\nand effective values to perform sparse-to-sparse training of DMs.", "authors": ["Inês Cardoso Oliveira", "Decebal Constantin Mocanu", "Luis A. Leiva"], "category": "cs.LG", "updated": "2025-04-30T07:28:11Z"}
{"id": "2504.21383v1", "title": "FAST-Q: Fast-track Exploration with Adversarially Balanced State\n  Representations for Counterfactual Action Estimation in Offline Reinforcement\n  Learning", "link": "http://arxiv.org/abs/2504.21383v1", "summary": "Recent advancements in state-of-the-art (SOTA) offline reinforcement learning\n(RL) have primarily focused on addressing function approximation errors, which\ncontribute to the overestimation of Q-values for out-of-distribution actions, a\nchallenge that static datasets exacerbate. However, high stakes applications\nsuch as recommendation systems in online gaming, introduce further complexities\ndue to player's psychology (intent) driven by gameplay experiences and the\ninherent volatility on the platform. These factors create highly sparse,\npartially overlapping state spaces across policies, further influenced by the\nexperiment path selection logic which biases state spaces towards specific\npolicies. Current SOTA methods constrain learning from such offline data by\nclipping known counterfactual actions as out-of-distribution due to poor\ngeneralization across unobserved states. Further aggravating conservative\nQ-learning and necessitating more online exploration. FAST-Q introduces a novel\napproach that (1) leverages Gradient Reversal Learning to construct balanced\nstate representations, regularizing the policy-specific bias between the\nplayer's state and action thereby enabling counterfactual estimation; (2)\nsupports offline counterfactual exploration in parallel with static data\nexploitation; and (3) proposes a Q-value decomposition strategy for\nmulti-objective optimization, facilitating explainable recommendations over\nshort and long-term objectives. These innovations demonstrate superiority of\nFAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent\nincrease in player returns, 2 percent improvement in lifetime value (LTV), 0.4\npercent enhancement in the recommendation driven engagement, 2 percent\nimprovement in the player's platform dwell time and an impressive 10 percent\nreduction in the costs associated with the recommendation, on our volatile\ngaming platform.", "authors": ["Pulkit Agrawal", "Rukma Talwadker", "Aditya Pareek", "Tridib Mukherjee"], "category": "cs.LG", "updated": "2025-04-30T07:32:40Z"}
{"id": "2504.21427v1", "title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of\n  Clustering-Based Classifiers", "link": "http://arxiv.org/abs/2504.21427v1", "summary": "Accurate classification of EEG signals is crucial for brain-computer\ninterfaces (BCIs) and neuroprosthetic applications, yet many existing methods\nfail to account for the non-Euclidean, manifold structure of EEG data,\nresulting in suboptimal performance. Preserving this manifold information is\nessential to capture the true geometry of EEG signals, but traditional\nclassification techniques largely overlook this need. To this end, we propose\nMPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based\nClassifiers), that introduces two key innovations: (1) a feature engineering\nphase that combines covariance matrices and Radial Basis Function (RBF) kernels\nto capture both linear and non-linear relationships among EEG channels, and (2)\na clustering phase that employs a modified K-means algorithm tailored for the\nRiemannian manifold space, ensuring local geometric sensitivity. Ensembling\nmultiple clustering-based classifiers, MPEC achieves superior results,\nvalidated by significant improvements on the BCI Competition IV dataset 2a.", "authors": ["Shermin Shahbazi", "Mohammad-Reza Nasiri", "Majid Ramezani"], "category": "cs.LG", "updated": "2025-04-30T08:34:15Z"}
{"id": "2504.21436v1", "title": "Whispers of Data: Unveiling Label Distributions in Federated Learning\n  Through Virtual Client Simulation", "link": "http://arxiv.org/abs/2504.21436v1", "summary": "Federated Learning enables collaborative training of a global model across\nmultiple geographically dispersed clients without the need for data sharing.\nHowever, it is susceptible to inference attacks, particularly label inference\nattacks.\n  Existing studies on label distribution inference exhibits sensitive to the\nspecific settings of the victim client and typically underperforms under\ndefensive strategies. In this study, we propose a novel label distribution\ninference attack that is stable and adaptable to various scenarios.\nSpecifically, we estimate the size of the victim client's dataset and construct\nseveral virtual clients tailored to the victim client. We then quantify the\ntemporal generalization of each class label for the virtual clients and utilize\nthe variation in temporal generalization to train an inference model that\npredicts the label distribution proportions of the victim client.\n  We validate our approach on multiple datasets, including MNIST,\nFashion-MNIST, FER2013, and AG-News. The results demonstrate the superiority of\nour method compared to state-of-the-art techniques. Furthermore, our attack\nremains effective even under differential privacy defense mechanisms,\nunderscoring its potential for real-world applications.", "authors": ["Zhixuan Ma", "Haichang Gao", "Junxiang Huang", "Ping Wang"], "category": "cs.LG", "updated": "2025-04-30T08:51:06Z"}
{"id": "2504.21438v1", "title": "Wasserstein-Aitchison GAN for angular measures of multivariate extremes", "link": "http://arxiv.org/abs/2504.21438v1", "summary": "Economically responsible mitigation of multivariate extreme risks -- extreme\nrainfall in a large area, huge variations of many stock prices, widespread\nbreakdowns in transportation systems -- requires estimates of the probabilities\nthat such risks will materialize in the future. This paper develops a new\nmethod, Wasserstein--Aitchison Generative Adversarial Networks (WA-GAN), which\nprovides simulated values of future $d$-dimensional multivariate extreme events\nand which hence can be used to give estimates of such probabilities. The main\nhypothesis is that, after transforming the observations to the unit-Pareto\nscale, their distribution is regularly varying in the sense that the\ndistributions of their radial and angular components (with respect to the\n$L_1$-norm) converge and become asymptotically independent as the radius gets\nlarge. The method is a combination of standard extreme value analysis modeling\nof the tails of the marginal distributions with nonparametric GAN modeling of\nthe angular distribution. For the latter, the angular values are transformed to\nAitchison coordinates in a full $(d-1)$-dimensional linear space, and a\nWasserstein GAN is trained on these coordinates and used to generate new\nvalues. A reverse transformation is then applied to these values and gives\nsimulated values on the original data scale. The method shows good performance\ncompared to other existing methods in the literature, both in terms of\ncapturing the dependence structure of the extremes in the data, as well as in\ngenerating accurate new extremes of the data distribution. The comparison is\nperformed on simulated multivariate extremes from a logistic model in\ndimensions up to 50 and on a 30-dimensional financial data set.", "authors": ["Stéphane Lhaut", "Holger Rootzén", "Johan Segers"], "category": "cs.LG", "updated": "2025-04-30T08:54:28Z"}
{"id": "2504.21457v1", "title": "xEEGNet: Towards Explainable AI in EEG Dementia Classification", "link": "http://arxiv.org/abs/2504.21457v1", "summary": "This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.", "authors": ["Andrea Zanola", "Louis Fabrice Tshimanga", "Federico Del Pup", "Marco Baiesi", "Manfredo Atzori"], "category": "cs.LG", "updated": "2025-04-30T09:24:50Z"}
{"id": "2504.21565v1", "title": "Towards proactive self-adaptive AI for non-stationary environments with\n  dataset shifts", "link": "http://arxiv.org/abs/2504.21565v1", "summary": "Artificial Intelligence (AI) models deployed in production frequently face\nchallenges in maintaining their performance in non-stationary environments.\nThis issue is particularly noticeable in medical settings, where temporal\ndataset shifts often occur. These shifts arise when the distributions of\ntraining data differ from those of the data encountered during deployment over\ntime. Further, new labeled data to continuously retrain AI is not typically\navailable in a timely manner due to data access limitations. To address these\nchallenges, we propose a proactive self-adaptive AI approach, or pro-adaptive,\nwhere we model the temporal trajectory of AI parameters, allowing us to\nshort-term forecast parameter values. To this end, we use polynomial spline\nbases, within an extensible Functional Data Analysis framework. We validate our\nmethodology with a logistic regression model addressing prior probability\nshift, covariate shift, and concept shift. This validation is conducted on both\na controlled simulated dataset and a publicly available real-world COVID-19\ndataset from Mexico, with various shifts occurring between 2020 and 2024. Our\nresults indicate that this approach enhances the performance of AI against\nshifts compared to baseline stable models trained at different time distances\nfrom the present, without requiring updated training data. This work lays the\nfoundation for pro-adaptive AI research against dynamic, non-stationary\nenvironments, being compatible with data protection, in resilient AI production\nenvironments for health.", "authors": ["David Fernández Narro", "Pablo Ferri", "Juan M. García-Gómez", "Carlos Sáez"], "category": "cs.LG", "updated": "2025-04-30T12:09:59Z"}
{"id": "2504.21602v1", "title": "Real Time Semantic Segmentation of High Resolution Automotive LiDAR\n  Scans", "link": "http://arxiv.org/abs/2504.21602v1", "summary": "In recent studies, numerous previous works emphasize the importance of\nsemantic segmentation of LiDAR data as a critical component to the development\nof driver-assistance systems and autonomous vehicles. However, many\nstate-of-the-art methods are tested on outdated, lower-resolution LiDAR sensors\nand struggle with real-time constraints. This study introduces a novel semantic\nsegmentation framework tailored for modern high-resolution LiDAR sensors that\naddresses both accuracy and real-time processing demands. We propose a novel\nLiDAR dataset collected by a cutting-edge automotive 128 layer LiDAR in urban\ntraffic scenes. Furthermore, we propose a semantic segmentation method\nutilizing surface normals as strong input features. Our approach is bridging\nthe gap between cutting-edge research and practical automotive applications.\nAdditionaly, we provide a Robot Operating System (ROS2) implementation that we\noperate on our research vehicle. Our dataset and code are publicly available:\nhttps://github.com/kav-institute/SemanticLiDAR.", "authors": ["Hannes Reichert", "Benjamin Serfling", "Elijah Schüssler", "Kerim Turacan", "Konrad Doll", "Bernhard Sick"], "category": "cs.LG", "updated": "2025-04-30T13:00:50Z"}
{"id": "2504.21775v1", "title": "Learning Heterogeneous Performance-Fairness Trade-offs in Federated\n  Learning", "link": "http://arxiv.org/abs/2504.21775v1", "summary": "Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.", "authors": ["Rongguang Ye", "Ming Tang"], "category": "cs.LG", "updated": "2025-04-30T16:25:02Z"}
{"id": "2504.21789v1", "title": "Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation", "link": "http://arxiv.org/abs/2504.21789v1", "summary": "Magnetic Resonance Imaging (MRI) plays an important role in identifying\nclinically significant prostate cancer (csPCa), yet automated methods face\nchallenges such as data imbalance, variable tumor sizes, and a lack of\nannotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which\nincorporates anomaly maps derived from biparametric MRI sequences into a deep\nlearning-based segmentation framework to improve csPCa identification. We\nconduct a comparative analysis of anomaly detection methods and evaluate the\nintegration of anomaly maps into the segmentation pipeline. Anomaly maps,\ngenerated using Fixed-Point GAN reconstruction, highlight deviations from\nnormal prostate tissue, guiding the segmentation model to potential cancerous\nregions. We compare the performance by using the average score, computed as the\nmean of the AUROC and Average Precision (AP). On the external test set, adU-Net\nachieves the best average score of 0.618, outperforming the baseline nnU-Net\nmodel (0.605). The results demonstrate that incorporating anomaly detection\ninto segmentation improves generalization and performance, particularly with\nADC-based anomaly maps, offering a promising direction for automated csPCa\nidentification.", "authors": ["Alessia Hu", "Regina Beets-Tan", "Lishan Cai", "Eduardo Pooch"], "category": "cs.LG", "updated": "2025-04-30T16:48:00Z"}
{"id": "2504.21808v1", "title": "Stable Trajectory Clustering: An Efficient Split and Merge Algorithm", "link": "http://arxiv.org/abs/2504.21808v1", "summary": "Clustering algorithms group data points by characteristics to identify\npatterns. Over the past two decades, researchers have extended these methods to\nanalyze trajectories of humans, animals, and vehicles, studying their behavior\nand movement across applications. This paper presents whole-trajectory\nclustering and sub-trajectory clustering algorithms based on DBSCAN line\nsegment clustering, which encompasses two key events: split and merge of line\nsegments. The events are employed by object movement history and the average\nEuclidean distance between line segments. In this framework, whole-trajectory\nclustering considers entire entities' trajectories, whereas sub-trajectory\nclustering employs a sliding window model to identify similar sub-trajectories.\nMany existing trajectory clustering algorithms respond to temporary anomalies\nin data by splitting trajectories, which often obscures otherwise consistent\nclustering patterns and leads to less reliable insights. We introduce the\nstable trajectory clustering algorithm, which leverages the mean absolute\ndeviation concept to demonstrate that selective omission of transient\ndeviations not only preserves the integrity of clusters but also improves their\nstability and interpretability. We run all proposed algorithms on real\ntrajectory datasets to illustrate their effectiveness and sensitivity to\nparameter variations.", "authors": ["Atieh Rahmani", "Mansoor Davoodi", "Justin M. Calabrese"], "category": "cs.LG", "updated": "2025-04-30T17:11:36Z"}
{"id": "2505.00065v1", "title": "ConSens: Assessing context grounding in open-book question answering", "link": "http://arxiv.org/abs/2505.00065v1", "summary": "Large Language Models (LLMs) have demonstrated considerable success in\nopen-book question answering (QA), where the task requires generating answers\ngrounded in a provided external context. A critical challenge in open-book QA\nis to ensure that model responses are based on the provided context rather than\nits parametric knowledge, which can be outdated, incomplete, or incorrect.\nExisting evaluation methods, primarily based on the LLM-as-a-judge approach,\nface significant limitations, including biases, scalability issues, and\ndependence on costly external systems. To address these challenges, we propose\na novel metric that contrasts the perplexity of the model response under two\nconditions: when the context is provided and when it is not. The resulting\nscore quantifies the extent to which the model's answer relies on the provided\ncontext. The validity of this metric is demonstrated through a series of\nexperiments that show its effectiveness in identifying whether a given answer\nis grounded in the provided context. Unlike existing approaches, this metric is\ncomputationally efficient, interpretable, and adaptable to various use cases,\noffering a scalable and practical solution to assess context utilization in\nopen-book QA systems.", "authors": ["Ivan Vankov", "Matyo Ivanov", "Adriana Correia", "Victor Botev"], "category": "cs.LG", "updated": "2025-04-30T16:23:15Z"}
{"id": "2505.00101v1", "title": "From Lab to Wrist: Bridging Metabolic Monitoring and Consumer Wearables\n  for Heart Rate and Oxygen Consumption Modeling", "link": "http://arxiv.org/abs/2505.00101v1", "summary": "Understanding physiological responses during running is critical for\nperformance optimization, tailored training prescriptions, and athlete health\nmanagement. We introduce a comprehensive framework -- what we believe to be the\nfirst capable of predicting instantaneous oxygen consumption (VO$_{2}$)\ntrajectories exclusively from consumer-grade wearable data. Our approach\nemploys two complementary physiological models: (1) accurate modeling of heart\nrate (HR) dynamics via a physiologically constrained ordinary differential\nequation (ODE) and neural Kalman filter, trained on over 3 million HR\nobservations, achieving 1-second interval predictions with mean absolute errors\nas low as 2.81\\,bpm (correlation 0.87); and (2) leveraging the principles of\nprecise HR modeling, a novel VO$_{2}$ prediction architecture requiring only\nthe initial second of VO$_{2}$ data for calibration, enabling robust,\nsequence-to-sequence metabolic demand estimation. Despite relying solely on\nsmartwatch and chest-strap data, our method achieves mean absolute percentage\nerrors of approximately 13\\%, effectively capturing rapid physiological\ntransitions and steady-state conditions across diverse running intensities. Our\nsynchronized dataset, complemented by blood lactate measurements, further lays\nthe foundation for future noninvasive metabolic zone identification. By\nembedding physiological constraints within modern machine learning, this\nframework democratizes advanced metabolic monitoring, bridging laboratory-grade\naccuracy and everyday accessibility, thus empowering both elite athletes and\nrecreational fitness enthusiasts.", "authors": ["Barak Gahtan", "Sanketh Vedula", "Gil Samuelly Leichtag", "Einat Kodesh", "Alex M. Bronstein"], "category": "cs.LG", "updated": "2025-04-30T18:15:00Z"}
{"id": "2505.00131v1", "title": "Kernel-Based Ensemble Gaussian Mixture Probability Hypothesis Density\n  Filter", "link": "http://arxiv.org/abs/2505.00131v1", "summary": "In this work, a kernel-based Ensemble Gaussian Mixture Probability Hypothesis\nDensity (EnGM-PHD) filter is presented for multi-target filtering applications.\nThe EnGM-PHD filter combines the Gaussian-mixture-based techniques of the\nGaussian Mixture Probability Hypothesis Density (GM-PHD) filter with the\nparticle-based techniques of the Sequential Monte Carlo Probability Hypothesis\nDensity (SMC-PHD) filter. It achieves this by obtaining particles from the\nposterior intensity function, propagating them through the system dynamics, and\nthen using Kernel Density Estimation (KDE) techniques to approximate the\nGaussian mixture of the prior intensity function. This approach guarantees\nconvergence to the true intensity function in the limit of the number of\ncomponents. Moreover, in the special case of a single target with no births,\ndeaths, clutter, and perfect detection probability, the EnGM-PHD filter reduces\nto the standard Ensemble Gaussian Mixture Filter (EnGMF). In the presented\nexperiment, the results indicate that the EnGM-PHD filter achieves better\nmulti-target filtering performance than both the GM-PHD and SMC-PHD filters\nwhile using the same number of components or particles.", "authors": ["Dalton Durant", "Renato Zanetti"], "category": "cs.LG", "updated": "2025-04-30T19:00:02Z"}
{"id": "2505.00162v1", "title": "Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search", "link": "http://arxiv.org/abs/2505.00162v1", "summary": "Efficient optimization remains a fundamental challenge across numerous\nscientific and engineering domains, especially when objective function and\ngradient evaluations are computationally expensive. While zeroth-order\noptimization methods offer effective approaches when gradients are\ninaccessible, their practical performance can be limited by the high cost\nassociated with function queries. This work introduces the bi-fidelity\nstochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order\noptimization method designed to reduce this computational burden. BF-SSD\nleverages a bi-fidelity framework, constructing a surrogate model from a\ncombination of computationally inexpensive low-fidelity (LF) and accurate\nhigh-fidelity (HF) function evaluations. This surrogate model facilitates an\nefficient backtracking line search for step size selection, for which we\nprovide theoretical convergence guarantees under standard assumptions. We\nperform a comprehensive empirical evaluation of BF-SSD across four distinct\nproblems: a synthetic optimization benchmark, dual-form kernel ridge\nregression, black-box adversarial attacks on machine learning models, and\ntransformer-based black-box language model fine-tuning. Numerical results\ndemonstrate that BF-SSD consistently achieves superior optimization performance\nwhile requiring significantly fewer HF function evaluations compared to\nrelevant baseline methods. This study highlights the efficacy of integrating\nbi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as\na promising and computationally efficient approach for tackling large-scale,\nhigh-dimensional problems encountered in various real-world applications.", "authors": ["Nuojin Cheng", "Alireza Doostan", "Stephen Becker"], "category": "cs.LG", "updated": "2025-04-30T20:17:35Z"}
{"id": "2505.00169v1", "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D\n  Molecule Generation", "link": "http://arxiv.org/abs/2505.00169v1", "summary": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.", "authors": ["Filipp Nikitin", "Ian Dunn", "David Ryan Koes", "Olexandr Isayev"], "category": "cs.LG", "updated": "2025-04-30T20:29:22Z"}
{"id": "2505.00171v1", "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence\n  Prediction", "link": "http://arxiv.org/abs/2505.00171v1", "summary": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels.", "authors": ["Saram Abbas", "Naeem Soomro", "Rishad Shafik", "Rakesh Heer", "Kabita Adhikari"], "category": "cs.LG", "updated": "2025-04-30T20:39:33Z"}
{"id": "2505.00190v1", "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders", "link": "http://arxiv.org/abs/2505.00190v1", "summary": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off.", "authors": ["Hans Peter", "Anders Søgaard"], "category": "cs.LG", "updated": "2025-04-30T21:08:32Z"}
{"id": "2505.00196v1", "title": "Mapping minds not averages: a scalable subject-specific manifold\n  learning framework for neuroimaging data", "link": "http://arxiv.org/abs/2505.00196v1", "summary": "Mental and cognitive representations are believed to reside on\nlow-dimensional, non-linear manifolds embedded within high-dimensional brain\nactivity. Uncovering these manifolds is key to understanding individual\ndifferences in brain function, yet most existing machine learning methods\neither rely on population-level spatial alignment or assume data that is\ntemporally structured, either because data is aligned among subjects or because\nevent timings are known. We introduce a manifold learning framework that can\ncapture subject-specific spatial variations across both structured and\ntemporally unstructured neuroimaging data. On simulated data and two\nnaturalistic fMRI datasets (Sherlock and Forrest Gump), our framework\noutperforms group-based baselines by recovering more accurate and\nindividualized representations. We further show that the framework scales\nefficiently to large datasets and generalizes well to new subjects. To test\nthis, we apply the framework to temporally unstructured resting-state fMRI data\nfrom individuals with schizophrenia and healthy controls. We further apply our\nmethod to a large resting-state fMRI dataset comprising individuals with\nschizophrenia and controls. In this setting, we demonstrate that the framework\nscales efficiently to large populations and generalizes robustly to unseen\nsubjects. The learned subject-specific spatial maps our model finds reveal\nclinically relevant patterns, including increased activation in the basal\nganglia, visual, auditory, and somatosensory regions, and decreased activation\nin the insula, inferior frontal gyrus, and angular gyrus. These findings\nsuggest that our framework can uncover clinically relevant subject-specific\nbrain activity patterns. Our approach thus provides a scalable and\nindividualized framework for modeling brain activity, with applications in\ncomputational neuroscience and clinical research.", "authors": ["Eloy Geenjaar", "Vince Calhoun"], "category": "cs.LG", "updated": "2025-04-30T21:40:54Z"}
{"id": "2505.00209v1", "title": "Direct Motion Models for Assessing Generated Videos", "link": "http://arxiv.org/abs/2505.00209v1", "summary": "A current limitation of video generative video models is that they generate\nplausible looking frames, but poor motion -- an issue that is not well captured\nby FVD and other popular methods for evaluating generated videos. Here we go\nbeyond FVD by developing a metric which better measures plausible object\ninteractions and motion. Our novel approach is based on auto-encoding point\ntracks and yields motion features that can be used to not only compare\ndistributions of videos (as few as one generated and one ground truth, or as\nmany as two datasets), but also for evaluating motion of single videos. We show\nthat using point tracks instead of pixel reconstruction or action recognition\nfeatures results in a metric which is markedly more sensitive to temporal\ndistortions in synthetic data, and can predict human evaluations of temporal\nconsistency and realism in generated videos obtained from open-source models\nbetter than a wide range of alternatives. We also show that by using a point\ntrack representation, we can spatiotemporally localize generative video\ninconsistencies, providing extra interpretability of generated video errors\nrelative to prior work. An overview of the results and link to the code can be\nfound on the project page: http://trajan-paper.github.io.", "authors": ["Kelsey Allen", "Carl Doersch", "Guangyao Zhou", "Mohammed Suhail", "Danny Driess", "Ignacio Rocco", "Yulia Rubanova", "Thomas Kipf", "Mehdi S. M. Sajjadi", "Kevin Murphy", "Joao Carreira", "Sjoerd van Steenkiste"], "category": "cs.LG", "updated": "2025-04-30T22:34:52Z"}
{"id": "2505.00225v1", "title": "Predicting Estimated Times of Restoration for Electrical Outages Using\n  Longitudinal Tabular Transformers", "link": "http://arxiv.org/abs/2505.00225v1", "summary": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities.", "authors": ["Bogireddy Sai Prasanna Teja", "Valliappan Muthukaruppan", "Carls Benjamin"], "category": "cs.LG", "updated": "2025-05-01T00:25:43Z"}
{"id": "2505.00232v1", "title": "Scaling On-Device GPU Inference for Large Generative Models", "link": "http://arxiv.org/abs/2505.00232v1", "summary": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines.", "authors": ["Jiuqiang Tang", "Raman Sarokin", "Ekaterina Ignasheva", "Grant Jensen", "Lin Chen", "Juhyun Lee", "Andrei Kulik", "Matthias Grundmann"], "category": "cs.LG", "updated": "2025-05-01T00:44:13Z"}
{"id": "2505.00233v1", "title": "Explorative Curriculum Learning for Strongly Correlated Electron Systems", "link": "http://arxiv.org/abs/2505.00233v1", "summary": "Recent advances in neural network quantum states (NQS) have enabled\nhigh-accuracy predictions for complex quantum many-body systems such as\nstrongly correlated electron systems. However, the computational cost remains\nprohibitive, making exploration of the diverse parameters of interaction\nstrengths and other physical parameters inefficient. While transfer learning\nhas been proposed to mitigate this challenge, achieving generalization to\nlarge-scale systems and diverse parameter regimes remains difficult. To address\nthis limitation, we propose a novel curriculum learning framework based on\ntransfer learning for NQS. This facilitates efficient and stable exploration\nacross a vast parameter space of quantum many-body systems. In addition, by\ninterpreting NQS transfer learning through a perturbative lens, we demonstrate\nhow prior physical knowledge can be flexibly incorporated into the curriculum\nlearning process. We also propose Pairing-Net, an architecture to practically\nimplement this strategy for strongly correlated electron systems, and\nempirically verify its effectiveness. Our results show an approximately\n200-fold speedup in computation and a marked improvement in optimization\nstability compared to conventional methods.", "authors": ["Kimihiro Yamazaki", "Takuya Konishi", "Yoshinobu Kawahara"], "category": "cs.LG", "updated": "2025-05-01T00:46:52Z"}
{"id": "2505.00234v2", "title": "Self-Generated In-Context Examples Improve LLM Agents for Sequential\n  Decision-Making Tasks", "link": "http://arxiv.org/abs/2505.00234v2", "summary": "Many methods for improving Large Language Model (LLM) agents for sequential\ndecision-making tasks depend on task-specific knowledge engineering--such as\nprompt tuning, curated in-context examples, or customized observation and\naction spaces. Using these approaches, agent performance improves with the\nquality or amount of knowledge engineering invested. Instead, we investigate\nhow LLM agents can automatically improve their performance by learning\nin-context from their own successful experiences on similar tasks. Rather than\nrelying on task-specific knowledge engineering, we focus on constructing and\nrefining a database of self-generated examples. We demonstrate that even a\nnaive accumulation of successful trajectories across training tasks boosts test\nperformance on three benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%),\nand InterCode-SQL (75% to 79%)--matching the performance the initial agent\nachieves if allowed two to three attempts per task. We then introduce two\nextensions: (1) database-level selection through population-based training to\nidentify high-performing example collections, and (2) exemplar-level selection\nthat retains individual trajectories based on their empirical utility as\nin-context examples. These extensions further enhance performance, achieving\n91% on ALFWorld--matching more complex approaches that employ task-specific\ncomponents and prompts. Our results demonstrate that automatic trajectory\ndatabase construction offers a compelling alternative to labor-intensive\nknowledge engineering.", "authors": ["Vishnu Sarukkai", "Zhiqiang Xie", "Kayvon Fatahalian"], "category": "cs.LG", "updated": "2025-05-02T16:44:02Z"}
{"id": "2505.00738v1", "title": "XeMap: Contextual Referring in Large-Scale Remote Sensing Environments", "link": "http://arxiv.org/abs/2505.00738v1", "summary": "Advancements in remote sensing (RS) imagery have provided high-resolution\ndetail and vast coverage, yet existing methods, such as image-level\ncaptioning/retrieval and object-level detection/segmentation, often fail to\ncapture mid-scale semantic entities essential for interpreting large-scale\nscenes. To address this, we propose the conteXtual referring Map (XeMap) task,\nwhich focuses on contextual, fine-grained localization of text-referred regions\nin large-scale RS scenes. Unlike traditional approaches, XeMap enables precise\nmapping of mid-scale semantic entities that are often overlooked in image-level\nor object-level methods. To achieve this, we introduce XeMap-Network, a novel\narchitecture designed to handle the complexities of pixel-level cross-modal\ncontextual referring mapping in RS. The network includes a fusion layer that\napplies self- and cross-attention mechanisms to enhance the interaction between\ntext and image embeddings. Furthermore, we propose a Hierarchical Multi-Scale\nSemantic Alignment (HMSA) module that aligns multiscale visual features with\nthe text semantic vector, enabling precise multimodal matching across\nlarge-scale RS imagery. To support XeMap task, we provide a novel, annotated\ndataset, XeMap-set, specifically tailored for this task, overcoming the lack of\nXeMap datasets in RS imagery. XeMap-Network is evaluated in a zero-shot setting\nagainst state-of-the-art methods, demonstrating superior performance. This\nhighlights its effectiveness in accurately mapping referring regions and\nproviding valuable insights for interpreting large-scale RS environments.", "authors": ["Yuxi Li", "Lu Si", "Yujie Hou", "Chengaung Liu", "Bin Li", "Hongjian Fang", "Jun Zhang"], "category": "cs.LG", "updated": "2025-04-30T02:14:39Z"}
{"id": "2505.00741v1", "title": "Detection and Classification of Diseases in Multi-Crop Leaves using LSTM\n  and CNN Models", "link": "http://arxiv.org/abs/2505.00741v1", "summary": "Plant diseases pose a serious challenge to agriculture by reducing crop yield\nand affecting food quality. Early detection and classification of these\ndiseases are essential for minimising losses and improving crop management\npractices. This study applies Convolutional Neural Networks (CNN) and Long\nShort-Term Memory (LSTM) models to classify plant leaf diseases using a dataset\ncontaining 70,295 training images and 17,572 validation images across 38\ndisease classes. The CNN model was trained using the Adam optimiser with a\nlearning rate of 0.0001 and categorical cross-entropy as the loss function.\nAfter 10 training epochs, the model achieved a training accuracy of 99.1% and a\nvalidation accuracy of 96.4%. The LSTM model reached a validation accuracy of\n93.43%. Performance was evaluated using precision, recall, F1-score, and\nconfusion matrix, confirming the reliability of the CNN-based approach. The\nresults suggest that deep learning models, particularly CNN, enable an\neffective solution for accurate and scalable plant disease classification,\nsupporting practical applications in agricultural monitoring.", "authors": ["Srinivas Kanakala", "Sneha Ningappa"], "category": "cs.LG", "updated": "2025-04-30T02:36:51Z"}
{"id": "2505.00745v1", "title": "Responsive DNN Adaptation for Video Analytics against Environment Shift\n  via Hierarchical Mobile-Cloud Collaborations", "link": "http://arxiv.org/abs/2505.00745v1", "summary": "Mobile video analysis systems often encounter various deploying environments,\nwhere environment shifts present greater demands for responsiveness in\nadaptations of deployed \"expert DNN models\". Existing model adaptation\nframeworks primarily operate in a cloud-centric way, exhibiting degraded\nperformance during adaptation and delayed reactions to environment shifts.\nInstead, this paper proposes MOCHA, a novel framework optimizing the\nresponsiveness of continuous model adaptation through hierarchical\ncollaborations between mobile and cloud resources. Specifically, MOCHA (1)\nreduces adaptation response delays by performing on-device model reuse and fast\nfine-tuning before requesting cloud model retrieval and end-to-end retraining;\n(2) accelerates history expert model retrieval by organizing them into a\nstructured taxonomy utilizing domain semantics analyzed by a cloud foundation\nmodel as indices; (3) enables efficient local model reuse by maintaining\nonboard expert model caches for frequent scenes, which proactively prefetch\nmodel weights from the cloud model database. Extensive evaluations with\nreal-world videos on three DNN tasks show MOCHA improves the model accuracy\nduring adaptation by up to 6.8% while saving the response delay and retraining\ntime by up to 35.5x and 3.0x respectively.", "authors": ["Maozhe Zhao", "Shengzhong Liu", "Fan Wu", "Guihai Chen"], "category": "cs.LG", "updated": "2025-04-30T08:08:15Z"}
{"id": "2505.01448v1", "title": "OpenAVS: Training-Free Open-Vocabulary Audio Visual Segmentation with\n  Foundational Models", "link": "http://arxiv.org/abs/2505.01448v1", "summary": "Audio-visual segmentation aims to separate sounding objects from videos by\npredicting pixel-level masks based on audio signals. Existing methods primarily\nconcentrate on closed-set scenarios and direct audio-visual alignment and\nfusion, which limits their capability to generalize to new, unseen situations.\nIn this paper, we propose OpenAVS, a novel training-free language-based\napproach that, for the first time, effectively aligns audio and visual\nmodalities using text as a proxy for open-vocabulary Audio-Visual Segmentation\n(AVS). Equipped with multimedia foundation models, OpenAVS directly infers\nmasks through 1) audio-to-text prompt generation, 2) LLM-guided prompt\ntranslation, and 3) text-to-visual sounding object segmentation. The objective\nof OpenAVS is to establish a simple yet flexible architecture that relies on\nthe most appropriate foundation models by fully leveraging their capabilities\nto enable more effective knowledge transfer to the downstream AVS task.\nMoreover, we present a model-agnostic framework OpenAVS-ST that enables the\nintegration of OpenAVS with any advanced supervised AVS model via pseudo-label\nbased self-training. This approach enhances performance by effectively\nutilizing large-scale unlabeled data when available. Comprehensive experiments\non three benchmark datasets demonstrate the superior performance of OpenAVS. It\nsurpasses existing unsupervised, zero-shot, and few-shot AVS methods by a\nsignificant margin, achieving absolute performance gains of approximately 9.4%\nand 10.9% in mIoU and F-score, respectively, in challenging scenarios.", "authors": ["Shengkai Chen", "Yifang Yin", "Jinming Cao", "Shili Xiang", "Zhenguang Liu", "Roger Zimmermann"], "category": "cs.LG", "updated": "2025-04-30T01:52:10Z"}
{"id": "2505.01454v2", "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in\n  Communication-Efficient Federated Learning", "link": "http://arxiv.org/abs/2505.01454v2", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy, yet it faces significant\nchallenges in communication efficiency and vulnerability to poisoning attacks.\nWhile sparsification techniques mitigate communication overhead by transmitting\nonly critical model parameters, they inadvertently amplify security risks:\nadversarial clients can exploit sparse updates to evade detection and degrade\nmodel performance. Existing defense mechanisms, designed for standard FL\ncommunication scenarios, are ineffective in addressing these vulnerabilities\nwithin sparsified FL. To bridge this gap, we propose FLARE, a novel federated\nlearning framework that integrates sparse index mask inspection and model\nupdate sign similarity analysis to detect and mitigate poisoning attacks in\nsparsified FL. Extensive experiments across multiple datasets and adversarial\nscenarios demonstrate that FLARE significantly outperforms existing defense\nstrategies, effectively securing sparsified FL against poisoning attacks while\nmaintaining communication efficiency.", "authors": ["Zhiyong Jin", "Runhua Xu", "Chao Li", "Yizhong Liu", "Jianxin Li"], "category": "cs.LG", "updated": "2025-05-09T13:27:29Z"}
{"id": "2505.01455v1", "title": "Seasonal Prediction with Neural GCM and Simplified Boundary Forcings:\n  Large-scale Atmospheric Variability and Tropical Cyclone Activity", "link": "http://arxiv.org/abs/2505.01455v1", "summary": "Machine learning (ML) models are successful with weather forecasting and have\nshown progress in climate simulations, yet leveraging them for useful climate\npredictions needs exploration. Here we show this feasibility using NeuralGCM, a\nhybrid ML-physics atmospheric model, for seasonal predictions of large-scale\natmospheric variability and Northern Hemisphere tropical cyclone (TC) activity.\nInspired by physical model studies, we simplify boundary conditions, assuming\nsea surface temperature (SST) and sea ice follow their climatological cycle but\npersist anomalies present at initialization. With such forcings, NeuralGCM\nsimulates realistic atmospheric circulation and TC climatology patterns.\nFurthermore, this configuration yields useful seasonal predictions\n(July-November) for the tropical atmosphere and various TC activity metrics.\nNotably, the prediction skill for TC frequency in the North Atlantic and East\nPacific basins is comparable to existing physical models. These findings\nhighlight the promise of leveraging ML models with physical insights to model\nTC risks and deliver seamless weather-climate predictions.", "authors": ["Gan Zhang", "Megha Rao", "Janni Yuval", "Ming Zhao"], "category": "cs.LG", "updated": "2025-04-30T19:42:16Z"}
{"id": "2505.03783v1", "title": "A general physics-constrained method for the modelling of equation's\n  closure terms with sparse data", "link": "http://arxiv.org/abs/2505.03783v1", "summary": "Accurate modeling of closure terms is a critical challenge in engineering and\nscientific research, particularly when data is sparse (scarse or incomplete),\nmaking widely applicable models difficult to develop. This study proposes a\nnovel approach for constructing closure models in such challenging scenarios.\nWe introduce a Series-Parallel Multi-Network Architecture that integrates\nPhysics-Informed Neural Networks (PINNs) to incorporate physical constraints\nand heterogeneous data from multiple initial and boundary conditions, while\nemploying dedicated subnetworks to independently model unknown closure terms,\nenhancing generalizability across diverse problems. These closure models are\nintegrated into an accurate Partial Differential Equation (PDE) solver,\nenabling robust solutions to complex predictive simulations in engineering\napplications.", "authors": ["Tian Chen", "Shengping Liu", "Li Liu", "Heng Yong"], "category": "cs.LG", "updated": "2025-04-30T14:41:18Z"}
{"id": "2505.03785v1", "title": "mAIstro: an open-source multi-agentic system for automated end-to-end\n  development of radiomics and deep learning models for medical imaging", "link": "http://arxiv.org/abs/2505.03785v1", "summary": "Agentic systems built on large language models (LLMs) offer promising\ncapabilities for automating complex workflows in healthcare AI. We introduce\nmAIstro, an open-source, autonomous multi-agentic framework for end-to-end\ndevelopment and deployment of medical AI models. The system orchestrates\nexploratory data analysis, radiomic feature extraction, image segmentation,\nclassification, and regression through a natural language interface, requiring\nno coding from the user. Built on a modular architecture, mAIstro supports both\nopen- and closed-source LLMs, and was evaluated using a large and diverse set\nof prompts across 16 open-source datasets, covering a wide range of imaging\nmodalities, anatomical regions, and data types. The agents successfully\nexecuted all tasks, producing interpretable outputs and validated models. This\nwork presents the first agentic framework capable of unifying data analysis, AI\nmodel development, and inference across varied healthcare applications,\noffering a reproducible and extensible foundation for clinical and research AI\nintegration. The code is available at: https://github.com/eltzanis/mAIstro", "authors": ["Eleftherios Tzanis", "Michail E. Klontzas"], "category": "cs.LG", "updated": "2025-04-30T16:25:51Z"}
{"id": "2505.03786v1", "title": "When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as\n  Discriminator", "link": "http://arxiv.org/abs/2505.03786v1", "summary": "Large Language Models (LLM) with reasoning capabilities offer a promising\npath for improving candidate evaluation in planning frameworks, but their\nrelative performance against traditional non-reasoning models remains largely\nunderexplored. In this study, we benchmark a distilled 1.5B parameter reasoning\nmodel (DeepSeek-R1) against several state-of-the-art non-reasoning LLMs within\na generator-discriminator LLM planning framework for the text-to-SQL task. For\nthis, we introduce a novel method for extracting soft scores from the\nchain-of-thought (CoT) outputs from reasoning that enables fine-grained ranking\nof candidates. Our central hypothesis is that reasoning models are more\neffective discriminators than non-reasoning LLMs. Our results show that\ndistilled DeepSeek-R1-1.5B achieves up to $87\\%$ higher F1 and $3.7\\%$ better\ndiscrimination accuracy than CodeLlama-7B, as well as $3.7\\%$ higher execution\naccuracy than CodeLlama-13B, despite having significantly fewer parameters.\nFurthermore, we find that there is a limit to the logical capabilities of\nreasoning models, and only providing more context or allowing more compute\nbudget for reasoning is not enough to improve their discrimination performance.\nFinally, we demonstrate that, unlike non-reasoning LLMs, reasoning models find\ngeneration more challenging than discrimination and may underperform as\ngenerators compared to smaller non-reasoning LLMs. Our work highlights the\npotential of reasoning models as discriminators in agentic frameworks, far\noutweighing their capabilities as generators, offering insights into their\noptimal role within LLM planning infrastructures.", "authors": ["Md Fahim Anjum"], "category": "cs.LG", "updated": "2025-04-30T17:27:13Z"}
{"id": "2505.04634v1", "title": "MatMMFuse: Multi-Modal Fusion model for Material Property Prediction", "link": "http://arxiv.org/abs/2505.04634v1", "summary": "The recent progress of using graph based encoding of crystal structures for\nhigh throughput material property prediction has been quite successful.\nHowever, using a single modality model prevents us from exploiting the\nadvantages of an enhanced features space by combining different\nrepresentations. Specifically, pre-trained Large language models(LLMs) can\nencode a large amount of knowledge which is beneficial for training of models.\nMoreover, the graph encoder is able to learn the local features while the text\nencoder is able to learn global information such as space group and crystal\nsymmetry. In this work, we propose Material Multi-Modal Fusion(MatMMFuse), a\nfusion based model which uses a multi-head attention mechanism for the\ncombination of structure aware embedding from the Crystal Graph Convolution\nNetwork (CGCNN) and text embeddings from the SciBERT model. We train our model\nin an end-to-end framework using data from the Materials Project Dataset. We\nshow that our proposed model shows an improvement compared to the vanilla CGCNN\nand SciBERT model for all four key properties: formation energy, band gap,\nenergy above hull and fermi energy. Specifically, we observe an improvement of\n40% compared to the vanilla CGCNN model and 68% compared to the SciBERT model\nfor predicting the formation energy per atom. Importantly, we demonstrate the\nzero shot performance of the trained model on small curated datasets of\nPerovskites, Chalcogenides and the Jarvis Dataset. The results show that the\nproposed model exhibits better zero shot performance than the individual plain\nvanilla CGCNN and SciBERT model. This enables researchers to deploy the model\nfor specialized industrial applications where collection of training data is\nprohibitively expensive.", "authors": ["Abhiroop Bhattacharya", "Sylvain G. Cloutier"], "category": "cs.LG", "updated": "2025-04-30T09:26:28Z"}
{"id": "2505.05489v1", "title": "Akkumula: Evidence accumulation driver models with Spiking Neural\n  Networks", "link": "http://arxiv.org/abs/2505.05489v1", "summary": "Processes of evidence accumulation for motor control contribute to the\necological validity of driver models. According to established theories of\ncognition, drivers make control adjustments when a process of accumulation of\nperceptual inputs reaches a decision boundary. Unfortunately, there is not a\nstandard way for building such models, limiting their use. Current\nimplementations are hand-crafted, lack adaptability, and rely on inefficient\noptimization techniques that do not scale well with large datasets. This paper\nintroduces Akkumula, an evidence accumulation modelling framework built using\ndeep learning techniques to leverage established coding libraries, gradient\noptimization, and large batch training. The core of the library is based on\nSpiking Neural Networks, whose operation mimic the evidence accumulation\nprocess in the biological brain. The model was tested on data collected during\na test-track experiment. Results are promising. The model fits well the time\ncourse of vehicle control (brake, accelerate, steering) based on vehicle sensor\ndata. The perceptual inputs are extracted by a dedicated neural network,\nincreasing the context-awareness of the model in dynamic scenarios. Akkumula\nintegrates with existing machine learning architectures, benefits from\ncontinuous advancements in deep learning, efficiently processes large datasets,\nadapts to diverse driving scenarios, and maintains a degree of transparency in\nits core mechanisms.", "authors": ["Alberto Morando"], "category": "cs.LG", "updated": "2025-04-30T10:03:11Z"}
{"id": "2504.21260v1", "title": "Power Flow Approximations for Multiphase Distribution Networks using\n  Gaussian Processes", "link": "http://arxiv.org/abs/2504.21260v1", "summary": "Learning-based approaches are increasingly leveraged to manage and coordinate\nthe operation of grid-edge resources in active power distribution networks.\nAmong these, model-based techniques stand out for their superior data\nefficiency and robustness compared to model-free methods. However, effective\nmodel learning requires a learning-based approximator for the underlying power\nflow model. This study extends existing work by introducing a data-driven power\nflow method based on Gaussian Processes (GPs) to approximate the multiphase\npower flow model, by mapping net load injections to nodal voltages. Simulation\nresults using the IEEE 123-bus and 8500-node distribution test feeders\ndemonstrate that the trained GP model can reliably predict the nonlinear power\nflow solutions with minimal training data. We also conduct a comparative\nanalysis of the training efficiency and testing performance of the proposed\nGP-based power flow approximator against a deep neural network-based\napproximator, highlighting the advantages of our data-efficient approach.\nResults over realistic operating conditions show that despite an 85% reduction\nin the training sample size (corresponding to a 92.8% improvement in training\ntime), GP models produce a 99.9% relative reduction in mean absolute error\ncompared to the baselines of deep neural networks.", "authors": ["Daniel Glover", "Parikshit Pareek", "Deepjyoti Deka", "Anamika Dubey"], "category": "cs.LG", "updated": "2025-04-30T02:26:31Z"}
{"id": "2504.21261v1", "title": "Multi-Domain Causal Discovery in Bijective Causal Models", "link": "http://arxiv.org/abs/2504.21261v1", "summary": "We consider the problem of causal discovery (a.k.a., causal structure\nlearning) in a multi-domain setting. We assume that the causal functions are\ninvariant across the domains, while the distribution of the exogenous noise may\nvary. Under causal sufficiency (i.e., no confounders exist), we show that the\ncausal diagram can be discovered under less restrictive functional assumptions\ncompared to previous work. What enables causal discovery in this setting is\nbijective generation mechanisms (BGM), which ensures that the functional\nrelation between the exogenous noise $E$ and the endogenous variable $Y$ is\nbijective and differentiable in both directions at every level of the cause\nvariable $X = x$. BGM generalizes a variety of models including additive noise\nmodel, LiNGAM, post-nonlinear model, and location-scale noise model. Further,\nwe derive a statistical test to find the parents set of the target variable.\nExperiments on various synthetic and real-world datasets validate our\ntheoretical findings.", "authors": ["Kasra Jalaldoust", "Saber Salehkaleybar", "Negar Kiyavash"], "category": "cs.LG", "updated": "2025-04-30T02:30:10Z"}
{"id": "2504.21263v1", "title": "Embracing Collaboration Over Competition: Condensing Multiple Prompts\n  for Visual In-Context Learning", "link": "http://arxiv.org/abs/2504.21263v1", "summary": "Visual In-Context Learning (VICL) enables adaptively solving vision tasks by\nleveraging pixel demonstrations, mimicking human-like task completion through\nanalogy. Prompt selection is critical in VICL, but current methods assume the\nexistence of a single \"ideal\" prompt in a pool of candidates, which in practice\nmay not hold true. Multiple suitable prompts may exist, but individually they\noften fall short, leading to difficulties in selection and the exclusion of\nuseful context. To address this, we propose a new perspective: prompt\ncondensation. Rather than relying on a single prompt, candidate prompts\ncollaborate to efficiently integrate informative contexts without sacrificing\nresolution. We devise Condenser, a lightweight external plugin that compresses\nrelevant fine-grained context across multiple prompts. Optimized end-to-end\nwith the backbone, Condenser ensures accurate integration of contextual cues.\nExperiments demonstrate Condenser outperforms state-of-the-arts across\nbenchmark tasks, showing superior context compression, scalability with more\nprompts, and enhanced computational efficiency compared to ensemble methods,\npositioning it as a highly competitive solution for VICL. Code is open-sourced\nat https://github.com/gimpong/CVPR25-Condenser.", "authors": ["Jinpeng Wang", "Tianci Luo", "Yaohua Zha", "Yan Feng", "Ruisheng Luo", "Bin Chen", "Tao Dai", "Long Chen", "Yaowei Wang", "Shu-Tao Xia"], "category": "cs.LG", "updated": "2025-04-30T02:43:03Z"}
{"id": "2504.21317v1", "title": "Redundancy Analysis and Mitigation for Machine Learning-Based Process\n  Monitoring of Additive Manufacturing", "link": "http://arxiv.org/abs/2504.21317v1", "summary": "The deployment of machine learning (ML)-based process monitoring systems has\nsignificantly advanced additive manufacturing (AM) by enabling real-time defect\ndetection, quality assessment, and process optimization. However, redundancy is\na critical yet often overlooked challenge in the deployment and operation of\nML-based AM process monitoring systems. Excessive redundancy leads to increased\nequipment costs, compromised model performance, and high computational\nrequirements, posing barriers to industrial adoption. However, existing\nresearch lacks a unified definition of redundancy and a systematic framework\nfor its evaluation and mitigation. This paper defines redundancy in ML-based AM\nprocess monitoring and categorizes it into sample-level, feature-level, and\nmodel-level redundancy. A comprehensive multi-level redundancy mitigation\n(MLRM) framework is proposed, incorporating advanced methods such as data\nregistration, downscaling, cross-modality knowledge transfer, and model pruning\nto systematically reduce redundancy while improving model performance. The\nframework is validated through an ML-based in-situ defect detection case study\nfor directed energy deposition (DED), demonstrating a 91% reduction in latency,\na 47% decrease in error rate, and a 99.4% reduction in storage requirements.\nAdditionally, the proposed approach lowers sensor costs and energy consumption,\nenabling a lightweight, cost-effective, and scalable monitoring system. By\ndefining redundancy and introducing a structured mitigation framework, this\nstudy establishes redundancy analysis and mitigation as a key enabler of\nefficient ML-based process monitoring in production environments.", "authors": ["Jiarui Xie", "Yaoyao Fiona Zhao"], "category": "cs.LG", "updated": "2025-04-30T05:04:53Z"}
{"id": "2504.21323v1", "title": "How to Backdoor the Knowledge Distillation", "link": "http://arxiv.org/abs/2504.21323v1", "summary": "Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.", "authors": ["Chen Wu", "Qian Ma", "Prasenjit Mitra", "Sencun Zhu"], "category": "cs.LG", "updated": "2025-04-30T05:19:23Z"}
{"id": "2504.21328v1", "title": "Multi-level datasets training method in Physics-Informed Neural Networks", "link": "http://arxiv.org/abs/2504.21328v1", "summary": "Physics-Informed Neural Networks have emerged as a promising methodology for\nsolving PDEs, gaining significant attention in computer science and various\nphysics-related fields. Despite being demonstrated the ability to incorporate\nthe physics of laws for versatile applications, PINNs still struggle with the\nchallenging problems which are stiff to be solved and/or have high-frequency\ncomponents in the solutions, resulting in accuracy and convergence issues. It\nmay not only increase computational costs, but also lead to accuracy loss or\nsolution divergence. In this study, an alternative approach is proposed to\nmitigate the above-mentioned problems. Inspired by the multi-grid method in CFD\ncommunity, the underlying idea of the current approach is to efficiently remove\ndifferent frequency errors via training with different levels of training\nsamples, resulting in a simpler way to improve the training accuracy without\nspending time in fine-tuning of neural network structures, loss weights as well\nas hyperparameters. To demonstrate the efficacy of current approach, we first\ninvestigate canonical 1D ODE with high-frequency component and 2D\nconvection-diffusion equation with V-cycle training strategy. Finally, the\ncurrent method is employed for the classical benchmark problem of steady\nLid-driven cavity flows at different Reynolds numbers, to investigate the\napplicability and efficacy for the problem involved multiple modes of high and\nlow frequency. By virtue of various training sequence modes, improvement\nthrough predictions lead to 30% to 60% accuracy improvement. We also\ninvestigate the synergies between current method and transfer learning\ntechniques for more challenging problems (i.e., higher Re). From the present\nresults, it also revealed that the current framework can produce good\npredictions even for the case of Re=5000, demonstrating the ability to solve\ncomplex high-frequency PDEs.", "authors": ["Yao-Hsuan Tsai", "Hsiao-Tung Juan", "Pao-Hsiung Chiu", "Chao-An Lin"], "category": "cs.LG", "updated": "2025-04-30T05:30:27Z"}
{"id": "2504.21411v1", "title": "Galvatron: An Automatic Distributed System for Efficient Foundation\n  Model Training", "link": "http://arxiv.org/abs/2504.21411v1", "summary": "Galvatron is a distributed system for efficiently training large-scale\nFoundation Models. It overcomes the complexities of selecting optimal\nparallelism strategies by automatically identifying the most efficient hybrid\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\nparallelism, along with recomputation. The system's architecture includes a\nprofiler for hardware and model analysis, a search engine for strategy\noptimization using decision trees and dynamic programming, and a runtime for\nexecuting these strategies efficiently. Benchmarking on various clusters\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\nThis open-source system offers user-friendly interfaces and comprehensive\ndocumentation, making complex distributed training accessible and efficient.\nThe source code of Galvatron is available at\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.", "authors": ["Xinyi Liu", "Yujie Wang", "Shenhan Zhu", "Fangcheng Fu", "Qingshuo Liu", "Guangming Lin", "Bin Cui"], "category": "cs.LG", "updated": "2025-04-30T08:11:45Z"}
{"id": "2504.21413v1", "title": "An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and\n  Applications to Streaming Differential Privacy", "link": "http://arxiv.org/abs/2504.21413v1", "summary": "Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation.", "authors": ["H. Brendan McMahan", "Krishna Pillutla"], "category": "cs.LG", "updated": "2025-04-30T08:14:09Z"}
{"id": "2504.21419v1", "title": "Kernel Density Machines", "link": "http://arxiv.org/abs/2504.21419v1", "summary": "We introduce kernel density machines (KDM), a novel density ratio estimator\nin a reproducing kernel Hilbert space setting. KDM applies to general\nprobability measures on countably generated measurable spaces without\nrestrictive assumptions on continuity, or the existence of a Lebesgue density.\nFor computational efficiency, we incorporate a low-rank approximation with\nprecisely controlled error that grants scalability to large-sample settings. We\nprovide rigorous theoretical guarantees, including asymptotic consistency, a\nfunctional central limit theorem, and finite-sample error bounds, establishing\na strong foundation for practical use. Empirical results based on simulated and\nreal data demonstrate the efficacy and precision of KDM.", "authors": ["Damir Filipovic", "Paul Schneider"], "category": "cs.LG", "updated": "2025-04-30T08:25:25Z"}
{"id": "2504.21475v1", "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based\n  Approach with Dataset Construction Guidelines", "link": "http://arxiv.org/abs/2504.21475v1", "summary": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.", "authors": ["Serry Sibaee", "Samar Ahmed", "Abdullah Al Harbi", "Omer Nacar", "Adel Ammar", "Yasser Habashi", "Wadii Boulila"], "category": "cs.LG", "updated": "2025-04-30T09:56:36Z"}
{"id": "2504.21491v1", "title": "ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic\n  Segmentation of Remote Sensing Imagery", "link": "http://arxiv.org/abs/2504.21491v1", "summary": "We propose a result-level category-specific fusion architecture called\nClassWise-CRF. This architecture employs a two-stage process: first, it selects\nexpert networks that perform well in specific categories from a pool of\ncandidate networks using a greedy algorithm; second, it integrates the\nsegmentation predictions of these selected networks by adaptively weighting\ntheir contributions based on their segmentation performance in each category.\nInspired by Conditional Random Field (CRF), the ClassWise-CRF architecture\ntreats the segmentation predictions from multiple networks as confidence vector\nfields. It leverages segmentation metrics (such as Intersection over Union)\nfrom the validation set as priors and employs an exponential weighting strategy\nto fuse the category-specific confidence scores predicted by each network. This\nfusion method dynamically adjusts the weights of each network for different\ncategories, achieving category-specific optimization. Building on this, the\narchitecture further optimizes the fused results using unary and pairwise\npotentials in CRF to ensure spatial consistency and boundary accuracy. To\nvalidate the effectiveness of ClassWise-CRF, we conducted experiments on two\nremote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced\nsemantic segmentation networks. The results show that the ClassWise-CRF\narchitecture significantly improves segmentation performance: on the LoveDA\ndataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on\nthe validation set and by 0.68% on the test set; on the Vaihingen dataset, the\nmIoU improved by 0.87% on the validation set and by 0.91% on the test set.\nThese results fully demonstrate the effectiveness and generality of the\nClassWise-CRF architecture in semantic segmentation of remote sensing images.\nThe full code is available at https://github.com/zhuqinfeng1999/ClassWise-CRF.", "authors": ["Qinfeng Zhu", "Yunxi Jiang", "Lei Fan"], "category": "cs.LG", "updated": "2025-04-30T10:19:21Z"}
{"id": "2504.21527v1", "title": "Low-rank computation of the posterior mean in Multi-Output Gaussian\n  Processes", "link": "http://arxiv.org/abs/2504.21527v1", "summary": "Gaussian processes (GP) are a versatile tool in machine learning and\ncomputational science. We here consider the case of multi-output Gaussian\nprocesses (MOGP) and present low-rank approaches for efficiently computing the\nposterior mean of a MOGP. Starting from low-rank spatio-temporal data we\nconsider a structured covariance function, assuming separability across space\nand time. This separability, in turn, gives a decomposition of the covariance\nmatrix into a Kronecker product of individual covariance matrices.\nIncorporating the typical noise term to the model then requires the solution of\na large-scale Stein equation for computing the posterior mean. For this, we\npropose efficient low-rank methods based on a combination of a LRPCG method\nwith the Sylvester equation solver KPIK adjusted for solving Stein equations.\nWe test the developed method on real world street network graphs by using graph\nfilters as covariance matrices. Moreover, we propose a degree-weighted average\ncovariance matrix, which can be employed under specific assumptions to achieve\nmore efficient convergence.", "authors": ["Sebastian Esche", "Martin Stoll"], "category": "cs.LG", "updated": "2025-04-30T11:19:58Z"}
{"id": "2504.21634v1", "title": "Quantitative Auditing of AI Fairness with Differentially Private\n  Synthetic Data", "link": "http://arxiv.org/abs/2504.21634v1", "summary": "Fairness auditing of AI systems can identify and quantify biases. However,\ntraditional auditing using real-world data raises security and privacy\nconcerns. It exposes auditors to security risks as they become custodians of\nsensitive information and targets for cyberattacks. Privacy risks arise even\nwithout direct breaches, as data analyses can inadvertently expose confidential\ninformation. To address these, we propose a framework that leverages\ndifferentially private synthetic data to audit the fairness of AI systems. By\napplying privacy-preserving mechanisms, it generates synthetic data that\nmirrors the statistical properties of the original dataset while ensuring\nprivacy. This method balances the goal of rigorous fairness auditing and the\nneed for strong privacy protections. Through experiments on real datasets like\nAdult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real\ndata. By analyzing the alignment and discrepancies between these metrics, we\nassess the capacity of synthetic data to preserve the fairness properties of\nreal data. Our results demonstrate the framework's ability to enable meaningful\nfairness evaluations while safeguarding sensitive information, proving its\napplicability across critical and sensitive domains.", "authors": ["Chih-Cheng Rex Yuan", "Bow-Yaw Wang"], "category": "cs.LG", "updated": "2025-04-30T13:36:27Z"}
{"id": "2504.21668v1", "title": "Traceback of Poisoning Attacks to Retrieval-Augmented Generation", "link": "http://arxiv.org/abs/2504.21668v1", "summary": "Large language models (LLMs) integrated with retrieval-augmented generation\n(RAG) systems improve accuracy by leveraging external knowledge sources.\nHowever, recent research has revealed RAG's susceptibility to poisoning\nattacks, where the attacker injects poisoned texts into the knowledge database,\nleading to attacker-desired responses. Existing defenses, which predominantly\nfocus on inference-time mitigation, have proven insufficient against\nsophisticated attacks. In this paper, we introduce RAGForensics, the first\ntraceback system for RAG, designed to identify poisoned texts within the\nknowledge database that are responsible for the attacks. RAGForensics operates\niteratively, first retrieving a subset of texts from the database and then\nutilizing a specially crafted prompt to guide an LLM in detecting potential\npoisoning texts. Empirical evaluations across multiple datasets demonstrate the\neffectiveness of RAGForensics against state-of-the-art poisoning attacks. This\nwork pioneers the traceback of poisoned texts in RAG systems, providing a\npractical and promising defense mechanism to enhance their security.", "authors": ["Baolei Zhang", "Haoran Xin", "Minghong Fang", "Zhuqing Liu", "Biao Yi", "Tong Li", "Zheli Liu"], "category": "cs.LG", "updated": "2025-04-30T14:10:02Z"}
{"id": "2504.21700v1", "title": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs", "link": "http://arxiv.org/abs/2504.21700v1", "summary": "Large Language Models are fundamental actors in the modern IT landscape\ndominated by AI solutions. However, security threats associated with them might\nprevent their reliable adoption in critical application scenarios such as\ngovernment organizations and medical institutions. For this reason, commercial\nLLMs typically undergo a sophisticated censoring mechanism to eliminate any\nharmful output they could possibly produce. In response to this, LLM\nJailbreaking is a significant threat to such protections, and many previous\napproaches have already demonstrated its effectiveness across diverse domains.\nExisting jailbreak proposals mostly adopt a generate-and-test strategy to craft\nmalicious input. To improve the comprehension of censoring mechanisms and\ndesign a targeted jailbreak attack, we propose an Explainable-AI solution that\ncomparatively analyzes the behavior of censored and uncensored models to derive\nunique exploitable alignment patterns. Then, we propose XBreaking, a novel\njailbreak attack that exploits these unique patterns to break the security\nconstraints of LLMs by targeted noise injection. Our thorough experimental\ncampaign returns important insights about the censoring mechanisms and\ndemonstrates the effectiveness and performance of our attack.", "authors": ["Marco Arazzi", "Vignesh Kumar Kembu", "Antonino Nocera", "Vinod P"], "category": "cs.LG", "updated": "2025-04-30T14:44:24Z"}
{"id": "2504.21730v1", "title": "Cert-SSB: Toward Certified Sample-Specific Backdoor Defense", "link": "http://arxiv.org/abs/2504.21730v1", "summary": "Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an\nattacker manipulates a small portion of the training data to implant hidden\nbackdoors into the model. The compromised model behaves normally on clean\nsamples but misclassifies backdoored samples into the attacker-specified target\nclass, posing a significant threat to real-world DNN applications. Currently,\nseveral empirical defense methods have been proposed to mitigate backdoor\nattacks, but they are often bypassed by more advanced backdoor techniques. In\ncontrast, certified defenses based on randomized smoothing have shown promise\nby adding random noise to training and testing samples to counteract backdoor\nattacks. In this paper, we reveal that existing randomized smoothing defenses\nimplicitly assume that all samples are equidistant from the decision boundary.\nHowever, it may not hold in practice, leading to suboptimal certification\nperformance. To address this issue, we propose a sample-specific certified\nbackdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic\ngradient ascent to optimize the noise magnitude for each sample, ensuring a\nsample-specific noise level that is then applied to multiple poisoned training\nsets to retrain several smoothed models. After that, Cert-SSB aggregates the\npredictions of multiple smoothed models to generate the final robust\nprediction. In particular, in this case, existing certification methods become\ninapplicable since the optimized noise varies across different samples. To\nconquer this challenge, we introduce a storage-update-based certification\nmethod, which dynamically adjusts each sample's certification region to improve\ncertification performance. We conduct extensive experiments on multiple\nbenchmark datasets, demonstrating the effectiveness of our proposed method. Our\ncode is available at https://github.com/NcepuQiaoTing/Cert-SSB.", "authors": ["Ting Qiao", "Yingjia Wang", "Xing Liu", "Sixing Wu", "Jianbing Li", "Yiming Li"], "category": "cs.LG", "updated": "2025-04-30T15:21:25Z"}
{"id": "2504.21795v2", "title": "Balancing Interpretability and Flexibility in Modeling Diagnostic\n  Trajectories with an Embedded Neural Hawkes Process Model", "link": "http://arxiv.org/abs/2504.21795v2", "summary": "The Hawkes process (HP) is commonly used to model event sequences with\nself-reinforcing dynamics, including electronic health records (EHRs).\nTraditional HPs capture self-reinforcement via parametric impact functions that\ncan be inspected to understand how each event modulates the intensity of\nothers. Neural network-based HPs offer greater flexibility, resulting in\nimproved fit and prediction performance, but at the cost of interpretability,\nwhich is often critical in healthcare. In this work, we aim to understand and\nimprove upon this tradeoff. We propose a novel HP formulation in which impact\nfunctions are modeled by defining a flexible impact kernel, instantiated as a\nneural network, in event embedding space, which allows us to model large-scale\nevent sequences with many event types. This approach is more flexible than\ntraditional HPs yet more interpretable than other neural network approaches,\nand allows us to explicitly trade flexibility for interpretability by adding\ntransformer encoder layers to further contextualize the event embeddings.\nResults show that our method accurately recovers impact functions in\nsimulations, achieves competitive performance on MIMIC-IV procedure dataset,\nand gains clinically meaningful interpretation on XX-EHR with children\ndiagnosis dataset even without transformer layers. This suggests that our\nflexible impact kernel is often sufficient to capture self-reinforcing dynamics\nin EHRs and other data effectively, implying that interpretability can be\nmaintained without loss of performance.", "authors": ["Yuankang Zhao", "Matthew Engelhard"], "category": "cs.LG", "updated": "2025-05-03T19:17:50Z"}
{"id": "2504.21844v1", "title": "Scalable Multi-Task Learning for Particle Collision Event Reconstruction\n  with Heterogeneous Graph Neural Networks", "link": "http://arxiv.org/abs/2504.21844v1", "summary": "The growing luminosity frontier at the Large Hadron Collider is challenging\nthe reconstruction and analysis of particle collision events. Increased\nparticle multiplicities are straining latency and storage requirements at the\ndata acquisition stage, while new complications are emerging, including higher\nbackground levels and more frequent particle vertex misassociations. This in\nturn necessitates the development of more holistic and scalable reconstruction\nmethods that take advantage of recent advances in machine learning. We propose\na novel Heterogeneous Graph Neural Network (HGNN) architecture featuring unique\nrepresentations for diverse particle collision relationships and integrated\ngraph pruning layers for scalability. Trained with a multi-task paradigm in an\nenvironment mimicking the LHCb experiment, this HGNN significantly improves\nbeauty hadron reconstruction performance. Notably, it concurrently performs\nparticle vertex association and graph pruning within a single framework. We\nquantify reconstruction and pruning performance, demonstrate enhanced inference\ntime scaling with event complexity, and mitigate potential performance loss\nusing a weighted message passing scheme.", "authors": ["William Sutcliffe", "Marta Calvi", "Simone Capelli", "Jonas Eschle", "Julián García Pardiñas", "Abhijit Mathad", "Azusa Uzuki", "Nicola Serra"], "category": "cs.LG", "updated": "2025-04-30T17:53:08Z"}
{"id": "2505.00049v1", "title": "Humanizing LLMs: A Survey of Psychological Measurements with Tools,\n  Datasets, and Human-Agent Applications", "link": "http://arxiv.org/abs/2505.00049v1", "summary": "As large language models (LLMs) are increasingly used in human-centered\ntasks, assessing their psychological traits is crucial for understanding their\nsocial impact and ensuring trustworthy AI alignment. While existing reviews\nhave covered some aspects of related research, several important areas have not\nbeen systematically discussed, including detailed discussions of diverse\npsychological tests, LLM-specific psychological datasets, and the applications\nof LLMs with psychological traits. To address this gap, we systematically\nreview six key dimensions of applying psychological theories to LLMs: (1)\nassessment tools; (2) LLM-specific datasets; (3) evaluation metrics\n(consistency and stability); (4) empirical findings; (5) personality simulation\nmethods; and (6) LLM-based behavior simulation. Our analysis highlights both\nthe strengths and limitations of current methods. While some LLMs exhibit\nreproducible personality patterns under specific prompting schemes, significant\nvariability remains across tasks and settings. Recognizing methodological\nchallenges such as mismatches between psychological tools and LLMs'\ncapabilities, as well as inconsistencies in evaluation practices, this study\naims to propose future directions for developing more interpretable, robust,\nand generalizable psychological assessment frameworks for LLMs.", "authors": ["Wenhan Dong", "Yuemeng Zhao", "Zhen Sun", "Yule Liu", "Zifan Peng", "Jingyi Zheng", "Zongmin Zhang", "Ziyi Zhang", "Jun Wu", "Ruiming Wang", "Shengmin Xu", "Xinyi Huang", "Xinlei He"], "category": "cs.LG", "updated": "2025-04-30T06:09:40Z"}
{"id": "2505.00056v2", "title": "Clustering Internet Memes Through Template Matching and\n  Multi-Dimensional Similarity", "link": "http://arxiv.org/abs/2505.00056v2", "summary": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch.", "authors": ["Tygo Bloem", "Filip Ilievski"], "category": "cs.LG", "updated": "2025-05-02T07:34:59Z"}
{"id": "2505.00060v1", "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business\n  Intelligence Using Exaone 3.5", "link": "http://arxiv.org/abs/2505.00060v1", "summary": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.", "authors": ["Jeho Choi"], "category": "cs.LG", "updated": "2025-04-30T14:42:18Z"}
{"id": "2505.00110v1", "title": "On the expressivity of deep Heaviside networks", "link": "http://arxiv.org/abs/2505.00110v1", "summary": "We show that deep Heaviside networks (DHNs) have limited expressiveness but\nthat this can be overcome by including either skip connections or neurons with\nlinear activation. We provide lower and upper bounds for the\nVapnik-Chervonenkis (VC) dimensions and approximation rates of these network\nclasses. As an application, we derive statistical convergence rates for DHN\nfits in the nonparametric regression model.", "authors": ["Insung Kong", "Juntong Chen", "Sophie Langer", "Johannes Schmidt-Hieber"], "category": "cs.LG", "updated": "2025-04-30T18:25:05Z"}
{"id": "2505.00136v1", "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks", "link": "http://arxiv.org/abs/2505.00136v1", "summary": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications.", "authors": ["Maksim Helmann", "Alexander Strack", "Dirk Pflüger"], "category": "cs.LG", "updated": "2025-04-30T19:08:51Z"}
{"id": "2505.00137v1", "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM\n  for Fraud Detection", "link": "http://arxiv.org/abs/2505.00137v1", "summary": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis", "authors": ["Rushikesh Ubale", "Sujan K. K.", "Sangram Deshpande", "Gregory T. Byrd"], "category": "cs.LG", "updated": "2025-04-30T19:09:12Z"}
{"id": "2505.00195v1", "title": "Algorithmic Collective Action with Two Collectives", "link": "http://arxiv.org/abs/2505.00195v1", "summary": "Given that data-dependent algorithmic systems have become impactful in more\ndomains of life, the need for individuals to promote their own interests and\nhold algorithms accountable has grown. To have meaningful influence,\nindividuals must band together to engage in collective action. Groups that\nengage in such algorithmic collective action are likely to vary in size,\nmembership characteristics, and crucially, objectives. In this work, we\nintroduce a first of a kind framework for studying collective action with two\nor more collectives that strategically behave to manipulate data-driven\nsystems. With more than one collective acting on a system, unexpected\ninteractions may occur. We use this framework to conduct experiments with\nlanguage model-based classifiers and recommender systems where two collectives\neach attempt to achieve their own individual objectives. We examine how\ndiffering objectives, strategies, sizes, and homogeneity can impact a\ncollective's efficacy. We find that the unintentional interactions between\ncollectives can be quite significant; a collective acting in isolation may be\nable to achieve their objective (e.g., improve classification outcomes for\nthemselves or promote a particular item), but when a second collective acts\nsimultaneously, the efficacy of the first group drops by as much as $75\\%$. We\nfind that, in the recommender system context, neither fully heterogeneous nor\nfully homogeneous collectives stand out as most efficacious and that\nheterogeneity's impact is secondary compared to collective size. Our results\nsignal the need for more transparency in both the underlying algorithmic models\nand the different behaviors individuals or collectives may take on these\nsystems. This approach also allows collectives to hold algorithmic system\ndevelopers accountable and provides a framework for people to actively use\ntheir own data to promote their own interests.", "authors": ["Aditya Karan", "Nicholas Vincent", "Karrie Karahalios", "Hari Sundaram"], "category": "cs.LG", "updated": "2025-04-30T21:39:06Z"}
{"id": "2505.00210v1", "title": "Generative Machine Learning in Adaptive Control of Dynamic Manufacturing\n  Processes: A Review", "link": "http://arxiv.org/abs/2505.00210v1", "summary": "Dynamic manufacturing processes exhibit complex characteristics defined by\ntime-varying parameters, nonlinear behaviors, and uncertainties. These\ncharacteristics require sophisticated in-situ monitoring techniques utilizing\nmultimodal sensor data and adaptive control systems that can respond to\nreal-time feedback while maintaining product quality. Recently, generative\nmachine learning (ML) has emerged as a powerful tool for modeling complex\ndistributions and generating synthetic data while handling these manufacturing\nuncertainties. However, adopting these generative technologies in dynamic\nmanufacturing systems lacks a functional control-oriented perspective to\ntranslate their probabilistic understanding into actionable process controls\nwhile respecting constraints. This review presents a functional classification\nof Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated\napproaches, offering a perspective for understanding existing ML-enhanced\ncontrol systems and incorporating generative ML. The analysis of generative ML\narchitectures within this framework demonstrates control-relevant properties\nand potential to extend current ML-enhanced approaches where conventional\nmethods prove insufficient. We show generative ML's potential for manufacturing\ncontrol through decision-making applications, process guidance, simulation, and\ndigital twins, while identifying critical research gaps: separation between\ngeneration and control functions, insufficient physical understanding of\nmanufacturing phenomena, and challenges adapting models from other domains. To\naddress these challenges, we propose future research directions aimed at\ndeveloping integrated frameworks that combine generative ML and control\ntechnologies to address the dynamic complexities of modern manufacturing\nsystems.", "authors": ["Suk Ki Lee", "Hyunwoong Ko"], "category": "cs.LG", "updated": "2025-04-30T22:48:04Z"}
{"id": "2505.00216v1", "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box\n  Encoders", "link": "http://arxiv.org/abs/2505.00216v1", "summary": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored.", "authors": ["Xuwei Yang", "Fatemeh Tavakoli", "David B. Emerson", "Anastasis Kratsios"], "category": "cs.LG", "updated": "2025-04-30T23:19:37Z"}
{"id": "2505.03787v1", "title": "ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual\n  Explanations for ECG Arrhythmia Classification", "link": "http://arxiv.org/abs/2505.03787v1", "summary": "Cardiac arrhythmias are a leading cause of life-threatening cardiac events,\nhighlighting the urgent need for accurate and timely detection.\nElectrocardiography (ECG) remains the clinical gold standard for arrhythmia\ndiagnosis; however, manual interpretation is time-consuming, dependent on\nclinical expertise, and prone to human error. Although deep learning has\nadvanced automated ECG analysis, many existing models abstract away the\nsignal's intrinsic temporal and morphological features, lack interpretability,\nand are computationally intensive-hindering their deployment on\nresource-constrained platforms. In this work, we propose two novel lightweight\n1D convolutional neural networks, ArrhythmiNet V1 and V2, optimized for\nefficient, real-time arrhythmia classification on edge devices. Inspired by\nMobileNet's depthwise separable convolutional design, these models maintain\nmemory footprints of just 302.18 KB and 157.76 KB, respectively, while\nachieving classification accuracies of 0.99 (V1) and 0.98 (V2) on the MIT-BIH\nArrhythmia Dataset across five classes: Normal Sinus Rhythm, Left Bundle Branch\nBlock, Right Bundle Branch Block, Atrial Premature Contraction, and Premature\nVentricular Contraction. In order to ensure clinical transparency and\nrelevance, we integrate Shapley Additive Explanations and Gradient-weighted\nClass Activation Mapping, enabling both local and global interpretability.\nThese techniques highlight physiologically meaningful patterns such as the QRS\ncomplex and T-wave that contribute to the model's predictions. We also discuss\nperformance-efficiency trade-offs and address current limitations related to\ndataset diversity and generalizability. Overall, our findings demonstrate the\nfeasibility of combining interpretability, predictive accuracy, and\ncomputational efficiency in practical, wearable, and embedded ECG monitoring\nsystems.", "authors": ["Zuraiz Baig", "Sidra Nasir", "Rizwan Ahmed Khan", "Muhammad Zeeshan Ul Haque"], "category": "cs.LG", "updated": "2025-04-30T18:22:45Z"}
{"id": "2505.00222v1", "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders", "link": "http://arxiv.org/abs/2505.00222v1", "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.", "authors": ["Peter Yichen Chen", "Pingchuan Ma", "Niklas Hagemann", "John Romanishin", "Wei Wang", "Daniela Rus", "Wojciech Matusik"], "category": "cs.LG", "updated": "2025-04-30T23:55:44Z"}
{"id": "2505.00229v1", "title": "Inference for max-linear Bayesian networks with noise", "link": "http://arxiv.org/abs/2505.00229v1", "summary": "Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal\ninference in extreme-value settings; we consider MLBNs with noise parameters\nwith a given topology in terms of the max-plus algebra by taking its logarithm.\nThen, we show that an estimator of a parameter for each edge in a directed\nacyclic graph (DAG) is distributed normally. We end this paper with\ncomputational experiments with the expectation and maximization (EM) algorithm\nand quadratic optimization.", "authors": ["Mark Adams", "Kamillo Ferry", "Ruriko Yoshida"], "category": "cs.LG", "updated": "2025-05-01T00:31:37Z"}
{"id": "2504.21707v1", "title": "Recursive KL Divergence Optimization: A Dynamic Framework for\n  Representation Learning", "link": "http://arxiv.org/abs/2504.21707v1", "summary": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.", "authors": ["Anthony D Martin"], "category": "cs.LG", "updated": "2025-04-30T14:51:27Z"}
{"id": "2504.21787v1", "title": "Estimation of discrete distributions in relative entropy, and the\n  deviations of the missing mass", "link": "http://arxiv.org/abs/2504.21787v1", "summary": "We study the problem of estimating a distribution over a finite alphabet from\nan i.i.d. sample, with accuracy measured in relative entropy (Kullback-Leibler\ndivergence). While optimal expected risk bounds are known, high-probability\nguarantees remain less well-understood. First, we analyze the classical Laplace\n(add-$1$) estimator, obtaining matching upper and lower bounds on its\nperformance and showing its optimality among confidence-independent estimators.\nWe then characterize the minimax-optimal high-probability risk achievable by\nany estimator, which is attained via a simple confidence-dependent smoothing\ntechnique. Interestingly, the optimal non-asymptotic risk contains an\nadditional logarithmic factor over the ideal asymptotic risk. Next, motivated\nby scenarios where the alphabet exceeds the sample size, we investigate methods\nthat adapt to the sparsity of the distribution at hand. We introduce an\nestimator using data-dependent smoothing, for which we establish a\nhigh-probability risk bound depending on two effective sparsity parameters. As\npart of the analysis, we also derive a sharp high-probability upper bound on\nthe missing mass.", "authors": ["Jaouad Mourtada"], "category": "cs.LG", "updated": "2025-04-30T16:47:10Z"}
{"id": "2504.21252v1", "title": "Talk Before You Retrieve: Agent-Led Discussions for Better RAG in\n  Medical QA", "link": "http://arxiv.org/abs/2504.21252v1", "summary": "Medical question answering (QA) is a reasoning-intensive task that remains\nchallenging for large language models (LLMs) due to hallucinations and outdated\ndomain knowledge. Retrieval-Augmented Generation (RAG) provides a promising\npost-training solution by leveraging external knowledge. However, existing\nmedical RAG systems suffer from two key limitations: (1) a lack of modeling for\nhuman-like reasoning behaviors during information retrieval, and (2) reliance\non suboptimal medical corpora, which often results in the retrieval of\nirrelevant or noisy snippets. To overcome these challenges, we propose\nDiscuss-RAG, a plug-and-play module designed to enhance the medical QA RAG\nsystem through collaborative agent-based reasoning. Our method introduces a\nsummarizer agent that orchestrates a team of medical experts to emulate\nmulti-turn brainstorming, thereby improving the relevance of retrieved content.\nAdditionally, a decision-making agent evaluates the retrieved snippets before\ntheir final integration. Experimental results on four benchmark medical QA\ndatasets show that Discuss-RAG consistently outperforms MedRAG, especially\nsignificantly improving answer accuracy by up to 16.67% on BioASQ and 12.20% on\nPubMedQA. The code is available at: https://github.com/LLM-VLM-GSL/Discuss-RAG.", "authors": ["Xuanzhao Dong", "Wenhui Zhu", "Hao Wang", "Xiwen Chen", "Peijie Qiu", "Rui Yin", "Yi Su", "Yalin Wang"], "category": "cs.CL", "updated": "2025-04-30T01:37:44Z"}
{"id": "2504.21299v1", "title": "BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language\n  Models", "link": "http://arxiv.org/abs/2504.21299v1", "summary": "Identifying bias in LLM-generated content is a crucial prerequisite for\nensuring fairness in LLMs. Existing methods, such as fairness classifiers and\nLLM-based judges, face limitations related to difficulties in understanding\nunderlying intentions and the lack of criteria for fairness judgment. In this\npaper, we introduce BiasGuard, a novel bias detection tool that explicitly\nanalyzes inputs and reasons through fairness specifications to provide accurate\njudgments. BiasGuard is implemented through a two-stage approach: the first\nstage initializes the model to explicitly reason based on fairness\nspecifications, while the second stage leverages reinforcement learning to\nenhance its reasoning and judgment capabilities. Our experiments, conducted\nacross five datasets, demonstrate that BiasGuard outperforms existing tools,\nimproving accuracy and reducing over-fairness misjudgments. We also highlight\nthe importance of reasoning-enhanced decision-making and provide evidence for\nthe effectiveness of our two-stage optimization pipeline.", "authors": ["Zhiting Fan", "Ruizhe Chen", "Zuozhu Liu"], "category": "cs.CL", "updated": "2025-04-30T04:13:03Z"}
{"id": "2504.21303v1", "title": "Confidence in Large Language Model Evaluation: A Bayesian Approach to\n  Limited-Sample Challenges", "link": "http://arxiv.org/abs/2504.21303v1", "summary": "Large language models (LLMs) exhibit probabilistic output characteristics,\nyet conventional evaluation frameworks rely on deterministic scalar metrics.\nThis study introduces a Bayesian approach for LLM capability assessment that\nintegrates prior knowledge through probabilistic inference, addressing\nlimitations under limited-sample regimes. By treating model capabilities as\nlatent variables and leveraging a curated query set to induce discriminative\nresponses, we formalize model ranking as a Bayesian hypothesis testing problem\nover mutually exclusive capability intervals. Experimental evaluations with\nGPT-series models demonstrate that the proposed method achieves superior\ndiscrimination compared to conventional evaluation methods. Results indicate\nthat even with reduced sample sizes, the approach maintains statistical\nrobustness while providing actionable insights, such as probabilistic\nstatements about a model's likelihood of surpassing specific baselines. This\nwork advances LLM evaluation methodologies by bridging Bayesian inference with\npractical constraints in real-world deployment scenarios.", "authors": ["Xiao Xiao", "Yu Su", "Sijing Zhang", "Zhang Chen", "Yadong Chen", "Tian Liu"], "category": "cs.CL", "updated": "2025-04-30T04:24:50Z"}
{"id": "2504.21330v1", "title": "Does the Prompt-based Large Language Model Recognize Students'\n  Demographics and Introduce Bias in Essay Scoring?", "link": "http://arxiv.org/abs/2504.21330v1", "summary": "Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES)\ndue to their ability to capture semantic meaning. Traditional fine-tuning\napproaches required technical expertise, limiting accessibility for educators\nwith limited technical backgrounds. However, prompt-based tools like ChatGPT\nhave made AES more accessible, enabling educators to obtain machine-generated\nscores using natural-language prompts (i.e., the prompt-based paradigm).\nDespite advancements, prior studies have shown bias in fine-tuned LLMs,\nparticularly against disadvantaged groups. It remains unclear whether such\nbiases persist or are amplified in the prompt-based paradigm with cutting-edge\ntools. Since such biases are believed to stem from the demographic information\nembedded in pre-trained models (i.e., the ability of LLMs' text embeddings to\npredict demographic attributes), this study explores the relationship between\nthe model's predictive power of students' demographic attributes based on their\nwritten works and its predictive bias in the scoring task in the prompt-based\nparadigm. Using a publicly available dataset of over 25,000 students'\nargumentative essays, we designed prompts to elicit demographic inferences\n(i.e., gender, first-language background) from GPT-4o and assessed fairness in\nautomated scoring. Then we conducted multivariate regression analysis to\nexplore the impact of the model's ability to predict demographics on its\nscoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat\ninfer students' demographics, particularly their first-language backgrounds,\nfrom their essays; (ii) scoring biases are more pronounced when the LLM\ncorrectly predicts students' first-language background than when it does not;\nand (iii) scoring error for non-native English speakers increases when the LLM\ncorrectly identifies them as non-native.", "authors": ["Kaixun Yang", "Mladen Raković", "Dragan Gašević", "Guanliang Chen"], "category": "cs.CL", "updated": "2025-04-30T05:36:28Z"}
{"id": "2504.21421v1", "title": "The Distribution of Dependency Distance and Hierarchical Distance in\n  Contemporary Written Japanese and Its Influencing Factors", "link": "http://arxiv.org/abs/2504.21421v1", "summary": "To explore the relationship between dependency distance (DD) and hierarchical\ndistance (HD) in Japanese, we compared the probability distributions of DD and\nHD with and without sentence length fixed, and analyzed the changes in mean\ndependency distance (MDD) and mean hierarchical distance (MHD) as sentence\nlength increases, along with their correlation coefficient based on the\nBalanced Corpus of Contemporary Written Japanese. It was found that the valency\nof the predicates is the underlying factor behind the trade-off relation\nbetween MDD and MHD in Japanese. Native speakers of Japanese regulate the\nlinear complexity and hierarchical complexity through the valency of the\npredicates, and the relative sizes of MDD and MHD depend on whether the\nthreshold of valency has been reached. Apart from the cognitive load, the\nvalency of the predicates also affects the probability distributions of DD and\nHD. The effect of the valency of the predicates on the distribution of HD is\ngreater than on that of DD, which leads to differences in their probability\ndistributions and causes the mean of MDD to be lower than that of MHD.", "authors": ["Linxuan Wang", "Shuiyuan Yu"], "category": "cs.CL", "updated": "2025-04-30T08:27:33Z"}
{"id": "2504.21463v2", "title": "RWKV-X: A Linear Complexity Hybrid Language Model", "link": "http://arxiv.org/abs/2504.21463v2", "summary": "In this paper, we introduce RWKV-X, a novel hybrid architecture that combines\nthe efficiency of RWKV for short-range modeling with a sparse attention\nmechanism designed to capture long-range context. Unlike previous hybrid\napproaches that rely on full attention layers and retain quadratic complexity,\nRWKV-X achieves linear-time complexity in training and constant-time complexity\nin inference decoding. We demonstrate that RWKV-X, when continually pretrained\non 64K-token sequences, achieves near-perfect accuracy on the 64K passkey\nretrieval benchmark. It consistently outperforms prior RWKV-7 models on\nlong-context benchmarks, while maintaining strong performance on short-context\ntasks. These results highlight RWKV-X as a scalable and efficient backbone for\ngeneral-purpose language modeling, capable of decoding sequences up to 1\nmillion tokens with stable speed and memory usage. To facilitate further\nresearch and analysis, we have made the checkpoints and the associated code\npublicly accessible at: https://github.com/howard-hou/RWKV-X.", "authors": ["Haowen Hou", "Zhiyi Huang", "Kaifeng Tan", "Rongchang Lu", "Fei Richard Yu"], "category": "cs.CL", "updated": "2025-05-09T03:59:15Z"}
{"id": "2504.21540v1", "title": "Improving Informally Romanized Language Identification", "link": "http://arxiv.org/abs/2504.21540v1", "summary": "The Latin script is often used to informally write languages with non-Latin\nnative scripts. In many cases (e.g., most languages in India), there is no\nconventional spelling of words in the Latin script, hence there will be high\nspelling variability in written text. Such romanization renders languages that\nare normally easily distinguished based on script highly confusable, such as\nHindi and Urdu. In this work, we increase language identification (LID)\naccuracy for romanized text by improving the methods used to synthesize\ntraining sets. We find that training on synthetic samples which incorporate\nnatural spelling variation yields higher LID system accuracy than including\navailable naturally occurring examples in the training set, or even training\nhigher capacity models. We demonstrate new state-of-the-art LID performance on\nromanized text from 20 Indic languages in the Bhasha-Abhijnaanam evaluation set\n(Madhani et al., 2023a), improving test F1 from the reported 74.7% (using a\npretrained neural model) to 85.4% using a linear classifier trained solely on\nsynthetic data and 88.2% when also training on available harvested text.", "authors": ["Adrian Benton", "Alexander Gutkin", "Christo Kirov", "Brian Roark"], "category": "cs.CL", "updated": "2025-04-30T11:36:28Z"}
{"id": "2504.21547v1", "title": "TartuNLP at SemEval-2025 Task 5: Subject Tagging as Two-Stage\n  Information Retrieval", "link": "http://arxiv.org/abs/2504.21547v1", "summary": "We present our submission to the Task 5 of SemEval-2025 that aims to aid\nlibrarians in assigning subject tags to the library records by producing a list\nof likely relevant tags for a given document. We frame the task as an\ninformation retrieval problem, where the document content is used to retrieve\nsubject tags from a large subject taxonomy. We leverage two types of encoder\nmodels to build a two-stage information retrieval system -- a bi-encoder for\ncoarse-grained candidate extraction at the first stage, and a cross-encoder for\nfine-grained re-ranking at the second stage. This approach proved effective,\ndemonstrating significant improvements in recall compared to single-stage\nmethods and showing competitive results according to qualitative evaluation.", "authors": ["Aleksei Dorkin", "Kairit Sirts"], "category": "cs.CL", "updated": "2025-04-30T11:44:08Z"}
{"id": "2504.21553v1", "title": "Precision Where It Matters: A Novel Spike Aware Mixed-Precision\n  Quantization Strategy for LLaMA-based Language Models", "link": "http://arxiv.org/abs/2504.21553v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, their size presents\nsignificant challenges for deployment and inference. This paper investigates\nthe quantization of LLMs, focusing on the LLaMA architecture and its\nderivatives. We challenge existing assumptions about activation outliers in\nLLMs and propose a novel mixed-precision quantization approach tailored for\nLLaMA-like models. Our method leverages the observation that activation spikes\nin LLaMA architectures are predominantly concentrated in specific projection\nlayers. By applying higher precision (FP16 or FP8) to these layers while\nquantizing the rest of the model to lower bit-widths, we achieve superior\nperformance compared to existing quantization techniques. Experimental results\non LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in\nperplexity and zero-shot accuracy, particularly for 8-bit per-tensor\nquantization. Our approach outperforms general-purpose methods designed to\nhandle outliers across all architecture types, highlighting the benefits of\narchitecture-specific quantization strategies. This research contributes to the\nongoing efforts to make LLMs more efficient and deployable, potentially\nenabling their use in resource-constrained environments. Our findings emphasize\nthe importance of considering model-specific characteristics in developing\neffective quantization pipelines for state-of-the-art language models by\nidentifying and targeting a small number of projections that concentrate\nactivation spikes.", "authors": ["Lucas Maisonnave", "Cyril Moineau", "Olivier Bichler", "Fabrice Rastello"], "category": "cs.CL", "updated": "2025-04-30T11:52:18Z"}
{"id": "2504.21625v1", "title": "Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn\n  Instruction-Following Ability", "link": "http://arxiv.org/abs/2504.21625v1", "summary": "The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nWhile existing instruction-following benchmarks are either single-turn or\nintroduce new requirements in each turn without allowing self-correction,\nMeeseeks simulates realistic human-LLM interactions through an iterative\nfeedback process. This design enables models to self-correct based on specific\nrequirement failures, better reflecting real-world user-end usage patterns. The\nbenchmark implements a comprehensive evaluation system with 38 capability tags\norganized across three dimensions: Intent Recognition, Granular Content\nValidation, and Output Structure Validation. Through rigorous evaluation across\nLLMs, Meeseeks provides valuable insights into LLMs' instruction-following\ncapabilities in practical applications.", "authors": ["Jiaming Wang"], "category": "cs.CL", "updated": "2025-04-30T13:28:19Z"}
{"id": "2504.21677v1", "title": "20min-XD: A Comparable Corpus of Swiss News Articles", "link": "http://arxiv.org/abs/2504.21677v1", "summary": "We present 20min-XD (20 Minuten cross-lingual document-level), a\nFrench-German, document-level comparable corpus of news articles, sourced from\nthe Swiss online news outlet 20 Minuten/20 minutes. Our dataset comprises\naround 15,000 article pairs spanning 2015 to 2024, automatically aligned based\non semantic similarity. We detail the data collection process and alignment\nmethodology. Furthermore, we provide a qualitative and quantitative analysis of\nthe corpus. The resulting dataset exhibits a broad spectrum of cross-lingual\nsimilarity, ranging from near-translations to loosely related articles, making\nit valuable for various NLP applications and broad linguistically motivated\nstudies. We publicly release the dataset in document- and sentence-aligned\nversions and code for the described experiments.", "authors": ["Michelle Wastl", "Jannis Vamvas", "Selena Calleri", "Rico Sennrich"], "category": "cs.CL", "updated": "2025-04-30T14:16:08Z"}
{"id": "2504.21681v1", "title": "Investigating the Effect of Parallel Data in the Cross-Lingual Transfer\n  for Vision-Language Encoders", "link": "http://arxiv.org/abs/2504.21681v1", "summary": "Most pre-trained Vision-Language (VL) models and training data for the\ndownstream tasks are only available in English. Therefore, multilingual VL\ntasks are solved using cross-lingual transfer: fine-tune a multilingual\npre-trained model or transfer the text encoder using parallel data. We study\nthe alternative approach: transferring an already trained encoder using\nparallel data. We investigate the effect of parallel data: domain and the\nnumber of languages, which were out of focus in previous work. Our results show\nthat even machine-translated task data are the best on average, caption-like\nauthentic parallel data outperformed it in some languages. Further, we show\nthat most languages benefit from multilingual training.", "authors": ["Andrei-Alexandru Manea", "Jindřich Libovický"], "category": "cs.CL", "updated": "2025-04-30T14:19:15Z"}
{"id": "2504.21742v1", "title": "Investigating Literary Motifs in Ancient and Medieval Novels with Large\n  Language Models", "link": "http://arxiv.org/abs/2504.21742v1", "summary": "The Greek fictional narratives often termed love novels or romances, ranging\nfrom the first century CE to the middle of the 15th century, have long been\nconsidered as similar in many ways, not least in the use of particular literary\nmotifs. By applying the use of fine-tuned large language models, this study\naims to investigate which motifs exactly that the texts in this corpus have in\ncommon, and in which ways they differ from each other. The results show that\nwhile some motifs persist throughout the corpus, others fluctuate in frequency,\nindicating certain trends or external influences. Conclusively, the method\nproves to adequately extract literary motifs according to a set definition,\nproviding data for both quantitative and qualitative analyses.", "authors": ["Emelie Hallenberg"], "category": "cs.CL", "updated": "2025-04-30T15:39:06Z"}
{"id": "2504.21747v1", "title": "Improving Retrieval-Augmented Neural Machine Translation with\n  Monolingual Data", "link": "http://arxiv.org/abs/2504.21747v1", "summary": "Conventional retrieval-augmented neural machine translation (RANMT) systems\nleverage bilingual corpora, e.g., translation memories (TMs). Yet, in many\nsettings, in-domain monolingual target-side corpora are often available. This\nwork explores ways to take advantage of such resources by retrieving relevant\nsegments directly in the target language, based on a source-side query. For\nthis, we design improved cross-lingual retrieval systems, trained with both\nsentence level and word-level matching objectives. In our experiments with two\nRANMT architectures, we first demonstrate the benefits of such cross-lingual\nobjectives in a controlled setting, obtaining translation performances that\nsurpass standard TM-based models. We then showcase our method on a real-world\nset-up, where the target monolingual resources far exceed the amount of\nparallel data and observe large improvements of our new techniques, which\noutperform both the baseline setting, and general-purpose cross-lingual\nretrievers.", "authors": ["Maxime Bouthors", "Josep Crego", "François Yvon"], "category": "cs.CL", "updated": "2025-04-30T15:41:03Z"}
{"id": "2505.00047v1", "title": "Base Models Beat Aligned Models at Randomness and Creativity", "link": "http://arxiv.org/abs/2505.00047v1", "summary": "Alignment has quickly become a default ingredient in LLM development, with\ntechniques such as reinforcement learning from human feedback making models act\nsafely, follow instructions, and perform ever-better on complex tasks. While\nthese techniques are certainly useful, we propose that they should not be\nuniversally applied and demonstrate a range of tasks on which base language\nmodels consistently outperform their popular aligned forms. Particularly, we\nstudy tasks that require unpredictable outputs, such as random number\ngeneration, mixed strategy games (rock-paper-scissors and hide-and-seek), and\ncreative writing. In each case, aligned models tend towards narrow behaviors\nthat result in distinct disadvantages, for instance, preferring to generate \"7\"\nover other uniformly random numbers, becoming almost fully predictable in some\ngame states, or prioritizing pleasant writing over creative originality. Across\nmodels tested, better performance on common benchmarks tends to correlate with\nworse performance on our tasks, suggesting an effective trade-off in the\nrequired capabilities.", "authors": ["Peter West", "Christopher Potts"], "category": "cs.CL", "updated": "2025-04-30T03:41:55Z"}
{"id": "2505.00057v1", "title": "A Report on the llms evaluating the high school questions", "link": "http://arxiv.org/abs/2505.00057v1", "summary": "This report aims to evaluate the performance of large language models (LLMs)\nin solving high school science questions and to explore their potential\napplications in the educational field. With the rapid development of LLMs in\nthe field of natural language processing, their application in education has\nattracted widespread attention. This study selected mathematics exam questions\nfrom the college entrance examinations (2019-2023) as evaluation data and\nutilized at least eight LLM APIs to provide answers. A comprehensive assessment\nwas conducted based on metrics such as accuracy, response time, logical\nreasoning, and creativity. Through an in-depth analysis of the evaluation\nresults, this report reveals the strengths and weaknesses of LLMs in handling\nhigh school science questions and discusses their implications for educational\npractice. The findings indicate that although LLMs perform excellently in\ncertain aspects, there is still room for improvement in logical reasoning and\ncreative problem-solving. This report provides an empirical foundation for\nfurther research and application of LLMs in the educational field and offers\nsuggestions for improvement.", "authors": ["Zhu Jiawei", "Chen Wei"], "category": "cs.CL", "updated": "2025-04-30T11:54:23Z"}
{"id": "2505.00147v1", "title": "AdaptMI: Adaptive Skill-based In-context Math Instruction for Small\n  Language Models", "link": "http://arxiv.org/abs/2505.00147v1", "summary": "In-context learning (ICL) allows a language model to improve its\nproblem-solving capability when provided with suitable information in context.\nSince the choice of in-context information can be determined based on the\nproblem itself, in-context learning is analogous to human learning from\nteachers in a classroom. Recent works (Didolkar et al., 2024a; 2024b) show that\nICL performance can be improved by leveraging a frontier large language model's\n(LLM) ability to predict required skills to solve a problem, popularly referred\nto as an LLM's metacognition, and using the recommended skills to construct\nnecessary in-context examples. While this skill-based strategy boosts ICL\nperformance in larger models, its gains on small language models (SLMs) have\nbeen minimal, highlighting a performance gap in ICL capabilities. We\ninvestigate this gap and show that skill-based prompting can hurt SLM\nperformance on easy questions by introducing unnecessary information, akin to\ncognitive overload. To address this, we introduce AdaptMI, an adaptive approach\nto selecting skill-based in-context Math Instructions for SLMs. Inspired by\ncognitive load theory from human pedagogy, our method only introduces\nskill-based examples when the model performs poorly. We further propose\nAdaptMI+, which adds examples targeted to the specific skills missing from the\nmodel's responses. On 5-shot evaluations across popular math benchmarks and\nfive SLMs (1B--7B; Qwen, Llama), AdaptMI+ improves accuracy by up to 6% over\nnaive skill-based strategies.", "authors": ["Yinghui He", "Abhishek Panigrahi", "Yong Lin", "Sanjeev Arora"], "category": "cs.CL", "updated": "2025-04-30T19:35:46Z"}
{"id": "2505.00191v1", "title": "IP-CRR: Information Pursuit for Interpretable Classification of Chest\n  Radiology Reports", "link": "http://arxiv.org/abs/2505.00191v1", "summary": "The development of AI-based methods for analyzing radiology reports could\nlead to significant advances in medical diagnosis--from improving diagnostic\naccuracy to enhancing efficiency and reducing workload. However, the lack of\ninterpretability in these methods has hindered their adoption in clinical\nsettings. In this paper, we propose an interpretable-by-design framework for\nclassifying radiology reports. The key idea is to extract a set of most\ninformative queries from a large set of reports and use these queries and their\ncorresponding answers to predict a diagnosis. Thus, the explanation for a\nprediction is, by construction, the set of selected queries and answers. We use\nthe Information Pursuit framework to select informative queries, the Flan-T5\nmodel to determine if facts are present in the report, and a classifier to\npredict the disease. Experiments on the MIMIC-CXR dataset demonstrate the\neffectiveness of the proposed method, highlighting its potential to enhance\ntrust and usability in medical AI.", "authors": ["Yuyan Ge", "Kwan Ho Ryan Chan", "Pablo Messina", "René Vidal"], "category": "cs.CL", "updated": "2025-04-30T21:20:05Z"}
{"id": "2504.21318v1", "title": "Phi-4-reasoning Technical Report", "link": "http://arxiv.org/abs/2504.21318v1", "summary": "We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that\nachieves strong performance on complex reasoning tasks. Trained via supervised\nfine-tuning of Phi-4 on carefully curated set of \"teachable\" prompts-selected\nfor the right level of complexity and diversity-and reasoning demonstrations\ngenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chains\nthat effectively leverage inference-time compute. We further develop\nPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer\nreasoning traces. Across a wide range of reasoning tasks, both models\noutperform significantly larger open-weight models such as\nDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full\nDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and\nscientific reasoning, coding, algorithmic problem solving, planning, and\nspatial understanding. Interestingly, we observe a non-trivial transfer of\nimprovements to general-purpose benchmarks as well. In this report, we provide\ninsights into our training data, our training methodologies, and our\nevaluations. We show that the benefit of careful data curation for supervised\nfine-tuning (SFT) extends to reasoning language models, and can be further\namplified by reinforcement learning (RL). Finally, our evaluation points to\nopportunities for improving how we assess the performance and robustness of\nreasoning models.", "authors": ["Marah Abdin", "Sahaj Agarwal", "Ahmed Awadallah", "Vidhisha Balachandran", "Harkirat Behl", "Lingjiao Chen", "Gustavo de Rosa", "Suriya Gunasekar", "Mojan Javaheripi", "Neel Joshi", "Piero Kauffmann", "Yash Lara", "Caio César Teodoro Mendes", "Arindam Mitra", "Besmira Nushi", "Dimitris Papailiopoulos", "Olli Saarikivi", "Shital Shah", "Vaishnavi Shrivastava", "Vibhav Vineet", "Yue Wu", "Safoora Yousefi", "Guoqing Zheng"], "category": "cs.CL", "updated": "2025-04-30T05:05:09Z"}
{"id": "2504.21372v1", "title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction", "link": "http://arxiv.org/abs/2504.21372v1", "summary": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.", "authors": ["Máté Gedeon"], "category": "cs.CL", "updated": "2025-04-30T07:10:10Z"}
{"id": "2504.21474v1", "title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner\n  for Subject Tagging", "link": "http://arxiv.org/abs/2504.21474v1", "summary": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject\nTagging, which focuses on automatically assigning subject labels to technical\nrecords from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage\nOntoAligner, a modular ontology alignment toolkit, to address this task by\nintegrating retrieval-augmented generation (RAG) techniques. Our approach\nformulates the subject tagging problem as an alignment task, where records are\nmatched to GND categories based on semantic similarity. We evaluate\nOntoAligner's adaptability for subject indexing and analyze its effectiveness\nin handling multilingual records. Experimental results demonstrate the\nstrengths and limitations of this method, highlighting the potential of\nalignment techniques for improving subject tagging in digital libraries.", "authors": ["Hadi Bayrami Asl Tekanlou", "Jafar Razmara", "Mahsa Sanaei", "Mostafa Rahgouy", "Hamed Babaei Giglou"], "category": "cs.CL", "updated": "2025-04-30T09:52:51Z"}
{"id": "2504.21578v1", "title": "Glucagon and insulin production in pancreatic cells modeled using Petri\n  nets and Boolean networks", "link": "http://arxiv.org/abs/2504.21578v1", "summary": "Diabetes is a civilization chronic disease characterized by a constant\nelevated concentration of glucose in the blood. Many processes are involved in\nthe glucose regulation, and their interactions are very complex. To better\nunderstand those processes we set ourselves a goal to create a Petri net model\nof the glucose regulation in the whole body. So far we have managed to create a\nmodel of glycolysis and synthesis of glucose in the liver, and the general\noverview models of the glucose regulation in a healthy and diabetic person. In\nthis paper we introduce Petri nets models of insulin secretion in beta cell of\nthe pancreas, and glucagon in the pancreas alpha cells. Those two hormones have\nmutually opposite effects: insulin preventing hyperglycemia, and glucagon\npreventing hypoglycemia. Understanding the mechanisms of insulin and glucagon\nsecretion constitutes the basis for understanding diabetes. We also present a\nmodel in which both processes occur together, depending on the blood glucose\nlevel. The dynamics of each model is analysed. Additionally, we transform the\noverall insulin and glucagon secretion system to a Boolean network, following\nstandard transformation rules.", "authors": ["Kamila Barylska", "Frank Delaplace", "Anna Gogolińska", "Ewa Pańkowska"], "category": "cs.CL", "updated": "2025-04-30T12:36:02Z"}
{"id": "2504.21604v1", "title": "Robust Misinformation Detection by Visiting Potential Commonsense\n  Conflict", "link": "http://arxiv.org/abs/2504.21604v1", "summary": "The development of Internet technology has led to an increased prevalence of\nmisinformation, causing severe negative effects across diverse domains. To\nmitigate this challenge, Misinformation Detection (MD), aiming to detect online\nmisinformation automatically, emerges as a rapidly growing research topic in\nthe community. In this paper, we propose a novel plug-and-play augmentation\nmethod for the MD task, namely Misinformation Detection with Potential\nCommonsense Conflict (MD-PCC). We take inspiration from the prior studies\nindicating that fake articles are more likely to involve commonsense conflict.\nAccordingly, we construct commonsense expressions for articles, serving to\nexpress potential commonsense conflicts inferred by the difference between\nextracted commonsense triplet and golden ones inferred by the well-established\ncommonsense reasoning tool COMET. These expressions are then specified for each\narticle as augmentation. Any specific MD methods can be then trained on those\ncommonsense-augmented articles. Besides, we also collect a novel\ncommonsense-oriented dataset named CoMis, whose all fake articles are caused by\ncommonsense conflict. We integrate MD-PCC with various existing MD backbones\nand compare them across both 4 public benchmark datasets and CoMis. Empirical\nresults demonstrate that MD-PCC can consistently outperform the existing MD\nbaselines.", "authors": ["Bing Wang", "Ximing Li", "Changchun Li", "Bingrui Zhao", "Bo Fu", "Renchu Guan", "Shengsheng Wang"], "category": "cs.CL", "updated": "2025-04-30T13:03:17Z"}
{"id": "2504.21635v1", "title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model", "link": "http://arxiv.org/abs/2504.21635v1", "summary": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools.", "authors": ["Zeina Aldallal", "Sara Chrouf", "Khalil Hennara", "Mohamed Motaism Hamed", "Muhammad Hreden", "Safwan AlModhayan"], "category": "cs.CL", "updated": "2025-04-30T13:37:24Z"}
{"id": "2504.21659v1", "title": "AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning\n  Optimization", "link": "http://arxiv.org/abs/2504.21659v1", "summary": "Recently, long-thought reasoning models achieve strong performance on complex\nreasoning tasks, but often incur substantial inference overhead, making\nefficiency a critical concern. Our empirical analysis reveals that the benefit\nof using Long-CoT varies across problems: while some problems require elaborate\nreasoning, others show no improvement, or even degraded accuracy. This\nmotivates adaptive reasoning strategies that tailor reasoning depth to the\ninput. However, prior work primarily reduces redundancy within long reasoning\npaths, limiting exploration of more efficient strategies beyond the Long-CoT\nparadigm. To address this, we propose a novel two-stage framework for adaptive\nand efficient reasoning. First, we construct a hybrid reasoning model by\nmerging long and short CoT models to enable diverse reasoning styles. Second,\nwe apply bi-level preference training to guide the model to select suitable\nreasoning styles (group-level), and prefer concise and correct reasoning within\neach style group (instance-level). Experiments demonstrate that our method\nsignificantly reduces inference costs compared to other baseline approaches,\nwhile maintaining performance. Notably, on five mathematical datasets, the\naverage length of reasoning is reduced by more than 50%, highlighting the\npotential of adaptive strategies to optimize reasoning efficiency in large\nlanguage models. Our code is coming soon at https://github.com/StarDewXXX/AdaR1", "authors": ["Haotian Luo", "Haiying He", "Yibo Wang", "Jinluan Yang", "Rui Liu", "Naiqiang Tan", "Xiaochun Cao", "Dacheng Tao", "Li Shen"], "category": "cs.CL", "updated": "2025-04-30T14:01:45Z"}
{"id": "2504.21685v1", "title": "Enhancing Health Mention Classification Performance: A Study on\n  Advancements in Parameter Efficient Tuning", "link": "http://arxiv.org/abs/2504.21685v1", "summary": "Health Mention Classification (HMC) plays a critical role in leveraging\nsocial media posts for real-time tracking and public health monitoring.\nNevertheless, the process of HMC presents significant challenges due to its\nintricate nature, primarily stemming from the contextual aspects of health\nmentions, such as figurative language and descriptive terminology, rather than\nexplicitly reflecting a personal ailment. To address this problem, we argue\nthat clearer mentions can be achieved through conventional fine-tuning with\nenhanced parameters of biomedical natural language methods (NLP). In this\nstudy, we explore different techniques such as the utilisation of\npart-of-speech (POS) tagger information, improving on PEFT techniques, and\ndifferent combinations thereof. Extensive experiments are conducted on three\nwidely used datasets: RHDM, PHM, and Illness. The results incorporated POS\ntagger information, and leveraging PEFT techniques significantly improves\nperformance in terms of F1-score compared to state-of-the-art methods across\nall three datasets by utilising smaller models and efficient training.\nFurthermore, the findings highlight the effectiveness of incorporating POS\ntagger information and leveraging PEFT techniques for HMC. In conclusion, the\nproposed methodology presents a potentially effective approach to accurately\nclassifying health mentions in social media posts while optimising the model\nsize and training efficiency.", "authors": ["Reem Abdel-Salam", "Mary Adewunmi"], "category": "cs.CL", "updated": "2025-04-30T14:21:54Z"}
{"id": "2504.21751v1", "title": "CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code\n  Generation", "link": "http://arxiv.org/abs/2504.21751v1", "summary": "Real world development demands code that is readable, extensible, and\ntestable by organizing the implementation into modular components and\niteratively reuse pre-implemented code. We term this iterative, multi-turn\nprocess codeflow and introduce CodeFlowBench, the first benchmark designed for\ncomprehensively evaluating LLMs' ability to perform codeflow, namely to\nimplement new functionality by reusing existing functions over multiple turns.\nCodeFlowBench comprises 5258 problems drawn from Codeforces and is continuously\nupdated via an automated pipeline that decomposes each problem into a series of\nfunction-level subproblems based on its dependency tree and each subproblem is\npaired with unit tests. We further propose a novel evaluation framework with\ntasks and metrics tailored to multi-turn code reuse to assess model\nperformance. In experiments across various LLMs under both multi-turn and\nsingle-turn patterns. We observe models' poor performance on CodeFlowBench,\nwith a substantial performance drop in the iterative codeflow scenario. For\ninstance, o1-mini achieves a pass@1 of 20.8% in multi-turn pattern versus 37.8%\nin single-turn pattern. Further analysis shows that different models excel at\ndifferent dependency depths, yet all struggle to correctly solve structurally\ncomplex problems, highlighting challenges for current LLMs to serve as code\ngeneration tools when performing codeflow. Overall, CodeFlowBench offers a\ncomprehensive benchmark and new insights into LLM capabilities for multi-turn,\niterative code generation, guiding future advances in code generation tasks.", "authors": ["Sizhe Wang", "Zhengren Wang", "Dongsheng Ma", "Yongan Yu", "Rui Ling", "Zhiyu Li", "Feiyu Xiong", "Wentao Zhang"], "category": "cs.CL", "updated": "2025-04-30T15:45:28Z"}
{"id": "2504.21773v1", "title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced\n  Knowledge Boundary Awareness", "link": "http://arxiv.org/abs/2504.21773v1", "summary": "With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.", "authors": ["Junsheng Huang", "Zhitao He", "Sandeep Polisetty", "Qingyun Wang", "May Fung"], "category": "cs.CL", "updated": "2025-04-30T16:17:53Z"}
{"id": "2504.21801v1", "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via\n  Reinforcement Learning for Subgoal Decomposition", "link": "http://arxiv.org/abs/2504.21801v1", "summary": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.", "authors": ["Z. Z. Ren", "Zhihong Shao", "Junxiao Song", "Huajian Xin", "Haocheng Wang", "Wanjia Zhao", "Liyue Zhang", "Zhe Fu", "Qihao Zhu", "Dejian Yang", "Z. F. Wu", "Zhibin Gou", "Shirong Ma", "Hongxuan Tang", "Yuxuan Liu", "Wenjun Gao", "Daya Guo", "Chong Ruan"], "category": "cs.CL", "updated": "2025-04-30T16:57:48Z"}
{"id": "2504.21851v1", "title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and\n  Structured Assessments", "link": "http://arxiv.org/abs/2504.21851v1", "summary": "Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.", "authors": ["Sichang Tu", "Abigail Powers", "Stephen Doogan", "Jinho D. Choi"], "category": "cs.CL", "updated": "2025-04-30T17:58:06Z"}
{"id": "2505.00050v1", "title": "Emotional Analysis of Fashion Trends Using Social Media and AI:\n  Sentiment Analysis on Twitter for Fashion Trend Forecasting", "link": "http://arxiv.org/abs/2505.00050v1", "summary": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories.", "authors": ["Aayam Bansal", "Agneya Tharun"], "category": "cs.CL", "updated": "2025-04-30T07:27:06Z"}
{"id": "2505.00061v1", "title": "Enhancing Security and Strengthening Defenses in Automated Short-Answer\n  Grading Systems", "link": "http://arxiv.org/abs/2505.00061v1", "summary": "This study examines vulnerabilities in transformer-based automated\nshort-answer grading systems used in medical education, with a focus on how\nthese systems can be manipulated through adversarial gaming strategies. Our\nresearch identifies three main types of gaming strategies that exploit the\nsystem's weaknesses, potentially leading to false positives. To counteract\nthese vulnerabilities, we implement several adversarial training methods\ndesigned to enhance the systems' robustness. Our results indicate that these\nmethods significantly reduce the susceptibility of grading systems to such\nmanipulations, especially when combined with ensemble techniques like majority\nvoting and ridge regression, which further improve the system's defense against\nsophisticated adversarial inputs. Additionally, employing large language models\nsuch as GPT-4 with varied prompting techniques has shown promise in recognizing\nand scoring gaming strategies effectively. The findings underscore the\nimportance of continuous improvements in AI-driven educational tools to ensure\ntheir reliability and fairness in high-stakes settings.", "authors": ["Sahar Yarmohammadtoosky", "Yiyun Zhou", "Victoria Yaneva", "Peter Baldwin", "Saed Rezayi", "Brian Clauser", "Polina Harikeo"], "category": "cs.CL", "updated": "2025-04-30T14:53:09Z"}
{"id": "2505.00063v1", "title": "GDI-Bench: A Benchmark for General Document Intelligence with Vision and\n  Reasoning Decoupling", "link": "http://arxiv.org/abs/2505.00063v1", "summary": "The rapid advancement of multimodal large language models (MLLMs) has\nprofoundly impacted the document domain, creating a wide array of application\nscenarios. This progress highlights the need for a comprehensive benchmark to\nevaluate these models' capabilities across various document-specific tasks.\nHowever, existing benchmarks often fail to locate specific model weaknesses or\nguide systematic improvements. To bridge this gap, we introduce a General\nDocument Intelligence Benchmark (GDI-Bench), featuring 1.9k images across 9 key\nscenarios and 19 document-specific tasks. By decoupling visual complexity and\nreasoning complexity, the GDI-Bench structures graded tasks that allow\nperformance assessment by difficulty, aiding in model weakness identification\nand optimization guidance. We evaluate the GDI-Bench on various open-source and\nclosed-source models, conducting decoupled analyses in the visual and reasoning\ndomains. For instance, the GPT-4o model excels in reasoning tasks but exhibits\nlimitations in visual capabilities. To address the diverse tasks and domains in\nthe GDI-Bench, we propose a GDI Model that mitigates the issue of catastrophic\nforgetting during the supervised fine-tuning (SFT) process through a\nintelligence-preserving training strategy. Our model achieves state-of-the-art\nperformance on previous benchmarks and the GDI-Bench. Both our benchmark and\nmodel will be open source.", "authors": ["Siqi Li", "Yufan Shen", "Xiangnan Chen", "Jiayi Chen", "Hengwei Ju", "Haodong Duan", "Song Mao", "Hongbin Zhou", "Bo Zhang", "Pinlong Cai", "Licheng Wen", "Botian Shi", "Yong Liu", "Xinyu Cai", "Yu Qiao"], "category": "cs.CL", "updated": "2025-04-30T15:46:46Z"}
{"id": "2505.00065v1", "title": "ConSens: Assessing context grounding in open-book question answering", "link": "http://arxiv.org/abs/2505.00065v1", "summary": "Large Language Models (LLMs) have demonstrated considerable success in\nopen-book question answering (QA), where the task requires generating answers\ngrounded in a provided external context. A critical challenge in open-book QA\nis to ensure that model responses are based on the provided context rather than\nits parametric knowledge, which can be outdated, incomplete, or incorrect.\nExisting evaluation methods, primarily based on the LLM-as-a-judge approach,\nface significant limitations, including biases, scalability issues, and\ndependence on costly external systems. To address these challenges, we propose\na novel metric that contrasts the perplexity of the model response under two\nconditions: when the context is provided and when it is not. The resulting\nscore quantifies the extent to which the model's answer relies on the provided\ncontext. The validity of this metric is demonstrated through a series of\nexperiments that show its effectiveness in identifying whether a given answer\nis grounded in the provided context. Unlike existing approaches, this metric is\ncomputationally efficient, interpretable, and adaptable to various use cases,\noffering a scalable and practical solution to assess context utilization in\nopen-book QA systems.", "authors": ["Ivan Vankov", "Matyo Ivanov", "Adriana Correia", "Victor Botev"], "category": "cs.CL", "updated": "2025-04-30T16:23:15Z"}
{"id": "2505.00114v1", "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of\n  Lebanese", "link": "http://arxiv.org/abs/2505.00114v1", "summary": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github.", "authors": ["Silvana Yakhni", "Ali Chehab"], "category": "cs.CL", "updated": "2025-04-30T18:33:53Z"}
{"id": "2505.00127v1", "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning\n  Length and correctness in LLMs", "link": "http://arxiv.org/abs/2505.00127v1", "summary": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation.", "authors": ["Jinyan Su", "Jennifer Healey", "Preslav Nakov", "Claire Cardie"], "category": "cs.CL", "updated": "2025-04-30T18:48:06Z"}
{"id": "2505.00212v1", "title": "Which Agent Causes Task Failures and When? On Automated Failure\n  Attribution of LLM Multi-Agent Systems", "link": "http://arxiv.org/abs/2505.00212v1", "summary": "Failure attribution in LLM multi-agent systems-identifying the agent and step\nresponsible for task failures-provides crucial clues for systems debugging but\nremains underexplored and labor-intensive. In this paper, we propose and\nformulate a new research area: automated failure attribution for LLM\nmulti-agent systems. To support this initiative, we introduce the Who&When\ndataset, comprising extensive failure logs from 127 LLM multi-agent systems\nwith fine-grained annotations linking failures to specific agents and decisive\nerror steps. Using the Who&When, we develop and evaluate three automated\nfailure attribution methods, summarizing their corresponding pros and cons. The\nbest method achieves 53.5% accuracy in identifying failure-responsible agents\nbut only 14.2% in pinpointing failure steps, with some methods performing below\nrandom. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to\nachieve practical usability. These results highlight the task's complexity and\nthe need for further research in this area. Code and dataset are available at\nhttps://github.com/mingyin1/Agents_Failure_Attribution", "authors": ["Shaokun Zhang", "Ming Yin", "Jieyu Zhang", "Jiale Liu", "Zhiguang Han", "Jingyang Zhang", "Beibin Li", "Chi Wang", "Huazheng Wang", "Yiran Chen", "Qingyun Wu"], "category": "cs.CL", "updated": "2025-04-30T23:09:44Z"}
{"id": "2505.00234v2", "title": "Self-Generated In-Context Examples Improve LLM Agents for Sequential\n  Decision-Making Tasks", "link": "http://arxiv.org/abs/2505.00234v2", "summary": "Many methods for improving Large Language Model (LLM) agents for sequential\ndecision-making tasks depend on task-specific knowledge engineering--such as\nprompt tuning, curated in-context examples, or customized observation and\naction spaces. Using these approaches, agent performance improves with the\nquality or amount of knowledge engineering invested. Instead, we investigate\nhow LLM agents can automatically improve their performance by learning\nin-context from their own successful experiences on similar tasks. Rather than\nrelying on task-specific knowledge engineering, we focus on constructing and\nrefining a database of self-generated examples. We demonstrate that even a\nnaive accumulation of successful trajectories across training tasks boosts test\nperformance on three benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%),\nand InterCode-SQL (75% to 79%)--matching the performance the initial agent\nachieves if allowed two to three attempts per task. We then introduce two\nextensions: (1) database-level selection through population-based training to\nidentify high-performing example collections, and (2) exemplar-level selection\nthat retains individual trajectories based on their empirical utility as\nin-context examples. These extensions further enhance performance, achieving\n91% on ALFWorld--matching more complex approaches that employ task-specific\ncomponents and prompts. Our results demonstrate that automatic trajectory\ndatabase construction offers a compelling alternative to labor-intensive\nknowledge engineering.", "authors": ["Vishnu Sarukkai", "Zhiqiang Xie", "Kayvon Fatahalian"], "category": "cs.CL", "updated": "2025-05-02T16:44:02Z"}
{"id": "2505.03786v1", "title": "When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as\n  Discriminator", "link": "http://arxiv.org/abs/2505.03786v1", "summary": "Large Language Models (LLM) with reasoning capabilities offer a promising\npath for improving candidate evaluation in planning frameworks, but their\nrelative performance against traditional non-reasoning models remains largely\nunderexplored. In this study, we benchmark a distilled 1.5B parameter reasoning\nmodel (DeepSeek-R1) against several state-of-the-art non-reasoning LLMs within\na generator-discriminator LLM planning framework for the text-to-SQL task. For\nthis, we introduce a novel method for extracting soft scores from the\nchain-of-thought (CoT) outputs from reasoning that enables fine-grained ranking\nof candidates. Our central hypothesis is that reasoning models are more\neffective discriminators than non-reasoning LLMs. Our results show that\ndistilled DeepSeek-R1-1.5B achieves up to $87\\%$ higher F1 and $3.7\\%$ better\ndiscrimination accuracy than CodeLlama-7B, as well as $3.7\\%$ higher execution\naccuracy than CodeLlama-13B, despite having significantly fewer parameters.\nFurthermore, we find that there is a limit to the logical capabilities of\nreasoning models, and only providing more context or allowing more compute\nbudget for reasoning is not enough to improve their discrimination performance.\nFinally, we demonstrate that, unlike non-reasoning LLMs, reasoning models find\ngeneration more challenging than discrimination and may underperform as\ngenerators compared to smaller non-reasoning LLMs. Our work highlights the\npotential of reasoning models as discriminators in agentic frameworks, far\noutweighing their capabilities as generators, offering insights into their\noptimal role within LLM planning infrastructures.", "authors": ["Md Fahim Anjum"], "category": "cs.CL", "updated": "2025-04-30T17:27:13Z"}
{"id": "2504.21400v1", "title": "Who Gets the Callback? Generative AI and Gender Bias", "link": "http://arxiv.org/abs/2504.21400v1", "summary": "Generative artificial intelligence (AI), particularly large language models\n(LLMs), is being rapidly deployed in recruitment and for candidate\nshortlisting. We audit several mid-sized open-source LLMs for gender bias using\na dataset of 332,044 real-world online job postings. For each posting, we\nprompt the model to recommend whether an equally qualified male or female\ncandidate should receive an interview callback. We find that most models tend\nto favor men, especially for higher-wage roles. Mapping job descriptions to the\nStandard Occupational Classification system, we find lower callback rates for\nwomen in male-dominated occupations and higher rates in female-associated ones,\nindicating occupational segregation. A comprehensive analysis of linguistic\nfeatures in job ads reveals strong alignment of model recommendations with\ntraditional gender stereotypes. To examine the role of recruiter identity, we\nsteer model behavior by infusing Big Five personality traits and simulating the\nperspectives of historical figures. We find that less agreeable personas reduce\nstereotyping, consistent with an agreeableness bias in LLMs. Our findings\nhighlight how AI-driven hiring may perpetuate biases in the labor market and\nhave implications for fairness and diversity within firms.", "authors": ["Sugat Chaturvedi", "Rochana Chaturvedi"], "category": "cs.CL", "updated": "2025-04-30T07:55:52Z"}
{"id": "2504.21435v2", "title": "SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding", "link": "http://arxiv.org/abs/2504.21435v2", "summary": "With the rapid development of Multi-modal Large Language Models (MLLMs), an\nincreasing number of benchmarks have been established to evaluate the video\nunderstanding capabilities of these models. However, these benchmarks focus on\nstandalone videos and mainly assess \"visual elements\" like human actions and\nobject states. In reality, contemporary videos often encompass complex and\ncontinuous narratives, typically presented as a series. To address this\nchallenge, we propose SeriesBench, a benchmark consisting of 105 carefully\ncurated narrative-driven series, covering 28 specialized tasks that require\ndeep narrative understanding. Specifically, we first select a diverse set of\ndrama series spanning various genres. Then, we introduce a novel long-span\nnarrative annotation method, combined with a full-information transformation\napproach to convert manual annotations into diverse task formats. To further\nenhance model capacity for detailed analysis of plot structures and character\nrelationships within series, we propose a novel narrative reasoning framework,\nPC-DCoT. Extensive results on SeriesBench indicate that existing MLLMs still\nface significant challenges in understanding narrative-driven series, while\nPC-DCoT enables these MLLMs to achieve performance improvements. Overall, our\nSeriesBench and PC-DCoT highlight the critical necessity of advancing model\ncapabilities to understand narrative-driven series, guiding the future\ndevelopment of MLLMs. SeriesBench is publicly available at\nhttps://github.com/zackhxn/SeriesBench-CVPR2025.", "authors": ["Chenkai Zhang", "Yiming Lei", "Zeming Liu", "Haitao Leng", "Shaoguo Liu", "Tingting Gao", "Qingjie Liu", "Yunhong Wang"], "category": "cs.CL", "updated": "2025-05-08T09:08:01Z"}
{"id": "2504.21475v1", "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based\n  Approach with Dataset Construction Guidelines", "link": "http://arxiv.org/abs/2504.21475v1", "summary": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.", "authors": ["Serry Sibaee", "Samar Ahmed", "Abdullah Al Harbi", "Omer Nacar", "Adel Ammar", "Yasser Habashi", "Wadii Boulila"], "category": "cs.CL", "updated": "2025-04-30T09:56:36Z"}
{"id": "2504.21559v1", "title": "Black-Box Visual Prompt Engineering for Mitigating Object Hallucination\n  in Large Vision Language Models", "link": "http://arxiv.org/abs/2504.21559v1", "summary": "Large Vision Language Models (LVLMs) often suffer from object hallucination,\nwhich undermines their reliability. Surprisingly, we find that simple\nobject-based visual prompting -- overlaying visual cues (e.g., bounding box,\ncircle) on images -- can significantly mitigate such hallucination; however,\ndifferent visual prompts (VPs) vary in effectiveness. To address this, we\npropose Black-Box Visual Prompt Engineering (BBVPE), a framework to identify\noptimal VPs that enhance LVLM responses without needing access to model\ninternals. Our approach employs a pool of candidate VPs and trains a router\nmodel to dynamically select the most effective VP for a given input image. This\nblack-box approach is model-agnostic, making it applicable to both open-source\nand proprietary LVLMs. Evaluations on benchmarks such as POPE and CHAIR\ndemonstrate that BBVPE effectively reduces object hallucination.", "authors": ["Sangmin Woo", "Kang Zhou", "Yun Zhou", "Shuai Wang", "Sheng Guan", "Haibo Ding", "Lin Lee Cheong"], "category": "cs.CL", "updated": "2025-04-30T11:58:30Z"}
{"id": "2504.21589v1", "title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for\n  Automated Subject Indexing", "link": "http://arxiv.org/abs/2504.21589v1", "summary": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.", "authors": ["Lisa Kluge", "Maximilian Kähler"], "category": "cs.CL", "updated": "2025-04-30T12:47:09Z"}
{"id": "2504.21605v1", "title": "RDF-Based Structured Quality Assessment Representation of Multilingual\n  LLM Evaluations", "link": "http://arxiv.org/abs/2504.21605v1", "summary": "Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\nsystematically assessing their reliability with conflicting information remains\ndifficult. We propose an RDF-based framework to assess multilingual LLM\nquality, focusing on knowledge conflicts. Our approach captures model responses\nacross four distinct context conditions (complete, incomplete, conflicting, and\nno-context information) in German and English. This structured representation\nenables the comprehensive analysis of knowledge leakage-where models favor\ntraining data over provided context-error detection, and multilingual\nconsistency. We demonstrate the framework through a fire safety domain\nexperiment, revealing critical patterns in context prioritization and\nlanguage-specific performance, and demonstrating that our vocabulary was\nsufficient to express every assessment facet encountered in the 28-question\nstudy.", "authors": ["Jonas Gwozdz", "Andreas Both"], "category": "cs.CL", "updated": "2025-04-30T13:06:40Z"}
{"id": "2504.21716v1", "title": "LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in\n  Household Robotics", "link": "http://arxiv.org/abs/2504.21716v1", "summary": "We present an embodied robotic system with an LLM-driven agent-orchestration\narchitecture for autonomous household object management. The system integrates\nmemory-augmented task planning, enabling robots to execute high-level user\ncommands while tracking past actions. It employs three specialized agents: a\nrouting agent, a task planning agent, and a knowledge base agent, each powered\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\nneed for explicit model training. RAG enables the system to retrieve context\nfrom past interactions, enhancing long-term object tracking. A combination of\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\nsemantic scene understanding for task planning. Evaluation across three\nhousehold scenarios demonstrates high task planning accuracy and an improvement\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\navailable at: https://github.com/marc1198/chat-hsr.", "authors": ["Marc Glocker", "Peter Hönig", "Matthias Hirschmanner", "Markus Vincze"], "category": "cs.CL", "updated": "2025-04-30T15:00:20Z"}
{"id": "2504.21776v1", "title": "WebThinker: Empowering Large Reasoning Models with Deep Research\n  Capability", "link": "http://arxiv.org/abs/2504.21776v1", "summary": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.", "authors": ["Xiaoxi Li", "Jiajie Jin", "Guanting Dong", "Hongjin Qian", "Yutao Zhu", "Yongkang Wu", "Ji-Rong Wen", "Zhicheng Dou"], "category": "cs.CL", "updated": "2025-04-30T16:25:25Z"}
{"id": "2504.21798v1", "title": "SWE-smith: Scaling Data for Software Engineering Agents", "link": "http://arxiv.org/abs/2504.21798v1", "summary": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.", "authors": ["John Yang", "Kilian Leret", "Carlos E. Jimenez", "Alexander Wettig", "Kabir Khandpur", "Yanzhe Zhang", "Binyuan Hui", "Ofir Press", "Ludwig Schmidt", "Diyi Yang"], "category": "cs.CL", "updated": "2025-04-30T16:56:06Z"}
{"id": "2504.21800v2", "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in\n  Prolonged Exposure Dialogues", "link": "http://arxiv.org/abs/2504.21800v2", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "category": "cs.CL", "updated": "2025-05-01T16:44:18Z"}
{"id": "2505.00049v1", "title": "Humanizing LLMs: A Survey of Psychological Measurements with Tools,\n  Datasets, and Human-Agent Applications", "link": "http://arxiv.org/abs/2505.00049v1", "summary": "As large language models (LLMs) are increasingly used in human-centered\ntasks, assessing their psychological traits is crucial for understanding their\nsocial impact and ensuring trustworthy AI alignment. While existing reviews\nhave covered some aspects of related research, several important areas have not\nbeen systematically discussed, including detailed discussions of diverse\npsychological tests, LLM-specific psychological datasets, and the applications\nof LLMs with psychological traits. To address this gap, we systematically\nreview six key dimensions of applying psychological theories to LLMs: (1)\nassessment tools; (2) LLM-specific datasets; (3) evaluation metrics\n(consistency and stability); (4) empirical findings; (5) personality simulation\nmethods; and (6) LLM-based behavior simulation. Our analysis highlights both\nthe strengths and limitations of current methods. While some LLMs exhibit\nreproducible personality patterns under specific prompting schemes, significant\nvariability remains across tasks and settings. Recognizing methodological\nchallenges such as mismatches between psychological tools and LLMs'\ncapabilities, as well as inconsistencies in evaluation practices, this study\naims to propose future directions for developing more interpretable, robust,\nand generalizable psychological assessment frameworks for LLMs.", "authors": ["Wenhan Dong", "Yuemeng Zhao", "Zhen Sun", "Yule Liu", "Zifan Peng", "Jingyi Zheng", "Zongmin Zhang", "Ziyi Zhang", "Jun Wu", "Ruiming Wang", "Shengmin Xu", "Xinyi Huang", "Xinlei He"], "category": "cs.CL", "updated": "2025-04-30T06:09:40Z"}
{"id": "2505.00056v2", "title": "Clustering Internet Memes Through Template Matching and\n  Multi-Dimensional Similarity", "link": "http://arxiv.org/abs/2505.00056v2", "summary": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch.", "authors": ["Tygo Bloem", "Filip Ilievski"], "category": "cs.CL", "updated": "2025-05-02T07:34:59Z"}
{"id": "2505.00059v1", "title": "BERSting at the Screams: A Benchmark for Distanced, Emotional and\n  Shouted Speech Recognition", "link": "http://arxiv.org/abs/2505.00059v1", "summary": "Some speech recognition tasks, such as automatic speech recognition (ASR),\nare approaching or have reached human performance in many reported metrics.\nYet, they continue to struggle in complex, real-world, situations, such as with\ndistanced speech. Previous challenges have released datasets to address the\nissue of distanced ASR, however, the focus remains primarily on distance,\nspecifically relying on multi-microphone array systems. Here we present the\nB(asic) E(motion) R(andom phrase) S(hou)t(s) (BERSt) dataset. The dataset\ncontains almost 4 hours of English speech from 98 actors with varying regional\nand non-native accents. The data was collected on smartphones in the actors\nhomes and therefore includes at least 98 different acoustic environments. The\ndata also includes 7 different emotion prompts and both shouted and spoken\nutterances. The smartphones were places in 19 different positions, including\nobstructions and being in a different room than the actor. This data is\npublicly available for use and can be used to evaluate a variety of speech\nrecognition tasks, including: ASR, shout detection, and speech emotion\nrecognition (SER). We provide initial benchmarks for ASR and SER tasks, and\nfind that ASR degrades both with an increase in distance and shout level and\nshows varied performance depending on the intended emotion. Our results show\nthat the BERSt dataset is challenging for both ASR and SER tasks and continued\nwork is needed to improve the robustness of such systems for more accurate\nreal-world use.", "authors": ["Paige Tuttösí", "Mantaj Dhillon", "Luna Sang", "Shane Eastwood", "Poorvi Bhatia", "Quang Minh Dinh", "Avni Kapoor", "Yewon Jin", "Angelica Lim"], "category": "cs.CL", "updated": "2025-04-30T14:08:14Z"}
{"id": "2505.00060v1", "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business\n  Intelligence Using Exaone 3.5", "link": "http://arxiv.org/abs/2505.00060v1", "summary": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.", "authors": ["Jeho Choi"], "category": "cs.CL", "updated": "2025-04-30T14:42:18Z"}
{"id": "2505.00105v1", "title": "Optimization of embeddings storage for RAG systems using quantization\n  and dimensionality reduction techniques", "link": "http://arxiv.org/abs/2505.00105v1", "summary": "Retrieval-Augmented Generation enhances language models by retrieving\nrelevant information from external knowledge bases, relying on high-dimensional\nvector embeddings typically stored in float32 precision. However, storing these\nembeddings at scale presents significant memory challenges. To address this\nissue, we systematically investigate on MTEB benchmark two complementary\noptimization strategies: quantization, evaluating standard formats (float16,\nint8, binary) and low-bit floating-point types (float8), and dimensionality\nreduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and\nAutoencoders. Our results show that float8 quantization achieves a 4x storage\nreduction with minimal performance degradation (<0.3%), significantly\noutperforming int8 quantization at the same compression level, being simpler to\nimplement. PCA emerges as the most effective dimensionality reduction\ntechnique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions)\nwith float8 quantization offers an excellent trade-off, achieving 8x total\ncompression with less performance impact than using int8 alone (which provides\nonly 4x compression). To facilitate practical application, we propose a\nmethodology based on visualizing the performance-storage trade-off space to\nidentify the optimal configuration that maximizes performance within their\nspecific memory constraints.", "authors": ["Naamán Huerga-Pérez", "Rubén Álvarez", "Rubén Ferrero-Guillén", "Alberto Martínez-Gutiérrez", "Javier Díez-González"], "category": "cs.CL", "updated": "2025-04-30T18:20:16Z"}
{"id": "2505.00150v1", "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with\n  Vision-Language Models", "link": "http://arxiv.org/abs/2505.00150v1", "summary": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments.", "authors": ["Minh-Hao Van", "Xintao Wu"], "category": "cs.CL", "updated": "2025-04-30T19:48:12Z"}
{"id": "2505.03788v1", "title": "Calibrating Uncertainty Quantification of Multi-Modal LLMs using\n  Grounding", "link": "http://arxiv.org/abs/2505.03788v1", "summary": "We introduce a novel approach for calibrating uncertainty quantification (UQ)\ntailored for multi-modal large language models (LLMs). Existing\nstate-of-the-art UQ methods rely on consistency among multiple responses\ngenerated by the LLM on an input query under diverse settings. However, these\napproaches often report higher confidence in scenarios where the LLM is\nconsistently incorrect. This leads to a poorly calibrated confidence with\nrespect to accuracy. To address this, we leverage cross-modal consistency in\naddition to self-consistency to improve the calibration of the multi-modal\nmodels. Specifically, we ground the textual responses to the visual inputs. The\nconfidence from the grounding model is used to calibrate the overall\nconfidence. Given that using a grounding model adds its own uncertainty in the\npipeline, we apply temperature scaling - a widely accepted parametric\ncalibration technique - to calibrate the grounding model's confidence in the\naccuracy of generated responses. We evaluate the proposed approach across\nmultiple multi-modal tasks, such as medical question answering (Slake) and\nvisual question answering (VQAv2), considering multi-modal models such as\nLLaVA-Med and LLaVA. The experiments demonstrate that the proposed framework\nachieves significantly improved calibration on both tasks.", "authors": ["Trilok Padhi", "Ramneet Kaur", "Adam D. Cobb", "Manoj Acharya", "Anirban Roy", "Colin Samplawski", "Brian Matejek", "Alexander M. Berenbeim", "Nathaniel D. Bastian", "Susmit Jha"], "category": "cs.CL", "updated": "2025-04-30T19:19:21Z"}
